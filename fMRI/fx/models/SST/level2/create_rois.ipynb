{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-3.local\n",
      "Benjamins-MacBook-Pro-3.local\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import nibabel as nib\n",
    "import nilearn as nil\n",
    "from nilearn import plotting\n",
    "\n",
    "from socket import gethostname\n",
    "from yaml.loader import SafeLoader\n",
    "import yaml\n",
    "\n",
    "from level2_utils import read_yaml_for_host\n",
    "\n",
    "\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "config = read_yaml_for_host('l2_config.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['sst_wave1_path', 'sst_allwaves_path', 'spm_l2_script_template_filepath', 'spm_l2_script_w_confounders_template_filepath', 'confounder_template_path', 'nonbids_data_path', 'dev_scripts_path', 'sst_level_2_path', 'dropbox_datapath', 'spm_path', 'automotion_output_path', 'template_mlr_main', 'template_mlr_confounder_no_centering', 'template_mlr_consess', 'template_mlr_conspec', 'mask_location'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functional_mask_filepath=neurosynth_response_inhibition_filepath\n",
    "# base_anatomical_img_set=superior_frontal_gyrus_filepath\n",
    "# hemisphere_filepath = right_hemisphere\n",
    "# functional_thresh = 5\n",
    "# out_filename = mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition_right_sup_fron_gyrus.nii.gz'\n",
    "\n",
    "# multiply the two h-o masks by the hemisphere mask to get the right hemisphere\n",
    "def combine_neurosynth_anatomical(functional_mask_filepath, base_anatomical_img_filepath, hemisphere_filepath = None, functional_thresh = None, out_filename = None):\n",
    "    base_anatomical_img = nil.image.load_img(base_anatomical_img_filepath)\n",
    "    \n",
    "    # binarize the h-o masks\n",
    "    anatomical_mask_bin_25 = nil.image.binarize_img(base_anatomical_img,25)\n",
    "    anatomical_mask_bin_25.to_filename(base_anatomical_img_filepath.replace('.nii.gz', '_bin_25.nii.gz'))\n",
    "    \n",
    "    if hemisphere_filepath is not None:\n",
    "        hemisphere_img = nil.image.load_img(hemisphere_filepath)\n",
    "        # binarize the hemisphere mask\n",
    "        hemisphere_mask_bin_25 = nil.image.binarize_img(hemisphere_img,25)\n",
    "        hemispheric_anatomical_mask = nil.image.math_img(\"img1 * img2\", img1=anatomical_mask_bin_25, img2=hemisphere_mask_bin_25)\n",
    "        hemispheric_anatomical_mask.to_filename(base_anatomical_img_filepath.replace('.nii.gz', '_hemi_bin_25.nii.gz'))\n",
    "    else:\n",
    "        hemispheric_anatomical_mask = anatomical_mask_bin_25\n",
    "    #transform neurosynth mask\n",
    "    functional_mask = nil.image.load_img(functional_mask_filepath)\n",
    "    #apply 6mm smoothing kernel\n",
    "    functional_mask_sm = nil.image.smooth_img(functional_mask, fwhm=6)\n",
    "\n",
    "    functional_mask_trans = nil.image.resample_to_img(functional_mask_sm, base_anatomical_img)\n",
    "    # binarize the neurosynth mask\n",
    "    functional_mask_bin = nil.image.binarize_img(functional_mask_trans,functional_thresh)\n",
    "\n",
    "    # multiply the neurosynth mask by each of the h-o masks\n",
    "    combined_mask = nil.image.math_img(\"img1 * img2\", img1=functional_mask_bin, img2=hemispheric_anatomical_mask)\n",
    "    \n",
    "    # save each output\n",
    "    combined_mask.to_filename(out_filename)\n",
    "    combined_mask.to_filename(out_filename + '.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sst_wave1_path': '/Users/benjaminsmith/Google Drive/oregon/data/DEV/nonbids_data/fMRI/fx/models/SST/wave1/',\n",
       " 'sst_allwaves_path': '/Users/benjaminsmith/Google Drive/oregon/data/DEV/nonbids_data/fMRI/fx/models/SST/all_waves/',\n",
       " 'spm_l2_script_template_filepath': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/models/SST/level2/template_one_sample_design_estimate.m',\n",
       " 'spm_l2_script_w_confounders_template_filepath': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/models/SST/level2/template_one_sample_with_confounders_design_estimate.m',\n",
       " 'confounder_template_path': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/models/SST/level2/template_one_sample_with_confounders_confounder.m',\n",
       " 'nonbids_data_path': '/Users/benjaminsmith/Google Drive/oregon/data/DEV/nonbids_data/',\n",
       " 'dev_scripts_path': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts',\n",
       " 'sst_level_2_path': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/level2/SST/',\n",
       " 'dropbox_datapath': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/',\n",
       " 'spm_path': '/Users/benjaminsmith/spm12',\n",
       " 'automotion_output_path': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/motion/motion_percent_summary.csv',\n",
       " 'template_mlr_main': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/models/SST/level2/templates/multiple_regression/template_main.m',\n",
       " 'template_mlr_confounder_no_centering': '/Users/benjaminsmith/Google Drive/oregon//code/DEV_scripts/fMRI/fx/models/SST/level2/templates/multiple_regression/template_confounder_no_centering.m',\n",
       " 'template_mlr_consess': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/models/SST/level2/templates/multiple_regression/template_consess.m',\n",
       " 'template_mlr_conspec': '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/fx/models/SST/level2/templates/multiple_regression/template_conspec.m',\n",
       " 'mask_location': '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Striatum joint mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the paths of the six striatal mask areas\n",
    "import glob\n",
    "\n",
    "\n",
    "mask_path = config['mask_location']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "striatal_masks = glob.glob(mask_path + 'striatum' + '/*.nii.gz')\n",
    "\n",
    "#load the masks and add them\n",
    "striatal_joint_mask = nil.image.math_img(\n",
    "    \" + \".join([\"img\" + str(i) for i in range(len(striatal_masks))]),\n",
    "    **{'img'+str(i):sm for i, sm in enumerate(striatal_masks)}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "#now save that mask\n",
    "striatal_joint_mask_filepath = mask_path + 'aim3/striatum_joint_mask.nii.gz'\n",
    "striatal_joint_mask.to_filename(striatal_joint_mask_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next mask we want is an intersection of the striatum mask and the motor control striatal mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(\"Input images cannot be compared, you provided 'dict_values(['/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/striatum_joint_mask.nii.gz', '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz'])',\", 'Following field of view errors were detected:\\n- img_#0 and img_#1 do not have the same shape\\n- img_#0 and img_#1 do not have the same affine')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m motor_control_mask \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mmath_img(\n\u001b[1;32m      2\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mstriatum * motor_control\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m     striatum \u001b[39m=\u001b[39;49m striatal_joint_mask_filepath,\n\u001b[1;32m      4\u001b[0m     motor_control \u001b[39m=\u001b[39;49m mask_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39maim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m motor_control_mask\u001b[39m.\u001b[39mto_filename(mask_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39maim3/motor_control_striatum_joint_mask.nii.gz\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1038\u001b[0m, in \u001b[0;36mmath_img\u001b[0;34m(formula, **imgs)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m     niimgs \u001b[39m=\u001b[39m [check_niimg(image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m imgs\u001b[39m.\u001b[39mvalues()]\n\u001b[0;32m-> 1038\u001b[0m     _check_same_fov(\u001b[39m*\u001b[39;49mniimgs, raise_error\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1039\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1040\u001b[0m     exc\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\n\u001b[1;32m   1041\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput images cannot be compared, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myou provided \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mimgs\u001b[39m.\u001b[39mvalues()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     ) \u001b[39m+\u001b[39m exc\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/_utils/niimg_conversions.py:63\u001b[0m, in \u001b[0;36m_check_same_fov\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         errors\u001b[39m.\u001b[39mappend((a_name, b_name, \u001b[39m\"\u001b[39m\u001b[39maffine\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(errors) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m raise_error:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     64\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFollowing field of view errors were detected:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     66\u001b[0m             [\u001b[39m\"\u001b[39m\u001b[39m- \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m do not have the same \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m errors]\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(errors) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: (\"Input images cannot be compared, you provided 'dict_values(['/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/striatum_joint_mask.nii.gz', '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz'])',\", 'Following field of view errors were detected:\\n- img_#0 and img_#1 do not have the same shape\\n- img_#0 and img_#1 do not have the same affine')"
     ]
    }
   ],
   "source": [
    "motor_control_mask = nil.image.math_img(\n",
    "    \"striatum * motor_control\",\n",
    "    striatum = striatal_joint_mask_filepath,\n",
    "    motor_control = mask_path + 'aim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz')\n",
    "\n",
    "motor_control_mask.to_filename(mask_path + 'aim3/motor_control_striatum_joint_mask.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the same, but with reward; and also, include a 1.96 threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Striatal SST functional contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run this, the striatal clusters need to be manually created in SPM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scriptsfMRI/fx/models/SST/level2/posterror_cues_no_rt_20230512/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_1.nii\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or no access: '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scriptsfMRI/fx/models/SST/level2/posterror_cues_no_rt_20230512/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_1.nii'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nibabel/loadsave.py:100\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     stat_result \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scriptsfMRI/fx/models/SST/level2/posterror_cues_no_rt_20230512/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_1.nii'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m roi_file \u001b[39min\u001b[39;00m roi_files:\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(roi_file)\n\u001b[0;32m---> 13\u001b[0m     ni_file \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39;49mload(roi_file)\n\u001b[1;32m     14\u001b[0m     \u001b[39m#binarize roi using nilearn\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     ni_file \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mmath_img(\u001b[39m\"\u001b[39m\u001b[39mimg > 0\u001b[39m\u001b[39m\"\u001b[39m, img\u001b[39m=\u001b[39mni_file)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nibabel/loadsave.py:102\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     stat_result \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mstat(filename)\n\u001b[1;32m    101\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mOSError\u001b[39;00m:\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo such file or no access: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[39mif\u001b[39;00m stat_result\u001b[39m.\u001b[39mst_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    104\u001b[0m     \u001b[39mraise\u001b[39;00m ImageFileError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEmpty file: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: No such file or no access: '/Users/benjaminsmith/Google Drive/oregon/code/DEV_scriptsfMRI/fx/models/SST/level2/posterror_cues_no_rt_20230512/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_1.nii'"
     ]
    }
   ],
   "source": [
    "dev_scripts_abs_path = config['dev_scripts_path']\n",
    "posterror_folder = 'posterror_cues_no_rt_20230512'\n",
    "\n",
    "#these two files need to be manually created in SPM.\n",
    "# roi file to open\n",
    "roi_files = [dev_scripts_abs_path + 'fMRI/fx/models/SST/level2/' + posterror_folder + '/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_1.nii',\n",
    "dev_scripts_abs_path + 'fMRI/fx/models/SST/level2/' + posterror_folder + '/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_2.nii']\n",
    "# load each of the roi files\n",
    " \n",
    "roi_data = []\n",
    "for roi_file in roi_files:\n",
    "    print(roi_file)\n",
    "    ni_file = nib.load(roi_file)\n",
    "    #binarize roi using nilearn\n",
    "    ni_file = nil.image.math_img(\"img > 0\", img=ni_file)\n",
    "    roi_data = roi_data + [ni_file]\n",
    "    #display the roi\n",
    "    #plotting.plot_roi(ni_file, title=roi_file)\n",
    "    print(\"displayed\")\n",
    "#combine the rois\n",
    "#concatenate them\n",
    "combined_roi_data = nil.image.concat_imgs(roi_data)\n",
    "#then add them\n",
    "combined_roi_data = nil.image.math_img(\"np.sum(imgs, axis=3)\", imgs=combined_roi_data)\n",
    "\n",
    "plotting.plot_roi(combined_roi_data, title=\"combined\")\n",
    "#save the combined roi\n",
    "combined_roi_data.to_filename(\n",
    "    dev_scripts_abs_path + '/fMRI/fx/models/SST/level2/' + posterror_folder + '/CueFollowing(CS>FS)/CueFollowing(CS>FS)striatal_cluster_combined.nii')\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hedy Kober image conversion\n",
    "\n",
    "This converts a mask from hdr/img format to nii format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nil.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koban_kober_img = nib.load(config['mask_location'] + \"aim3/signatures/koban_kober_craving_wmapN99_boot10K_02-May-2022.img\")\n",
    "\n",
    "img_variance = koban_kober_img.get_fdata()[koban_kober_img.get_fdata()!=0].var()\n",
    "variance_reciprocal = 1/img_variance\n",
    "img_not_zero = np.sum(koban_kober_img.get_fdata()!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69160"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(koban_kober_img.get_fdata()!=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koban_kober_img_var1 = nil.image.math_img(\"img *\" + str(variance_reciprocal), img=koban_kober_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nib.save(koban_kober_img_var1, config['mask_location'] + \"aim3/signatures/koban_kober_craving_wmapN99_boot10K_02-May-2022_var1.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "koban_kober_img_scaled_up = nil.image.math_img(\"img *\" + str(img_not_zero), img=koban_kober_img)\n",
    "nib.save(koban_kober_img_scaled_up, config['mask_location'] + \"aim3/signatures/koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero.nii.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response inhibition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_path = config['mask_location']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the paths of the six striatal mask areas\n",
    "import glob\n",
    "\n",
    "\n",
    "mask_path = config['mask_location']\n",
    "\n",
    "neurosynth_response_inhibition_filepath = mask_path + 'response_inhibition_related/response inhibition_association-test_z_FDR_0.01.nii.gz'\n",
    "\n",
    "superior_frontal_gyrus_filepath = mask_path + 'response_inhibition_related/harvardoxford-cortical_prob_Superior Frontal Gyrus.nii.gz'\n",
    "\n",
    "right_hemisphere_filepath = mask_path + 'harvardoxford-subcortical_prob_Right Cerebral Cortex.nii.gz'\n",
    "\n",
    "frontal_pole_filepath  = mask_path + 'response_inhibition_related/harvardoxford-cortical_prob_Frontal Pole.nii.gz'\n",
    "\n",
    "insula_filepath = mask_path + 'response_inhibition_related/harvardoxford-cortical_prob_Insular Cortex.nii.gz'\n",
    "\n",
    "#set a threshold of 25 for the h-o masks\n",
    "# superior_frontal_gyrus_25 = nil.image.math_img(\"img > 25\", img=superior_frontal_gyrus_filepath)\n",
    "# frontal_pole_25 = nil.image.math_img(\"img > 25\", img=frontal_pole_filepath)\n",
    "# right_hemisphere_0 = nil.image.math_img(\"img > 0\", img=right_hemisphere_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurosynth_response_inhibition = nil.image.load_img(neurosynth_response_inhibition_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#could use the regions extractor, but I would rather use the neurosynth mask as, although we don't necessarily get continguous regions,\n",
    "#the strict multiply method gets us a more replicable mask\n",
    "# import nilearn.regions as regions\n",
    "\n",
    "# regions_list, index_of_each_map = regions.connected_regions(neurosynth_response_inhibition, min_region_size=1000)\n",
    "# regions_list.to_filename(mask_path + 'response_inhibition_related/neurosynth_response_inhibition_connected_regions.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'functional_mask_bin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combined_mask \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mmath_img(\u001b[39m\"\u001b[39m\u001b[39mimg1 * img2\u001b[39m\u001b[39m\"\u001b[39m, img1\u001b[39m=\u001b[39mfunctional_mask_bin, img2\u001b[39m=\u001b[39mhemispheric_anatomical_mask)\n\u001b[1;32m      2\u001b[0m \u001b[39m# save each output\u001b[39;00m\n\u001b[1;32m      3\u001b[0m combined_mask\u001b[39m.\u001b[39mto_filename(out_filename)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'functional_mask_bin' is not defined"
     ]
    }
   ],
   "source": [
    "combined_mask = nil.image.math_img(\"img1 * img2\", img1=functional_mask_bin, img2=hemispheric_anatomical_mask)\n",
    "# save each output\n",
    "combined_mask.to_filename(out_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binarized_functional_mask(functional_mask_filepath,functional_thresh):\n",
    "    functional_mask = nil.image.load_img(functional_mask_filepath)\n",
    "    #apply 6mm smoothing kernel\n",
    "    functional_mask_sm = nil.image.smooth_img(functional_mask, fwhm=6)\n",
    "\n",
    "    # binarize the neurosynth mask\n",
    "    functional_mask_bin = nil.image.binarize_img(functional_mask_sm,functional_thresh)\n",
    "    return(functional_mask_bin)\n",
    "\n",
    "ri_mask= get_binarized_functional_mask(neurosynth_response_inhibition_filepath,\n",
    "                              functional_thresh=1.96)\n",
    "\n",
    "ri_mask.to_filename(mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition.nii')\n",
    "ri_mask.to_filename(mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/harvardoxford-subcortical_prob_Right Cerebral Cortex.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combine_neurosynth_anatomical(neurosynth_response_inhibition_filepath,superior_frontal_gyrus_filepath,\n\u001b[1;32m      2\u001b[0m                               right_hemisphere_filepath,functional_thresh\u001b[39m=\u001b[39;49m\u001b[39m1.96\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                               out_filename\u001b[39m=\u001b[39;49mmask_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mresponse_inhibition_anatomical_combined/neurosynth_response_inhibition_right_sup_fron_gyrus.nii\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mcombine_neurosynth_anatomical\u001b[0;34m(functional_mask_filepath, base_anatomical_img_filepath, hemisphere_filepath, functional_thresh, out_filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m anatomical_mask_bin_25\u001b[39m.\u001b[39mto_filename(base_anatomical_img_filepath\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.nii.gz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_bin_25.nii.gz\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m hemisphere_filepath \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     hemisphere_img \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mload_img(hemisphere_filepath)\n\u001b[1;32m     17\u001b[0m     \u001b[39m# binarize the hemisphere mask\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     hemisphere_mask_bin_25 \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mbinarize_img(hemisphere_img,\u001b[39m25\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1333\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(img, wildcards\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1296\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a Niimg-like object from filenames or list of filenames.\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \n\u001b[1;32m   1298\u001b[0m \u001b[39m    .. versionadded:: 0.2.5\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \n\u001b[1;32m   1332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m check_niimg(img, wildcards\u001b[39m=\u001b[39;49mwildcards, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/_utils/niimg_conversions.py:303\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n\u001b[1;32m    302\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mniimg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(niimg):\n\u001b[1;32m    305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mniimg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/harvardoxford-subcortical_prob_Right Cerebral Cortex.nii.gz'"
     ]
    }
   ],
   "source": [
    "combine_neurosynth_anatomical(neurosynth_response_inhibition_filepath,superior_frontal_gyrus_filepath,\n",
    "                              right_hemisphere_filepath,functional_thresh=1.96,\n",
    "                              out_filename=mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition_right_sup_fron_gyrus.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "File not found: '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/harvardoxford-subcortical_prob_Right Cerebral Cortex.nii.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combine_neurosynth_anatomical(neurosynth_response_inhibition_filepath,frontal_pole_filepath,\n\u001b[1;32m      2\u001b[0m                               right_hemisphere_filepath,functional_thresh\u001b[39m=\u001b[39;49m\u001b[39m1.96\u001b[39;49m,\n\u001b[1;32m      3\u001b[0m                               out_filename\u001b[39m=\u001b[39;49mmask_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mresponse_inhibition_anatomical_combined/neurosynth_response_inhibition_right_frontal_pole.nii\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[12], line 16\u001b[0m, in \u001b[0;36mcombine_neurosynth_anatomical\u001b[0;34m(functional_mask_filepath, base_anatomical_img_filepath, hemisphere_filepath, functional_thresh, out_filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m anatomical_mask_bin_25\u001b[39m.\u001b[39mto_filename(base_anatomical_img_filepath\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m.nii.gz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_bin_25.nii.gz\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m     15\u001b[0m \u001b[39mif\u001b[39;00m hemisphere_filepath \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     hemisphere_img \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mload_img(hemisphere_filepath)\n\u001b[1;32m     17\u001b[0m     \u001b[39m# binarize the hemisphere mask\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     hemisphere_mask_bin_25 \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mbinarize_img(hemisphere_img,\u001b[39m25\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1333\u001b[0m, in \u001b[0;36mload_img\u001b[0;34m(img, wildcards, dtype)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_img\u001b[39m(img, wildcards\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1296\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a Niimg-like object from filenames or list of filenames.\u001b[39;00m\n\u001b[1;32m   1297\u001b[0m \n\u001b[1;32m   1298\u001b[0m \u001b[39m    .. versionadded:: 0.2.5\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1331\u001b[0m \n\u001b[1;32m   1332\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1333\u001b[0m     \u001b[39mreturn\u001b[39;00m check_niimg(img, wildcards\u001b[39m=\u001b[39;49mwildcards, dtype\u001b[39m=\u001b[39;49mdtype)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/_utils/niimg_conversions.py:303\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(message)\n\u001b[1;32m    302\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mniimg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    304\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(niimg):\n\u001b[1;32m    305\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFile not found: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mniimg\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: File not found: '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/harvardoxford-subcortical_prob_Right Cerebral Cortex.nii.gz'"
     ]
    }
   ],
   "source": [
    "combine_neurosynth_anatomical(neurosynth_response_inhibition_filepath,frontal_pole_filepath,\n",
    "                              right_hemisphere_filepath,functional_thresh=1.96,\n",
    "                              out_filename=mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition_right_frontal_pole.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_neurosynth_anatomical(neurosynth_response_inhibition_filepath,frontal_pole_filepath,\n",
    "                              right_hemisphere_filepath,functional_thresh=1.96,\n",
    "                              out_filename=mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition_right_frontal_pole.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/image/image.py:1041: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/image/image.py:1041: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "combine_neurosynth_anatomical(neurosynth_response_inhibition_filepath,insula_filepath,\n",
    "                              right_hemisphere_filepath,functional_thresh=1.96,\n",
    "                              out_filename=mask_path + 'response_inhibition_anatomical_combined/neurosynth_response_inhibition_right_insula.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "(\"Input images cannot be compared, you provided 'dict_values(['/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/striatum_joint_mask.nii.gz', '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz'])',\", 'Following field of view errors were detected:\\n- img_#0 and img_#1 do not have the same shape\\n- img_#0 and img_#1 do not have the same affine')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#load the masks and add them\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m motor_control_mask \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mmath_img(\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mstriatum * motor_control\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m     striatum \u001b[39m=\u001b[39;49m striatal_joint_mask_filepath,\n\u001b[1;32m      5\u001b[0m     motor_control \u001b[39m=\u001b[39;49m mask_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39maim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m#now save that mask\u001b[39;00m\n\u001b[1;32m      8\u001b[0m striatal_joint_mask_filepath \u001b[39m=\u001b[39m mask_path \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39maim3/striatum_joint_mask.nii.gz\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1038\u001b[0m, in \u001b[0;36mmath_img\u001b[0;34m(formula, **imgs)\u001b[0m\n\u001b[1;32m   1036\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1037\u001b[0m     niimgs \u001b[39m=\u001b[39m [check_niimg(image) \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m imgs\u001b[39m.\u001b[39mvalues()]\n\u001b[0;32m-> 1038\u001b[0m     _check_same_fov(\u001b[39m*\u001b[39;49mniimgs, raise_error\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1039\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m   1040\u001b[0m     exc\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m (\n\u001b[1;32m   1041\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mInput images cannot be compared, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1042\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myou provided \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mimgs\u001b[39m.\u001b[39mvalues()\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     ) \u001b[39m+\u001b[39m exc\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/_utils/niimg_conversions.py:63\u001b[0m, in \u001b[0;36m_check_same_fov\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         errors\u001b[39m.\u001b[39mappend((a_name, b_name, \u001b[39m\"\u001b[39m\u001b[39maffine\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m     62\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(errors) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m raise_error:\n\u001b[0;32m---> 63\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m     64\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFollowing field of view errors were detected:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     65\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m     66\u001b[0m             [\u001b[39m\"\u001b[39m\u001b[39m- \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m and \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m do not have the same \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m errors]\n\u001b[1;32m     67\u001b[0m         )\n\u001b[1;32m     68\u001b[0m     )\n\u001b[1;32m     69\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(errors) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: (\"Input images cannot be compared, you provided 'dict_values(['/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/striatum_joint_mask.nii.gz', '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz'])',\", 'Following field of view errors were detected:\\n- img_#0 and img_#1 do not have the same shape\\n- img_#0 and img_#1 do not have the same affine')"
     ]
    }
   ],
   "source": [
    "#load the masks and add them\n",
    "motor_control_mask = nil.image.math_img(\n",
    "    \"striatum * motor_control\",\n",
    "    striatum = striatal_joint_mask_filepath,\n",
    "    motor_control = mask_path + 'aim3/neurosynth/motor control_association-test_z_FDR_0.01.nii.gz')\n",
    "\n",
    "#now save that mask\n",
    "striatal_joint_mask_filepath = mask_path + 'aim3/striatum_joint_mask.nii.gz'\n",
    "striatal_joint_mask.to_filename(striatal_joint_mask_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1065: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "combine_neurosynth_anatomical(\n",
    "    functional_mask_filepath = mask_path + 'aim3/neurosynth/value_association-test_z_FDR_0.01.nii.gz', \n",
    "    base_anatomical_img_filepath = mask_path + 'prefrontal_cortex/harvardoxford-cortical_prob_Frontal Medial Cortex.nii.gz', \n",
    "    hemisphere_filepath = None, \n",
    "    functional_thresh = 1.96, out_filename = mask_path + 'value_association_frontal_medial_cortex.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1065: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "combine_neurosynth_anatomical(\n",
    "    functional_mask_filepath = mask_path + 'aim3/neurosynth/value_association-test_z_FDR_0.01.nii.gz', \n",
    "    base_anatomical_img_filepath = mask_path + 'prefrontal_cortex/harvardoxford-cortical_prob_Frontal Medial Cortex.nii.gz', \n",
    "    hemisphere_filepath = None, \n",
    "    functional_thresh = 5, out_filename = mask_path + 'value_association_frontal_medial_cortex_t5.nii')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## binarizing for health condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "nil.image.binarize_img(mask_path + 'value/value_association-test_z_FDR_0.01.nii.gz',5).to_filename(mask_path + 'value/value_association-test_z_FDR_0.01_t5.nii.gz')\n",
    "nil.image.binarize_img(mask_path + 'value/value_association-test_z_FDR_0.01.nii.gz',9).to_filename(mask_path + 'value/value_association-test_z_FDR_0.01_t9.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1065: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "nil.image.binarize_img('/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/prefrontal_cortex/harvardoxford-cortical_prob_Frontal Medial Cortex.nii.gz',50).to_filename('/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/prefrontal_cortex/harvardoxford-cortical_prob_Frontal Medial Cortex_t50.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1065: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "fname = '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/response_inhibition_related/response inhibition_association-test_z_FDR_0.01.nii.gz'\n",
    "nil.image.binarize_img(fname,5).to_filename(fname.replace('.nii.gz','_t5.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/image.py:1065: UserWarning: Data array used to create a new image contains 64-bit ints. This is likely due to creating the array with numpy and passing `int` as the `dtype`. Many tools such as FSL and SPM cannot deal with int64 in Nifti images, so for compatibility the data has been converted to int32.\n",
      "  return new_img_like(niimg, result, niimg.affine)\n"
     ]
    }
   ],
   "source": [
    "fname = '/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/aim3/striatum_joint_mask.nii.gz'\n",
    "nil.image.binarize_img(fname,50).to_filename(fname.replace('.nii.gz','_t50.nii.gz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fmc_paracingulate = [\n",
    "    mask_path + 'prefrontal_cortex/harvardoxford-cortical_prob_Frontal Medial Cortex.nii.gz',\n",
    "    mask_path + 'prefrontal_cortex/harvardoxford-cortical_prob_Paracingulate Gyrus.nii.gz'\n",
    "]\n",
    "\n",
    "#load the masks and add them\n",
    "fmc_joint_mask = nil.image.math_img(\n",
    "    \" + \".join([\"img\" + str(i) for i in range(len(fmc_paracingulate))]),\n",
    "    **{'img'+str(i):sm for i, sm in enumerate(fmc_paracingulate)}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "#now save that mask\n",
    "fmc_joint_mask_filepath = mask_path + 'fmc_paracingulate.nii.gz'\n",
    "fmc_joint_mask.to_filename(fmc_joint_mask_filepath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/fmc_paracingulate.nii.gz'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmc_joint_mask_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmc_joint_mask_bin_filepath = fmc_joint_mask_filepath.replace('.nii.gz','_t50.nii.gz')\n",
    "nil.image.binarize_img(fmc_joint_mask_filepath,50).to_filename(fmc_joint_mask_bin_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/benjaminsmith/Google Drive/oregon/data/DEV/brainmaps/fmc_paracingulate_t50.nii.gz'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fmc_joint_mask_bin_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combine_neurosynth_anatomical(\n\u001b[1;32m      2\u001b[0m     functional_mask_filepath \u001b[39m=\u001b[39;49m mask_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39maim3/neurosynth/value_association-test_z_FDR_0.01.nii.gz\u001b[39;49m\u001b[39m'\u001b[39;49m, \n\u001b[1;32m      3\u001b[0m     base_anatomical_img_filepath \u001b[39m=\u001b[39;49m fmc_joint_mask_filepath, \n\u001b[1;32m      4\u001b[0m     hemisphere_filepath \u001b[39m=\u001b[39;49m \u001b[39mNone\u001b[39;49;00m, \n\u001b[1;32m      5\u001b[0m     functional_thresh \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, out_filename \u001b[39m=\u001b[39;49m mask_path \u001b[39m+\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mfmc_paracing_t25_value_t5.nii\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[11], line 28\u001b[0m, in \u001b[0;36mcombine_neurosynth_anatomical\u001b[0;34m(functional_mask_filepath, base_anatomical_img_filepath, hemisphere_filepath, functional_thresh, out_filename)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39m#apply 6mm smoothing kernel\u001b[39;00m\n\u001b[1;32m     26\u001b[0m functional_mask_sm \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39msmooth_img(functional_mask, fwhm\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m functional_mask_trans \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mresample_to_img(functional_mask_sm, base_anatomical_img)\n\u001b[1;32m     29\u001b[0m \u001b[39m# binarize the neurosynth mask\u001b[39;00m\n\u001b[1;32m     30\u001b[0m functional_mask_bin \u001b[39m=\u001b[39m nil\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mbinarize_img(functional_mask_trans,functional_thresh)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/resampling.py:768\u001b[0m, in \u001b[0;36mresample_to_img\u001b[0;34m(source_img, target_img, interpolation, copy, order, clip, fill_value, force_resample)\u001b[0m\n\u001b[1;32m    765\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(target_shape) \u001b[39m>\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    766\u001b[0m     target_shape \u001b[39m=\u001b[39m target\u001b[39m.\u001b[39mshape[:\u001b[39m3\u001b[39m]\n\u001b[0;32m--> 768\u001b[0m \u001b[39mreturn\u001b[39;00m resample_img(\n\u001b[1;32m    769\u001b[0m     source_img,\n\u001b[1;32m    770\u001b[0m     target_affine\u001b[39m=\u001b[39;49mtarget\u001b[39m.\u001b[39;49maffine,\n\u001b[1;32m    771\u001b[0m     target_shape\u001b[39m=\u001b[39;49mtarget_shape,\n\u001b[1;32m    772\u001b[0m     interpolation\u001b[39m=\u001b[39;49minterpolation,\n\u001b[1;32m    773\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    774\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    775\u001b[0m     clip\u001b[39m=\u001b[39;49mclip,\n\u001b[1;32m    776\u001b[0m     fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    777\u001b[0m     force_resample\u001b[39m=\u001b[39;49mforce_resample,\n\u001b[1;32m    778\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/resampling.py:673\u001b[0m, in \u001b[0;36mresample_img\u001b[0;34m(img, target_affine, target_shape, interpolation, copy, order, clip, fill_value, force_resample)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[39m# Iterate over a set of 3D volumes, as the interpolation problem is\u001b[39;00m\n\u001b[1;32m    670\u001b[0m     \u001b[39m# separable in the extra dimensions. This reduces the\u001b[39;00m\n\u001b[1;32m    671\u001b[0m     \u001b[39m# computational cost\u001b[39;00m\n\u001b[1;32m    672\u001b[0m     \u001b[39mfor\u001b[39;00m ind \u001b[39min\u001b[39;00m np\u001b[39m.\u001b[39mndindex(\u001b[39m*\u001b[39mother_shape):\n\u001b[0;32m--> 673\u001b[0m         _resample_one_img(\n\u001b[1;32m    674\u001b[0m             data[all_img \u001b[39m+\u001b[39;49m ind],\n\u001b[1;32m    675\u001b[0m             A,\n\u001b[1;32m    676\u001b[0m             b,\n\u001b[1;32m    677\u001b[0m             target_shape,\n\u001b[1;32m    678\u001b[0m             interpolation_order,\n\u001b[1;32m    679\u001b[0m             out\u001b[39m=\u001b[39;49mresampled_data[all_img \u001b[39m+\u001b[39;49m ind],\n\u001b[1;32m    680\u001b[0m             copy\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m input_img_is_string,\n\u001b[1;32m    681\u001b[0m             fill_value\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    682\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[39mif\u001b[39;00m clip:\n\u001b[1;32m    685\u001b[0m     \u001b[39m# force resampled data to have a range contained in the original data\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[39m# preventing ringing artefact\u001b[39;00m\n\u001b[1;32m    687\u001b[0m     \u001b[39m# We need to add zero as a value considered for clipping, as it\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[39m# appears in padding images.\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     vmin \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(data\u001b[39m.\u001b[39mmin(), \u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/nilearn/image/resampling.py:306\u001b[0m, in \u001b[0;36m_resample_one_img\u001b[0;34m(data, A, b, target_shape, interpolation_order, out, copy, fill_value)\u001b[0m\n\u001b[1;32m    304\u001b[0m         warnings\u001b[39m.\u001b[39msimplefilter(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mUserWarning\u001b[39;00m)\n\u001b[1;32m    305\u001b[0m     \u001b[39m# The resampling itself\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m     affine_transform(\n\u001b[1;32m    307\u001b[0m         data,\n\u001b[1;32m    308\u001b[0m         A,\n\u001b[1;32m    309\u001b[0m         offset\u001b[39m=\u001b[39;49mb,\n\u001b[1;32m    310\u001b[0m         output_shape\u001b[39m=\u001b[39;49mtarget_shape,\n\u001b[1;32m    311\u001b[0m         output\u001b[39m=\u001b[39;49mout,\n\u001b[1;32m    312\u001b[0m         cval\u001b[39m=\u001b[39;49mfill_value,\n\u001b[1;32m    313\u001b[0m         order\u001b[39m=\u001b[39;49minterpolation_order,\n\u001b[1;32m    314\u001b[0m     )\n\u001b[1;32m    316\u001b[0m \u001b[39mif\u001b[39;00m has_not_finite:\n\u001b[1;32m    317\u001b[0m     \u001b[39m# Suppresses warnings in https://github.com/nilearn/nilearn/issues/1363\u001b[39;00m\n\u001b[1;32m    318\u001b[0m     \u001b[39mwith\u001b[39;00m warnings\u001b[39m.\u001b[39mcatch_warnings():\n",
      "File \u001b[0;32m~/anaconda/envs/neuroanalysis/lib/python3.10/site-packages/scipy/ndimage/_interpolation.py:611\u001b[0m, in \u001b[0;36maffine_transform\u001b[0;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[1;32m    605\u001b[0m \u001b[39mif\u001b[39;00m matrix\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    606\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    607\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe behavior of affine_transform with a 1-D \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    608\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray supplied for the matrix parameter has changed in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSciPy 0.18.0.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    610\u001b[0m     )\n\u001b[0;32m--> 611\u001b[0m     _nd_image\u001b[39m.\u001b[39;49mzoom_shift(filtered, matrix, offset\u001b[39m/\u001b[39;49mmatrix, output, order,\n\u001b[1;32m    612\u001b[0m                          mode, cval, npad, \u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    614\u001b[0m     _nd_image\u001b[39m.\u001b[39mgeometric_transform(filtered, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, matrix, offset,\n\u001b[1;32m    615\u001b[0m                                   output, order, mode, cval, npad, \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    616\u001b[0m                                   \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "combine_neurosynth_anatomical(\n",
    "    functional_mask_filepath = mask_path + 'aim3/neurosynth/value_association-test_z_FDR_0.01.nii.gz', \n",
    "    base_anatomical_img_filepath = fmc_joint_mask_filepath, \n",
    "    hemisphere_filepath = None, \n",
    "    functional_thresh = 5, out_filename = mask_path + 'fmc_paracing_t25_value_t5.nii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
