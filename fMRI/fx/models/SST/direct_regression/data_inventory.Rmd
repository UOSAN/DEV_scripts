---
title: "SST Paper generation Wave 1 and 2"
author: "Ben Smith"
date: "2022-12-19"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
    theme: spacelab
  pdf_document:
    toc: yes
    keep_tex: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE)

```
This file just generates the stuf that goes into the final paper.
# Prep

```{r}
library(tidyverse)
library(MuMIn)
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])
print(Sys.info()["nodename"])
library(stargazer)
library(tidyverse)
library(gt)
source("preprocessing.R")
source("display_utils.R")
library(lmerTest)

```

```{r}
dropbbox_dir <- config::get("dev_analysis_data_dir")
output_folder <- "sst_paper_generation_w12_output"

```



```{r}
cache_filepath <- paste0(dropbbox_dir,"sst_paper_generation_w12.Rdata")
loaded_from_cache<-FALSE
if (file.exists(cache_filepath)){
  load(cache_filepath)
  loaded_from_cache<-TRUE
} 

```



# Counting included subjects
```{r}
included_in_contrasts<-unique(included_subjects_table$subject_id)
print(length(included_in_contrasts))

included_in_time_points <- unique(time_points_raw$subid)
length(included_in_time_points)
#missing in time_points, included in contrast
setdiff(included_in_contrasts,included_in_time_points)
setdiff(included_in_time_points,included_in_contrasts)
length(intersect(included_in_contrasts,included_in_time_points))
included_in_tp_contrast_intersection<-unique(time_points$subid)
length(unique(time_points_c$subid))
length(unique(trial_summary_data$subid))
length(unique(trial_summary_data_delat_pp$subid))
length(unique(trial_neural_behav_data_not_na$subid))
length(unique(trial_neural_behav_roi$subid))

data_all_valid<-(    #rowSums(is.na(trial_summary_data_delat_pp[,c("response_amplitude","post_pre_rt_change")]))==0 & #no NA values in correlation and
    is.na(trial_summary_data_delat_pp[,c("post_pre_rt_change")])==FALSE & #no NA values in correlation and
      #is.finite(trial_summary_data_delat_pp$response_amplitude) #&
      is.finite(trial_summary_data_delat_pp$post_pre_rt_change) & #no infinite values
      (is.finite(trial_summary_data_delat_pp$med_post_trial) |  
       is.finite(trial_summary_data_delat_pp$med_post_trial_1_5)
     ))

 retained_data<-trial_summary_data_delat_pp[
data_all_valid
      ,]
  
setdiff(retained_data$subid,trial_summary_data_delat_pp$subid)
eliminated_subjects <- setdiff(trial_summary_data_delat_pp$subid,retained_data$subid)
View(trial_summary_data_delat_pp[trial_summary_data_delat_pp$subid %in% eliminated_subjects,])
#It looks like the 5 subjects excluded are excluded because there is not behavioral data for them. How far back does _that_ go?
post_pre_rt_data[post_pre_rt_data$subid %in% eliminated_subjects,]

```

```{r}
#there are non of them at all in the data, okay...
# sst_all_data[sst_all_data$subid %in% eliminated_subjects,]
# 
# sst_all_data_raw[sst_all_data_raw$subid %in% eliminated_subjects,]
#it IS in the raw data...
sst_all_data_raw <- readr::read_csv(sst_all_data_filepath)  %>% filter(waveid %in% c(1,2))
  sst_all_data_raw_cleaned<-clean_sst_data(sst_all_data_raw)
  #cleaned SST data
  # sst_all_data_raw_cleaned[sst_all_data_raw_cleaned$subid %in% eliminated_subjects,"subid"] %>% unique
  # these subjects are still in the cleaned dataset!
  
  sst_all_data_processed.1 <- get_expected_tone_time(sst_all_data_raw_cleaned)
  
  sst_all_data_processed.2<-calculate_response_latency(sst_all_data_processed.1)
  sst_all_data_processed.3<-calculate_rpe(sst_all_data_processed.2)
  
  sst_all_data_processed.4<-get_more_sst_stats(sst_all_data_processed.3)
  
  sst_all_data_processed.4[sst_all_data_processed.4$subid %in% eliminated_subjects,"subid"] %>% unique
  
  sst_all_data_accuracy[sst_all_data_accuracy$subid %in% eliminated_subjects,"subid"] %>% unique
  
  sst_all_data_accuracy[,"subid"] %>% unique %>% length
  sst_all_data_processed.4[,"subid"] %>% unique %>% length
  
  
```

```{r}
    prop_correct_included_range <- c(0.2,0.8)
  print("before removing very high and low performance trials:")
  print(sst_all_data$subid %>% unique %>% length)
  sst_all_data_accuracy_filtered <- sst_all_data_processed.4 %>% filter(
    stop_prop_correct>prop_correct_included_range[[1]] & 
      stop_prop_correct<prop_correct_included_range[[2]])
  
  sst_all_data_accuracy_filtered[sst_all_data_accuracy_filtered$subid %in% eliminated_subjects,"subid"] %>% unique
```


ahh of course. The 
# Accuracy

```{r}

included_subjects <- unique(trial_neural_behav_roi$subid)
length(included_subjects)
length(unique(sst_all_data$subid))
length(unique(sst_all_data_accuracy$subid))
sst_accuracy_by_run<-sst_all_data_accuracy %>% filter(waveid %in% c(1,2)) %>%
  filter(subid %in% included_subjects) %>%
  group_by(subid,waveid,runid) %>% 
  
  dplyr::summarise(stop_prop_correct=mean(stop_prop_correct),
         stop_prop_correct_nunique<-length(unique(stop_prop_correct))
         )

spc_mean<-mean(sst_accuracy_by_run$stop_prop_correct)
spc_sd_1<-sd(sst_accuracy_by_run$stop_prop_correct)
spc_sd_1_pos<-c(spc_mean-spc_sd_1,spc_mean+spc_sd_1)
spc_sd_2_pos<-c(spc_mean-spc_sd_1*2,spc_mean+spc_sd_1*2)

sst_accuracy_by_run$stop_prop_correct_too_low<-sst_accuracy_by_run$stop_prop_correct>prop_correct_included_range[[1]]
sst_accuracy_by_run$stop_prop_correct_too_high<-sst_accuracy_by_run$stop_prop_correct>prop_correct_included_range[[2]]
sst_accuracy_by_run$included<-(!sst_accuracy_by_run$stop_prop_correct_too_low & !sst_accuracy_by_run$stop_prop_correct_too_high)

# # Generate random data
# data <- data.frame(values = rnorm(1000))
# 
# # Define breakpoints for the ranges
# breakpoints <- c(-Inf, -1.5, 0, 1.5, Inf)
# 
# # Cut data into ranges
# data$range_categories <- cut(data$values, breaks = breakpoints)

fig_accuracy_supp<-ggplot(sst_accuracy_by_run,aes(x=stop_prop_correct, fill=included))+
  geom_histogram(bins=25, color="black")+labs(
    title="Included and excluded runs by proportion stop trials correct",
    y="Number of runs",x="Proportion of Stop Trials Correct")+
  scale_x_continuous(labels=scales::percent_format())+
  theme(legend.position = "bottom")+geom_vline(xintercept=prop_correct_included_range)+
  #geom_vline(xintercept=spc_sd_2_pos,color="red")+
  annotate("text", x = prop_correct_included_range[1], y = 60, label = "Lower Limit ", hjust = "right") +
  annotate("text", x = prop_correct_included_range[2], y = 60, label =" Upper Limit", hjust = "left")# +
  # annotate("text", x = spc_sd_2_pos[1], y = 60, label = "2 SD", hjust = "right") +
  # annotate("text", x = spc_sd_2_pos[2], y = 60, label = "2 SD", hjust = "left")

removal_summary_stats<-sst_accuracy_by_run %>% group_by(subid) %>% summarise(
  AnyRunRetained=any(included),
  AllRunsRetained=all(included)
  )

table(sst_accuracy_by_run$stop_prop_correct_too_low)

table(removal_summary_stats$AnyRunRetained)

table(sst_accuracy_by_run$stop_prop_correct_too_high)

table(removal_summary_stats$AllRunsRetained)

ggsave(paste0(output_folder, "/fig_accuracy_supp.svg"),width = 6,height=4)
ggsave(paste0(output_folder, "/fig_accuracy_supp.png"),width = 6,height=4)


```

# How many trials follow a stop trial?