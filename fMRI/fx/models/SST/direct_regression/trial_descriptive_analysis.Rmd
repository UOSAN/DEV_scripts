---
title: "learning analysis, new subjects"
author: "Ben Smith"
date: "2023-03-06"
output: 
  html_document: 
    toc: true
    toc_float: true
    code_folding: hide
    theme: spacelab
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,warning = FALSE)
```

We've noticed an accumbens signal that has a particularly pronounced CS-FS difference among late trials.

That led us to ask: is it correlated with reaction time; specifically, 

1) is accumbens BOLD CS-FS contrast at tone+5 s (which reacts negatively) negatively related to longer reaction times in subsequent trials, and 
2) is accumbens bold CS-FS contrast at tone+9 (which reacts positively) positively related to longer reaction times in subsequent trials?

We are really mostly interested in FS so at the trial level we'd do

1) is accumbens BOLD FS contrast at tone+5 s (which reacts positively) positively related to longer reaction times in subsequent trials, and 
2) is accumbens bold FS contrast at tone+9 (which reacts negatively) negatively related to longer reaction times in subsequent trials?

# Prep

```{r}
library(tidyverse)
Sys.setenv(R_CONFIG_ACTIVE = Sys.info()["nodename"])
print(Sys.info()["nodename"])

```

```{r}
dropbbox_dir <- config::get("dev_analysis_data_dir")

```



```{r}
time_points <- readr::read_csv(paste0(dropbbox_dir,"/SST_roi_by_time_point.csv"))
```

So how do we design this experiment; what are we correlating over, exactly? Some designs are:

1. Across subject, so:
  a. apply the script I have created on late trials to get average measurements every 10 s--maybe the last half or third of the task, not just the last few, but do this at a per subject level
  b. take the MAXIMUM accumbens activity at the 1-9 s range across trials for each subject (to get the peak), and the MINIMUM accumbens activity at the 4-12 s range (to get the trough)
  c. correlate across subject average reaction times, or post-pre change in reaction times

2. Within subject, so:
  a. get peak and trough accumbens signal for each FS trial in the last third of the task. Perhaps use the difference between the peak and trough as your measure. Though we're really now kind of getting a crude HRF...the advantage of this measure is we aren't bound to a particular shape of it, which is probably useful.
  b. get (i) reaction time and (ii) post-pre difference for subsequent go trial
  c. correlate the difference of peak and trough gathered in (a) with the two measures in (b). Summarize in two ways:
    i. get average correlations within-subject, then average across subjects as a crude multi-level model to test across subject
    ii. apply a true multi-level model
    
We'll want to re-use existing pre-post data.

So--this will yield quite different data to the data we used previously!


```{r}
roi_cols <- colnames(time_points)[grepl("harvardoxford",colnames(time_points))]
time_points$tr_roi_mean <- rowMeans(time_points[,roi_cols])
time_points<- 
  time_points %>% group_by(subid,wave) %>%
  mutate(run_mean_across_rois = mean(tr_roi_mean, na.rm = TRUE))

#now mean-center the ROIs
time_points_c<-time_points
for (roi_col in roi_cols){
  time_points_c[,roi_col]<-time_points_c[,roi_col]-time_points_c$run_mean_across_rois
}

#roi_cols <- colnames(time_points_c)[grepl("harvardoxford",colnames(time_points_c))]
#roi_cols_all <- colnames(time_points_c)#[grepl("((?<=harvardoxford-.{0,3}cortical_prob_)(.*))|(CueFollowing\\(CS\\>FS\\).*)",colnames(time_points_c),perl=TRUE)]
roi_detect_pattern<-"((?<=harvardoxford-.{0,3}cortical_prob_)(.*))|(CueFollowing\\(CS\\>FS\\).*)"

roi_cols_vec <- colnames(time_points_c) %>% stringr::str_detect(pattern = roi_detect_pattern)
new_roi_cols <- colnames(time_points_c) %>% stringr::str_extract_all(pattern = roi_detect_pattern) %>% unlist
unique(new_roi_cols)
colnames(time_points_c)[roi_cols_vec] <- new_roi_cols

```

We need to group by subject, wave, and trial, select just the FailedStop trials, and just the high trial numbers, then get the min and max accumbens activity. We could even do a long transform across the ROIs, then also group by ROI and get the min and max for ROIs

So let's first long transform the ROIs
```{r}

tpc_long<-time_points_c %>% pivot_longer(cols=all_of(new_roi_cols),names_to="ROI",values_to="value")

```


Now do the grouping and summarizing.

We define a peak period and trough period based on the previously observed shape of the accumbens response in the FS trial. This will put a peak around 2-6 seconds and a trough around 7-10 seconds. These values were chosen subjectively to try to encompass the peak and trough allowing for as much variability as possible without grabbing unrelated data from other time points. With a TR of 2.0 we should always have one or two images to grab from within these ranges, too.

```{r}

trial_summary_data <- tpc_long %>% 
  #filter(condition=="FailedStop") %>% 
  group_by(subid,wave,trial_n,ROI, condition) %>%
  summarise(
    peak=max(value[offset>=1.0 & offset <=5.0],na.rm = TRUE),
    trough = min(value[offset>=0.0 & offset <=5.0],na.rm = TRUE),
    peak_time = offset[offset>=1.0 & offset <=5.0][value[offset>=1.0 & offset <=5.0]==max(value[offset>=1.0 & offset <=5.0],na.rm = TRUE)],
    trough_time = offset[offset>=0.0 & offset <=5.0][value[offset>=0.0 & offset <=5.0]==min(value[offset>=0.0 & offset <=5.0],na.rm = TRUE)]
  )
  

trial_summary_data$response_amplitude <-trial_summary_data$peak-trial_summary_data$trough

ggplot(trial_summary_data %>% filter(condition=="FailedStop"),aes(response_amplitude,group=ROI,color=ROI))+geom_density(adjust=0.5)
```

OK. So now, let's try to merge in that with post-pre RTs. Where do we get those from?


## get the SST Post-pre data

```{r}
source(paste0(config::get("ben_dev_data_analysis"),"SST_processing.R"))

dropbox_file_dir = config::get("dev_analysis_data_dir")
sst_all_data_filepath <- paste0(dropbox_file_dir,"sst_behavioral_data_all.csv")

sst_all_data_raw <- readr::read_csv(sst_all_data_filepath)
sst_all_data<-clean_sst_data(sst_all_data_raw)
sst_all_data <- get_expected_tone_time(sst_all_data)

sst_all_data<-calculate_response_latency(sst_all_data)
sst_all_data<-calculate_rpe(sst_all_data)

#calculate proportion of stop trials that were correct. ideally should be 50/50 but let's check it.
sst_all_data<-get_more_sst_stats(sst_all_data)

#sst_all_data %>% select(subid, waveid, runid,condition,stop_prop_correct,nth_reaction_time,ssrt_d1)
# sst_all_data %>% select(
#   subid, waveid, runid, reaction_time_clean, SSD_recorded,condition, last_tone_delay, trials_since_last_SSD,last_correct_go)# %>%
#   #View()

```






```{r}
readr::write_csv(sst_all_data,file=paste0(dropbox_file_dir,"sst_behavioral_data_all_with_analysis.csv"))
```




```{r}
post_pre_rt_data <- sst_all_data%>% 
  filter(condition!="Cue") #%>%
  #select(trial_n,reaction_time,subid,waveid,runid,condition,post_pre_rt_change)
```


## Prepare neural data



```{r}
trial_summary_data$ROI_delateralized <-  trial_summary_data$ROI %>% str_replace_all("(Left|Right)\\s","")


trial_summary_data_delat <- trial_summary_data %>% 
  #filter(ROI %in% c("Left Accumbens","Right Accumbens")) %>% 
  group_by(subid,wave,trial_n, ROI_delateralized,condition) %>%
  summarize(peak=mean(peak),
            trough=mean(trough),
            peak_time=mean(peak_time),
            trough_time=mean(trough_time),
            response_amplitude=mean(response_amplitude))

```


## Merge the datasets



```{r}


trial_summary_data_delat_pp <- merge(trial_summary_data_delat,post_pre_rt_data,by.x = c("subid","wave","trial_n","condition"),by.y=c("subid","waveid","trial_n","condition"),all.x = TRUE)
  
trial_summary_data_delat_pp$trial_n_c<-128-trial_summary_data_delat_pp$trial_n
  
FS_summary_data_accumbens <- trial_summary_data_delat_pp %>% 
  filter(ROI_delateralized=="Accumbens" & condition=="FailedStop") %>% select(-ROI_delateralized)



FS_neural_behav_data_not_na<-FS_summary_data_accumbens[
  rowSums(is.na(FS_summary_data_accumbens[,c("response_amplitude","post_pre_rt_change")]))==0 & #no NA values in correlation and
    is.finite(FS_summary_data_accumbens$response_amplitude) & is.finite(FS_summary_data_accumbens$post_pre_rt_change) #no infinite values
    ,]

```

# Single-level tests

```{r}

```


```{r}
FS_by_subj_raw <- FS_neural_behav_data_not_na %>% group_by(subid) %>%
  mutate(trial_count=n())
FS_by_subj <- FS_by_subj_raw %>% filter(trial_count >2) %>%
  summarize(peak_cor_est = cor.test(peak,post_pre_rt_change)$estimate,
            amplitude_cor_est = cor.test(response_amplitude,post_pre_rt_change)$estimate,
            mean_post_pre_rt_change=mean(post_pre_rt_change),
            mean_post_current_rt_change=mean(post_current_rt_change),
            mean_peak=mean(peak),
            mean_trough=mean(trough),
            mean_amplitude=mean(response_amplitude),
            trial_count=n()
            )

t.test(FS_by_subj$peak_cor_est)
t.test(FS_by_subj$amplitude_cor_est)


```
OK. So our "amplitude" measure correlates within subjects (p<0.05), when measuring the correlations within subject and then taking the average.

Would strengthen the data

```{r}
hist(FS_by_subj$peak_cor_est,breaks=40)
```
```{r}
hist(FS_by_subj$mean_post_pre_rt_change)
hist(FS_by_subj$mean_peak)
```


```{r}

cor.test(FS_by_subj$mean_post_pre_rt_change,FS_by_subj$mean_trough)

cor.test(FS_by_subj$mean_post_pre_rt_change,FS_by_subj$mean_peak)

cor.test(FS_by_subj$mean_post_pre_rt_change,FS_by_subj$mean_amplitude)
```


```{r}
cor.test(FS_by_subj$mean_post_pre_rt_change,FS_by_subj$mean_peak,method="spearman")
```

Not significant within subjects, either. OK. We can do a multi-level model but I don't think we're quite capable of pulling this out.


If you take away the accumbens selection, you do get some significant results, but these are taking false precision...

## Between subjects



```{r}

trial_neural_behav_data_not_na<-trial_summary_data_delat_pp[
  rowSums(is.na(trial_summary_data_delat_pp[,c("response_amplitude","post_pre_rt_change")]))==0 & #no NA values in correlation and
    is.finite(trial_summary_data_delat_pp$response_amplitude) & is.finite(trial_summary_data_delat_pp$post_pre_rt_change) #no infinite values
    ,]

trial_neural_behav_data_not_na$trial_n_c<-128-trial_neural_behav_data_not_na$trial_n
trial_neural_behav_data_not_na$trial_n_n<-scale(trial_neural_behav_data_not_na$trial_n_c)


FS_neural_behav_data_not_na<-trial_neural_behav_data_not_na[trial_neural_behav_data_not_na$condition=="FailedStop",]
```


```{r}

full_run_data <- sst_all_data %>% group_by(subid,waveid,runid) %>%
  summarize(mean_SSD_all_stop_trials=mean(SSD_recorded[SSD_recorded!=0]))

FS_by_subj_raw <- FS_neural_behav_data_not_na %>% group_by(ROI_delateralized, subid) %>%
  mutate(trial_count=n())
FS_by_subj <- FS_by_subj_raw %>% group_by(ROI_delateralized, subid,trial_count) %>% filter(trial_count >2) %>%
  summarize(peak_cor_est = cor.test(peak,post_pre_rt_change)$estimate,
            trough_cor_est = cor.test(trough,post_pre_rt_change)$estimate,
            amplitude_cor_est = cor.test(response_amplitude,post_pre_rt_change)$estimate,
            mean_post_pre_rt_change=mean(post_pre_rt_change),
            mean_post_current_rt_change=mean(post_current_rt_change),
            mean_post_rt=mean(next_reaction_time),
            mean_peak=mean(peak),
            mean_trough=mean(trough),
            mean_amplitude=mean(response_amplitude),
            mean_peak_offset=mean(peak_time),
            mean_trough_offset=mean(trough_time),
            
            ) 
FS_by_subj<-merge(FS_by_subj,
                  full_run_data %>% filter(runid==1 & waveid==1),
                  by='subid',how='left'
                  )

FS_neural_behav_data_not_na <- merge(
  FS_neural_behav_data_not_na %>% filter(runid==1),
  full_run_data %>% filter(runid==1 & waveid==1),
                  by=c('subid','runid'),how='left'
                  )

```

## Per subject:

```{r}

roi_within_subj_list<-list()

for (roi_i in unique(FS_by_subj$ROI_delateralized)){
  # cat("\n")
  # cat(roi_i)
  # cat("\n")
  peak<-t.test(FS_by_subj %>% filter(ROI_delateralized==roi_i) %>% .$peak_cor_est)
  trough<-t.test(FS_by_subj %>% filter(ROI_delateralized==roi_i) %>% .$trough_cor_est)
  amplitude<-t.test(FS_by_subj %>% filter(ROI_delateralized==roi_i) %>% .$amplitude_cor_est)
  # print(peak)
  # print(trough)
  # print(amplitude)
  
  roi_within_subj_row<-data.frame("roi"=roi_i,"measure"="peak","t"=peak[[1]],"estimate"=peak$estimate, "pvalue"=peak$p.value)
  roi_within_subj_list<-append(roi_within_subj_list,list(roi_within_subj_row))
  roi_within_subj_row<-data.frame("roi"=roi_i,"measure"="trough","t"=trough[[1]],"estimate"=trough$estimate, "pvalue"=trough$p.value)
  roi_within_subj_list<-append(roi_within_subj_list,list(roi_within_subj_row))
  roi_within_subj_row<-data.frame("roi"=roi_i,"measure"="amplitude","t"=amplitude[[1]],"estimate"=amplitude$estimate, "pvalue"=amplitude$p.value)
  roi_within_subj_list<-append(roi_within_subj_list,list(roi_within_subj_row))
  # cat("---\n")
}
print("example:")
cat(roi_i)
cat("\n")
print(peak)
  print(trough)
  print(amplitude)
  cat("---\n")
roi_within_subj_df <- do.call(rbind,roi_within_subj_list)

library(stats)
roi_within_subj_df$pvalue_fdr_adjust<-p.adjust(roi_within_subj_df$pvalue,method="fdr")
roi_within_subj_df <- roi_within_subj_df %>% mutate(signif=ifelse(pvalue_fdr_adjust<0.05,"*",""))

print("summary:")
print(roi_within_subj_df)
```

Look

## across subjects

```{r}


roi_inddiv_list<-list()
for (roi_i in unique(FS_by_subj$ROI_delateralized)){
  cat("\n")
  cat(roi_i)
  cat("\n")
  FS_by_subj_i <- FS_by_subj %>% filter(ROI_delateralized==roi_i)
  
  peak<-cor.test(FS_by_subj_i$mean_post_pre_rt_change,FS_by_subj_i$mean_peak)
  trough<-cor.test(FS_by_subj_i$mean_post_pre_rt_change,FS_by_subj_i$mean_trough)
  amplitude<-cor.test(FS_by_subj_i$mean_post_pre_rt_change,FS_by_subj_i$mean_amplitude)
  #roi_inddiv_row<-data.frame("roi"=character(0),"measure"=character(0),"value"=numeric(0))
  roi_inddiv_row<-data.frame("roi"=roi_i,"measure"="peak","value"=peak[[1]],"estimate"=peak$estimate,"pvalue"=peak$p.value)
  roi_inddiv_list<-append(roi_inddiv_list,list(roi_inddiv_row))
  roi_inddiv_row<-data.frame("roi"=roi_i,"measure"="trough","value"=trough[[1]],"estimate"=trough$estimate,"pvalue"=trough$p.value)
  roi_inddiv_list<-append(roi_inddiv_list,list(roi_inddiv_row))
  roi_inddiv_row<-data.frame("roi"=roi_i,"measure"="amplitude","value"=amplitude[[1]],"estimate"=amplitude$estimate,"pvalue"=amplitude$p.value)
  roi_inddiv_list<-append(roi_inddiv_list,list(roi_inddiv_row))
  # print(peak)
  # print(trough)
  # print(amplitude)
  # cat("---\n")
}

print("example of full analyses for last ROI")
cat(roi_i)
  cat("\n")
print(peak)
print(trough)
print(amplitude)
cat("---\n")
print("summary")
roi_inddiv_df <- do.call(rbind,roi_inddiv_list)

library(stats)
roi_inddiv_df$pvalue_fdr_adjust<-p.adjust(roi_inddiv_df$pvalue,method="fdr")
roi_inddiv_df <- roi_inddiv_df %>% mutate(signif=ifelse(pvalue_fdr_adjust<0.05,"*",""))

print(roi_inddiv_df)
```


# Basic Striatal cluster mixed effects models

The preliminary analysis suggests this should be significant both within and across individuals. Let's see!

First let's see if we should use the trial regressor.

```{r}
#FS_neural_behav_data_not_na$trial_n_c<-128-FS_neural_behav_data_not_na$trial_n

library(lme4)

FS_neural_behav_p <- FS_neural_behav_data_not_na %>% filter(ROI_delateralized=="CueFollowing(CS>FS)striatal_cluster_combined")

```

here, we clearly need to include the trial, but no evidence for including the quadratic.





By constraining our peak much more relative to the unconstrained peak, we have a much, much stronger effect in the linear model. It oddly doesn't really show up in the pairwise within-subject correlation; in fact, we lose the putamen effect we had previously observed.

## Figuring out a pre-trial confound

There's a possible confound here in that perhaps the pre-trial reaction time is what is actually driving the correlation. To do address this there is a simple check and a more comprehensive check. The simple check is to re-run with pre and post separated. The more comprehensive check is to include both CS and FS.

### separate pre and post


There is a lagging rt effect, but the leading effect appears to be bigger. what about if we include lagging, then the difference?





## include all trial types in the model


```{r}

trial_neural_behav_data_not_na<-trial_summary_data_delat_pp[
  rowSums(is.na(trial_summary_data_delat_pp[,c("response_amplitude","post_pre_rt_change")]))==0 & #no NA values in correlation and
    is.finite(trial_summary_data_delat_pp$response_amplitude) & is.finite(trial_summary_data_delat_pp$post_pre_rt_change) #no infinite values
    ,]

trial_neural_behav_data_not_na$trial_n_c<-128-trial_neural_behav_data_not_na$trial_n


trial_neural_behav_roi <- trial_neural_behav_data_not_na %>% filter(ROI_delateralized=="CueFollowing(CS>FS)striatal_cluster_combined")

trial_neural_behav_roi$condition<-(
  factor(trial_neural_behav_roi$condition,
            levels=c("CorrectGo","CorrectStop","FailedGo","FailedStop"),
            ordered=FALSE))
```

```{r}
trial_neural_behav_roi$trial_n_s<-scale(trial_neural_behav_roi$trial_n_c)

```




```{r}
trial_neural_behav_roi$trial_n_s<-scale(trial_neural_behav_roi$trial_n_c)

```


Perhaps it's good to know that SSD wasn't a specific factor.

We should probably control for SSD at an individual level though.



# Learning the probability of a stop trial

But at the same time, we're also learning the prior probability of a trial being a stop trial.

There are actually several possible intuitive models for this:

(1) "independent sample" model. take a sample of all trials seen so far, and the proportion of stop trials in that sample is the proportion that exists.

(2) "increasing probability" model. The longer we've gone without a stop trial, teh more likely we'll see another one. The simplest way to model this might simply be "number of trials since the last item.

We have done both of these before, right???

What does that learning look like? It is likely to be a model of the change in RT on each trial

Let's consider some candidate mechanisms

### P_stop trial and number of trials since last tone

I think it's good to consider these together since they might work against each other.


```{r add_standardized}

FS_neural_behav_p$peak_z<-scale(FS_neural_behav_p$peak)
FS_neural_behav_p$post_pre_rt_change_z<-scale(FS_neural_behav_p$post_pre_rt_change)
FS_neural_behav_p$P_stop_trial_change_z<-scale(FS_neural_behav_p$P_stop_trial_change)
FS_neural_behav_p$P_stop_trial_z<-scale(FS_neural_behav_p$P_stop_trial)

```



It also appears to make the trial number no longer significant. that's probably because it basically follows a curve from the start of trials to the end. This curve is consistent for every run.

```{r}


P_stop_trial_over_trials<-FS_neural_behav_p %>% group_by(trial_n) %>% summarize(
  mean_P_stop_trial=mean(P_stop_trial,na.rm=TRUE),
  sd_P_stop_trial=sd(P_stop_trial,na.rm=TRUE),
  mean_post_pre_rt_change = mean(post_pre_rt_change,na.rm=TRUE),
  sd_post_pre_rt_change = sd(post_pre_rt_change,na.rm=TRUE)
  
  )
ggplot(P_stop_trial_over_trials,aes(x=trial_n,y=mean_P_stop_trial))+geom_line()+geom_point()+geom_vline(xintercept = c(25,50),color="#009933")+
  #label every multiple of 50 on the x-axis, and also mark 25 as a special case
  scale_x_continuous(breaks=c(seq(0,max(FS_neural_behav_p$trial_n),by=50),25))+
  #add a legend
  scale_color_manual(name="",values=c("blue"="#009933"))+
  #add a title
  ggtitle("P(Stop) Change Over Trials")+
  #add axis labels
  xlab("Trial Number")+ylab("P(Stop) Change")

```



```{r}


ggplot(P_stop_trial_over_trials,aes(x=trial_n,y=mean_post_pre_rt_change))+geom_line()+geom_point()+geom_vline(xintercept = c(25,50),color="#009933")+
  #label every multiple of 50 on the x-axis, and also mark 25 as a special case
  scale_x_continuous(breaks=c(seq(0,max(FS_neural_behav_p$trial_n),by=50),25))+
  #add a legend
  scale_color_manual(name="",values=c("blue"="#009933"))+
  #add a title
  ggtitle("Post-Pre RT Change Over Trials")+
  #add axis labels
  xlab("Trial Number")+ylab("Post-Pre RT Change (ms)")

```

We could visualize all subjects here as well:


```{r}
ggplot(FS_neural_behav_p,aes(x=trial_n,y=post_pre_rt_change,group=interaction(subid,waveid,runid)))+
  geom_line(alpha=0.1)+geom_line(
    mapping=aes(x=trial_n,y=mean_post_pre_rt_change,group=NA),
    data=P_stop_trial_over_trials,color="blue")+geom_vline(xintercept = c(25,50),color="#009933")+
  #label every multiple of 50 on the x-axis, and also mark 25 as a special case
  scale_x_continuous(breaks=c(seq(0,max(FS_neural_behav_p$trial_n),by=50),25))+
  #add a legend
  scale_color_manual(name="",values=c("blue"="#009933"))+
  #add a title
  ggtitle("Post-Pre RT Change Over Trials")+
  #add axis labels
  xlab("Trial Number")+ylab("Post-Pre RT Change (ms)")
```

