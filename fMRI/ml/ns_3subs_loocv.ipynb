{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "million-maine",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 5 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "0    205\n",
      "1    115\n",
      "Name: response, dtype: int64\n",
      "0    205\n",
      "1    115\n",
      "Name: response, dtype: int64\n",
      "False    320\n",
      "Name: response, dtype: int64\n",
      "320\n",
      "320\n",
      "295.6 MiB\n",
      "1.1 GiB\n",
      "starting LeaveOneOut\n",
      "finished preprocessing\n",
      "Groups are the same.\n",
      "fold 1 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV010']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. predicting. test score was:. -0.33333333333333326\n",
      "fold 2 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV009']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. -0.6288441145281018\n",
      "fold 3 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV006']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. -0.3852813852813852\n",
      "fold 4 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV001']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. -0.7622027534418023\n",
      "fold 5 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV005']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. -0.5133004926108375\n",
      "-0.33333333333333326\n",
      "-0.33333333333333326\n",
      "finished learning\n",
      "saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from apply_dichotomized_prediction_loocv_and_save import *\n",
    "#     def apply_loocv_and_save(\n",
    "#     brain_data_filepath = '../data/Brain_Data_2sns_60subs.pkl',\n",
    "#     train_test_markers_filepath = \"../data/train_test_markers_20210601T183243.csv\",\n",
    "#     results_filepath=\"\",\n",
    "#     subjs_to_use = None #set this to get a subset, otherwise use all of them.\n",
    "# ):\n",
    "    \n",
    "apply_dichotomized_prediction_loocv_and_save(\n",
    "    results_filepath=\"../data/cv_train_test_ns_5subjs_outer_n_loocv.pkl\",\n",
    "    brain_data_filepath = '../data/Brain_Data_ns_5subs.pkl',\n",
    "    train_test_markers_filepath = \"../data/train_test_markers_20210601T183243.csv\"\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mathematical-fountain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(\"python initialized for apply_loocv_and_save\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltools as nlt\n",
    "import nilearn as nil\n",
    "import nibabel as nib\n",
    "import warnings\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "import dev_wtp_io_utils\n",
    "import gc #garbage collection\n",
    "from nilearn import plotting\n",
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "import os, warnings\n",
    "import pickle\n",
    "\n",
    "cpus_available = int(os.getenv('CPUS_PER_TASK'))\n",
    "#custom thing I have set in my jupyter notebook task.\n",
    "print(cpus_available)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "french-contents",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filepath=\"../data/cv_train_test_ns_5subjs_outer_n_loocv.pkl\"\n",
    "brain_data_filepath = '../data/Brain_Data_ns_5subs.pkl'\n",
    "train_test_markers_filepath = \"../data/train_test_markers_20210601T183243.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impossible-bible",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 5 subjects overlapping between the subjects marked for train data and the training dump file itself.\n"
     ]
    }
   ],
   "source": [
    "test_train_set = pd.read_csv(train_test_markers_filepath)\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "dev_wtp_io_utils.check_BD_against_test_train_set(Brain_Data_allsubs,test_train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hybrid-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= Brain_Data_allsubs.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "located-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "wsr_means = pd.DataFrame(X.groupby(['wave','subject','run']).response.mean()).reset_index()\n",
    "wsr_means = wsr_means.rename(columns={'response':'response_mean'})\n",
    "wsr_sds = pd.DataFrame(X.groupby(['wave','subject','run']).response.std()).reset_index()\n",
    "wsr_sds = wsr_sds.rename(columns={'response':'response_sd'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "veterinary-occasion",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_augmented = X[['run','wave','subject','response']].copy().merge(wsr_means).merge(wsr_sds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "burning-primary",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_norm = (X_augmented.response-X_augmented.response_mean)/X_augmented.response_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "loaded-writing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.175024\n",
       "1      0.130558\n",
       "2      0.130558\n",
       "3     -0.913908\n",
       "4      1.175024\n",
       "         ...   \n",
       "315   -1.009009\n",
       "316    1.614415\n",
       "317   -0.134535\n",
       "318         NaN\n",
       "319         NaN\n",
       "Length: 320, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "legislative-child",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.175024\n",
       "1      0.130558\n",
       "2      0.130558\n",
       "3     -0.913908\n",
       "4      1.175024\n",
       "         ...   \n",
       "315   -1.009009\n",
       "316    1.614415\n",
       "317   -0.134535\n",
       "318         NaN\n",
       "319         NaN\n",
       "Length: 320, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_normalize(X):\n",
    "    wsr_means = pd.DataFrame(X.groupby(['wave','subject','run']).response.mean()).reset_index()\n",
    "    wsr_means = wsr_means.rename(columns={'response':'response_mean'})\n",
    "    wsr_sds = pd.DataFrame(X.groupby(['wave','subject','run']).response.std()).reset_index()\n",
    "    wsr_sds = wsr_sds.rename(columns={'response':'response_sd'})\n",
    "    \n",
    "    X_augmented = X[['run','wave','subject','response']].copy().merge(wsr_means).merge(wsr_sds)\n",
    "\n",
    "    response_norm = (X_augmented.response-X_augmented.response_mean)/X_augmented.response_sd\n",
    "    \n",
    "    #now we need to group by \n",
    "    return(response_norm)\n",
    "    \n",
    "transform_normalize(Brain_Data_allsubs.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "attractive-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "4\n",
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 5 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      " 0.000000    9\n",
      " 0.091902    9\n",
      "-0.824040    8\n",
      "-0.835937    8\n",
      "-0.484123    8\n",
      "            ..\n",
      " 2.219490    1\n",
      " 1.871942    1\n",
      "-0.098346    1\n",
      " 0.866025    1\n",
      " 0.727094    1\n",
      "Length: 76, dtype: int64\n",
      " 0.000000    9\n",
      " 0.091902    9\n",
      "-0.824040    8\n",
      "-0.835937    8\n",
      "-0.484123    8\n",
      "            ..\n",
      " 2.219490    1\n",
      " 1.871942    1\n",
      "-0.098346    1\n",
      " 0.866025    1\n",
      " 0.727094    1\n",
      "Length: 76, dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "response_transform_func: 136\n",
      "results_filepath: 98\n",
      "train_test_markers_filepath: 95\n",
      "brain_data_filepath: 80\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 16\n",
      "False    307\n",
      "True      13\n",
      "dtype: int64\n",
      "307\n",
      "320\n",
      "284.3 MiB\n",
      "1.0 GiB\n",
      "starting LeaveOneOut\n",
      "finished preprocessing\n",
      "Groups are the same.\n",
      "using default regressor. fold 1 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV010']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. predicting. test score was:. 0.29401979060088\n",
      "fold 2 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV009']. prepping fold data.... regressing.... 1.6 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.07746336565448064\n",
      "fold 3 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV006']. prepping fold data.... regressing.... 1.7 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.2231032326643425\n",
      "fold 4 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV001']. prepping fold data.... regressing.... 1.6 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.34048640774154815\n",
      "fold 5 of 5\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV005']. prepping fold data.... regressing.... 1.6 GiB. trying regressor 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.2120862326740096\n",
      "0.29401979060088\n",
      "0.29401979060088\n",
      "finished learning\n",
      "saved.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from apply_loocv_and_save import *\n",
    "\n",
    "    \n",
    "apply_loocv_and_save(\n",
    "    results_filepath=\"../data/cv_train_test_ns_5subjs_outer_n_loocv.pkl\",\n",
    "    brain_data_filepath = '../data/Brain_Data_ns_5subs.pkl',\n",
    "    train_test_markers_filepath = \"../data/train_test_markers_20210601T183243.csv\",\n",
    "    response_transform_func =transform_normalize\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-civilian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
