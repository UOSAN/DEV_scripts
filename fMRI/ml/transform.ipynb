{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "focused-vegetable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from apply_loocv_and_save import *\n",
    "import gc\n",
    "import nibabel as nib\n",
    "\n",
    "\n",
    "\n",
    "data_path = '/gpfs/projects/sanlab/bsmith16/data/'\n",
    "mask_nifti = nib.load(data_path + 'prefrontal_cortex.nii.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "offshore-explanation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_normalize(X):\n",
    "    wsr_means = pd.DataFrame(X.groupby(['wave','subject','run']).response.mean()).reset_index()\n",
    "    wsr_means = wsr_means.rename(columns={'response':'response_mean'})\n",
    "    wsr_sds = pd.DataFrame(X.groupby(['wave','subject','run']).response.std()).reset_index()\n",
    "    wsr_sds = wsr_sds.rename(columns={'response':'response_sd'})\n",
    "    \n",
    "    X_augmented = X[['run','wave','subject','response']].copy().merge(wsr_means).merge(wsr_sds)\n",
    "    response_norm = (X_augmented.response-X_augmented.response_mean)/X_augmented.response_sd\n",
    "    #now we need to group by \n",
    "    return(response_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "liquid-moisture",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_binary(X):\n",
    "    wsr_means = pd.DataFrame(X.groupby(['wave','subject','run']).response.mean()).reset_index()\n",
    "    wsr_means = wsr_means.rename(columns={'response':'response_mean'})\n",
    "    X_augmented = X[['run','wave','subject','response']].copy().merge(wsr_means)\n",
    "    response_norm = (X_augmented.response>X_augmented.response_mean).astype(float)\n",
    "    return(response_norm)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "defensive-timing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 60 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "5.0    1164\n",
      "6.0    1018\n",
      "7.0     904\n",
      "8.0     604\n",
      "Name: response, dtype: int64\n",
      "5.0    1164\n",
      "6.0    1018\n",
      "7.0     904\n",
      "8.0     604\n",
      "Name: response, dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 124\n",
      "train_test_markers_filepath: 123\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 28\n",
      "response_transform_func: 16\n",
      "False    3690\n",
      "True      150\n",
      "Name: response, dtype: int64\n",
      "3690\n",
      "3840\n",
      "3.4 GiB\n",
      "3.3 GiB\n",
      "using 5 subjects\n",
      "starting LeaveOneOut\n",
      "finished preprocessing\n",
      "running one more time on whole dataset for beta map\n",
      "[NiftiMasker.fit] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:   12.2s remaining:    8.1s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "finished learning\n",
      "saved.\n"
     ]
    }
   ],
   "source": [
    "data_path = '/gpfs/projects/sanlab/bsmith16/data/'\n",
    "# HRF 2s\n",
    "dataset_name = 'ns_w_hrf_from_spm'\n",
    "apply_single_fit_and_save(\n",
    "    results_filepath=data_path + \"train_test_simple_results_\" + dataset_name + \"_5subs.pkl\",\n",
    "    brain_data_filepath = data_path + 'Brain_Data_' + dataset_name + '_60subs.pkl',\n",
    "    train_test_markers_filepath = data_path + \"train_test_markers_20210601T183243.csv\",\n",
    "    subjs_to_use = 5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dangerous-destiny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 60 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      " 0.000000    73\n",
      "-0.968246    34\n",
      "-0.601425    22\n",
      " 0.612372    21\n",
      "-0.866025    21\n",
      "             ..\n",
      " 2.088430     1\n",
      " 2.390955     1\n",
      " 2.624612     1\n",
      "-1.852396     1\n",
      "-2.213594     1\n",
      "Length: 774, dtype: int64\n",
      " 0.000000    73\n",
      "-0.968246    34\n",
      "-0.601425    22\n",
      " 0.612372    21\n",
      "-0.866025    21\n",
      "             ..\n",
      " 2.088430     1\n",
      " 2.390955     1\n",
      " 2.624612     1\n",
      "-1.852396     1\n",
      "-2.213594     1\n",
      "Length: 774, dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "response_transform_func: 136\n",
      "brain_data_filepath: 124\n",
      "train_test_markers_filepath: 123\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 28\n",
      "False    3690\n",
      "True      150\n",
      "dtype: int64\n",
      "3690\n",
      "3840\n",
      "3.4 GiB\n",
      "3.3 GiB\n",
      "using 5 subjects\n",
      "starting LeaveOneOut\n",
      "finished preprocessing\n",
      "running one more time on whole dataset for beta map\n",
      "[NiftiMasker.fit] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:   11.2s remaining:    7.5s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 307),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "finished learning\n",
      "saved.\n"
     ]
    }
   ],
   "source": [
    "data_path = '/gpfs/projects/sanlab/bsmith16/data/'\n",
    "# HRF 2s\n",
    "dataset_name = 'ns_w_hrf_from_spm'\n",
    "apply_single_fit_and_save(\n",
    "    results_filepath=data_path + \"train_test_simple_results_\" + dataset_name + \"_5subs.pkl\",\n",
    "    brain_data_filepath = data_path + 'Brain_Data_' + dataset_name + '_60subs.pkl',\n",
    "    train_test_markers_filepath = data_path + \"train_test_markers_20210601T183243.csv\",\n",
    "    response_transform_func = transform_normalize,\n",
    "    subjs_to_use = 5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "split-algebra",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 60 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "0.0    2136\n",
      "1.0    1704\n",
      "dtype: int64\n",
      "0.0    2136\n",
      "1.0    1704\n",
      "dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "response_transform_func: 136\n",
      "brain_data_filepath: 124\n",
      "train_test_markers_filepath: 123\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 28\n",
      "False    3840\n",
      "dtype: int64\n",
      "3840\n",
      "3840\n",
      "3.4 GiB\n",
      "3.4 GiB\n",
      "using 5 subjects\n",
      "starting LeaveOneOut\n",
      "finished preprocessing\n",
      "running one more time on whole dataset for beta map\n",
      "[NiftiMasker.fit] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 320),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 320),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "[Parallel(n_jobs=3)]: Done   3 out of   5 | elapsed:   12.0s remaining:    8.0s\n",
      "[Parallel(n_jobs=3)]: Done   5 out of   5 | elapsed:   22.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 320),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(91, 109, 91, 320),\n",
      "affine=array([[  -2.,    0.,    0.,   90.],\n",
      "       [   0.,    2.,    0., -126.],\n",
      "       [   0.,    0.,    2.,  -72.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "finished learning\n",
      "saved.\n"
     ]
    }
   ],
   "source": [
    "data_path = '/gpfs/projects/sanlab/bsmith16/data/'\n",
    "# HRF 2s\n",
    "dataset_name = 'ns_w_hrf_from_spm'\n",
    "apply_single_fit_and_save(\n",
    "    results_filepath=data_path + \"train_test_simple_results_\" + dataset_name + \"_5subs.pkl\",\n",
    "    brain_data_filepath = data_path + 'Brain_Data_' + dataset_name + '_60subs.pkl',\n",
    "    train_test_markers_filepath = data_path + \"train_test_markers_20210601T183243.csv\",\n",
    "    response_transform_func = transform_binary,\n",
    "    subjs_to_use = 5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-university",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
