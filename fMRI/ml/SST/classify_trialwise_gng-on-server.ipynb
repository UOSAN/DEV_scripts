{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying trialwise CorrectGo and NoGo trials\n",
    "\n",
    "There are a number of steps to this. Hopefully we can recycle previous code and be up fairly quickly!\n",
    "\n",
    "1. Load beta data. Ideally this process should include a cache into a pure python object so we don't have to reload it each time.\n",
    "2. Preprocess the data.\n",
    "3. Do cross-validated training and testing. Ideally an inner loop to select best parameters, an outer loop to get cross-validated performance, and final training over all the data to get an image. The inner loop can be probably be handled within the package we use probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "from apply_loocv_and_save import load_and_preprocess\n",
    "from dev_utils import read_yaml_for_host\n",
    "import warnings\n",
    "\n",
    "\n",
    "config_data = read_yaml_for_host(\"sst_config.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "from nilearn.decoding import DecoderRegressor,Decoder\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(cpus_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = config_data['nonbids_data_path']\n",
    "ml_data_folderpath = nonbids_data_path + \"fMRI/ml\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading beta data\n",
    "\n",
    "beta data is generally written in `load_multisubject_brain_data_sst_w1.ipynb`.\n",
    "\n",
    "We just have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-77f1eebe0208>:2: UserWarning: not sure if this file holds up--it was created in 2021; need to see if it's still valid\n",
      "  warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n"
     ]
    }
   ],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_15subs_correct_cond.pkl'\n",
    "warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20220818T144138.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 15 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 62918\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1549\n",
      "1549\n",
      "cleaning memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-71293bf63513>:8: UserWarning: the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\n",
      "  warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm not 100% clear this is good data, but it looks good; let's try it for now and move ahead. How do we classify it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>wave</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.25834</td>\n",
       "      <td>correct-stop</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0001.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.75834</td>\n",
       "      <td>0.40082</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0003.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.51390</td>\n",
       "      <td>0.66191</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0005.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12.52780</td>\n",
       "      <td>0.51712</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0009.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.90975</td>\n",
       "      <td>0.39906</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0011.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18.35212</td>\n",
       "      <td>0.33093</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0013.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>24.42644</td>\n",
       "      <td>0.72669</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0017.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33.87298</td>\n",
       "      <td>0.43048</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0021.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>38.87993</td>\n",
       "      <td>0.40215</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0023.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>42.57230</td>\n",
       "      <td>0.50627</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0025.nii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      onset  duration    trial_type subject   wave           beta\n",
       "0   0.00000   2.25834  correct-stop  DEV005  wave1  beta_0001.nii\n",
       "1   2.75834   0.40082    correct-go  DEV005  wave1  beta_0003.nii\n",
       "2   5.51390   0.66191    correct-go  DEV005  wave1  beta_0005.nii\n",
       "3  12.52780   0.51712    correct-go  DEV005  wave1  beta_0009.nii\n",
       "4  15.90975   0.39906    correct-go  DEV005  wave1  beta_0011.nii\n",
       "5  18.35212   0.33093    correct-go  DEV005  wave1  beta_0013.nii\n",
       "6  24.42644   0.72669    correct-go  DEV005  wave1  beta_0017.nii\n",
       "7  33.87298   0.43048    correct-go  DEV005  wave1  beta_0021.nii\n",
       "8  38.87993   0.40215    correct-go  DEV005  wave1  beta_0023.nii\n",
       "9  42.57230   0.50627    correct-go  DEV005  wave1  beta_0025.nii"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects['metadata'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "correct-go      1378\n",
       "correct-stop     171\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects['y'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nibabel.nifti1.Nifti1Image"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_subjects['X'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to select just the trials we want to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (97, 115, 97, 1536)\n",
      "y (1536,)\n",
      "groups (1536,)\n",
      "metadata (1536, 6)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'SpatialFirstSlicer' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X26sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# great, now use y to pick out the items we want, then filter the other objects accordingly.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X26sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m all_sub_go_stop[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m][include_vec]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X26sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m all_sub_go_stop[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mslicer(include_vec, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X26sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m all_sub_go_stop[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m][include_vec]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X26sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m all_sub_go_stop[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m][include_vec,]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'SpatialFirstSlicer' object is not callable"
     ]
    }
   ],
   "source": [
    "# groups_to_classify = ['correct-go','correct-stop']\n",
    "\n",
    "\n",
    "# # create a vector of booleans that will be used to filter the data\n",
    "# include_vec = all_subjects['y'].apply(lambda x: True if x in groups_to_classify else False)\n",
    "\n",
    "# #print the shape of each object in the dictionary\n",
    "# for key in all_subjects.keys():\n",
    "#     print(key, all_subjects[key].shape)\n",
    "\n",
    "# all_sub_go_stop={}\n",
    "# # great, now use y to pick out the items we want, then filter the other objects accordingly.\n",
    "# all_sub_go_stop['y'] = all_subjects['y'][include_vec]\n",
    "# #slice the nifti object with the vector of booleans\n",
    "# all_sub_go_stop['X'] = all_subjects['X'].slice(include_vec, axis=0)\n",
    "\n",
    "# all_sub_go_stop['groups'] = all_subjects['groups'][include_vec]\n",
    "# all_sub_go_stop['metadata'] = all_subjects['groups'][include_vec,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 115, 97, 1549)\n"
     ]
    }
   ],
   "source": [
    "# get the PFC mask\n",
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')\n",
    "\n",
    "full_img = all_subjects['X']\n",
    "print(full_img.shape)\n",
    "\n",
    "# #now apply the mask to the data using nibabel\n",
    "# masked_img = nl.masking.apply_mask(full_img, mask_nifti)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the y array to an integer array representing the string values of the y array\n",
    "all_subjects['y_cat'] = all_subjects['y'].astype('category')\n",
    "all_subjects['y_int']=all_subjects['y_cat'].cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "I'm going to start with `cv_train_test_sets` and see how that goes. It sems likely it'll have to be re-written somewhat, but it might be a good starting point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups are the same.\n",
      "fold 1 of 3\n",
      "In order to test on a training group of 10 items, holding out the following subjects:['DEV019' 'DEV018' 'DEV023' 'DEV010' 'DEV009']. prepping fold data.... fitting.... 8.2 GiB. trying decoder 1 of 1. predicting. test score was:. 0.4849092749222872\n",
      "fold 2 of 3\n",
      "In order to test on a training group of 10 items, holding out the following subjects:['DEV005' 'DEV021' 'DEV012' 'DEV006' 'DEV022']. prepping fold data.... fitting.... 8.5 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:141: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.4525170068027211\n",
      "fold 3 of 3\n",
      "In order to test on a training group of 10 items, holding out the following subjects:['DEV016' 'DEV014' 'DEV015' 'DEV017' 'DEV013']. prepping fold data.... fitting.... 8.3 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:141: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.5216873706004141\n"
     ]
    }
   ],
   "source": [
    "dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\n",
    "cv_results = cv_train_test_sets(\n",
    "    trainset_X = all_subjects['X'],\n",
    "    trainset_y = all_subjects['y_int'],\n",
    "    trainset_groups = all_subjects['metadata']['subject'],\n",
    "    decoders = [dec_main],\n",
    "    cv=KFold(n_splits=3) # we use KFold, not GroupKfold, because it's splitting on Group anyway\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "vscode": {
   "interpreter": {
    "hash": "0cca8238de402a161b34e58e1e3b4d299a0bf48c5783c9dc7c173d82c36576a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
