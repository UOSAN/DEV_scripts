{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "angry-conspiracy",
   "metadata": {
    "tags": []
   },
   "source": [
    "This builds on TESQ-ml-ns-nogo-go\n",
    "\n",
    "> **proposal 1**\n",
    "> \n",
    "> Two class (e.g., CorrectStop vs. CorrectGo)\n",
    "> \n",
    "> Leave-One-Out classifier...\n",
    "> \n",
    "> Neural similarity of a subject to the group with a Stop vs. Go contrast might actually be indicative of performance.\n",
    "> \n",
    "> subjects will naturally differ across the task as to how much their average signal responds to that, and the ones with better response might have better response inhibition.\n",
    "\n",
    "We use the same neural data, but instead of regressing on classifying these classes, we take one class or the other or we combine them in some way and we regress on our self report variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-discretion",
   "metadata": {},
   "source": [
    "So there are a couple of steps here...\n",
    "\n",
    "1. iterate through subjects, holding out one at a time, and do the following steps.\n",
    "2. Train a regressor across all the training subjects, regressing CorrectStop and CorrectGo on TESQ-E and other self report measures including FFQ either (a) independently (b) contrasted with each other (c) concatenated in a single image.\n",
    "3. If a link can be established, we've shown there is a relevant link between TESQ-E or other self-report measure, and the neural signature.\n",
    "4. ...that seems like a publication in itself!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-certification",
   "metadata": {},
   "source": [
    "As a first pass, we can simplify this a bit just trying that single classifier on all subjects. This means that we're using train for tes tset but it will give us an initial measure of feasibility.\n",
    "\n",
    "We probably do need to restrict to a specific brain region though, and that means retraining. - I think that prefrontal cortex mask we have works well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-glucose",
   "metadata": {},
   "source": [
    "## Data already generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-oxford",
   "metadata": {},
   "source": [
    "Can we use data already generated in `SST_inhibition_cv.ipynb`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mineral-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14428/659417397.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML, Markdown\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from IPython.core.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mechanical-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "economic-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_filepath=ml_data_folderpath + \"/SST/train_test_results_conditions_40subs_twoclasses.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "romance-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_2c = pickle.load(open(results_filepath,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-myrtle",
   "metadata": {},
   "source": [
    "Not quite--we need a PFC mask I think. But we can use the script already written to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-queue",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "limiting-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "\n",
    "#from apply_loocv_and_save import *\n",
    "#from dev_wtp_io_utils import *\n",
    "import gc\n",
    "import nibabel as nib\n",
    "\n",
    "from os import path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import ttest_1samp, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sealed-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymvpa2_ml_library import *\n",
    "from generic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "natural-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/mvpa2/datasets/base.py:465: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, shape=None, sid=None, fid=None, dtype=np.float):\n"
     ]
    }
   ],
   "source": [
    "from mvpa_pipeline_utils import get_Brain_Data_betas_as_mvpa_for_sub, import_beta_series_pymvpa2, sa_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "located-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from analyze_results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-colorado",
   "metadata": {},
   "source": [
    "## condition_contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "endless-texture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "#load the matrix associated with this file\n",
    "sl_mat = scipy.io.loadmat(\n",
    "'/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/fx/models/SST/wave1/conditions/sub-DEV073/SPM.mat',\n",
    "simplify_cells=True            \n",
    ")\n",
    "mat_betas = sl_mat['SPM']['Vbeta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floral-invite",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['spm_spm:beta (0001) - Sn(1) CorrectGo*bf(1)',\n",
       " 'spm_spm:beta (0002) - Sn(1) CorrectStop*bf(1)',\n",
       " 'spm_spm:beta (0003) - Sn(1) FailedStop*bf(1)',\n",
       " 'spm_spm:beta (0004) - Sn(1) Cue*bf(1)',\n",
       " 'spm_spm:beta (0005) - Sn(1) R1',\n",
       " 'spm_spm:beta (0006) - Sn(1) R2',\n",
       " 'spm_spm:beta (0007) - Sn(1) R3',\n",
       " 'spm_spm:beta (0008) - Sn(1) R4',\n",
       " 'spm_spm:beta (0009) - Sn(1) R5',\n",
       " 'spm_spm:beta (0010) - Sn(1) constant']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[mat_betas[beta_i]['descrip'] for beta_i in range(len(mat_betas))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-conjunction",
   "metadata": {},
   "source": [
    "## stitching contrasts together in different ways\n",
    "\n",
    "We'd want:\n",
    "\n",
    " - contrast of the two conditions\n",
    " - each of the two conditions alone.\n",
    " \n",
    "The contrast is a little tricky. Easiest thing is to try each of the conditions alone. Stitching the two together might not be too hard. Let's try doing CorrectStop first, and then we'll try concatenating the images. Doing a contrast is actually the most difficult becuase I have to backtrack in the process to generate new betas (see https://docs.google.com/presentation/d/1K-nFrZYE6rR8t0myNyacB7frBzV3B1--nMqPhVkwL8E/edit#slide=id.geeff6890fb_0_16)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-omaha",
   "metadata": {},
   "source": [
    "See `different ways of combining images.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-africa",
   "metadata": {},
   "source": [
    "## template"
   ]
  },
  {
   "cell_type": "raw",
   "id": "clinical-victorian",
   "metadata": {},
   "source": [
    "do_complete_analysis_for_mask('goal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-baseball",
   "metadata": {},
   "source": [
    "## regressing on self report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "superior-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\"\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20210601T183243.csv\"\n",
    "test_train_df = pd.read_csv(train_test_markers_filepath)\n",
    "\n",
    "all_sst_events= pd.read_csv(ml_data_folderpath +\"/SST/\" + \"all_sst_events.csv\")\n",
    "\n",
    "\n",
    "script_path = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml'\n",
    "# HRF 2s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "passive-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## additional masks\n",
    "\n",
    "all_masks = get_all_masks(ml_data_folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "noted-fabric",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           mask_name  \\\n",
      "0               planning_association-test_z_FDR_0.01   \n",
      "1     executive function_association-test_z_FDR_0.01   \n",
      "2    response inhibition_association-test_z_FDR_0.01   \n",
      "3             inhibition_association-test_z_FDR_0.01   \n",
      "4  harvardoxford-cortical_prob_Frontal Orbital Co...   \n",
      "5  harvardoxford-cortical_prob_Inferior Frontal G...   \n",
      "6  harvardoxford-cortical_prob_Inferior Frontal G...   \n",
      "\n",
      "                                       mask_filepath  thresh  \n",
      "0  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...     0.1  \n",
      "1  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...     0.1  \n",
      "2  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...     0.1  \n",
      "3  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...     0.1  \n",
      "4  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...    10.0  \n",
      "5  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...    10.0  \n",
      "6  /gpfs/projects/sanlab/shared/DEV/nonbids_data/...    10.0  \n"
     ]
    }
   ],
   "source": [
    "print(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "comparable-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_metadata(bd,target_val,standardize=True):\n",
    "    #set up chunks and targets so we can do the learning.\n",
    "    attribute_df = sa_to_df(bd.sa)\n",
    "    pd.concat([attribute_df['subject'],attribute_df['wave']],axis=1)\n",
    "    chunk = attribute_df['subject']+\"_\" + attribute_df['wave'].astype(str)\n",
    "    bd.sa['chunks'] = list(chunk)\n",
    "    if standardize:\n",
    "        target_data = bd.sa[target_val].value\n",
    "        target_data_mean = np.nanmean(target_data)\n",
    "        target_data_std = np.nanstd(target_data)\n",
    "        target_data_norm = (target_data-target_data_mean)/target_data_std\n",
    "        bd.sa['targets'] = list(target_data_norm)\n",
    "    else:\n",
    "        bd.sa['targets'] = list(bd.sa[target_val].value)\n",
    "    return(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "quantitative-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=2.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "optimum-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "def do_Ridge(train_X,train_y,test_X,test_y):\n",
    "    sklearn_regress = Ridge(alpha=5.0)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    return(predict_y,sklearn_regress)\n",
    "    \n",
    "def do_regression(dataset,normalization=None,get_prediction=None,verbose=False,require_mean_centered=True):\n",
    "    if get_prediction is None:\n",
    "        get_prediction = do_Ridge\n",
    "    logo=LeaveOneGroupOut()\n",
    "\n",
    "    group_scores = {}\n",
    "    sample_wise_results = []\n",
    "\n",
    "    items_to_eliminate_count = np.sum(np.isnan(dataset.sa.targets))\n",
    "    items_total = len(dataset.sa.targets)\n",
    "    print(\"eliminating \" + str(items_to_eliminate_count) + \" of \" + \n",
    "          str(items_total) + \" items due to null input values.\")\n",
    "    \n",
    "    dataset=dataset[np.isnan(dataset.sa.targets)==False]\n",
    "    \n",
    "    #ensure data is standardized\n",
    "    if abs(np.nanmean(dataset.sa.targets)>0.001) and require_mean_centered:\n",
    "        raise Exception(\"target data is not mean-centred, but mean centering is required.\")\n",
    "\n",
    "    for train_index, test_index in logo.split(\n",
    "        dataset.samples, dataset.sa.targets, dataset.sa.chunks):\n",
    "        iteration_label = np.unique(dataset.sa.chunks[test_index])[0]\n",
    "\n",
    "        #print(iteration_label, \"; TRAIN:\", len(train_index), \" items; TEST:\", test_index)\n",
    "        print(\".\",end=\"\",flush=True)\n",
    "\n",
    "        #do train-test split\n",
    "        train_X=dataset.samples[train_index]\n",
    "        test_X = dataset.samples[test_index]\n",
    "        train_y=dataset.sa.targets[train_index]\n",
    "        test_y = dataset.sa.targets[test_index]\n",
    "        #clf_svc = SVC()\n",
    "        \n",
    "        if normalization==\"train_set_based\":\n",
    "            #get mean based on train set alone\n",
    "            voxel_mean = np.mean(train_X,axis=0)\n",
    "            voxel_sd = np.std(train_X,axis=0)\n",
    "            #apply it to all.\n",
    "            train_X=(train_X-voxel_mean)/voxel_sd\n",
    "            test_X=(test_X-voxel_mean)/voxel_sd\n",
    "            raise Exception(\"this is obsolete--think this method is completely wrong.\")\n",
    "            #print(\"normalizing\")\n",
    "#         print(train_y)\n",
    "#         print(sum(np.isnan(train_y)))\n",
    "#         print(test_y)\n",
    "        predict_y, sklearn_clf = get_prediction(train_X,train_y,test_X,test_y)\n",
    "        predict_y_train = sklearn_clf.predict(train_X)\n",
    "#         print(pearsonr(predict_y_train,train_y))\n",
    "#         print(predict_y)\n",
    "#         print(predict_y_train)\n",
    "        \n",
    "        sample_wise_results_iter = pd.DataFrame({\n",
    "            'chunks':[iteration_label]*len(test_y),\n",
    "            'target_y':test_y,\n",
    "            'pred_y':predict_y,\n",
    "        })\n",
    "            \n",
    "        sample_wise_results = sample_wise_results + [sample_wise_results_iter]\n",
    "        \n",
    "    #need to create one more classifier to return.\n",
    "    #we test and train on the same here, which is OK, because we don't use this to assess performance\n",
    "    y_predict, model_final =get_prediction(\n",
    "        dataset.samples,dataset.sa.targets,dataset.samples,dataset.sa.targets)\n",
    "            \n",
    "    sample_wise_results_df = pd.concat(sample_wise_results)\n",
    "    return({'sample_wise':sample_wise_results_df,#'group_wise':group_scores,\n",
    "            'model':model_final})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-weapon",
   "metadata": {},
   "source": [
    "# Method fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "quarterly-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arabic-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "immune-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'TESQ_E_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "significant-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_CorrectStop = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectStop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "forty-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa2.measures.rsa import Regression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moral-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 12 of 162 items due to null input values.\n",
      "..........................................................................."
     ]
    }
   ],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "geographic-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import ttest_1samp, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "automated-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.1604586713191293, 0.04982091377259557)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-establishment",
   "metadata": {},
   "source": [
    "That's pretty good considering that we are regressing over all images whether they're Stop or Go signal. need to change this so that we alternately regress over stop or go only, or possibly, the difference between them.\n",
    "\n",
    "The contrast between them is probably best, which means we go to generate a new series based on that.\n",
    "\n",
    "Though, wait--why is it _negative_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "complete-crowd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 6 of 81 items due to null input values.\n",
      "..........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.22395277163350039, 0.0534184155525718)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results_CS = do_regression(Brain_Data_CorrectStop)\n",
    "pearsonr(regression_results_CS['sample_wise']['target_y'],regression_results_CS['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "british-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>target_y</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>-0.314867</td>\n",
       "      <td>0.412142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>1.328669</td>\n",
       "      <td>0.413454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV010_1</td>\n",
       "      <td>-0.747377</td>\n",
       "      <td>-0.225567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV011_1</td>\n",
       "      <td>-1.352890</td>\n",
       "      <td>-0.039303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV013_1</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>0.154750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV197_1</td>\n",
       "      <td>0.550152</td>\n",
       "      <td>0.112409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV206_1</td>\n",
       "      <td>-0.487871</td>\n",
       "      <td>-0.247337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV215_1</td>\n",
       "      <td>-0.833878</td>\n",
       "      <td>0.207193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV216_1</td>\n",
       "      <td>-1.093384</td>\n",
       "      <td>0.545270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV217_1</td>\n",
       "      <td>-0.141863</td>\n",
       "      <td>-0.051153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunks  target_y    pred_y\n",
       "0   DEV005_1 -0.314867  0.412142\n",
       "0   DEV006_1  1.328669  0.413454\n",
       "0   DEV010_1 -0.747377 -0.225567\n",
       "0   DEV011_1 -1.352890 -0.039303\n",
       "0   DEV013_1  0.031141  0.154750\n",
       "..       ...       ...       ...\n",
       "0   DEV197_1  0.550152  0.112409\n",
       "0   DEV206_1 -0.487871 -0.247337\n",
       "0   DEV215_1 -0.833878  0.207193\n",
       "0   DEV216_1 -1.093384  0.545270\n",
       "0   DEV217_1 -0.141863 -0.051153\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results_CS['sample_wise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "superb-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "accepting-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aaaffb78b50>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(regression_results_CS['sample_wise']['target_y'],regression_results_CS['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-thread",
   "metadata": {},
   "source": [
    "And really odd--why does it perform equally well for one class as for two? I thought two class analysis would be really nonsensical...which it is...considering the negative correlation for targets vs. pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fuzzy-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 6 of 81 items due to null input values.\n",
      "..........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.028789840475960636, 0.8063089701891368)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brain_Data_CorrectGo = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGo']\n",
    "regression_results_CG = do_regression(Brain_Data_CorrectGo)\n",
    "pearsonr(regression_results_CG['sample_wise']['target_y'],regression_results_CG['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-bubble",
   "metadata": {},
   "source": [
    "## try lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "native-connection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 12 of 162 items due to null input values.\n",
      "..........................................................................."
     ]
    }
   ],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "broken-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(nan, nan)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "prepared-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "0    0.0\n",
       "1    0.0\n",
       "0    0.0\n",
       "    ... \n",
       "1    0.0\n",
       "0    0.0\n",
       "1    0.0\n",
       "0    0.0\n",
       "1    0.0\n",
       "Name: pred_y, Length: 150, dtype: float32"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results['sample_wise']['pred_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-norway",
   "metadata": {},
   "source": [
    "Yes OK, because there's no variance ther ebecause we have both stop and go there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-while",
   "metadata": {},
   "source": [
    "## stop minus go contrast"
   ]
  },
  {
   "cell_type": "raw",
   "id": "varied-anchor",
   "metadata": {},
   "source": [
    "from analyze_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "polished-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast.pkl'\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'TESQ_E_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "tested-revolution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 6 of 81 items due to null input values.\n",
      "..........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.06451986257098531, 0.5823556904043573)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs,get_prediction = do_Lasso)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "italian-firmware",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.004470\n",
       "0   -0.168758\n",
       "0   -0.071507\n",
       "0   -0.080048\n",
       "0   -0.002358\n",
       "       ...   \n",
       "0    0.036890\n",
       "0    0.122977\n",
       "0    0.082224\n",
       "0    0.043664\n",
       "0    0.334942\n",
       "Name: pred_y, Length: 75, dtype: float32"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results['sample_wise']['pred_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "thermal-illustration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.314867\n",
       "0    1.328669\n",
       "0   -0.747377\n",
       "0   -1.352890\n",
       "0    0.031141\n",
       "       ...   \n",
       "0    0.550152\n",
       "0   -0.487871\n",
       "0   -0.833878\n",
       "0   -1.093384\n",
       "0   -0.141863\n",
       "Name: target_y, Length: 75, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results['sample_wise']['target_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-albany",
   "metadata": {},
   "source": [
    "## Trial dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-regard",
   "metadata": {},
   "source": [
    "We select a linear mix of voxels and try to predict that. should be easy to do with regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "interpreted-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'\n",
    "#mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "religious-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15010],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "precious-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 162 items due to null input values.\n",
      "................................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28250435621361414, 0.0002701825563630049)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'mix_target')\n",
    "\n",
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Ridge)\n",
    "\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-hudson",
   "metadata": {},
   "source": [
    "That's interesting--something like it should be, but not very good considering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "leading-sense",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 162 items due to null input values.\n",
      "................................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8000696992645617, 2.443511356815639e-37)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15100],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'mix_target')\n",
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Ridge)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-season",
   "metadata": {},
   "source": [
    "aahhh got it--if the pattern is spread over several voxels, we'll have a better time detecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "chief-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15100],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fourth-anchor",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scatter' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mscatter\u001b[49m(regression_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_y\u001b[39m\u001b[38;5;124m'\u001b[39m],regression_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_y\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'scatter' is not defined"
     ]
    }
   ],
   "source": [
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-blackberry",
   "metadata": {},
   "source": [
    "OK, so if there's a pattern representing a linear combination of voxels then we should be able to detect it using ridge regression. How about lasso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso2(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=True)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso2)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "comparative-right",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 162 items due to null input values.\n",
      ".."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.876e+02, tolerance: 2.702e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.119e+02, tolerance: 2.713e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.107e+02, tolerance: 2.735e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.364e+02, tolerance: 2.737e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.504e+02, tolerance: 2.745e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.822e+02, tolerance: 2.729e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.510e+02, tolerance: 2.748e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.377e+02, tolerance: 2.748e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.260e+02, tolerance: 2.738e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.927e+02, tolerance: 2.718e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.056e+03, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.187e+02, tolerance: 2.572e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.011e+03, tolerance: 2.748e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.679e+02, tolerance: 2.749e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.663e+02, tolerance: 2.745e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.364e+02, tolerance: 2.705e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.782e+02, tolerance: 2.744e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.878e+02, tolerance: 2.749e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.366e+02, tolerance: 2.741e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.768e+02, tolerance: 2.729e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.469e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.093e+03, tolerance: 2.739e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.369e+02, tolerance: 2.492e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.529e+02, tolerance: 2.717e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.362e+02, tolerance: 2.726e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.184e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.663e+02, tolerance: 2.529e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.113e+02, tolerance: 2.738e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.780e+02, tolerance: 2.743e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.809e+02, tolerance: 2.727e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.438e+02, tolerance: 2.749e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.715e+02, tolerance: 2.723e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.885e+02, tolerance: 2.735e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.010e+02, tolerance: 2.469e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.996e+02, tolerance: 2.635e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.883e+02, tolerance: 2.726e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.904e+02, tolerance: 2.716e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.338e+02, tolerance: 2.736e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.160e+02, tolerance: 2.738e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.090e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.096e+02, tolerance: 2.733e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.127e+02, tolerance: 2.735e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.677e+02, tolerance: 2.705e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.150e+02, tolerance: 2.730e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.289e+02, tolerance: 2.737e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.224e+02, tolerance: 2.744e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.036e+03, tolerance: 2.741e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.804e+02, tolerance: 2.742e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.026e+02, tolerance: 2.735e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.498e+02, tolerance: 2.727e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.191e+03, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.047e+03, tolerance: 2.749e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.198e+02, tolerance: 2.735e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.770e+02, tolerance: 2.728e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+03, tolerance: 2.726e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.230e+02, tolerance: 2.748e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.106e+02, tolerance: 2.747e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+03, tolerance: 2.726e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.436e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.205e+02, tolerance: 2.724e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.085e+02, tolerance: 2.736e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.290e+02, tolerance: 2.703e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.863e+02, tolerance: 2.733e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.009e+02, tolerance: 2.726e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.309e+02, tolerance: 2.697e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.149e+02, tolerance: 2.191e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.225e+02, tolerance: 2.745e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.138e+02, tolerance: 2.744e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.241e+02, tolerance: 2.748e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.439e+02, tolerance: 2.696e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.703e+02, tolerance: 2.747e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.061e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.484e+02, tolerance: 2.742e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.571e+02, tolerance: 2.743e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.639e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+03, tolerance: 2.745e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.045e+02, tolerance: 2.734e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.933e+02, tolerance: 2.713e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.883e+02, tolerance: 2.674e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.443e+02, tolerance: 2.743e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.089e+02, tolerance: 2.746e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.644e+02, tolerance: 2.749e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.9693185105846014, 2.032145825622152e-99)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15100],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'mix_target',standardize=False)\n",
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso2, require_mean_centered=False)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "green-celebrity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 162 items due to null input values.\n",
      ".................................................................................(0.3896282417311052, 2.9793285204147226e-07)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aaaf111bdc0>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso2)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "western-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 162 items due to null input values.\n",
      ".................................................................................(0.907475656018222, 3.7843850534794656e-62)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aab12f0a760>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "equipped-freedom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8000696765345883, 2.443531180731693e-37)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-director",
   "metadata": {},
   "source": [
    "So in summary--we can't predict TESQ-E-Sum using Ridge or Lasso regression. Because prediction is `greedy' in a sense--it'll take voxels anywhere in the image and emphasize them until they're useful--there's no point in trying different masks. We might try different scales, bu there's no use in doing a regression on masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-timeline",
   "metadata": {},
   "source": [
    "#### Elastic net?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "velvet-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "def do_ElasticNet(train_X,train_y,test_X,test_y):\n",
    "    sklearn_regress = ElasticNet(alpha=10.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "alive-raising",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 162 items due to null input values.\n",
      "................................................................................."
     ]
    }
   ],
   "source": [
    "\n",
    "elastic_regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_ElasticNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scatter(elastic_regression_results['sample_wise']['target_y'],elastic_regression_results['sample_wise']['pred_y'])\n",
    "pearsonr(elastic_regression_results['sample_wise']['target_y'],elastic_regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-commons",
   "metadata": {},
   "source": [
    "OK, of the three (Ridge, Elastic, Lasso), Lasso performs best on the dummy data, so we'll use that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-gasoline",
   "metadata": {},
   "source": [
    "## PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-marina",
   "metadata": {},
   "source": [
    "# Main analysis: Cycle through relevant variables...\n",
    "\n",
    "We'll cycle through:\n",
    "\n",
    " - TESQ-E subscales\n",
    " - BF%\n",
    " - SSRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-whole",
   "metadata": {},
   "source": [
    "### Stop Minus Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "athletic-insider",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "simple-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 6 of 81 items due to null input values.\n",
      "..........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.03887964227786027, 0.7405104037837731)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast.pkl'\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'TESQ_E_sum')\n",
    "\n",
    "regression_results = do_regression(Brain_Data_allsubs,do_Lasso)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "overall-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast.pkl'\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "characteristic-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESQ_E_sum\n",
      "eliminating 12 of 162 items due to null input values.\n",
      "......."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [87]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(regression_var)\n\u001b[1;32m     11\u001b[0m Brain_Data_allsubs \u001b[38;5;241m=\u001b[39m setup_metadata(Brain_Data_allsubs,regression_var)\n\u001b[0;32m---> 12\u001b[0m regression_results \u001b[38;5;241m=\u001b[39m \u001b[43mdo_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBrain_Data_allsubs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdo_Lasso\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m regression_results_dict[regression_var] \u001b[38;5;241m=\u001b[39m regression_results\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(pearsonr(regression_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_y\u001b[39m\u001b[38;5;124m'\u001b[39m],regression_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_y\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36mdo_regression\u001b[0;34m(dataset, normalization, get_prediction, verbose, require_mean_centered)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#do train-test split\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m train_X\u001b[38;5;241m=\u001b[39m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     44\u001b[0m test_X \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39msamples[test_index]\n\u001b[1;32m     45\u001b[0m train_y\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m.\u001b[39msa\u001b[38;5;241m.\u001b[39mtargets[train_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "regression_results_dict = {}\n",
    "for regression_var in [\n",
    "    'TESQ_E_sum',\n",
    "    'TESQ_E_distraction',\n",
    "    'TESQ_E_avoidance_of_temptations',\n",
    "                       'TESQ_E_goal_deliberation',\n",
    "                       'TESQ_E_goal_and_rule_setting','TESQ_E_suppression',\n",
    "                       'bf_1','SST_SSRT'\n",
    "                      ]:\n",
    "    print(regression_var)\n",
    "    Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,regression_var)\n",
    "    regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)\n",
    "    regression_results_dict[regression_var] = regression_results\n",
    "    print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-credits",
   "metadata": {},
   "source": [
    "### correct stop and Correct Go separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "sudden-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'\n",
    "#mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "violent-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_CorrectStop = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectStop']\n",
    "Brain_Data_CorrectGo = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "deadly-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_Ridge(train_X,train_y,test_X,test_y):\n",
    "    sklearn_regress = Ridge(alpha=2.0)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "efficient-huntington",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    predict_train_y = sklearn_regress.predict(train_X)\n",
    "    pearsonr(predict_train_y,)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "ranking-logistics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso2(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=True)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "handled-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CorrectStop']\n",
      "TESQ_E_sum\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.2897391570748111, 0.011688686319622759)\n",
      "---\n",
      "TESQ_E_avoidance_of_temptations\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.21211752121160998, 0.06770154797999485)\n",
      "---\n",
      "TESQ_E_goal_deliberation\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.20501276795575663, 0.07765867595589468)\n",
      "---\n",
      "TESQ_E_distraction\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.24358943934987354, 0.03520882472819055)\n",
      "---\n",
      "TESQ_E_goal_and_rule_setting\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.298899089729488, 0.009189922013265534)\n",
      "---\n",
      "TESQ_E_suppression\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.3830322874657558, 0.0006943964845521207)\n",
      "---\n",
      "bf_1\n",
      "eliminating 9 of 81 items due to null input values.\n",
      "........................................................................(-0.12341944404427349, 0.3016621046649797)\n",
      "---\n",
      "SST_SSRT\n",
      "eliminating 2 of 81 items due to null input values.\n",
      "...............................................................................(-0.1005129696608136, 0.37811545294588533)\n",
      "---\n",
      "['CorrectGo']\n",
      "TESQ_E_sum\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(0.11148386411421911, 0.3409777423110393)\n",
      "---\n",
      "TESQ_E_avoidance_of_temptations\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.11944703898422215, 0.3073836666703567)\n",
      "---\n",
      "TESQ_E_goal_deliberation\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(0.2596037649286658, 0.02450069630008311)\n",
      "---\n",
      "TESQ_E_distraction\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.015408085834020313, 0.895613552068508)\n",
      "---\n",
      "TESQ_E_goal_and_rule_setting\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "............."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [94]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(regression_var)\n\u001b[1;32m     10\u001b[0m bd \u001b[38;5;241m=\u001b[39m setup_metadata(bd,regression_var)\n\u001b[0;32m---> 11\u001b[0m regression_results \u001b[38;5;241m=\u001b[39m \u001b[43mdo_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_prediction\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdo_Lasso\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m regression_results_dict[regression_var] \u001b[38;5;241m=\u001b[39m regression_results\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(pearsonr(regression_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_y\u001b[39m\u001b[38;5;124m'\u001b[39m],regression_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_y\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n",
      "Input \u001b[0;32mIn [86]\u001b[0m, in \u001b[0;36mdo_regression\u001b[0;34m(dataset, normalization, get_prediction, verbose, require_mean_centered)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis is obsolete--think this method is completely wrong.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;66;03m#print(\"normalizing\")\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m#         print(train_y)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m#         print(sum(np.isnan(train_y)))\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#         print(test_y)\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m         predict_y, sklearn_clf \u001b[38;5;241m=\u001b[39m \u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m         predict_y_train \u001b[38;5;241m=\u001b[39m sklearn_clf\u001b[38;5;241m.\u001b[39mpredict(train_X)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;66;03m#         print(pearsonr(predict_y_train,train_y))\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m#         print(predict_y)\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m#         print(predict_y_train)\u001b[39;00m\n",
      "Input \u001b[0;32mIn [93]\u001b[0m, in \u001b[0;36mdo_Lasso\u001b[0;34m(train_X, train_y, test_X, test_y)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_Lasso\u001b[39m(train_X,train_y,test_X,test_y):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m#if we fit intercept, it actually uses the y values to refit the items, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m#adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m#may need to mean-center the predicted variable _before_ analysis.\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     sklearn_regress \u001b[38;5;241m=\u001b[39m Lasso(alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,fit_intercept\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m     \u001b[43msklearn_regress\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     predict_y \u001b[38;5;241m=\u001b[39m sklearn_regress\u001b[38;5;241m.\u001b[39mpredict(test_X)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#    print(predict_y,test_y)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:1039\u001b[0m, in \u001b[0;36mElasticNet.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m     this_Xy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1039\u001b[0m _, this_coef, this_dual_gap, this_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1045\u001b[0m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1058\u001b[0m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1061\u001b[0m coef_[k] \u001b[38;5;241m=\u001b[39m this_coef[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1062\u001b[0m dual_gaps_[k] \u001b[38;5;241m=\u001b[39m this_dual_gap[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/linear_model/_coordinate_descent.py:647\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    633\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    634\u001b[0m         coef_,\n\u001b[1;32m    635\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    644\u001b[0m         positive,\n\u001b[1;32m    645\u001b[0m     )\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 647\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mcd_fast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[1;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    650\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    652\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    653\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    654\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for bd in [Brain_Data_CorrectStop, Brain_Data_CorrectGo]:\n",
    "    print(np.unique(bd.sa.condition_label))\n",
    "    for regression_var in ['TESQ_E_sum', 'TESQ_E_avoidance_of_temptations',\n",
    "                           'TESQ_E_goal_deliberation','TESQ_E_distraction',\n",
    "                           'TESQ_E_goal_and_rule_setting','TESQ_E_suppression',\n",
    "                           'bf_1','SST_SSRT'\n",
    "                          ]:\n",
    "        print(regression_var)\n",
    "        \n",
    "        bd = setup_metadata(bd,regression_var)\n",
    "        regression_results = do_regression(bd, get_prediction = do_Lasso)\n",
    "        regression_results_dict[regression_var] = regression_results\n",
    "        print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "suburban-laser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CorrectStop']\n",
      "TESQ_E_sum\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.662050774249783, 9.939377950744506e-11)\n",
      "---\n",
      "TESQ_E_avoidance_of_temptations\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.8706736957303877, 3.40099294415994e-24)\n",
      "---\n",
      "TESQ_E_goal_deliberation\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.3689253159881247, 0.0011258348475313847)\n",
      "---\n",
      "TESQ_E_distraction\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.9888666517456229, 3.7537979907903164e-62)\n",
      "---\n",
      "TESQ_E_goal_and_rule_setting\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.4657845041006153, 2.5405831637441768e-05)\n",
      "---\n",
      "TESQ_E_suppression\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.7827640548676846, 1.0826926710266976e-16)\n",
      "---\n",
      "bf_1\n",
      "eliminating 9 of 81 items due to null input values.\n",
      "........................................................................(-0.29844081726703287, 0.010885610117737024)\n",
      "---\n",
      "SST_SSRT\n",
      "eliminating 2 of 81 items due to null input values.\n",
      "...............................................................................(-0.30127009353502177, 0.006974497194290303)\n",
      "---\n",
      "['CorrectGo']\n",
      "TESQ_E_sum\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(0.08999428391067682, 0.44258047078645824)\n",
      "---\n",
      "TESQ_E_avoidance_of_temptations\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.1444050814144539, 0.21643233935921433)\n",
      "---\n",
      "TESQ_E_goal_deliberation\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(0.23695641174309376, 0.040669261422939224)\n",
      "---\n",
      "TESQ_E_distraction\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.03122100219514951, 0.7903121386076513)\n",
      "---\n",
      "TESQ_E_goal_and_rule_setting\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.12237431465196014, 0.29559348442724537)\n",
      "---\n",
      "TESQ_E_suppression\n",
      "eliminating 6 of 81 items due to null input values.\n",
      "...........................................................................(-0.16839660209306773, 0.14868308304636338)\n",
      "---\n",
      "bf_1\n",
      "eliminating 9 of 81 items due to null input values.\n",
      "........................................................................(-0.04683043257461191, 0.6960712712016681)\n",
      "---\n",
      "SST_SSRT\n",
      "eliminating 2 of 81 items due to null input values.\n",
      "...............................................................................(-0.2669746621674908, 0.017385873017146027)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for bd in [Brain_Data_CorrectStop, Brain_Data_CorrectGo]:\n",
    "    print(np.unique(bd.sa.condition_label))\n",
    "    for regression_var in ['TESQ_E_sum', 'TESQ_E_avoidance_of_temptations',\n",
    "                           'TESQ_E_goal_deliberation','TESQ_E_distraction',\n",
    "                           'TESQ_E_goal_and_rule_setting','TESQ_E_suppression',\n",
    "                           'bf_1','SST_SSRT'\n",
    "                          ]:\n",
    "        print(regression_var)\n",
    "        \n",
    "        bd = setup_metadata(bd,regression_var)\n",
    "        regression_results = do_regression(bd, get_prediction = do_Lasso2)\n",
    "        regression_results_dict[regression_var] = regression_results\n",
    "        print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "revised-recipient",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.31486695,  1.32866935, -0.74737651, -1.35288988,  0.03114069,\n",
       "        1.93418272,  0.20414451,         nan, -0.92038033, -0.83387842,\n",
       "        1.15566553, -1.5258937 ,  1.24216744, -0.83387842,  0.29064642,\n",
       "        0.55015215, -0.48787078,  1.24216744,  0.03114069,  0.80965788,\n",
       "               nan,         nan, -0.6608746 ,  2.5396961 ,  1.67467699,\n",
       "       -0.83387842, -1.43939179, -1.09338415,  2.02068463, -1.17988606,\n",
       "        0.1176426 ,  1.06916362,  0.72315597, -0.92038033, -1.69889753,\n",
       "       -1.17988606, -0.48787078,  1.58817508,  1.41517126, -0.40136887,\n",
       "        0.89615979,  0.80965788,  0.46365024,  0.29064642,  0.20414451,\n",
       "        0.29064642, -0.40136887, -0.40136887,  0.20414451,  0.20414451,\n",
       "       -0.05536122, -1.35288988, -1.00688224,  0.1176426 , -1.61239562,\n",
       "       -0.31486695,  0.63665406,  0.1176426 , -1.78539944,         nan,\n",
       "       -0.31486695, -0.83387842,  0.72315597, -0.48787078,  1.06916362,\n",
       "       -0.6608746 ,  0.55015215,  0.89615979,  1.06916362, -0.22836504,\n",
       "        1.41517126, -2.04490517,  0.55015215,         nan, -0.05536122,\n",
       "        0.55015215, -0.48787078, -0.83387842, -1.09338415, -0.14186313,\n",
       "               nan])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brain_Data_CorrectStop.sa.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "divine-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.5432275959951593e-16"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results['sample_wise'].target_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "challenging-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.35489923,  1.33350454,  0.32321638,  0.32427986,  1.17047363,\n",
       "       -0.61622895,  0.31944403,  0.65823296, -0.64794871, -0.56187779,\n",
       "       -0.52485766, -0.63708751,  1.63167522,  1.7767727 ,  0.2489724 ,\n",
       "        1.08596331,  1.50447453,  0.11924886, -0.81639756, -0.56120991,\n",
       "       -1.16006164, -0.06219032,  0.25274589,  1.47628803, -0.16562328,\n",
       "        1.28279555, -0.8614737 ,  1.68693065,  0.13371825, -0.80895987,\n",
       "       -2.33323289,  1.01203432,  0.04789241,  1.21078765,  0.82256699,\n",
       "       -0.31517965, -1.18540216,  1.63190857,  0.06467069, -0.25444275,\n",
       "       -0.37610303, -1.82542296,  0.45290133, -1.25844849, -0.70067749,\n",
       "        1.03656128,  0.53553286,         nan,  0.61672861, -0.90490378,\n",
       "       -1.15360352, -0.78073143, -0.70612725,  1.36739265, -1.60374533,\n",
       "       -2.05778934,  0.29941276, -1.40719534, -1.43113237, -0.28508069,\n",
       "       -0.95971007,  0.56172321, -0.09578487,  2.11306786, -0.67054316,\n",
       "        0.35836219,  1.37141238,  0.18428869, -0.31119288,  0.14249292,\n",
       "        0.31678476,  0.76168316, -1.305214  ,  0.10307985,  0.9551002 ,\n",
       "       -0.84694448, -0.69253192, -1.4580169 , -0.43017377,  0.12322608,\n",
       "               nan])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.sa.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "disciplinary-punch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aaaf16587c0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import scatter\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "selective-virtue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.30319668000701344, 0.006604190146285526)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-thing",
   "metadata": {},
   "source": [
    "## Correct STop and Correct Go spatially concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lucky-observer",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3_mvpa]",
   "language": "python",
   "name": "conda-env-.conda-py3_mvpa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
