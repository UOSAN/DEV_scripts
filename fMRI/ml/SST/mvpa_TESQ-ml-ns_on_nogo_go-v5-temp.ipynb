{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fixed-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/mvpa2/datasets/base.py:465: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, shape=None, sid=None, fid=None, dtype=np.float):\n"
     ]
    }
   ],
   "source": [
    "from mvpa2.datasets.mri import fmri_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehavioralDataNotFoundForBrainDataException(Exception):\n",
    "    \"\"\"Behavioral data could not be matched to a subject.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-british",
   "metadata": {},
   "source": [
    "Replicating earlier work on mvpa. Try not to overly complicate it--the main point is just to verify we get similar results on a different package to validate prior work. ANd we are primarily interested in validating the very high cross-validation results I got with nltools. Should aim for readable code.\n",
    "\n",
    "\n",
    "Version 5 uses scikit-learn directly, bypassing mvpa2's framework altogether. We also implement a 'forced choice' scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mvpa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surrounded-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-lighting",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latest-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intimate-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_exclude_list = pd.read_csv(\"../nsc_subject_exclusions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_df_raw = pd.read_csv(nonbids_data_path + \"fMRI/ml/train_test_markers_20211027T173724.csv\")\n",
    "test_train_df_raw = test_train_df_raw.merge(include_exclude_list[include_exclude_list.Task=='SST'],left_on='sub_label',right_on='SubjectId',how='left')\n",
    "test_train_df_raw.loc[test_train_df_raw.Include.isna(),'Include'] = True\n",
    "test_train_df = test_train_df_raw[test_train_df_raw.Include==True]\n",
    "exclude_subjects = ['DEV061','DEV185','DEV187','DEV189','DEV190','DEV192','DEV198','DEV203','DEV220','DEV221']\n",
    "train_subjs = test_train_df.loc[test_train_df.SplitGroup=='Train','sub_label'].tolist()#only get the train subjects; ignore those previously marked hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caroline-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjs_selected = [ts for ts in train_subjs if (ts not in exclude_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continued-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_differences = pd.read_csv(ml_data_folderpath + \"/data_by_ppt.csv\")\n",
    "individual_differences = individual_differences.rename(columns={'SID':'subject'})\n",
    "individual_differences['wave']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-explosion",
   "metadata": {},
   "source": [
    "We probably actually want to start the pipeline from the betas rather than loading from pickle. to be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "african-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa_pipeline_utils import get_Brain_Data_betas_as_mvpa_for_sub, import_beta_series_pymvpa2, sa_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-screw",
   "metadata": {},
   "source": [
    "## new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "weekly-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "juvenile-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forced_choice(dataset):\n",
    "    logo=LeaveOneGroupOut()\n",
    "\n",
    "    group_scores = {}\n",
    "    sample_wise_results = []\n",
    "    \n",
    "    for train_index, test_index in logo.split(\n",
    "        dataset.samples, dataset.sa.targets, dataset.sa.chunks):\n",
    "        iteration_label = np.unique(dataset.sa.chunks[test_index])[0]\n",
    "\n",
    "        #print(iteration_label, \"; TRAIN:\", len(train_index), \" items; TEST:\", test_index)\n",
    "        print(\".\",end=\"\",flush=True)\n",
    "\n",
    "        #do train-test split\n",
    "        train_X=dataset.samples[train_index]\n",
    "        test_X = dataset.samples[test_index]\n",
    "        train_y=dataset.sa.targets[train_index]\n",
    "        test_y = dataset.sa.targets[test_index]\n",
    "        #clf_svc = SVC()\n",
    "        sklearn_clf = SVC(probability=True)\n",
    "        #sklearn_clf = LinearSVC()\n",
    "\n",
    "        #create the classifier with a probability function\n",
    "        #https://mmuratarat.github.io/2019-10-12/probabilistic-output-of-svm#:~:text=SVMs%20don't%20output%20probabilities,the%20output%20to%20class%20probabilities.&text=For%20many%20problems%2C%20it%20is,of%20certainty%20about%20the%20answer.\n",
    "        #we don't need this I'm doing my own probability estimate\n",
    "        #hmmm, is this why the model is performing so well? the tuning?\n",
    "        #sklearn_clf = CalibratedClassifierCV(clf_svc)\n",
    "        #train\n",
    "        sklearn_clf.fit(train_X, train_y)\n",
    "\n",
    "        #get the _probability_ we fall into each class\n",
    "        predict_y_prob = sklearn_clf.predict_proba(test_X)\n",
    "        predict_y = sklearn_clf.predict(test_X)\n",
    "        #need to label the output of the probability as CorrectStop and CorrectGo based on the classnames\n",
    "        #iterate through each class\n",
    "        proba_dict = {}\n",
    "        for i, cls in enumerate(sklearn_clf.classes_):\n",
    "            proba_dict[cls] = [x[i] for x in predict_y_prob]\n",
    "            \n",
    "        class_0 = sklearn_clf.classes_[0]\n",
    "        class_1 = sklearn_clf.classes_[1]\n",
    "\n",
    "        #find out which one of the two images is most likely to be CorrectGo\n",
    "        class_0_choice_index = np.argmax(proba_dict[class_0])\n",
    "        #now put that into a vector\n",
    "        forced_choice_predictions = [class_1]*2\n",
    "        forced_choice_predictions[class_0_choice_index] = class_0\n",
    "        accuracy_score = np.sum([pred==target for pred,target in zip(forced_choice_predictions,test_y)])/len(test_y)\n",
    "        #print(predict_y)\n",
    "        #print(proba_dict)\n",
    "        #print(forced_choice_predictions)\n",
    "        #print(accuracy_score)\n",
    "        #can we do a sample-wise table?\n",
    "\n",
    "        group_scores[iteration_label] = accuracy_score\n",
    "        sample_wise_results_iter = pd.DataFrame({\n",
    "            'chunks':[iteration_label]*len(test_y),\n",
    "            'target_y':test_y,\n",
    "            'pred_y':predict_y,\n",
    "            'pred_y_forced_choice':forced_choice_predictions\n",
    "        })\n",
    "        #add the class-wise probabilities\n",
    "        for cls in sklearn_clf.classes_:\n",
    "            sample_wise_results_iter['pred_prob_' + cls] = proba_dict[cls]\n",
    "            \n",
    "        sample_wise_results = sample_wise_results + [sample_wise_results_iter]\n",
    "        \n",
    "    #need to create one more classifier to return.\n",
    "    clf_svc = SVC()\n",
    "\n",
    "    #create the classifier with a probability function\n",
    "    #https://mmuratarat.github.io/2019-10-12/probabilistic-output-of-svm#:~:text=SVMs%20don't%20output%20probabilities,the%20output%20to%20class%20probabilities.&text=For%20many%20problems%2C%20it%20is,of%20certainty%20about%20the%20answer.\n",
    "    clf_svc_final = SVC()\n",
    "    sklearn_clf_final = CalibratedClassifierCV(clf_svc_final)\n",
    "    sklearn_clf_final.fit(dataset.samples, dataset.sa.targets)\n",
    "    \n",
    "\n",
    "    \n",
    "            \n",
    "    sample_wise_results_df = pd.concat(sample_wise_results)\n",
    "    return({'sample_wise':sample_wise_results_df,'group_wise':group_scores,'classifier':sklearn_clf})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "exciting-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_metadata(Brain_Data_allsubs):\n",
    "    #set up chunks and targets so we can do the learning.\n",
    "    attribute_df = sa_to_df(Brain_Data_allsubs.sa)\n",
    "    pd.concat([attribute_df['subject'],attribute_df['wave']],axis=1)\n",
    "    chunk = attribute_df['subject']+\"_\" + attribute_df['wave'].astype(str)\n",
    "    Brain_Data_allsubs.sa['chunks'] = list(chunk)\n",
    "    Brain_Data_allsubs.sa['targets'] = list(Brain_Data_allsubs.sa['condition_label'].value)\n",
    "    return(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-audio",
   "metadata": {},
   "source": [
    "## whole brain"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compliant-incidence",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "from mvpa2.measures.base import CrossValidation\n",
    "from mvpa2.clfs.meta import NFoldPartitioner\n",
    "from mvpa2.clfs.svm import LinearCSVMC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "metallic-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "hispanic-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from mvpa2.measures.base import CrossValidation\n",
    "#from mvpa2.clfs.meta import NFoldPartitioner\n",
    "#from mvpa2.clfs.svm import LinearCSVMC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-pocket",
   "metadata": {},
   "source": [
    "Now let's scale that up to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "express-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "wrong-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filepath=ml_data_folderpath + \"/SST/ttr_mvpa2_res_v5_conditions_84subs_twoclasses_wholebrain.pkl\"\n",
    "#results_filepath=ml_data_folderpath + \"/SST/train_test_results_\" + dataset_name + \"_58subs_twoclasses_pfcmask_repeat1.pkl\"\n",
    "\n",
    "relevant_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "traditional-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sixth-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "appointed-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".........."
     ]
    }
   ],
   "source": [
    "forced_choice_results = do_forced_choice(Brain_Data_allsubs[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "proof-ladder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95 1.0\n"
     ]
    }
   ],
   "source": [
    "prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y'])\n",
    "forced_choice_prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y_forced_choice'])\n",
    "print(prediction,forced_choice_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "presidential-joshua",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "charming-cardiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'wb') as pkl_file:\n",
    "    pickle.dump(results_filepath,file=pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "promising-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>target_y</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>pred_y_forced_choice</th>\n",
       "      <th>pred_prob_CorrectGo</th>\n",
       "      <th>pred_prob_CorrectStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.903737</td>\n",
       "      <td>0.096263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.125309</td>\n",
       "      <td>0.874691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.972710</td>\n",
       "      <td>0.027290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.218002</td>\n",
       "      <td>0.781998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV010_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.032308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV216_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.705225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV217_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.940275</td>\n",
       "      <td>0.059725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV217_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.107911</td>\n",
       "      <td>0.892089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV218_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.488167</td>\n",
       "      <td>0.511833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV218_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>0.941589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk     target_y       pred_y pred_y_forced_choice  \\\n",
       "0   DEV005_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "1   DEV005_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV006_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "1   DEV006_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV010_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "..       ...          ...          ...                  ...   \n",
       "1   DEV216_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV217_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "1   DEV217_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV218_1    CorrectGo  CorrectStop            CorrectGo   \n",
       "1   DEV218_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "\n",
       "    pred_prob_CorrectGo  pred_prob_CorrectStop  \n",
       "0              0.903737               0.096263  \n",
       "1              0.125309               0.874691  \n",
       "0              0.972710               0.027290  \n",
       "1              0.218002               0.781998  \n",
       "0              0.967692               0.032308  \n",
       "..                  ...                    ...  \n",
       "1              0.294775               0.705225  \n",
       "0              0.940275               0.059725  \n",
       "1              0.107911               0.892089  \n",
       "0              0.488167               0.511833  \n",
       "1              0.058411               0.941589  \n",
       "\n",
       "[162 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forced_choice_results['sample_wise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "christian-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876543209876543"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score = np.mean(list(forced_choice_results['group_wise'].values()))\n",
    "total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-supervisor",
   "metadata": {},
   "source": [
    "Alright--and how about if we don't do the forced-choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "retained-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y'])\n",
    "forced_choice_prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y_forced_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "subtle-microphone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9506172839506173\n",
      "0.9876543209876543\n"
     ]
    }
   ],
   "source": [
    "print(prediction)\n",
    "print(forced_choice_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-gender",
   "metadata": {},
   "source": [
    "## masks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-cosmetic",
   "metadata": {},
   "source": [
    "We get the same file this time, but we apply a mask before doing learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "isolated-grass",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fabulous-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "## additional masks\n",
    "\n",
    "all_masks = get_all_masks(ml_data_folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "chicken-nation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_name\n",
      "mask_filepath\n",
      "thresh\n"
     ]
    }
   ],
   "source": [
    "for mask_name in all_masks.keys():\n",
    "    mask_value = all_masks[mask_name]\n",
    "    print(mask_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-swimming",
   "metadata": {},
   "source": [
    "### try out one mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aggressive-controversy",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/SST/mvpa_Dataset_conditions_84subs_correct_cond_harvardoxford-cortical_prob_Frontal Orbital Cortex.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "brutal-assistant",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "nearby-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa2.mappers.flatten import mask_mapper\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "developmental-indonesian",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs.samples[np.isnan(Brain_Data_allsubs.samples)]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "collect-finnish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "488884"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(sum(Brain_Data_allsubs.samples>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "interpreted-stress",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................."
     ]
    }
   ],
   "source": [
    "forced_choice_results = do_forced_choice(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "failing-calvin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9567901234567902 0.9753086419753086\n"
     ]
    }
   ],
   "source": [
    "prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y'])\n",
    "forced_choice_prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y_forced_choice'])\n",
    "print(prediction,forced_choice_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-masters",
   "metadata": {},
   "source": [
    "yikes, that does seem a bit too good. Particularly considering that the non-forced-choice rsults are also up really high. We shouldn't be seeing resutls this high! Let's see how it goes across all the masks I have chosen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "billion-worse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative affect_association-test_z_FDR_0.01\n",
      "10525994\n",
      ".................................................................................\n",
      "0.9506172839506173 0.9876543209876543\n",
      "response inhibition_association-test_z_FDR_0.01\n",
      "10640421\n",
      ".................................................................................\n",
      "0.9506172839506173 0.9876543209876543\n",
      "negative emotions_association-test_z_FDR_0.01\n",
      "10254691\n",
      ".................................................................................\n",
      "0.9506172839506173 0.9876543209876543\n",
      "harvardoxford-cortical_prob_Superior Frontal Gyrus\n",
      "869400\n",
      ".................................................................................\n",
      "0.9259259259259259 0.9876543209876543\n",
      "harvardoxford-cortical_prob_Frontal Pole\n",
      "1631652\n",
      ".................................................................................\n",
      "0.9012345679012346 0.9629629629629629\n",
      "harvardoxford-cortical_prob_Cingulate Gyrus, posterior division\n",
      "369467\n",
      ".................................................................................\n",
      "0.9444444444444444 0.9629629629629629\n",
      "harvardoxford-cortical_prob_Frontal Orbital Cortex\n",
      "488884\n",
      ".................................................................................\n",
      "0.9567901234567902 0.9753086419753086\n",
      "harvardoxford-cortical_prob_Frontal Operculum Cortex\n",
      "173092\n",
      ".................................................................................\n",
      "0.9074074074074074 0.9753086419753086\n",
      "harvardoxford-cortical_prob_Supramarginal Gyrus, posterior division\n",
      "651138\n",
      ".................................................................................\n",
      "0.9382716049382716 0.9753086419753086\n",
      "harvardoxford-cortical_prob_Angular Gyrus\n",
      "674765\n",
      ".................................................................................\n",
      "0.9074074074074074 0.9753086419753086\n",
      "harvardoxford-cortical_prob_Cingulate Gyrus, anterior division\n",
      "467831\n",
      ".................................................................................\n",
      "0.9135802469135802 0.9876543209876543\n",
      "harvardoxford-cortical_prob_Lateral Occipital Cortex, superior division\n",
      "1376421\n",
      ".................................................................................\n",
      "0.9320987654320988 0.9876543209876543\n",
      "harvardoxford-cortical_prob_Inferior Frontal Gyrus, pars opercularis\n",
      "370804\n",
      ".................................................................................\n",
      "0.9197530864197531 0.9753086419753086\n",
      "harvardoxford-cortical_prob_Inferior Frontal Gyrus, pars triangularis\n",
      "321488\n",
      ".................................................................................\n",
      "0.9506172839506173 0.9753086419753086\n",
      "harvardoxford-cortical_prob_Insular Cortex\n",
      "376468\n",
      ".................................................................................\n",
      "0.9444444444444444 0.9753086419753086\n"
     ]
    }
   ],
   "source": [
    "forced_choice_results_dict = {}\n",
    "for m_i,m_r in all_masks.iterrows():\n",
    "    mask_name=m_r['mask_name']\n",
    "    brain_data_filepath = (\n",
    "        \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/SST/mvpa_Dataset_conditions_84subs_correct_cond_\" +\n",
    "        mask_name\n",
    "        + \".pkl\"\n",
    "    )\n",
    "    if os.path.exists(brain_data_filepath):\n",
    "        with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "            Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "            \n",
    "        print(mask_name)\n",
    "\n",
    "        Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)\n",
    "        \n",
    "        print(sum(sum(Brain_Data_allsubs.samples>0)))\n",
    "\n",
    "        forced_choice_results = do_forced_choice(Brain_Data_allsubs)\n",
    "        print(\"\")\n",
    "        \n",
    "        prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y'])\n",
    "        forced_choice_prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y_forced_choice'])\n",
    "        \n",
    "        print(prediction,forced_choice_prediction)\n",
    "\n",
    "        forced_choice_results_dict[mask_name]=forced_choice_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imposed-youth",
   "metadata": {},
   "outputs": [],
   "source": [
    "forced_choice_results_dict = {}\n",
    "#for m_i,m_r in all_masks.iterrows():\n",
    "mask_name='goal'\n",
    "\n",
    "#m_r['mask_name']\n",
    "brain_data_filepath = (\n",
    "    \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/SST/mvpa_Dataset_conditions_84subs_correct_cond_\" +\n",
    "    mask_name\n",
    "    + \".pkl\"\n",
    ")\n",
    "if os.path.exists(brain_data_filepath):\n",
    "    with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "        Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "    print(mask_name)\n",
    "\n",
    "    Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)\n",
    "\n",
    "    print(sum(sum(Brain_Data_allsubs.samples>0)))\n",
    "\n",
    "    forced_choice_results = do_forced_choice(Brain_Data_allsubs)\n",
    "    print(\"\")\n",
    "\n",
    "    prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y'])\n",
    "    forced_choice_prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y_forced_choice'])\n",
    "\n",
    "    print(prediction,forced_choice_prediction)\n",
    "\n",
    "    forced_choice_results_dict[mask_name]=forced_choice_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-stewart",
   "metadata": {},
   "source": [
    "## normalization..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "scheduled-salem",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "renewable-academy",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filepath=ml_data_folderpath + \"/SST/ttr_mvpa2_res_v3_conditions_84subs_twoclasses_wholebrain.pkl\"\n",
    "#results_filepath=ml_data_folderpath + \"/SST/train_test_results_\" + dataset_name + \"_58subs_twoclasses_pfcmask_repeat1.pkl\"\n",
    "\n",
    "def decoderConstructor(*args, **kwargs):\n",
    "    return(Decoder(scoring='accuracy',verbose=0, *args, **kwargs))\n",
    "\n",
    "\n",
    "relevant_mask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smart-brass",
   "metadata": {},
   "source": [
    "### across series, training data only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "wired-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "    \n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "seeing-trademark",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.7312383 ,  0.27183977, -0.09587598, ..., -0.9286324 ,\n",
       "         0.68275356, -0.1660184 ],\n",
       "       [-0.381091  , -0.41968623, -0.42312527, ..., -0.6829239 ,\n",
       "        -0.12775972, -0.3424021 ],\n",
       "       [-0.00422587, -0.6077599 , -0.9000941 , ..., -2.3298805 ,\n",
       "        -0.33732155, -1.3221407 ],\n",
       "       ...,\n",
       "       [ 0.41749677,  0.32663387,  0.26954317, ...,  0.38780513,\n",
       "        -0.2603853 ,  0.03476725],\n",
       "       [ 0.25094506, -0.56350684, -1.2193519 , ...,  0.9981551 ,\n",
       "         0.6138571 ,  0.8256795 ],\n",
       "       [ 0.03494082, -0.22820817, -0.46821654, ..., -0.01853149,\n",
       "        -0.21609281, -0.10853325]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brain_Data_allsubs.samples.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "western-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forced_choice(dataset,normalization=False):\n",
    "    logo=LeaveOneGroupOut()\n",
    "\n",
    "    group_scores = {}\n",
    "    sample_wise_results = []\n",
    "    for train_index, test_index in logo.split(\n",
    "        dataset.samples, dataset.sa.targets, dataset.sa.chunks):\n",
    "        iteration_label = np.unique(dataset.sa.chunks[test_index])[0]\n",
    "\n",
    "        #print(iteration_label, \"; TRAIN:\", len(train_index), \" items; TEST:\", test_index)\n",
    "        print(\".\",end=\"\",flush=True)\n",
    "        \n",
    "        \n",
    "        #do train-test split\n",
    "        \n",
    "        train_X=dataset.samples[train_index].copy()\n",
    "        test_X = dataset.samples[test_index].copy()\n",
    "        train_y=dataset.sa.targets[train_index]\n",
    "        test_y = dataset.sa.targets[test_index]\n",
    "        clf_svc = SVC()\n",
    "        \n",
    "        if normalization==\"train_set_based\":\n",
    "            #get mean based on train set alone\n",
    "            voxel_mean = np.mean(train_X,axis=0)\n",
    "            voxel_sd = np.std(train_X,axis=0)\n",
    "            #apply it to all.\n",
    "            train_X=(train_X-voxel_mean)/voxel_sd\n",
    "            test_X=(test_X-voxel_mean)/voxel_sd\n",
    "            #print(\"normalizing\")\n",
    "            \n",
    "        #print(np.mean(train_X,axis=0))\n",
    "        \n",
    "\n",
    "\n",
    "        #create the classifier with a probability function\n",
    "        #https://mmuratarat.github.io/2019-10-12/probabilistic-output-of-svm#:~:text=SVMs%20don't%20output%20probabilities,the%20output%20to%20class%20probabilities.&text=For%20many%20problems%2C%20it%20is,of%20certainty%20about%20the%20answer.\n",
    "        sklearn_clf = CalibratedClassifierCV(clf_svc)\n",
    "        #train\n",
    "        sklearn_clf.fit(train_X, train_y)\n",
    "\n",
    "        #get the _probability_ we fall into each class\n",
    "        predict_y_prob = sklearn_clf.predict_proba(test_X)\n",
    "        predict_y = sklearn_clf.predict(test_X)\n",
    "        #need to label the output of the probability as CorrectStop and CorrectGo based on the classnames\n",
    "        #iterate through each class\n",
    "        proba_dict = {}\n",
    "        for i, cls in enumerate(sklearn_clf.classes_):\n",
    "            proba_dict[cls] = [x[i] for x in predict_y_prob]\n",
    "            \n",
    "        class_0 = sklearn_clf.classes_[0]\n",
    "        class_1 = sklearn_clf.classes_[1]\n",
    "\n",
    "        #find out which one of the two images is most likely to be CorrectGo\n",
    "        class_0_choice_index = np.argmax(proba_dict[class_0])\n",
    "        #now put that into a vector\n",
    "        forced_choice_predictions = [class_1]*2\n",
    "        forced_choice_predictions[class_0_choice_index] = class_0\n",
    "        accuracy_score = np.sum([pred==target for pred,target in zip(forced_choice_predictions,test_y)])/len(test_y)\n",
    "        #print(predict_y)\n",
    "        #print(proba_dict)\n",
    "        #print(forced_choice_predictions)\n",
    "        #print(accuracy_score)\n",
    "        #can we do a sample-wise table?\n",
    "\n",
    "        group_scores[iteration_label] = accuracy_score\n",
    "        sample_wise_results_iter = pd.DataFrame({\n",
    "            'chunk':[iteration_label]*len(test_y),\n",
    "            'target_y':test_y,\n",
    "            'pred_y':predict_y,\n",
    "            'pred_y_forced_choice':forced_choice_predictions\n",
    "        })\n",
    "        #add the class-wise probabilities\n",
    "        for cls in sklearn_clf.classes_:\n",
    "            sample_wise_results_iter['pred_prob_' + cls] = proba_dict[cls]\n",
    "            \n",
    "        sample_wise_results = sample_wise_results + [sample_wise_results_iter]\n",
    "            \n",
    "    sample_wise_results_df = pd.concat(sample_wise_results)\n",
    "    return({'sample_wise':sample_wise_results_df,'group_wise':group_scores})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "classical-tours",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.1773757e-08  0.0000000e+00 -7.3585982e-09 ... -1.1773757e-08\n",
      "  6.6227386e-08  2.0604075e-08]\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(Brain_Data_allsubs.samples,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "better-highlight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.        1.0000001 1.        ... 1.        1.        0.9999999]\n"
     ]
    }
   ],
   "source": [
    "print(np.std(Brain_Data_allsubs.samples,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "immediate-courtesy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sample_wise':        chunk     target_y       pred_y pred_y_forced_choice  \\\n",
       " 0   DEV005_1    CorrectGo    CorrectGo            CorrectGo   \n",
       " 1   DEV005_1  CorrectStop  CorrectStop          CorrectStop   \n",
       " 0   DEV006_1    CorrectGo    CorrectGo            CorrectGo   \n",
       " 1   DEV006_1  CorrectStop  CorrectStop          CorrectStop   \n",
       " 0   DEV010_1    CorrectGo    CorrectGo            CorrectGo   \n",
       " ..       ...          ...          ...                  ...   \n",
       " 1   DEV216_1  CorrectStop  CorrectStop          CorrectStop   \n",
       " 0   DEV217_1    CorrectGo    CorrectGo            CorrectGo   \n",
       " 1   DEV217_1  CorrectStop  CorrectStop          CorrectStop   \n",
       " 0   DEV218_1    CorrectGo    CorrectGo            CorrectGo   \n",
       " 1   DEV218_1  CorrectStop  CorrectStop          CorrectStop   \n",
       " \n",
       "     pred_prob_CorrectGo  pred_prob_CorrectStop  \n",
       " 0              0.928721               0.071279  \n",
       " 1              0.148201               0.851799  \n",
       " 0              0.974001               0.025999  \n",
       " 1              0.248213               0.751787  \n",
       " 0              0.969462               0.030538  \n",
       " ..                  ...                    ...  \n",
       " 1              0.257557               0.742443  \n",
       " 0              0.924387               0.075613  \n",
       " 1              0.088072               0.911928  \n",
       " 0              0.526234               0.473766  \n",
       " 1              0.057398               0.942602  \n",
       " \n",
       " [162 rows x 6 columns],\n",
       " 'group_wise': {'DEV005_1': 1.0,\n",
       "  'DEV006_1': 1.0,\n",
       "  'DEV010_1': 1.0,\n",
       "  'DEV011_1': 1.0,\n",
       "  'DEV013_1': 1.0,\n",
       "  'DEV014_1': 1.0,\n",
       "  'DEV015_1': 1.0,\n",
       "  'DEV016_1': 1.0,\n",
       "  'DEV017_1': 1.0,\n",
       "  'DEV018_1': 1.0,\n",
       "  'DEV019_1': 1.0,\n",
       "  'DEV020_1': 1.0,\n",
       "  'DEV021_1': 1.0,\n",
       "  'DEV022_1': 1.0,\n",
       "  'DEV023_1': 1.0,\n",
       "  'DEV024_1': 1.0,\n",
       "  'DEV026_1': 1.0,\n",
       "  'DEV027_1': 1.0,\n",
       "  'DEV028_1': 1.0,\n",
       "  'DEV029_1': 1.0,\n",
       "  'DEV030_1': 1.0,\n",
       "  'DEV034_1': 1.0,\n",
       "  'DEV035_1': 1.0,\n",
       "  'DEV036_1': 1.0,\n",
       "  'DEV039_1': 1.0,\n",
       "  'DEV040_1': 1.0,\n",
       "  'DEV041_1': 1.0,\n",
       "  'DEV042_1': 1.0,\n",
       "  'DEV043_1': 1.0,\n",
       "  'DEV046_1': 1.0,\n",
       "  'DEV047_1': 1.0,\n",
       "  'DEV048_1': 1.0,\n",
       "  'DEV049_1': 1.0,\n",
       "  'DEV050_1': 1.0,\n",
       "  'DEV051_1': 1.0,\n",
       "  'DEV052_1': 1.0,\n",
       "  'DEV053_1': 1.0,\n",
       "  'DEV055_1': 0.0,\n",
       "  'DEV056_1': 1.0,\n",
       "  'DEV057_1': 1.0,\n",
       "  'DEV058_1': 1.0,\n",
       "  'DEV059_1': 1.0,\n",
       "  'DEV060_1': 1.0,\n",
       "  'DEV062_1': 1.0,\n",
       "  'DEV064_1': 1.0,\n",
       "  'DEV067_1': 1.0,\n",
       "  'DEV068_1': 1.0,\n",
       "  'DEV069_1': 1.0,\n",
       "  'DEV071_1': 1.0,\n",
       "  'DEV073_1': 1.0,\n",
       "  'DEV074_1': 1.0,\n",
       "  'DEV076_1': 1.0,\n",
       "  'DEV077_1': 1.0,\n",
       "  'DEV079_1': 1.0,\n",
       "  'DEV083_1': 1.0,\n",
       "  'DEV084_1': 1.0,\n",
       "  'DEV085_1': 1.0,\n",
       "  'DEV086_1': 1.0,\n",
       "  'DEV087_1': 1.0,\n",
       "  'DEV089_1': 1.0,\n",
       "  'DEV097_1': 1.0,\n",
       "  'DEV105_1': 1.0,\n",
       "  'DEV107_1': 1.0,\n",
       "  'DEV135_1': 1.0,\n",
       "  'DEV141_1': 1.0,\n",
       "  'DEV145_1': 1.0,\n",
       "  'DEV157_1': 1.0,\n",
       "  'DEV158_1': 1.0,\n",
       "  'DEV159_1': 1.0,\n",
       "  'DEV164_1': 1.0,\n",
       "  'DEV169_1': 1.0,\n",
       "  'DEV171_1': 1.0,\n",
       "  'DEV173_1': 1.0,\n",
       "  'DEV177_1': 1.0,\n",
       "  'DEV186_1': 1.0,\n",
       "  'DEV197_1': 1.0,\n",
       "  'DEV206_1': 1.0,\n",
       "  'DEV215_1': 1.0,\n",
       "  'DEV216_1': 1.0,\n",
       "  'DEV217_1': 1.0,\n",
       "  'DEV218_1': 1.0}}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "do_forced_choice(Brain_Data_allsubs,normalization=\"train_set_based\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-wallace",
   "metadata": {},
   "source": [
    "### across series, whole set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "polar-lotus",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "    \n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "typical-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_mean_across_images_per_voxel(bd):\n",
    "    voxel_mean = np.mean(bd.samples,axis=0)\n",
    "    voxel_sd = np.std(bd.samples,axis=0)\n",
    "    bd.samples = (bd.samples-voxel_mean)/voxel_sd\n",
    "    return(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "musical-parker",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs = bd_mean_across_images_per_voxel(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "announced-insider",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................."
     ]
    }
   ],
   "source": [
    "norm_across_whole_set = do_forced_choice(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "atlantic-filter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_fcp(x):\n",
    "    prediction = np.mean(x['sample_wise']['target_y']==x['sample_wise']['pred_y'])\n",
    "    forced_choice_prediction = np.mean(x['sample_wise']['target_y']==x['sample_wise']['pred_y_forced_choice'])\n",
    "    return(prediction,forced_choice_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "breathing-effort",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9506172839506173, 0.9876543209876543)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_pred_fcp(norm_across_whole_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorporate-northwest",
   "metadata": {},
   "source": [
    "## across each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "brutal-dating",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "    \n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "norwegian-lightweight",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bd_mean_across_voxels_per_img(bd):\n",
    "    img_mean = np.mean(bd.samples,axis=1,keepdims=True)\n",
    "    img_sd = np.std(bd.samples,axis=1,keepdims=True)\n",
    "    bd.samples = (bd.samples-img_mean)/img_sd\n",
    "    return(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "certified-dakota",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs = bd_mean_across_voxels_per_img(Brain_Data_allsubs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "egyptian-memorabilia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................................."
     ]
    }
   ],
   "source": [
    "norm_across_each_img = do_forced_choice(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "cosmetic-mailing",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.mean(norm_across_each_img['sample_wise']['target_y']==norm_across_each_img['sample_wise']['pred_y'])\n",
    "forced_choice_prediction = np.mean(norm_across_each_img['sample_wise']['target_y']==norm_across_each_img['sample_wise']['pred_y_forced_choice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "laden-upset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.845679012345679, 0.9876543209876543)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction, forced_choice_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaging-mobility",
   "metadata": {},
   "source": [
    "## neural similirity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-effects",
   "metadata": {},
   "source": [
    "Previously we used neural similarity. this learner is actually more accurate, and what's more, we get a numeric probability which will be helpful.\n",
    "\n",
    "Firstly, how can we re-eimplemnt the correlation I've already done?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "central-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = forced_choice_results['classifier']\n",
    "sample_wise_results = forced_choice_results['sample_wise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "continuing-therapy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop'], dtype='<U11')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(Brain_Data_allsubs[10:20].samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "straight-wrong",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90493252, 0.09506748],\n",
       "       [0.15675041, 0.84324959],\n",
       "       [0.89972668, 0.10027332],\n",
       "       [0.1837892 , 0.8162108 ],\n",
       "       [0.60870773, 0.39129227],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.9050255 , 0.0949745 ],\n",
       "       [0.15683357, 0.84316643],\n",
       "       [0.88505269, 0.11494731],\n",
       "       [0.21858803, 0.78141197]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict_proba(Brain_Data_allsubs[10:20].samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "phantom-winner",
   "metadata": {},
   "source": [
    "We'll use the predict_proba outcomes to calculate similarity instead of the similarity with image--since that's what we have here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "painful-british",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_cs_prob = sample_wise_results.loc[sample_wise_results.target_y=='CorrectStop']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "graphic-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>target_y</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>pred_y_forced_choice</th>\n",
       "      <th>pred_prob_CorrectGo</th>\n",
       "      <th>pred_prob_CorrectStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.180785</td>\n",
       "      <td>0.819215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.082440</td>\n",
       "      <td>0.917560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV010_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.226005</td>\n",
       "      <td>0.773995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV011_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.272213</td>\n",
       "      <td>0.727787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV013_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.104683</td>\n",
       "      <td>0.895317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV014_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.062398</td>\n",
       "      <td>0.937602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV015_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.173931</td>\n",
       "      <td>0.826069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV016_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.583941</td>\n",
       "      <td>0.416059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV017_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.046423</td>\n",
       "      <td>0.953577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV018_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.211199</td>\n",
       "      <td>0.788801</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     chunks     target_y       pred_y pred_y_forced_choice  \\\n",
       "1  DEV005_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV006_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV010_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV011_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV013_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV014_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV015_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV016_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV017_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "1  DEV018_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "\n",
       "   pred_prob_CorrectGo  pred_prob_CorrectStop  \n",
       "1             0.180785               0.819215  \n",
       "1             0.082440               0.917560  \n",
       "1             0.226005               0.773995  \n",
       "1             0.272213               0.727787  \n",
       "1             0.104683               0.895317  \n",
       "1             0.062398               0.937602  \n",
       "1             0.173931               0.826069  \n",
       "1             0.583941               0.416059  \n",
       "1             0.046423               0.953577  \n",
       "1             0.211199               0.788801  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs_cs_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "pressing-arizona",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_differences['subj_wave'] = individual_differences.subject+\"_\"+individual_differences.wave.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "communist-olive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      DEV001_1\n",
       "1      DEV002_1\n",
       "2      DEV004_1\n",
       "3      DEV005_1\n",
       "4      DEV006_1\n",
       "         ...   \n",
       "195    DEV216_1\n",
       "196    DEV217_1\n",
       "197    DEV219_1\n",
       "198    DEV250_1\n",
       "199    DEV280_1\n",
       "Name: subj_wave, Length: 200, dtype: object"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "individual_differences['subj_wave']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "direct-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset_cs = individual_differences.merge(cs_cs_prob,how='outer',left_on='subj_wave',right_on='chunks')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expected-stand",
   "metadata": {},
   "source": [
    "Test that similarity...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "central-matter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'subject, cancer_promoting_minus_preventing_FCI, cancer_promoting_minus_preventing_FFQ, cancer_promoting_minus_preventing_craved_FCI, cancer_promoting_minus_preventing_craved_FFQ, cancer_promoting_minus_preventing_liked_FCI, cancer_promoting_minus_preventing_liked_FFQ, cancer_promoting_FCI, cancer_promoting_FFQ, cancer_preventing_FCI, cancer_preventing_FFQ, BSCS, cSES, EDM, BIS_11, PCS, RS, TRSQ, bf_1, weight_0, height_0, birthsex, age365, bmi_0, bmi_1, bmi, bf_1_controlled, bf_1_bsexnormedzs, ACES_sum, ACES_household_dysfunction, ACES_neglectful_parenting, ACES_abuse, ACES_divorced_separated, BFI_agreeableness, BFI_conscientiousness, BFI_extraversion, BFI_neuroticism, BFI_openness, DEMO_mcarthur_social_standing, IMI_effort_importance, IMI_interest_enjoyment, IMI_perceived_choice, IMI_perceived_competence, IMI_value_usefulness, IPAQ_moderateminutes, IPAQ_sittinghours, IPAQ_vigorousminutes, IPAQ_walkingminutes, NCS_get_job_done, NCS_deliberating_issues, NCS_prefer_complex, NCS_prefer_little_thought, NCS_intellectual_task, NCS_relief_not_satisfaction, NCS_like_responsibility, NCS_new_solutions_to_problems, NCS_avoid_depth, NCS_tasks_little_thought, NCS_think_minimally, NCS_satisfaction_in_deliberating, NCS_small_daily_projects, NCS_solve_puzzles, NCS_total, NCS_thinking_not_exciting, NCS_abstract_thinking, NCS_thought_appealing, NCS_thinking_not_fun, PLAN_cognitive_strategies, PLAN_temporal_orientation, PLAN_mental_forecasting, RMQ_assessment, RMQ_lie, RMQ_locomotion, RTFS_factor_1, RTFS_factor_2, SRHI_sum, SRHI_healthy, SRHI_unhealthy, TESQ_E_avoidance_of_temptations, TESQ_E_goal_deliberation, TESQ_E_distraction, TESQ_E_goal_and_rule_setting, TESQ_E_sum, TESQ_E_controlling_temptations, TESQ_E_suppression, education_own, zipcode_median_income_acs, household_income_level_medamount, household_income_per_person, ses_aggregate, SST_CorrectGo, SST_CorrectStop, SST_Cue, SST_FailedGo, SST_FailedStop, SST_prop_successful_stops, SST_reaction_time, SST_go_trial_reaction_time, SST_GRTint, SST_GRTmean, SST_GRTmedian, SST_GRTquant, SST_NRCount, SST_PctInhib, SST_SSD, SST_SSRT, SST_SSRTint, SST_SSRTquant, ROC_Crave_Look, ROC_Crave_Regulate, ROC_Neutral_Look, ROC_No Crave_Look, ROC_Crave_Regulate_Minus_Look, ROC_Crave_Minus_Neutral, ROC_Crave_Minus_NoCrave, WTP_healthy, WTP_unhealthy, WTP_unhealthy_minus_healthy, SRHI_healthy_minus_unhealthy, RTFS_f1_minus_f2, IPAQ_walkingMETminutes, IPAQ_moderateMETminutes, IPAQ_vigorousMETminutes, IPAQ_total_METminutes, IPAQ_MET_kCal, birthsex_factor, wave, subj_wave, chunks, target_y, pred_y, pred_y_forced_choice, pred_prob_CorrectGo, pred_prob_CorrectStop'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(full_dataset_cs.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compact-error",
   "metadata": {},
   "source": [
    "\n",
    "def get_bd(brain_data_filepath,ns1,ns2,relevant_mask,condition1_name = 'PostError_similarity',condition2_name = 'PostCorrect_similarity',similarity_method='correlation'):\n",
    "    bd=pickle.load(open(brain_data_filepath,'rb'))\n",
    "    \n",
    "    if relevant_mask is None:\n",
    "        relevant_mask = nlt.Brain_Data(ns1).mask\n",
    "    print(\"applying mask\")\n",
    "    bd_to_measure = bd.apply_mask(relevant_mask)\n",
    "    #bd_PostError=bd[bd.X.condition_label==\"CorrectGoFollowingFailedStop\"]\n",
    "\n",
    "    #bd.X.condition_label.value_counts()\n",
    "\n",
    "    print(\"getting similarity 1\")\n",
    "    #bd.X[condition1_name] = (bd_to_measure.similarity(ns1))\n",
    "    bd.X[condition1_name] = (nlt.Brain_Data(ns1).similarity(bd_to_measure,similarity_method))\n",
    "    print(\"getting similarity 2\")\n",
    "    #bd.X[condition2_name] = (bd_to_measure.similarity(ns2))\n",
    "    bd.X[condition2_name] = (nlt.Brain_Data(ns2).similarity(bd_to_measure,similarity_method))\n",
    "\n",
    "    return(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "sorted-queue",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/SST/visualization.py:7: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML, Markdown\n"
     ]
    }
   ],
   "source": [
    "from visualization import visualize_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "western-scientist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "pred_prob_CorrectStop"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "r=0.01; p-value=0.9837"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "rho=0.07; p-value=0.8548"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_corr('bf_1','pred_prob_CorrectStop',full_dataset_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "forced-catalyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0.819215\n",
       "1      0.819215\n",
       "2      0.917560\n",
       "3      0.917560\n",
       "4      0.773995\n",
       "         ...   \n",
       "157         NaN\n",
       "158         NaN\n",
       "159         NaN\n",
       "160         NaN\n",
       "161         NaN\n",
       "Name: pred_prob_CorrectStop, Length: 162, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dataset_cs['pred_prob_CorrectStop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-click",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "needed-ordinance",
   "metadata": {},
   "source": [
    "from visualization import visualize_corr\n",
    "\n",
    "classifier = forced_choice_results['classifier']\n",
    "sample_wise_results = forced_choice_results['sample_wise']\n",
    "individual_differences['subj_wave'] = individual_differences.subject+\"_\"+individual_differences.wave.astype(str)\n",
    "full_dataset_cs = individual_differences.merge(cs_cs_prob,how='outer',left_on='subj_wave',right_on='chunks')\n",
    "\n",
    "visualize_corr('bf_1','pred_prob_CorrectStop',full_dataset_cs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3_mvpa]",
   "language": "python",
   "name": "conda-env-.conda-py3_mvpa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
