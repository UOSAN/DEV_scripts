{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fixed-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/mvpa2/datasets/base.py:465: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, shape=None, sid=None, fid=None, dtype=np.float):\n"
     ]
    }
   ],
   "source": [
    "from mvpa2.datasets.mri import fmri_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehavioralDataNotFoundForBrainDataException(Exception):\n",
    "    \"\"\"Behavioral data could not be matched to a subject.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-british",
   "metadata": {},
   "source": [
    "Replicating earlier work on mvpa. Try not to overly complicate it--the main point is just to verify we get similar results on a different package to validate prior work. ANd we are primarily interested in validating the very high cross-validation results I got with nltools. Should aim for readable code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "generic-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mvpa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surrounded-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-lighting",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latest-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "linear-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_10subs_correct_cond.pkl'\n",
    "results_filepath=ml_data_folderpath + \"/SST/mvpa_tt_res_v3_conditions_84subs_twoclasses_pfcmask.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intimate-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_exclude_list = pd.read_csv(\"../nsc_subject_exclusions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "level-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_df_raw = pd.read_csv(nonbids_data_path + \"fMRI/ml/train_test_markers_20211027T173724.csv\")\n",
    "test_train_df_raw = test_train_df_raw.merge(include_exclude_list[include_exclude_list.Task=='SST'],left_on='sub_label',right_on='SubjectId',how='left')\n",
    "test_train_df_raw.loc[test_train_df_raw.Include.isna(),'Include'] = True\n",
    "test_train_df = test_train_df_raw[test_train_df_raw.Include==True]\n",
    "exclude_subjects = ['DEV061','DEV185','DEV187','DEV189','DEV190','DEV192','DEV198','DEV203','DEV220','DEV221']\n",
    "train_subjs = test_train_df.loc[test_train_df.SplitGroup=='Train','sub_label'].tolist()#only get the train subjects; ignore those previously marked hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caroline-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjs_selected = [ts for ts in train_subjs if (ts not in exclude_subjects)]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "altered-newfoundland",
   "metadata": {},
   "source": [
    "pfc_mask = create_mask_from_images(get_pfc_image_filepaths(ml_data_folderpath + \"/\"),threshold=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "continued-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_differences = pd.read_csv(ml_data_folderpath + \"/data_by_ppt.csv\")\n",
    "individual_differences = individual_differences.rename(columns={'SID':'subject'})\n",
    "individual_differences['wave']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-explosion",
   "metadata": {},
   "source": [
    "We probably actually want to start the pipeline from the betas rather than loading from pickle. to be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "african-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa_pipeline_utils import get_Brain_Data_betas_as_mvpa_for_sub, import_beta_series_pymvpa2, sa_to_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "collective-jimmy",
   "metadata": {},
   "source": [
    "my_test_data =import_beta_series_pymvpa2(\n",
    "    train_subjs_selected,'conditions',\n",
    "    out_folder = ml_data_folderpath + \"/SST/\",\n",
    "    conditions_to_include = ['CorrectGo','CorrectStop'],\n",
    "    condition_count_required=2,\n",
    "    supplementary_df = individual_differences,\n",
    "    out_file_suffix = '_correct_cond',\n",
    "    concatenate_condition_labels=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-audio",
   "metadata": {},
   "source": [
    "## whole brain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "technological-miniature",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "affected-platinum",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filepath=ml_data_folderpath + \"/SST/ttr_mvpa2_res_v3_conditions_84subs_twoclasses_wholebrain.pkl\"\n",
    "#results_filepath=ml_data_folderpath + \"/SST/train_test_results_\" + dataset_name + \"_58subs_twoclasses_pfcmask_repeat1.pkl\"\n",
    "\n",
    "def decoderConstructor(*args, **kwargs):\n",
    "    return(Decoder(scoring='accuracy',verbose=0, *args, **kwargs))\n",
    "\n",
    "\n",
    "relevant_mask = None"
   ]
  },
  {
   "cell_type": "raw",
   "id": "elect-relaxation",
   "metadata": {},
   "source": [
    "mvpa2.datasets.mri.map2nifti(fmri_dataset1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "incoming-maple",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "understood-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa2.datasets.mri import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cathedral-antique",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up chunks and targets so we can do the learning.\n",
    "attribute_df = sa_to_df(Brain_Data_allsubs.sa)\n",
    "pd.concat([attribute_df['subject'],attribute_df['wave']],axis=1)\n",
    "chunk = attribute_df['subject']+\"_\" + attribute_df['wave'].astype(str)\n",
    "Brain_Data_allsubs.sa['chunks'] = list(chunk)\n",
    "Brain_Data_allsubs.sa['targets'] = list(Brain_Data_allsubs.sa['condition_label'].value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "announced-stopping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "cpus available; cpus to use:\n",
      "28 25\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "print(\"python initialized for apply_loocv_and_save\")\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "import glob\n",
    "import random\n",
    "import pickle\n",
    "#import dev_wtp_io_utils\n",
    "import gc #garbage collection\n",
    "#from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut, LeaveOneGroupOut\n",
    "import os, warnings\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import math\n",
    "\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(\"cpus available; cpus to use:\")\n",
    "print(cpus_available, cpus_to_use)\n",
    "\n",
    "#cpus_available = multiprocessing.cpu_count()\n",
    "#custom thing I have set in my jupyter notebook task.\n",
    "print(cpus_available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "billion-westminster",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'mvpa2.clfs' from '/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/mvpa2/clfs/__init__.py'>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mvpa2.clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "placed-receipt",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from mvpa2.measures.base import CrossValidation\n",
    "from mvpa2.clfs.meta import NFoldPartitioner\n",
    "from mvpa2.clfs.svm import LinearCSVMC\n",
    "clf = LinearCSVMC()\n",
    "cv = CrossValidation(clf, NFoldPartitioner(), errorfx=lambda p, t:np.mean(p==t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "alive-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossval_result = cv(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "saved-genome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['time_indices', 'time_coords', 'condition_index', 'condition_label', 'raw_beta_description', 'beta', 'subject', 'wave', 'cancer_promoting_minus_preventing_FCI', 'cancer_promoting_minus_preventing_FFQ', 'cancer_promoting_minus_preventing_craved_FCI', 'cancer_promoting_minus_preventing_craved_FFQ', 'cancer_promoting_minus_preventing_liked_FCI', 'cancer_promoting_minus_preventing_liked_FFQ', 'cancer_promoting_FCI', 'cancer_promoting_FFQ', 'cancer_preventing_FCI', 'cancer_preventing_FFQ', 'BSCS', 'cSES', 'EDM', 'BIS_11', 'PCS', 'RS', 'TRSQ', 'bf_1', 'weight_0', 'height_0', 'birthsex', 'age365', 'bmi_0', 'bmi_1', 'bmi', 'bf_1_controlled', 'bf_1_bsexnormedzs', 'ACES_sum', 'ACES_household_dysfunction', 'ACES_neglectful_parenting', 'ACES_abuse', 'ACES_divorced_separated', 'BFI_agreeableness', 'BFI_conscientiousness', 'BFI_extraversion', 'BFI_neuroticism', 'BFI_openness', 'DEMO_mcarthur_social_standing', 'IMI_effort_importance', 'IMI_interest_enjoyment', 'IMI_perceived_choice', 'IMI_perceived_competence', 'IMI_value_usefulness', 'IPAQ_moderateminutes', 'IPAQ_sittinghours', 'IPAQ_vigorousminutes', 'IPAQ_walkingminutes', 'NCS_get_job_done', 'NCS_deliberating_issues', 'NCS_prefer_complex', 'NCS_prefer_little_thought', 'NCS_intellectual_task', 'NCS_relief_not_satisfaction', 'NCS_like_responsibility', 'NCS_new_solutions_to_problems', 'NCS_avoid_depth', 'NCS_tasks_little_thought', 'NCS_think_minimally', 'NCS_satisfaction_in_deliberating', 'NCS_small_daily_projects', 'NCS_solve_puzzles', 'NCS_total', 'NCS_thinking_not_exciting', 'NCS_abstract_thinking', 'NCS_thought_appealing', 'NCS_thinking_not_fun', 'PLAN_cognitive_strategies', 'PLAN_temporal_orientation', 'PLAN_mental_forecasting', 'RMQ_assessment', 'RMQ_lie', 'RMQ_locomotion', 'RTFS_factor_1', 'RTFS_factor_2', 'SRHI_sum', 'SRHI_healthy', 'SRHI_unhealthy', 'TESQ_E_avoidance_of_temptations', 'TESQ_E_goal_deliberation', 'TESQ_E_distraction', 'TESQ_E_goal_and_rule_setting', 'TESQ_E_sum', 'TESQ_E_controlling_temptations', 'TESQ_E_suppression', 'education_own', 'zipcode_median_income_acs', 'household_income_level_medamount', 'household_income_per_person', 'ses_aggregate', 'SST_CorrectGo', 'SST_CorrectStop', 'SST_Cue', 'SST_FailedGo', 'SST_FailedStop', 'SST_prop_successful_stops', 'SST_reaction_time', 'SST_go_trial_reaction_time', 'SST_GRTint', 'SST_GRTmean', 'SST_GRTmedian', 'SST_GRTquant', 'SST_NRCount', 'SST_PctInhib', 'SST_SSD', 'SST_SSRT', 'SST_SSRTint', 'SST_SSRTquant', 'ROC_Crave_Look', 'ROC_Crave_Regulate', 'ROC_Neutral_Look', 'ROC_No Crave_Look', 'ROC_Crave_Regulate_Minus_Look', 'ROC_Crave_Minus_Neutral', 'ROC_Crave_Minus_NoCrave', 'WTP_healthy', 'WTP_unhealthy', 'WTP_unhealthy_minus_healthy', 'SRHI_healthy_minus_unhealthy', 'RTFS_f1_minus_f2', 'IPAQ_walkingMETminutes', 'IPAQ_moderateMETminutes', 'IPAQ_vigorousMETminutes', 'IPAQ_total_METminutes', 'IPAQ_MET_kCal', 'birthsex_factor', 'chunks', 'targets'])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brain_Data_allsubs.sa.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "floppy-glasgow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop', 'CorrectGo', 'CorrectStop',\n",
       "       'CorrectGo', 'CorrectStop'], dtype='<U11')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brain_Data_allsubs.sa.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "moved-performer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8703703703703703"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(crossval_result.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dimensional-criticism",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7407407407407407"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(crossval_result.samples>0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "linear-integer",
   "metadata": {},
   "source": [
    "That's interesting:\n",
    "\n",
    " - performance is less good than previously--we were getting 94% performance in the last version of my nltools-based classifier, but only 87% here, and that seems maybe complicated by the fact the learner is apparently labelling _both_ items from each set as a particular class (no idea whether it's consistent or not). It never gets both wrong. Does that artifically inflate the score? Rather than accuracy, we should probably have it output scores for each item and then compare the scores--that's what we're trying to do.\n",
    " - we should make sure the classification method is as similar as possible. The page for SVC in nilearn: https://nilearn.github.io/modules/generated/nilearn.decoding.Decoder.html, which uses sklearn's SVC.\n",
    "     - sklearn uses libsvm--see https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC.\n",
    " - pre-processing. we haven't preprocessed at all, so this result is more comparable to `TESQ-ml-ns_on_nogo_go-no-zscore.ipynb`. That obtained a performance of 85%, pretty close to what we saw here.\n",
    " - How do we pre-process? Not sure that there's an option to do it here in the manner we did it for the previous analysis. That was to apply z-scoring to the training set only, then apply the same function to the test set--I believe; see https://neurostars.org/t/does-nilearn-apply-standardization-used-during-training-to-predict/21354\n",
    " - We can try once more with z-scored original data-doing the entire dataset. Important to note this isn't the same as v3.\n",
    " - mvpa docs differ \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "joined-continent",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3_mvpa]",
   "language": "python",
   "name": "conda-env-.conda-py3_mvpa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
