{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying trialwise CorrectGo and NoGo trials\n",
    "\n",
    "There are a number of steps to this. Hopefully we can recycle previous code and be up fairly quickly!\n",
    "\n",
    "1. Load beta data. Ideally this process should include a cache into a pure python object so we don't have to reload it each time.\n",
    "2. Preprocess the data.\n",
    "3. Do cross-validated training and testing. Ideally an inner loop to select best parameters, an outer loop to get cross-validated performance, and final training over all the data to get an image. The inner loop can be probably be handled within the package we use probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "from apply_loocv_and_save import load_and_preprocess\n",
    "from dev_utils import read_yaml_for_host\n",
    "import warnings\n",
    "\n",
    "\n",
    "config_data = read_yaml_for_host(\"sst_config.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "from nilearn.decoding import DecoderRegressor,Decoder\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(cpus_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from nilearn.decoding import DecoderRegressor,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = config_data['nonbids_data_path']\n",
    "ml_data_folderpath = nonbids_data_path + \"fMRI/ml\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading beta data\n",
    "\n",
    "beta data is generally written in `load_multisubject_brain_data_sst_w1.ipynb`.\n",
    "\n",
    "We just have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_10596/442391669.py:3: UserWarning: not sure if this file holds up--it was created in 2021; need to see if it's still valid\n",
      "  warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n"
     ]
    }
   ],
   "source": [
    "#brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_30subs_correct_cond_pfc.pkl'\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_2subs_correct_cond_pfc.pkl'\n",
    "warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20220818T144138.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 2 subjects overlapping between the subjects marked for train data and the training dump file itself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_set: 62918\n",
      "brain_data_filepath: 172\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 158\n",
      "response_transform_func: 144\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n",
      "195\n",
      "195\n",
      "cleaning memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_10596/1474138623.py:8: UserWarning: the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\n",
      "  warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 115, 97, 195)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects['X'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.40641484,  6.16565233,  1.39700845,  3.82197252,  4.28057301,\n",
       "        2.14737517,  2.46158852,  3.06783847,  5.08154921,  4.87398956,\n",
       "        1.90658474,  1.67149771,  4.09974887,  2.4683288 ,  2.85134229,\n",
       "        2.07687452,  1.84022439,  2.66836484,  1.79617661,  1.74015298,\n",
       "        2.39447989,  2.31657667,  2.27748481, 13.77747435,  2.27482718,\n",
       "        2.21712153,  2.25681476,  1.78962211,  2.71576783,  3.33867676,\n",
       "        1.46974884,  3.84346906,  6.41834585,  2.22134288,  1.76487628,\n",
       "        2.39660948,  2.31400786,  3.97190644,  8.69752037,  3.11654149,\n",
       "        2.5391831 ,  1.94143088,  2.3291792 ,  2.76986559,  1.56136924,\n",
       "        2.19254842,  3.05239253,  9.26194489,  3.8193176 ,  3.95160097,\n",
       "        2.1973582 ,  2.20513672,  3.76381699,  1.89934796,  2.31493265,\n",
       "        2.31085593,  1.85610932,  1.24405478,  1.42646331,  1.56756357,\n",
       "        2.49645203,  2.63318324,  2.55775487,  3.37098409,  2.93091117,\n",
       "        5.68490989,  3.41321712,  2.62005231,  1.26193348,  4.84714348,\n",
       "        2.68712101,  1.67339258,  4.05745999,  2.29049349,  3.27063205,\n",
       "        2.8762282 ,  3.65011492,  5.24979285,  4.2829965 ,  4.98803581,\n",
       "        4.86572476,  2.07631535,  3.85715121,  3.40874864,  3.13286729,\n",
       "        3.26379671,  4.46634311,  7.45654876,  5.78824526,  8.0377062 ,\n",
       "       15.51200148,  4.96086075,  5.74982256, 12.69258168,  7.29578914,\n",
       "        2.96422227,  5.36488174,  4.51636883,  3.13538988,  4.72017027,\n",
       "        3.97721836,  3.70431764,  4.49570934,  7.92037055,  5.29391896,\n",
       "        2.63898257,  4.69088256,  4.04573506,  4.88003538,  3.33693005,\n",
       "        4.4097057 ,  6.07414622,  6.90760706,  5.84295372,  7.86007408,\n",
       "        2.17637295,  8.64819783, 10.54015711,  6.21447173,  1.50262055,\n",
       "        5.7480574 , 15.87368807, 13.83943226,  7.33210619, 11.19779677,\n",
       "        4.68199426,  3.04512938,  2.10927161,  4.15746034,  5.00376119,\n",
       "        3.4748151 ,  4.3601457 ,  4.16024857,  3.18551442,  8.9368698 ,\n",
       "        6.8820855 ,  9.66476411, 11.8714648 , 18.42828121,  8.34571646,\n",
       "        5.03626038,  4.53880498,  3.13737104,  4.01570266,  2.50471756,\n",
       "        3.46006579,  2.49830794,  5.07891877,  3.655182  ,  3.23757282,\n",
       "        3.3940055 ,  1.91494164,  2.66397579,  2.52782898,  2.58576885,\n",
       "        3.64641593,  2.46984234,  2.93019208,  2.90993394,  2.79743216,\n",
       "        3.37930667,  3.9240626 ,  2.31776056,  8.8760382 ,  5.32663205,\n",
       "        3.7970482 , 12.9592588 ,  2.19493926,  3.57554356,  4.00222512,\n",
       "        3.53774938,  6.88639321,  6.03812317,  3.41226881,  3.96529515,\n",
       "        3.55878277,  3.60117298,  3.76764064,  3.03771372,  4.643487  ,\n",
       "       14.52873016,  9.99833383,  8.4661088 ,  5.24398503,  4.39415859,\n",
       "        2.62310167,  2.33093535,  2.60296373,  5.05423109,  5.99693978,\n",
       "        2.24488137,  4.0123422 ,  2.62731013,  2.82239641,  0.17198649])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_std_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_img = all_subjects['X']\n",
    "#get average signal across voxels\n",
    "#voxel_avg_signal = nifti_img.get_fdata().mean(axis=3)\n",
    "#get average signal across first 3 axes of the array\n",
    "img_avg_signal = nifti_img.get_fdata().mean(axis=(0,1,2))\n",
    "img_std_signal = nifti_img.get_fdata().std(axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97, 115, 97, 195)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_avg_signal_ndarray =  np.array([np.tile(x,nifti_img.shape[0:3]) for x in img_avg_signal])\n",
    "#rotate the array so that the last axis is time\n",
    "series_avg_signal_ndarray = np.moveaxis(series_avg_signal_ndarray,0,-1)\n",
    "#series_avg_signal_ndarray.shape\n",
    "\n",
    "series_std_signal_ndarray =  np.array([np.tile(x,nifti_img.shape[0:3]) for x in img_std_signal])\n",
    "#rotate the array so that the last axis is time\n",
    "series_std_signal_ndarray = np.moveaxis(series_std_signal_ndarray,0,-1)\n",
    "#series_std_signal_ndarray.shape\n",
    "\n",
    "#now create nifti images out of them\n",
    "avg_img = nl.image.new_img_like(nifti_img.slicer[:,:,:,0], series_avg_signal_ndarray)\n",
    "std_img = nl.image.new_img_like(nifti_img.slicer[:,:,:,0], series_std_signal_ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.4064148370420857"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(std_img.get_fdata()[:,:,:,0])\n",
    "#np.std(std_img.get_fdata()[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "nifti_img_zsc=nl.image.math_img(\"(img-avg)/std\", img=nifti_img, avg=avg_img, std=std_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 115, 97)\n",
      "(195,)\n",
      "0\n",
      "<class 'nibabel.nifti1.Nifti1Image'>\n",
      "data shape (97, 115, 97)\n",
      "affine: \n",
      "[[   2.    0.    0.  -96.]\n",
      " [   0.    2.    0. -132.]\n",
      " [   0.    0.    2.  -78.]\n",
      " [   0.    0.    0.    1.]]\n",
      "metadata:\n",
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b''\n",
      "dim_info        : 0\n",
      "dim             : [  3  97 115  97   1   1   1   1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 0\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b''\n",
      "aux_file        : b''\n",
      "qform_code      : unknown\n",
      "sform_code      : aligned\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : -96.0\n",
      "qoffset_y       : -132.0\n",
      "qoffset_z       : -78.0\n",
      "srow_x          : [  2.   0.   0. -96.]\n",
      "srow_y          : [   0.    2.    0. -132.]\n",
      "srow_z          : [  0.   0.   2. -78.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n",
      "-0.06146603798097121\n",
      "2.4064148370420884\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "(\"Input images cannot be compared, you provided 'dict_values([<nibabel.nifti1.Nifti1Image object at 0x7f87a264d6f0>, -0.06146603798097121, 2.4064148370420884])',\", 'Data given cannot be loaded because it is not compatible with nibabel format:\\n-0.06146603798097121')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 14\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(img_std_signal[img_i])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#print(f\"img {img_i} avg: {img_avg_signal[img_i]} std: {img_std_signal[img_i]}\")\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m nifti_img\u001b[39m.\u001b[39mslicer[:,:,:,img_i]\u001b[39m=\u001b[39m nl\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mmath_img(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m(img - group_mean)/ group_std\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     img\u001b[39m=\u001b[39;49mnifti_img\u001b[39m.\u001b[39;49mslicer[:,:,:,img_i],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     group_mean\u001b[39m=\u001b[39;49mimg_avg_signal[img_i],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     group_std\u001b[39m=\u001b[39;49mimg_std_signal[img_i]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X35sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/image/image.py:1016\u001b[0m, in \u001b[0;36mmath_img\u001b[0;34m(formula, **imgs)\u001b[0m\n\u001b[1;32m   1014\u001b[0m     niimgs \u001b[39m=\u001b[39m []\n\u001b[1;32m   1015\u001b[0m     \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m imgs\u001b[39m.\u001b[39mvalues():\n\u001b[0;32m-> 1016\u001b[0m         niimgs\u001b[39m.\u001b[39mappend(check_niimg(image))\n\u001b[1;32m   1017\u001b[0m     _check_same_fov(\u001b[39m*\u001b[39mniimgs, raise_error\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1018\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/_utils/niimg_conversions.py:286\u001b[0m, in \u001b[0;36mcheck_niimg\u001b[0;34m(niimg, ensure_ndim, atleast_4d, dtype, return_iterator, wildcards)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[39mreturn\u001b[39;00m concat_niimgs(niimg, ensure_ndim\u001b[39m=\u001b[39mensure_ndim, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[1;32m    285\u001b[0m \u001b[39m# Otherwise, it should be a filename or a SpatialImage, we load it\u001b[39;00m\n\u001b[0;32m--> 286\u001b[0m niimg \u001b[39m=\u001b[39m load_niimg(niimg, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m ensure_ndim \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(niimg\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mand\u001b[39;00m niimg\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    289\u001b[0m     \u001b[39m# \"squeeze\" the image.\u001b[39;00m\n\u001b[1;32m    290\u001b[0m     data \u001b[39m=\u001b[39m _safe_get_data(niimg)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/_utils/niimg.py:133\u001b[0m, in \u001b[0;36mload_niimg\u001b[0;34m(niimg, dtype)\u001b[0m\n\u001b[1;32m    131\u001b[0m     niimg \u001b[39m=\u001b[39m nibabel\u001b[39m.\u001b[39mload(niimg)\n\u001b[1;32m    132\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(niimg, nibabel\u001b[39m.\u001b[39mspatialimages\u001b[39m.\u001b[39mSpatialImage):\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mData given cannot be loaded because it is\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m not compatible with nibabel format:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m                     \u001b[39m+\u001b[39m _repr_niimgs(niimg, shorten\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m))\n\u001b[1;32m    137\u001b[0m dtype \u001b[39m=\u001b[39m _get_target_dtype(_get_data(niimg)\u001b[39m.\u001b[39mdtype, dtype)\n\u001b[1;32m    139\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    140\u001b[0m     \u001b[39m# Copyheader and set dtype in header if header exists\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: (\"Input images cannot be compared, you provided 'dict_values([<nibabel.nifti1.Nifti1Image object at 0x7f87a264d6f0>, -0.06146603798097121, 2.4064148370420884])',\", 'Data given cannot be loaded because it is not compatible with nibabel format:\\n-0.06146603798097121')"
     ]
    }
   ],
   "source": [
    "\n",
    "# print(voxel_avg_signal.shape)\n",
    "# print(img_avg_signal.shape)\n",
    "# for img_i in range(len(img_avg_signal)):\n",
    "#     print(img_i)\n",
    "#     print(nifti_img.slicer[:,:,:,img_i])\n",
    "#     print(img_avg_signal[img_i])\n",
    "#     print(img_std_signal[img_i])\n",
    "#     #print(f\"img {img_i} avg: {img_avg_signal[img_i]} std: {img_std_signal[img_i]}\")\n",
    "#     nifti_img.slicer[:,:,:,img_i]= nl.image.math_img(\n",
    "#         \"(img - group_mean)/ group_std\",\n",
    "#         img=nifti_img.slicer[:,:,:,img_i],\n",
    "#         group_mean=img_avg_signal[img_i],\n",
    "#         group_std=img_std_signal[img_i]\n",
    "#     )\n",
    "\n",
    "#https://neurostars.org/t/questions-about-mvpa-with-nilearn/6966/3\n",
    "\n",
    "\n",
    "#normalize the image\n",
    "\n",
    "# nifti_img = (\n",
    "#     nl.image.math_img(\"(img - group_mean)/ group_std\",\n",
    "#     img=nifti_img.slicer,\n",
    "#     group_mean=img_avg_signal,\n",
    "#     group_std=img_std_signal)\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'Nifti1Image' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X53sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m nifti_img\u001b[39m.\u001b[39;49mslicer[:,:,:,\u001b[39m0\u001b[39;49m]\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'Nifti1Image' and 'int'"
     ]
    }
   ],
   "source": [
    "nifti_img.slicer[:,:,:,0]/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nl.image.math_img(\"np.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.40867886e-03, -5.76977312e-03,  4.90863348e-03,  3.42223332e-03,\n",
       "        3.24376801e-03,  3.37256269e-03,  8.03219802e-03,  1.71848334e-03,\n",
       "       -9.38978305e-04,  9.87957620e-03, -1.75230999e-03,  3.80476460e-03,\n",
       "        3.05915034e-03,  1.25113922e-03,  3.20592277e-04,  1.29469328e-04,\n",
       "        1.79955424e-03,  2.36097263e-03,  1.12486799e-03,  1.62190189e-03,\n",
       "        1.89820947e-03,  4.79181721e-04, -3.09397943e-03, -4.30256622e-02,\n",
       "        3.67031622e-03,  9.19802197e-04,  5.93557371e-04,  4.17763083e-03,\n",
       "        4.98921339e-03,  7.38724409e-03,  4.33128498e-03,  1.64611153e-02,\n",
       "        6.84638078e-03,  3.70184947e-03,  4.36493252e-03,  4.53694464e-03,\n",
       "        1.81922510e-03,  6.30703840e-03,  1.14317017e-02, -4.85179484e-04,\n",
       "        1.55431440e-03,  9.79339490e-04,  1.24492335e-03, -2.15732710e-04,\n",
       "        6.20987422e-05,  4.30458497e-03,  1.33365609e-03,  2.56995091e-03,\n",
       "       -3.49207760e-03, -1.63189768e-02,  6.56338318e-03,  4.56774919e-03,\n",
       "        3.32529165e-03,  3.61797471e-03,  1.70021623e-03,  1.49973511e-03,\n",
       "        1.99400172e-03,  3.86752392e-03,  2.71860469e-03,  1.19387723e-03,\n",
       "        4.42380654e-03,  1.49345433e-03,  4.36577290e-03, -3.02635845e-03,\n",
       "       -6.32382915e-03,  1.12637777e-02, -1.53959452e-03,  4.10758269e-03,\n",
       "        2.59915060e-03, -6.40619149e-04,  3.34750655e-04,  1.49128699e-03,\n",
       "       -1.59362953e-03,  1.45433171e-03,  3.79909398e-03,  4.67968736e-03,\n",
       "       -1.77721848e-03,  2.73537858e-03,  3.55013554e-03,  1.26689314e-02,\n",
       "        6.27358171e-04,  2.70566694e-03,  7.32168828e-05,  2.55753786e-03,\n",
       "        2.71294236e-03,  6.77446253e-03,  2.80881918e-02, -3.01823835e-02,\n",
       "       -2.95573294e-02,  5.88508090e-02, -9.71828922e-02, -9.97687660e-03,\n",
       "        3.86101276e-02, -3.27605841e-02,  3.03492377e-02,  4.38420711e-03,\n",
       "       -1.00486493e-02,  2.97192766e-03, -4.67334479e-03, -1.53288160e-02,\n",
       "        9.77039289e-03,  6.36015698e-03, -1.32296998e-02, -3.36319570e-02,\n",
       "       -2.16751493e-02,  3.97732544e-03, -1.93111718e-02,  1.99399090e-03,\n",
       "       -1.41602336e-02, -1.51508909e-02,  9.10868952e-03, -2.99776317e-04,\n",
       "        3.12903853e-02, -7.97663166e-03, -4.67981704e-03, -3.44401726e-03,\n",
       "       -4.14996284e-02,  5.32670225e-02,  3.31901493e-02,  8.64233479e-03,\n",
       "        6.19345193e-03,  7.24915819e-02, -4.81970080e-02,  3.25882628e-02,\n",
       "        3.43931338e-02,  5.12739566e-03, -4.44514457e-03,  6.05874982e-03,\n",
       "       -1.27609657e-02, -2.23875162e-02, -8.52576631e-03, -8.28477325e-03,\n",
       "       -1.33371963e-02, -5.27284717e-03, -3.41374248e-02, -2.13893700e-02,\n",
       "       -4.47666225e-02,  2.62053568e-02,  8.48525113e-02, -3.00501269e-02,\n",
       "       -4.28756525e-03,  1.94011656e-02, -2.28068214e-03,  1.87587417e-02,\n",
       "       -3.46425517e-03,  1.62580097e-02, -9.35487015e-03, -2.59070808e-02,\n",
       "        1.15910632e-02,  9.93669305e-03, -1.16481491e-02,  3.93103890e-03,\n",
       "       -8.12579521e-03, -1.68259099e-03, -6.35804870e-03, -1.26327465e-02,\n",
       "        9.41734249e-03,  7.46181609e-03, -4.57920883e-03,  2.25382827e-03,\n",
       "        1.53242555e-02,  9.66136993e-03, -2.91473279e-04, -4.60329554e-02,\n",
       "       -1.11922190e-02, -1.81117618e-04,  7.04559204e-02,  5.32576500e-03,\n",
       "       -1.20083550e-02,  2.14233286e-02,  3.38131166e-03, -2.60890003e-02,\n",
       "       -2.39291938e-02,  6.13784839e-04,  1.32238569e-02, -2.21906327e-03,\n",
       "       -3.69553728e-03, -1.16679548e-02, -1.10896964e-02,  1.05685489e-02,\n",
       "        4.98651091e-03, -1.76461289e-02, -2.57792418e-02,  3.90076323e-03,\n",
       "       -1.86475985e-02, -1.70800388e-03,  8.25114360e-03, -2.31821038e-03,\n",
       "       -2.05894576e-02, -3.38170756e-02, -6.28421739e-04, -1.63746274e-02,\n",
       "        8.08974550e-03,  9.44941017e-03,  2.04167897e-03])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_img_cleaned.get_fdata().mean(axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.09217749, 0.25219577, 0.06503871, 0.15558986, 0.16566586,\n",
       "       0.08874675, 0.09946406, 0.12204778, 0.19654376, 0.19058029,\n",
       "       0.0692678 , 0.07017509, 0.16092685, 0.09656423, 0.1125354 ,\n",
       "       0.08372946, 0.07400024, 0.10557848, 0.07282737, 0.07067738,\n",
       "       0.09578894, 0.09660275, 0.09598019, 0.54806186, 0.09405741,\n",
       "       0.08922732, 0.09467027, 0.07605038, 0.11119953, 0.13484648,\n",
       "       0.06293708, 0.16376664, 0.26548453, 0.09023509, 0.07427826,\n",
       "       0.09641357, 0.0924679 , 0.15875288, 0.34167887, 0.1230305 ,\n",
       "       0.10144487, 0.07960235, 0.0975562 , 0.11699436, 0.06679364,\n",
       "       0.08703316, 0.11953559, 0.37687538, 0.15921596, 0.15944638,\n",
       "       0.09071751, 0.09402247, 0.15207517, 0.0799574 , 0.09201675,\n",
       "       0.0980221 , 0.07886166, 0.05611828, 0.06182577, 0.06773784,\n",
       "       0.106248  , 0.10600871, 0.1038374 , 0.13389568, 0.11507357,\n",
       "       0.22951965, 0.13750664, 0.11261244, 0.05394646, 0.19183421,\n",
       "       0.10473073, 0.06854287, 0.15907249, 0.09134306, 0.13446535,\n",
       "       0.11712134, 0.1476355 , 0.207722  , 0.17238392, 0.21668215,\n",
       "       0.19159373, 0.089457  , 0.15077929, 0.1333545 , 0.12479798,\n",
       "       0.14005737, 0.18191627, 0.27047815, 0.27319913, 0.32692911,\n",
       "       0.57261279, 0.17669899, 0.24932894, 0.41555859, 0.25933083,\n",
       "       0.12406855, 0.16404116, 0.16256633, 0.11547261, 0.14272818,\n",
       "       0.16151045, 0.13788592, 0.15152183, 0.24994254, 0.17003191,\n",
       "       0.10236328, 0.16161909, 0.14075656, 0.16565031, 0.13091087,\n",
       "       0.17616222, 0.24174161, 0.24900135, 0.18950737, 0.27620938,\n",
       "       0.07257954, 0.31438304, 0.40132461, 0.24284119, 0.07016694,\n",
       "       0.20592899, 0.55722154, 0.44940416, 0.2561103 , 0.3928634 ,\n",
       "       0.18127824, 0.1213251 , 0.08716028, 0.14017922, 0.17792974,\n",
       "       0.12699362, 0.14656721, 0.13721972, 0.11649847, 0.28773066,\n",
       "       0.23195226, 0.38849393, 0.42864151, 0.62983088, 0.25960474,\n",
       "       0.1828684 , 0.18357145, 0.12775789, 0.1687017 , 0.09654707,\n",
       "       0.1473801 , 0.09519664, 0.17517588, 0.15050769, 0.13895259,\n",
       "       0.11835873, 0.08121051, 0.09410295, 0.10062174, 0.09456183,\n",
       "       0.13704499, 0.10442438, 0.12054509, 0.10637633, 0.11037828,\n",
       "       0.13119641, 0.14828718, 0.09271453, 0.30274588, 0.20780399,\n",
       "       0.15142984, 0.4628356 , 0.09334728, 0.11753335, 0.15017488,\n",
       "       0.14535893, 0.23208441, 0.19258022, 0.13290275, 0.1711204 ,\n",
       "       0.1426147 , 0.13750834, 0.13106795, 0.10299226, 0.18238932,\n",
       "       0.54868385, 0.34528399, 0.28962461, 0.20388804, 0.16135831,\n",
       "       0.10990305, 0.10184683, 0.0949645 , 0.18146872, 0.2345422 ,\n",
       "       0.09831622, 0.13438406, 0.11423251, 0.11966657, 0.02522942])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nifti_img_cleaned.get_fdata().std(axis=(0,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    import itertools\n",
    "    #just to show we can, let's figure out how to z-score each voxel by subject.\n",
    "    for group in all_subjects['groups'].unique():\n",
    "        print(group)\n",
    "        #grab images for the current group\n",
    "        group_bool=all_subjects['groups']==group\n",
    "        #get a list of indices where the group_bool changes from True to False\n",
    "        group_bool_start = [i+1 for i, (a, b) in enumerate(zip(group_bool, group_bool[1:])) if a != b and b==True]\n",
    "        if group_bool[0]:\n",
    "            group_bool_start.insert(0,0)\n",
    "        #get a list of indices where the group_bool changes from False to True\n",
    "        group_bool_end = [i+1 for i, (a, b) in enumerate(zip(group_bool, group_bool[1:])) if a != b and b==False]\n",
    "        if group_bool[len(group_bool)-1]:\n",
    "            group_bool_end.append(len(group_bool))\n",
    "        \n",
    "        #go through each of these groups of matching bools\n",
    "        for start, end in zip(group_bool_start, group_bool_end):\n",
    "            print(start,end)\n",
    "            #get the mean and std for the current group\n",
    "            #group_mean = nifti_img.slicer[:,:,:,start:end].get_fdata().mean(axis=(3))\n",
    "            #group_std = nifti_img.slicer[:,:,:,start:end].get_fdata().std(axis=(3))\n",
    "            nifti_img.slicer[:,:,:,start:end] = nl.image.clean_img(nifti_img.slicer[:,:,:,start:end], detrend=False, standardize=True, low_pass=None, high_pass=None, t_r=None)\n",
    "            # nib.norm_img(group_mean)\n",
    "            # print(group_mean.shape)\n",
    "            # print(group_std.shape)\n",
    "            # #z-score the current group\n",
    "            # nifti_img.slicer[:,:,:,start:end] = (\n",
    "            #     nl.image.math_img(\"(img - group_mean)/ group_std\",\n",
    "            #     img=nifti_img.slicer[:,:,:,start:end],\n",
    "            #     group_mean=group_mean,\n",
    "            #     group_std=group_std)\n",
    "            # )\n",
    "        #use nibabel concat to concatenate iomg1 and img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group_bool[84]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X', 'y', 'groups', 'metadata', 'y_cat', 'y_int'])\n"
     ]
    }
   ],
   "source": [
    "#cut down to just 9 subjects\n",
    "selected_subjs={}\n",
    "print(all_subjects.keys())\n",
    "num_subjs = 9\n",
    "#select subjs\n",
    "subjs = all_subjects['metadata']['subject'].unique()\n",
    "subjs.sort()\n",
    "selected_sub_ids=subjs[0:num_subjs]\n",
    "#get index of selected subjs\n",
    "selected_subjs_idx_bool = all_subjects['metadata']['subject'].isin(selected_sub_ids)\n",
    "#get list of True indices\n",
    "selected_subjs_idx = selected_subjs_idx_bool[selected_subjs_idx].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on RangeIndex with these indexers [0        True\n1        True\n2        True\n3        True\n4        True\n        ...  \n3166    False\n3167    False\n3168    False\n3169    False\n3170    False\nName: subject, Length: 3171, dtype: bool] of type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m subjs \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msubject\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39mfuncs\u001b[39m.\u001b[39mconcat_images([all_subjects[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mslicer[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,s] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m selected_subjs_idx])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m:selected_subjs_idx_bool]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m:selected_subjs_idx_bool]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m:selected_subjs_idx_bool]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/series.py:984\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    981\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    982\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[0;32m--> 984\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/series.py:991\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_with\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    987\u001b[0m     \u001b[39m# other: fancy integer or otherwise\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m    989\u001b[0m         \u001b[39m# _convert_slice_indexer to determine if this slice is positional\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m#  or label based, and if the latter, convert to positional\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m         slobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49m_convert_slice_indexer(key, kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgetitem\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    992\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice(slobj)\n\u001b[1;32m    993\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, ABCDataFrame):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/indexes/numeric.py:279\u001b[0m, in \u001b[0;36mNumericIndex._convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39m# We always treat __getitem__ slicing as label-based\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[39m# translate to locations\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_indexer(key\u001b[39m.\u001b[39mstart, key\u001b[39m.\u001b[39mstop, key\u001b[39m.\u001b[39mstep)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_convert_slice_indexer(key, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/indexes/base.py:4042\u001b[0m, in \u001b[0;36mIndex._convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   4040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_integer() \u001b[39mor\u001b[39;00m is_index_slice:\n\u001b[1;32m   4041\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_indexer(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mstart, \u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4042\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_indexer(\u001b[39m\"\u001b[39;49m\u001b[39mslice\u001b[39;49m\u001b[39m\"\u001b[39;49m, key\u001b[39m.\u001b[39;49mstop, \u001b[39m\"\u001b[39;49m\u001b[39mgetitem\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   4043\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_indexer(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mstep, \u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4044\u001b[0m     \u001b[39mreturn\u001b[39;00m key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/indexes/base.py:6308\u001b[0m, in \u001b[0;36mIndex._validate_indexer\u001b[0;34m(self, form, key, kind)\u001b[0m\n\u001b[1;32m   6305\u001b[0m \u001b[39massert\u001b[39;00m kind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   6307\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 6308\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalid_indexer(form, key)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot do slice indexing on RangeIndex with these indexers [0        True\n1        True\n2        True\n3        True\n4        True\n        ...  \n3166    False\n3167    False\n3168    False\n3169    False\n3170    False\nName: subject, Length: 3171, dtype: bool] of type Series"
     ]
    }
   ],
   "source": [
    "\n",
    "subjs = all_subjects['metadata']['subject'].unique()\n",
    "selected_subjs['X'] = nib.funcs.concat_images([all_subjects['X'].slicer[...,s] for s in selected_subjs_idx])\n",
    "selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n",
    "selected_subjs['groups'] = all_subjects['groups'][selected_subjs_idx_bool]\n",
    "selected_subjs['metadata'] = all_subjects['metadata'][selected_subjs_idx_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the PFC mask\n",
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the y array to an integer array representing the string values of the y array\n",
    "selected_subjs['y_cat'] = selected_subjs['y'].astype('category')\n",
    "selected_subjs['y_int']=selected_subjs['y_cat'].cat.codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "I'm going to start with `cv_train_test_sets` and see how that goes. It sems likely it'll have to be re-written somewhat, but it might be a good starting point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I need to run this without all the extra scaffolding--just tresting the Decoder on the data until I get something sensible. At the very least we need to know the Decoder object is handling balanced classes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use add PFC mask.ipynb to figure out how to get a PFC mask onto this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups are the same.\n",
      "fold 1 of 3\n",
      "In order to test on a training group of 6 items, holding out the following subjects:['DEV015' 'DEV006' 'DEV009']. prepping fold data.... fitting.... 4.9 GiB. trying decoder 1 of 1. predicting. test score was:. 0.5122285267071023\n",
      "fold 2 of 3\n",
      "In order to test on a training group of 6 items, holding out the following subjects:['DEV010' 'DEV005' 'DEV011']. prepping fold data.... fitting.... 5.0 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/decoding/decoder.py:141: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.43445692883895126\n",
      "fold 3 of 3\n",
      "In order to test on a training group of 6 items, holding out the following subjects:['DEV012' 'DEV013' 'DEV014']. prepping fold data.... fitting.... 4.9 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/decoding/decoder.py:141: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.5957894736842105\n"
     ]
    }
   ],
   "source": [
    "dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\n",
    "cv_results = cv_train_test_sets(\n",
    "    trainset_X = selected_subjs['X'],\n",
    "    trainset_y = selected_subjs['y_int'],\n",
    "    trainset_groups = selected_subjs['metadata']['subject'],\n",
    "    decoders = [dec_main],\n",
    "    cv=KFold(n_splits=3) # we use KFold, not GroupKfold, because it's splitting on Group anyway\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_dict = {\n",
    "    'test_scores':cv_results[0],\n",
    "    'results':cv_results[1],\n",
    "    'results_by_trainset_item':cv_results[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>group</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>1</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y   group y_pred\n",
       "0    1  DEV005      0\n",
       "1    0  DEV005      0\n",
       "2    0  DEV005      0\n",
       "3    0  DEV005      1\n",
       "4    0  DEV005      1\n",
       "..  ..     ...    ...\n",
       "912  0  DEV015      1\n",
       "913  0  DEV015      0\n",
       "914  1  DEV015      0\n",
       "915  0  DEV015      1\n",
       "916  0  DEV015      1\n",
       "\n",
       "[917 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_dict['results_by_trainset_item']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is derived from 3-fold cross-validation, and should indicate train/test performance classifying trials across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5015090495368123, 0.5040220259845717, 0.4038898145712142, None)\n",
      "0.5040220259845718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#get precision and recall\n",
    "print(precision_recall_fscore_support(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "cv_results_dict['results_by_trainset_item']['y_pred'].astype(int),average='macro'))\n",
    "\n",
    "#get roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "    cv_results_dict['results_by_trainset_item']['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralsignature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cca8238de402a161b34e58e1e3b4d299a0bf48c5783c9dc7c173d82c36576a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
