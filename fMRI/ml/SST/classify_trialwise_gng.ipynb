{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying trialwise CorrectGo and NoGo trials\n",
    "\n",
    "There are a number of steps to this. Hopefully we can recycle previous code and be up fairly quickly!\n",
    "\n",
    "1. Load beta data. Ideally this process should include a cache into a pure python object so we don't have to reload it each time.\n",
    "2. Preprocess the data.\n",
    "3. Do cross-validated training and testing. Ideally an inner loop to select best parameters, an outer loop to get cross-validated performance, and final training over all the data to get an image. The inner loop can be probably be handled within the package we use probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import yaml\n",
    "hostname=socket.gethostname()\n",
    "hostname='zzz'\n",
    "with open('sst_config.yml', \"r\") as f:\n",
    "    test_config= yaml.safe_load(f)#[hostname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "cpus available; cpus to use:\n",
      "10 9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "from apply_loocv_and_save import load_and_preprocess\n",
    "from dev_utils import read_yaml_for_host\n",
    "import warnings\n",
    "\n",
    "\n",
    "config_data = read_yaml_for_host(\"sst_config.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "from nilearn.decoding import DecoderRegressor,Decoder\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(cpus_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from nilearn.decoding import DecoderRegressor,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = config_data['nonbids_data_path']\n",
    "ml_data_folderpath = nonbids_data_path + \"fMRI/ml\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading beta data\n",
    "\n",
    "beta data is generally written in `load_multisubject_brain_data_sst_w1.ipynb`.\n",
    "\n",
    "We just have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_11420/2753699166.py:3: UserWarning: not sure if this file holds up--it was created in 2021; need to see if it's still valid\n",
      "  warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n"
     ]
    }
   ],
   "source": [
    "#brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_30subs_correct_cond_pfc.pkl'\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_6subs_correct_cond.pkl'\n",
    "warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20220818T144138.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 6 subjects overlapping between the subjects marked for train data and the training dump file itself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_set: 62918\n",
      "brain_data_filepath: 168\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 158\n",
      "response_transform_func: 144\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n",
      "601\n",
      "601\n",
      "cleaning memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_11420/1474138623.py:8: UserWarning: the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\n",
      "  warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile,f_classif\n",
    "\n",
    "#convert the y array to an integer array representing the string values of the y array\n",
    "all_subjects['y_cat'] = all_subjects['y'].astype('category')\n",
    "all_subjects['y_int']=all_subjects['y_cat'].cat.codes\n",
    "\n",
    "# #get the X fdata\n",
    "# x_fdata = all_subjects['X'].get_fdata()\n",
    "# print(x_fdata.shape)\n",
    "# #flatten first 3 dims of X fdata to a single dim\n",
    "# x_fdata_1d = x_fdata.reshape([np.prod(x_fdata.shape[0:3]), x_fdata.shape[3]])\n",
    "# print(x_fdata_1d.shape)\n",
    "\n",
    "\n",
    "\n",
    "# #SelectPercentile(f_classif,percentile=5).fit_transform(,all_subjects['y_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X', 'y', 'groups', 'metadata', 'y_cat', 'y_int'])\n"
     ]
    }
   ],
   "source": [
    "num_subjs = 6\n",
    "if num_subjs<len(all_subjects['metadata']['subject'].unique()):\n",
    "    #cut down to just 9 subjects\n",
    "    selected_subjs={}\n",
    "    print(all_subjects.keys())\n",
    "\n",
    "    #select subjs\n",
    "    subjs = all_subjects['metadata']['subject'].unique()\n",
    "    subjs.sort()\n",
    "    selected_sub_ids=subjs[0:num_subjs]\n",
    "    #get index of selected subjs\n",
    "    selected_subjs_idx_bool = all_subjects['metadata']['subject'].isin(selected_sub_ids)\n",
    "    #get list of True indices\n",
    "    selected_subjs_idx = selected_subjs_idx_bool[selected_subjs_idx_bool].index.tolist()\n",
    "\n",
    "    subjs = all_subjects['metadata']['subject'].unique()\n",
    "    selected_subjs['X'] = nib.funcs.concat_images([all_subjects['X'].slicer[...,s] for s in selected_subjs_idx])\n",
    "    selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n",
    "\n",
    "    selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n",
    "    selected_subjs['groups'] = all_subjects['groups'][selected_subjs_idx_bool]\n",
    "    selected_subjs['metadata'] = all_subjects['metadata'][selected_subjs_idx_bool]\n",
    "else:\n",
    "    selected_subjs = all_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the PFC mask\n",
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the y array to an integer array representing the string values of the y array\n",
    "selected_subjs['y_cat'] = selected_subjs['y'].astype('category')\n",
    "selected_subjs['y_int']=selected_subjs['y_cat'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "HeaderDataError",
     "evalue": "shape (1082035, 601) does not fit in dim datatype",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHeaderDataError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m(X_nifti)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#apply the preprocessing function to the X data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mX2\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m preprocess_func(selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 17\u001b[0m in \u001b[0;36mpreprocess_func\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_func\u001b[39m(X):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     X_2d \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(X\u001b[39m.\u001b[39mget_fdata(),[np\u001b[39m.\u001b[39mprod(X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m]),X\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m]])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     X_nifti \u001b[39m=\u001b[39m nl\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mnew_img_like(X,X_2d)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y101sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m(X_nifti)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/image/image.py:787\u001b[0m, in \u001b[0;36mnew_img_like\u001b[0;34m(ref_niimg, data, affine, copy_header)\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[39mif\u001b[39;00m klass \u001b[39mis\u001b[39;00m nibabel\u001b[39m.\u001b[39mNifti1Pair:\n\u001b[1;32m    784\u001b[0m     \u001b[39m# Nifti1Pair is an internal class, without a to_filename,\u001b[39;00m\n\u001b[1;32m    785\u001b[0m     \u001b[39m# we shouldn't return it\u001b[39;00m\n\u001b[1;32m    786\u001b[0m     klass \u001b[39m=\u001b[39m nibabel\u001b[39m.\u001b[39mNifti1Image\n\u001b[0;32m--> 787\u001b[0m \u001b[39mreturn\u001b[39;00m klass(data, affine, header\u001b[39m=\u001b[39;49mheader)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/nifti1.py:1824\u001b[0m, in \u001b[0;36mNifti1Pair.__init__\u001b[0;34m(self, dataobj, affine, header, extra, file_map, dtype)\u001b[0m\n\u001b[1;32m   1819\u001b[0m     msg \u001b[39m=\u001b[39m (\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mImage data has type \u001b[39m\u001b[39m{\u001b[39;00mdataobj\u001b[39m.\u001b[39mdtype\u001b[39m}\u001b[39;00m\u001b[39m, which may cause \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1820\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mincompatibilities with other tools. This will error in \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1821\u001b[0m            \u001b[39m\"\u001b[39m\u001b[39mNiBabel 5.0. This warning can be silenced \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1822\u001b[0m            \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mby passing the dtype argument to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m().\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1823\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(msg, \u001b[39mFutureWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m-> 1824\u001b[0m \u001b[39msuper\u001b[39;49m(Nifti1Pair, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(dataobj,\n\u001b[1;32m   1825\u001b[0m                                  affine,\n\u001b[1;32m   1826\u001b[0m                                  header,\n\u001b[1;32m   1827\u001b[0m                                  extra,\n\u001b[1;32m   1828\u001b[0m                                  file_map,\n\u001b[1;32m   1829\u001b[0m                                  dtype)\n\u001b[1;32m   1830\u001b[0m \u001b[39m# Force set of s/q form when header is None unless affine is also None\u001b[39;00m\n\u001b[1;32m   1831\u001b[0m \u001b[39mif\u001b[39;00m header \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m affine \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/analyze.py:918\u001b[0m, in \u001b[0;36mAnalyzeImage.__init__\u001b[0;34m(self, dataobj, affine, header, extra, file_map, dtype)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, dataobj, affine, header\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    917\u001b[0m              extra\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, file_map\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 918\u001b[0m     \u001b[39msuper\u001b[39;49m(AnalyzeImage, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    919\u001b[0m         dataobj, affine, header, extra, file_map)\n\u001b[1;32m    920\u001b[0m     \u001b[39m# Reset consumable values\u001b[39;00m\n\u001b[1;32m    921\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_header\u001b[39m.\u001b[39mset_data_offset(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/spatialimages.py:468\u001b[0m, in \u001b[0;36mSpatialImage.__init__\u001b[0;34m(self, dataobj, affine, header, extra, file_map)\u001b[0m\n\u001b[1;32m    466\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_header\u001b[39m.\u001b[39mset_data_dtype(dataobj\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    467\u001b[0m \u001b[39m# make header correspond with image and affine\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate_header()\n\u001b[1;32m    469\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_cache \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/nifti1.py:2250\u001b[0m, in \u001b[0;36mNifti1Image.update_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2248\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_header\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   2249\u001b[0m     \u001b[39m\"\"\" Harmonize header with image data and affine \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2250\u001b[0m     \u001b[39msuper\u001b[39;49m(Nifti1Image, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mupdate_header()\n\u001b[1;32m   2251\u001b[0m     hdr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_header\n\u001b[1;32m   2252\u001b[0m     hdr[\u001b[39m'\u001b[39m\u001b[39mmagic\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hdr\u001b[39m.\u001b[39msingle_magic\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/nifti1.py:1864\u001b[0m, in \u001b[0;36mNifti1Pair.update_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1848\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mupdate_header\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   1849\u001b[0m     \u001b[39m\"\"\" Harmonize header with image data and affine\u001b[39;00m\n\u001b[1;32m   1850\u001b[0m \n\u001b[1;32m   1851\u001b[0m \u001b[39m    See AnalyzeImage.update_header for more examples\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1862\u001b[0m \u001b[39m    True\u001b[39;00m\n\u001b[1;32m   1863\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1864\u001b[0m     \u001b[39msuper\u001b[39;49m(Nifti1Pair, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mupdate_header()\n\u001b[1;32m   1865\u001b[0m     hdr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_header\n\u001b[1;32m   1866\u001b[0m     hdr[\u001b[39m'\u001b[39m\u001b[39mmagic\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m hdr\u001b[39m.\u001b[39mpair_magic\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/spatialimages.py:495\u001b[0m, in \u001b[0;36mSpatialImage.update_header\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[39m# We need to update the header if the data shape has changed.  It's a\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \u001b[39m# bit difficult to change the data shape using the standard API, but\u001b[39;00m\n\u001b[1;32m    493\u001b[0m \u001b[39m# maybe it happened\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[39mif\u001b[39;00m hdr\u001b[39m.\u001b[39mget_data_shape() \u001b[39m!=\u001b[39m shape:\n\u001b[0;32m--> 495\u001b[0m     hdr\u001b[39m.\u001b[39;49mset_data_shape(shape)\n\u001b[1;32m    496\u001b[0m \u001b[39m# If the affine is not None, and it is different from the main affine\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[39m# in the header, update the header\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affine \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/nifti1.py:883\u001b[0m, in \u001b[0;36mNifti1Header.set_data_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    880\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mUsing large vector Freesurfer hack; header will \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    881\u001b[0m                   \u001b[39m'\u001b[39m\u001b[39mnot be compatible with SPM or FSL\u001b[39m\u001b[39m'\u001b[39m, stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m    882\u001b[0m     shape \u001b[39m=\u001b[39m (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m shape[\u001b[39m3\u001b[39m:]\n\u001b[0;32m--> 883\u001b[0m \u001b[39msuper\u001b[39;49m(Nifti1Header, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49mset_data_shape(shape)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nibabel/analyze.py:633\u001b[0m, in \u001b[0;36mAnalyzeHeader.set_data_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[39m# Error if we did not succeed setting dimensions\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m values_fit:\n\u001b[0;32m--> 633\u001b[0m     \u001b[39mraise\u001b[39;00m HeaderDataError(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mshape \u001b[39m\u001b[39m{\u001b[39;00mshape\u001b[39m}\u001b[39;00m\u001b[39m does not fit in dim datatype\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_structarr[\u001b[39m'\u001b[39m\u001b[39mpixdim\u001b[39m\u001b[39m'\u001b[39m][ndims \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m:] \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m\n",
      "\u001b[0;31mHeaderDataError\u001b[0m: shape (1082035, 601) does not fit in dim datatype"
     ]
    }
   ],
   "source": [
    "#reshape the X data to a 2D array\n",
    "def preprocess_func(X):\n",
    "    X_2d = np.reshape(X.get_fdata(),[np.prod(X.shape[0:3]),X.shape[3]])\n",
    "    X_nifti = nl.image.new_img_like(X,X_2d)\n",
    "    return(X_nifti)\n",
    "\n",
    "#apply the preprocessing function to the X data\n",
    "selected_subjs['X2'] = preprocess_func(selected_subjs['X'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "I'm going to start with `cv_train_test_sets` and see how that goes. It sems likely it'll have to be re-written somewhat, but it might be a good starting point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I need to run this without all the extra scaffolding--just tresting the Decoder on the data until I get something sensible. At the very least we need to know the Decoder object is handling balanced classes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use add PFC mask.ipynb to figure out how to get a PFC mask onto this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "f_classif() missing 2 required positional arguments: 'X' and 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m transformer \u001b[39m=\u001b[39m f_classif()\n",
      "\u001b[0;31mTypeError\u001b[0m: f_classif() missing 2 required positional arguments: 'X' and 'y'"
     ]
    }
   ],
   "source": [
    "transformer = f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EstimatorWithPreprocessing import EstimatorWithPreprocessor\n",
    "#import SVC\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_classif, SequentialFeatureSelector, SelectKBest\n",
    "\n",
    "\n",
    "ewp = EstimatorWithPreprocessor(\n",
    "    estimator=LinearSVC(penalty='l2',max_iter=1e4),\n",
    "    preprocess_func= SelectKBest(f_classif, k=1000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups are the same.\n",
      "fold 1 of 3\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV009' 'DEV010']. prepping fold data.... fitting.... 3.2 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv_results \u001b[39m=\u001b[39m cv_train_test_sets(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     trainset_X \u001b[39m=\u001b[39;49m selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     trainset_y \u001b[39m=\u001b[39;49m selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39my_int\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     trainset_groups \u001b[39m=\u001b[39;49m selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msubject\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     decoders \u001b[39m=\u001b[39;49m [ewp],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cv\u001b[39m=\u001b[39;49mKFold(n_splits\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m) \u001b[39m# we use KFold, not GroupKfold, because it's splitting on Group anyway\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/fMRI/ml/dev_wtp_io_utils.py:729\u001b[0m, in \u001b[0;36mcv_train_test_sets\u001b[0;34m(trainset_X, trainset_y, trainset_groups, decoders, testset_X, testset_y, testset_groups, param_grid, cpus_to_use, cv, regressors)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrying decoder \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(r_i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m of \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(decoders)),end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    727\u001b[0m \u001b[39m#if there is nested CV within this function the best hyper-paramters are already being chosen\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m#we need only to finish the job by identifying the best overall decoder, as the final hyper-parameter\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m reg\u001b[39m.\u001b[39;49mfit(y\u001b[39m=\u001b[39;49mtrain_y,X\u001b[39m=\u001b[39;49mtrain_X,groups\u001b[39m=\u001b[39;49mtrain_groups)\n\u001b[1;32m    730\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpredicting\u001b[39m\u001b[39m\"\u001b[39m,end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    731\u001b[0m \u001b[39m#hyper_score = reg.score(train_X,train_y)\u001b[39;00m\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/fMRI/ml/EstimatorWithPreprocessing.py:22\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(self, y, X, groups)\u001b[0m\n\u001b[1;32m     20\u001b[0m elif estimator is not None:\n\u001b[1;32m     21\u001b[0m     self.estimator = estimator\n\u001b[0;32m---> 22\u001b[0m else:\n\u001b[1;32m     23\u001b[0m     raise ValueError(\"You must specify either an estimator class or an estimator instance\")\n\u001b[1;32m     25\u001b[0m if preprocessor_class is not None:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'function' object has no attribute 'fit'"
     ]
    }
   ],
   "source": [
    "#dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\n",
    "cv_results = cv_train_test_sets(\n",
    "    trainset_X = selected_subjs['X'],\n",
    "    trainset_y = selected_subjs['y_int'],\n",
    "    trainset_groups = selected_subjs['metadata']['subject'],\n",
    "    decoders = [ewp],\n",
    "    cv=KFold(n_splits=3) # we use KFold, not GroupKfold, because it's splitting on Group anyway\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_dict = {\n",
    "    'test_scores':cv_results[0],\n",
    "    'results':cv_results[1],\n",
    "    'results_by_trainset_item':cv_results[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>group</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>1</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y   group y_pred\n",
       "0    1  DEV005      0\n",
       "1    0  DEV005      0\n",
       "2    0  DEV005      0\n",
       "3    0  DEV005      1\n",
       "4    0  DEV005      1\n",
       "..  ..     ...    ...\n",
       "912  0  DEV015      1\n",
       "913  0  DEV015      0\n",
       "914  1  DEV015      0\n",
       "915  0  DEV015      1\n",
       "916  0  DEV015      1\n",
       "\n",
       "[917 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_dict['results_by_trainset_item']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is derived from 3-fold cross-validation, and should indicate train/test performance classifying trials across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5015090495368123, 0.5040220259845717, 0.4038898145712142, None)\n",
      "0.5040220259845718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#get precision and recall\n",
    "print(precision_recall_fscore_support(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "cv_results_dict['results_by_trainset_item']['y_pred'].astype(int),average='macro'))\n",
    "\n",
    "#get roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "    cv_results_dict['results_by_trainset_item']['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralsignature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cca8238de402a161b34e58e1e3b4d299a0bf48c5783c9dc7c173d82c36576a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
