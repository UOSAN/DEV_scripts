{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying trialwise CorrectGo and NoGo trials\n",
    "\n",
    "There are a number of steps to this. Hopefully we can recycle previous code and be up fairly quickly!\n",
    "\n",
    "1. Load beta data. Ideally this process should include a cache into a pure python object so we don't have to reload it each time.\n",
    "2. Preprocess the data.\n",
    "3. Do cross-validated training and testing. Ideally an inner loop to select best parameters, an outer loop to get cross-validated performance, and final training over all the data to get an image. The inner loop can be probably be handled within the package we use probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "cpus available; cpus to use:\n",
      "10 9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "from apply_loocv_and_save import load_and_preprocess\n",
    "from dev_utils import read_yaml_for_host\n",
    "import warnings\n",
    "\n",
    "\n",
    "config_data = read_yaml_for_host(\"sst_config.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "from nilearn.decoding import DecoderRegressor,Decoder\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(cpus_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from nilearn.decoding import DecoderRegressor,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = config_data['nonbids_data_path']\n",
    "ml_data_folderpath = nonbids_data_path + \"fMRI/ml\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading beta data\n",
    "\n",
    "beta data is generally written in `load_multisubject_brain_data_sst_w1.ipynb`.\n",
    "\n",
    "We just have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_25653/256071196.py:2: UserWarning: not sure if this file holds up--it was created in 2021; need to see if it's still valid\n",
      "  warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n"
     ]
    }
   ],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_30subs_correct_cond_pfc.pkl'\n",
    "warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20220818T144138.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 30 subjects overlapping between the subjects marked for train data and the training dump file itself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_set: 62918\n",
      "brain_data_filepath: 173\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 158\n",
      "response_transform_func: 144\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n",
      "3171\n",
      "3171\n",
      "cleaning memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_25653/1474138623.py:8: UserWarning: the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\n",
      "  warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['X', 'y', 'groups', 'metadata', 'y_cat', 'y_int'])\n"
     ]
    }
   ],
   "source": [
    "#cut down to just 9 subjects\n",
    "selected_subjs={}\n",
    "print(all_subjects.keys())\n",
    "num_subjs = 9\n",
    "#select subjs\n",
    "subjs = all_subjects['metadata']['subject'].unique()\n",
    "subjs.sort()\n",
    "selected_sub_ids=subjs[0:num_subjs]\n",
    "#get index of selected subjs\n",
    "selected_subjs_idx_bool = all_subjects['metadata']['subject'].isin(selected_sub_ids)\n",
    "#get list of True indices\n",
    "selected_subjs_idx = selected_subjs_idx_bool[selected_subjs_idx].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot do slice indexing on RangeIndex with these indexers [0        True\n1        True\n2        True\n3        True\n4        True\n        ...  \n3166    False\n3167    False\n3168    False\n3169    False\n3170    False\nName: subject, Length: 3171, dtype: bool] of type Series",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m subjs \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39msubject\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m nib\u001b[39m.\u001b[39mfuncs\u001b[39m.\u001b[39mconcat_images([all_subjects[\u001b[39m'\u001b[39m\u001b[39mX\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mslicer[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,s] \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m selected_subjs_idx])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39;49m\u001b[39my\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m0\u001b[39;49m:selected_subjs_idx_bool]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mgroups\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m:selected_subjs_idx_bool]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y122sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m selected_subjs[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m all_subjects[\u001b[39m'\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m0\u001b[39m:selected_subjs_idx_bool]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/series.py:984\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    981\u001b[0m     key \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(key, dtype\u001b[39m=\u001b[39m\u001b[39mbool\u001b[39m)\n\u001b[1;32m    982\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_values(key)\n\u001b[0;32m--> 984\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_with(key)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/series.py:991\u001b[0m, in \u001b[0;36mSeries._get_with\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    986\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_with\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[1;32m    987\u001b[0m     \u001b[39m# other: fancy integer or otherwise\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, \u001b[39mslice\u001b[39m):\n\u001b[1;32m    989\u001b[0m         \u001b[39m# _convert_slice_indexer to determine if this slice is positional\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[39m#  or label based, and if the latter, convert to positional\u001b[39;00m\n\u001b[0;32m--> 991\u001b[0m         slobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49m_convert_slice_indexer(key, kind\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgetitem\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    992\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_slice(slobj)\n\u001b[1;32m    993\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(key, ABCDataFrame):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/indexes/numeric.py:279\u001b[0m, in \u001b[0;36mNumericIndex._convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[39m# We always treat __getitem__ slicing as label-based\u001b[39;00m\n\u001b[1;32m    276\u001b[0m     \u001b[39m# translate to locations\u001b[39;00m\n\u001b[1;32m    277\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_indexer(key\u001b[39m.\u001b[39mstart, key\u001b[39m.\u001b[39mstop, key\u001b[39m.\u001b[39mstep)\n\u001b[0;32m--> 279\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_convert_slice_indexer(key, kind\u001b[39m=\u001b[39;49mkind)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/indexes/base.py:4042\u001b[0m, in \u001b[0;36mIndex._convert_slice_indexer\u001b[0;34m(self, key, kind)\u001b[0m\n\u001b[1;32m   4040\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_integer() \u001b[39mor\u001b[39;00m is_index_slice:\n\u001b[1;32m   4041\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_indexer(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mstart, \u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 4042\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_indexer(\u001b[39m\"\u001b[39;49m\u001b[39mslice\u001b[39;49m\u001b[39m\"\u001b[39;49m, key\u001b[39m.\u001b[39;49mstop, \u001b[39m\"\u001b[39;49m\u001b[39mgetitem\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m   4043\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_indexer(\u001b[39m\"\u001b[39m\u001b[39mslice\u001b[39m\u001b[39m\"\u001b[39m, key\u001b[39m.\u001b[39mstep, \u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   4044\u001b[0m     \u001b[39mreturn\u001b[39;00m key\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/pandas/core/indexes/base.py:6308\u001b[0m, in \u001b[0;36mIndex._validate_indexer\u001b[0;34m(self, form, key, kind)\u001b[0m\n\u001b[1;32m   6305\u001b[0m \u001b[39massert\u001b[39;00m kind \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mgetitem\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   6307\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(key):\n\u001b[0;32m-> 6308\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalid_indexer(form, key)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot do slice indexing on RangeIndex with these indexers [0        True\n1        True\n2        True\n3        True\n4        True\n        ...  \n3166    False\n3167    False\n3168    False\n3169    False\n3170    False\nName: subject, Length: 3171, dtype: bool] of type Series"
     ]
    }
   ],
   "source": [
    "\n",
    "subjs = all_subjects['metadata']['subject'].unique()\n",
    "selected_subjs['X'] = nib.funcs.concat_images([all_subjects['X'].slicer[...,s] for s in selected_subjs_idx])\n",
    "selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n",
    "selected_subjs['groups'] = all_subjects['groups'][selected_subjs_idx_bool]\n",
    "selected_subjs['metadata'] = all_subjects['metadata'][selected_subjs_idx_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the PFC mask\n",
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the y array to an integer array representing the string values of the y array\n",
    "selected_subjs['y_cat'] = selected_subjs['y'].astype('category')\n",
    "selected_subjs['y_int']=selected_subjs['y_cat'].cat.codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "I'm going to start with `cv_train_test_sets` and see how that goes. It sems likely it'll have to be re-written somewhat, but it might be a good starting point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I need to run this without all the extra scaffolding--just tresting the Decoder on the data until I get something sensible. At the very least we need to know the Decoder object is handling balanced classes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use add PFC mask.ipynb to figure out how to get a PFC mask onto this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups are the same.\n",
      "fold 1 of 3\n",
      "In order to test on a training group of 6 items, holding out the following subjects:['DEV015' 'DEV006' 'DEV009']. prepping fold data.... fitting.... 4.9 GiB. trying decoder 1 of 1. predicting. test score was:. 0.5122285267071023\n",
      "fold 2 of 3\n",
      "In order to test on a training group of 6 items, holding out the following subjects:['DEV010' 'DEV005' 'DEV011']. prepping fold data.... fitting.... 5.0 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/decoding/decoder.py:141: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.43445692883895126\n",
      "fold 3 of 3\n",
      "In order to test on a training group of 6 items, holding out the following subjects:['DEV012' 'DEV013' 'DEV014']. prepping fold data.... fitting.... 4.9 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/decoding/decoder.py:141: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting. test score was:. 0.5957894736842105\n"
     ]
    }
   ],
   "source": [
    "dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\n",
    "cv_results = cv_train_test_sets(\n",
    "    trainset_X = selected_subjs['X'],\n",
    "    trainset_y = selected_subjs['y_int'],\n",
    "    trainset_groups = selected_subjs['metadata']['subject'],\n",
    "    decoders = [dec_main],\n",
    "    cv=KFold(n_splits=3) # we use KFold, not GroupKfold, because it's splitting on Group anyway\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_dict = {\n",
    "    'test_scores':cv_results[0],\n",
    "    'results':cv_results[1],\n",
    "    'results_by_trainset_item':cv_results[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>group</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>1</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>0</td>\n",
       "      <td>DEV015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>917 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y   group y_pred\n",
       "0    1  DEV005      0\n",
       "1    0  DEV005      0\n",
       "2    0  DEV005      0\n",
       "3    0  DEV005      1\n",
       "4    0  DEV005      1\n",
       "..  ..     ...    ...\n",
       "912  0  DEV015      1\n",
       "913  0  DEV015      0\n",
       "914  1  DEV015      0\n",
       "915  0  DEV015      1\n",
       "916  0  DEV015      1\n",
       "\n",
       "[917 rows x 3 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results_dict['results_by_trainset_item']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is derived from 3-fold cross-validation, and should indicate train/test performance classifying trials across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5015090495368123, 0.5040220259845717, 0.4038898145712142, None)\n",
      "0.5040220259845718\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#get precision and recall\n",
    "print(precision_recall_fscore_support(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "cv_results_dict['results_by_trainset_item']['y_pred'].astype(int),average='macro'))\n",
    "\n",
    "#get roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "    cv_results_dict['results_by_trainset_item']['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralsignature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cca8238de402a161b34e58e1e3b4d299a0bf48c5783c9dc7c173d82c36576a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
