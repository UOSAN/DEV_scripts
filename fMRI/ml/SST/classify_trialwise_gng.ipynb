{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying trialwise CorrectGo and NoGo trials\n",
    "\n",
    "There are a number of steps to this. Hopefully we can recycle previous code and be up fairly quickly!\n",
    "\n",
    "1. Load beta data. Ideally this process should include a cache into a pure python object so we don't have to reload it each time.\n",
    "2. Preprocess the data.\n",
    "3. Do cross-validated training and testing. Ideally an inner loop to select best parameters, an outer loop to get cross-validated performance, and final training over all the data to get an image. The inner loop can be probably be handled within the package we use probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import yaml\n",
    "hostname=socket.gethostname()\n",
    "hostname='zzz'\n",
    "with open('sst_config.yml', \"r\") as f:\n",
    "    test_config= yaml.safe_load(f)#[hostname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "cpus available; cpus to use:\n",
      "10 9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "from apply_loocv_and_save import load_and_preprocess\n",
    "from dev_utils import read_yaml_for_host\n",
    "from dev_utils import get_2DX_from_4DX\n",
    "import warnings\n",
    "\n",
    "\n",
    "config_data = read_yaml_for_host(\"sst_config.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "from nilearn.decoding import DecoderRegressor,Decoder\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(cpus_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from nilearn.decoding import DecoderRegressor,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = config_data['nonbids_data_path']\n",
    "ml_data_folderpath = nonbids_data_path + \"fMRI/ml\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading beta data\n",
    "\n",
    "beta data is generally written in `load_multisubject_brain_data_sst_w1.ipynb`.\n",
    "\n",
    "We just have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_29428/2753699166.py:3: UserWarning: not sure if this file holds up--it was created in 2021; need to see if it's still valid\n",
      "  warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n"
     ]
    }
   ],
   "source": [
    "#brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_30subs_correct_cond_pfc.pkl'\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_6subs_correct_cond.pkl'\n",
    "warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20220818T144138.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 6 subjects overlapping between the subjects marked for train data and the training dump file itself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_set: 62918\n",
      "brain_data_filepath: 168\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 158\n",
      "response_transform_func: 144\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601\n",
      "601\n",
      "cleaning memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_29428/1474138623.py:8: UserWarning: the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\n",
      "  warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectPercentile,f_classif\n",
    "\n",
    "#convert the y array to an integer array representing the string values of the y array\n",
    "all_subjects['y_cat'] = all_subjects['y'].astype('category')\n",
    "all_subjects['y_int']=all_subjects['y_cat'].cat.codes\n",
    "\n",
    "# #get the X fdata\n",
    "# x_fdata = all_subjects['X'].get_fdata()\n",
    "# print(x_fdata.shape)\n",
    "# #flatten first 3 dims of X fdata to a single dim\n",
    "# x_fdata_1d = x_fdata.reshape([np.prod(x_fdata.shape[0:3]), x_fdata.shape[3]])\n",
    "# print(x_fdata_1d.shape)\n",
    "\n",
    "\n",
    "\n",
    "# #SelectPercentile(f_classif,percentile=5).fit_transform(,all_subjects['y_int'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subjs = 6\n",
    "if num_subjs<len(all_subjects['metadata']['subject'].unique()):\n",
    "    #cut down to just 9 subjects\n",
    "    selected_subjs={}\n",
    "    print(all_subjects.keys())\n",
    "\n",
    "    #select subjs\n",
    "    subjs = all_subjects['metadata']['subject'].unique()\n",
    "    subjs.sort()\n",
    "    selected_sub_ids=subjs[0:num_subjs]\n",
    "    #get index of selected subjs\n",
    "    selected_subjs_idx_bool = all_subjects['metadata']['subject'].isin(selected_sub_ids)\n",
    "    #get list of True indices\n",
    "    selected_subjs_idx = selected_subjs_idx_bool[selected_subjs_idx_bool].index.tolist()\n",
    "\n",
    "    subjs = all_subjects['metadata']['subject'].unique()\n",
    "    selected_subjs['X'] = nib.funcs.concat_images([all_subjects['X'].slicer[...,s] for s in selected_subjs_idx])\n",
    "    selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n",
    "\n",
    "    selected_subjs['y'] = all_subjects['y'][selected_subjs_idx_bool]\n",
    "    selected_subjs['groups'] = all_subjects['groups'][selected_subjs_idx_bool]\n",
    "    selected_subjs['metadata'] = all_subjects['metadata'][selected_subjs_idx_bool]\n",
    "else:\n",
    "    selected_subjs = all_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the PFC mask\n",
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the y array to an integer array representing the string values of the y array\n",
    "selected_subjs['y_cat'] = selected_subjs['y'].astype('category')\n",
    "selected_subjs['y_int']=selected_subjs['y_cat'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=selected_subjs['X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_2DX_from_4DX(nifti_X):\n",
    "    #rotate my array so that the last dimension is first\n",
    "    print(nifti_X.shape)\n",
    "    nifti_X=np.moveaxis(nifti_X,-1,0)\n",
    "    print(nifti_X.shape)\n",
    "    pre_reshaped_shape = nifti_X.shape\n",
    "    #now flatten dims 2-4 into a single dimension\n",
    "    arr2d=myarr.reshape([nifti_X.shape[0],np.prod(nifti_X.shape[1:4])])\n",
    "    print(\"this is the form of the data that the decoder wants, (n_samples, n_features)\")\n",
    "    print(arr2d.shape)\n",
    "    return(arr2d)\n",
    "\n",
    "\n",
    "def get_4DX_from_2DX(arr2d,pre_reshaped_shape):\n",
    "    #now undo the above operations to get the original matrix\n",
    "    print(arr2d.shape)\n",
    "    arr4d=arr2d.reshape(pre_reshaped_shape)\n",
    "    print(myarr_rev.shape)\n",
    "    arr4d=np.moveaxis(arr4d,0,-1)\n",
    "    print(arr4d.shape)\n",
    "    return(arr4d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97, 115, 97, 601)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y113sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdev_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_2DX_from_4DX\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y113sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m X_2d\u001b[39m=\u001b[39mget_2DX_from_4DX(X\u001b[39m.\u001b[39;49mget_fdata())\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/fMRI/ml/dev_utils.py:25\u001b[0m, in \u001b[0;36mget_2DX_from_4DX\u001b[0;34m(nifti_X)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_2DX_from_4DX\u001b[39m(nifti_X):\n\u001b[1;32m     23\u001b[0m     \u001b[39m#rotate my array so that the last dimension is first\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[39mprint\u001b[39m(nifti_X\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 25\u001b[0m     nifti_X\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mmoveaxis(nifti_X,\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m0\u001b[39m)\n\u001b[1;32m     26\u001b[0m     \u001b[39mprint\u001b[39m(nifti_X\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     27\u001b[0m     pre_reshaped_shape \u001b[39m=\u001b[39m nifti_X\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#from dev_utils import get_2DX_from_4DX\n",
    "X_2d=get_2DX_from_4DX(X.get_fdata())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_2d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y112sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m X_2d\u001b[39m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_2d' is not defined"
     ]
    }
   ],
   "source": [
    "X_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1082035, 601]\n",
      "(97, 115, 97, 601)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y105sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mget_fdata()\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y105sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m#collapse the first 3 dims of X fdata to a single dim\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y105sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m X_reshaped \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mreshape(X\u001b[39m.\u001b[39;49mget_fdata(),[np\u001b[39m.\u001b[39;49mprod(X\u001b[39m.\u001b[39;49mshape[\u001b[39m0\u001b[39;49m:\u001b[39m3\u001b[39;49m]),X\u001b[39m.\u001b[39;49mshape[\u001b[39m3\u001b[39;49m]])\u001b[39m.\u001b[39mshape\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/numpy/core/fromnumeric.py:298\u001b[0m, in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_reshape_dispatcher)\n\u001b[1;32m    199\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreshape\u001b[39m(a, newshape, order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    200\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[39m    Gives a new shape to an array without changing its data.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39m           [5, 6]])\u001b[39;00m\n\u001b[1;32m    297\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 298\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapfunc(a, \u001b[39m'\u001b[39;49m\u001b[39mreshape\u001b[39;49m\u001b[39m'\u001b[39;49m, newshape, order\u001b[39m=\u001b[39;49morder)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/numpy/core/fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m     56\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 57\u001b[0m     \u001b[39mreturn\u001b[39;00m bound(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     60\u001b[0m     \u001b[39m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[39m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[39m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapit(obj, method, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "X.shape\n",
    "print([np.prod(X.shape[0:3]),X.shape[3]])\n",
    "print(X.get_fdata().shape)\n",
    "#collapse the first 3 dims of X fdata to a single dim\n",
    "X_reshaped = np.reshape(X.get_fdata(),[np.prod(X.shape[0:3]),X.shape[3]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape the X data to a 2D array\n",
    "def preprocess_func(X):\n",
    "    X_2d = np.reshape(X.get_fdata(),[np.prod(X.shape[0:3]),X.shape[3]])\n",
    "    X_nifti = nl.image.new_img_like(X,X_2d)\n",
    "    return(X_nifti)\n",
    "\n",
    "#apply the preprocessing function to the X data\n",
    "selected_subjs['X2'] = preprocess_func(selected_subjs['X'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "I'm going to start with `cv_train_test_sets` and see how that goes. It sems likely it'll have to be re-written somewhat, but it might be a good starting point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I need to run this without all the extra scaffolding--just tresting the Decoder on the data until I get something sensible. At the very least we need to know the Decoder object is handling balanced classes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use add PFC mask.ipynb to figure out how to get a PFC mask onto this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from EstimatorWithPreprocessing import EstimatorWithPreprocessor\n",
    "#import SVC\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import f_classif, SequentialFeatureSelector, SelectKBest\n",
    "\n",
    "\n",
    "ewp = EstimatorWithPreprocessor(\n",
    "    estimator=LinearSVC(penalty='l2',max_iter=1e4),\n",
    "    preprocessor= \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=<class 'nibabel.nifti1.Nifti1Image'>\ndata shape (97, 115, 97, 601)\naffine: \n[[   2.    0.    0.  -96.]\n [   0.    2.    0. -132.]\n [   0.    0.    2.  -78.]\n [   0.    0.    0.    1.]]\nmetadata:\n<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\nsizeof_hdr      : 348\ndata_type       : b''\ndb_name         : b''\nextents         : 0\nsession_error   : 0\nregular         : b''\ndim_info        : 0\ndim             : [  4  97 115  97 601   1   1   1]\nintent_p1       : 0.0\nintent_p2       : 0.0\nintent_p3       : 0.0\nintent_code     : none\ndatatype        : float32\nbitpix          : 32\nslice_start     : 0\npixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\nvox_offset      : 0.0\nscl_slope       : nan\nscl_inter       : nan\nslice_end       : 0\nslice_code      : unknown\nxyzt_units      : 0\ncal_max         : 0.0\ncal_min         : 0.0\nslice_duration  : 0.0\ntoffset         : 0.0\nglmax           : 0\nglmin           : 0\ndescrip         : b''\naux_file        : b''\nqform_code      : unknown\nsform_code      : aligned\nquatern_b       : 0.0\nquatern_c       : 0.0\nquatern_d       : 0.0\nqoffset_x       : -96.0\nqoffset_y       : -132.0\nqoffset_z       : -78.0\nsrow_x          : [  2.   0.   0. -96.]\nsrow_y          : [   0.    2.    0. -132.]\nsrow_z          : [  0.   0.   2. -78.]\nintent_name     : b''\nmagic           : b'n+1'.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#Y103sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m k_fit \u001b[39m=\u001b[39m SelectKBest(f_classif, k\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\u001b[39m.\u001b[39;49mfit(selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m],y\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49marray(selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39my_int\u001b[39;49m\u001b[39m'\u001b[39;49m]))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:397\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    381\u001b[0m     \u001b[39m\"\"\"Run score function on (X, y) and get the appropriate features.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    398\u001b[0m         X, y, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    401\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func):\n\u001b[1;32m    402\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    403\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe score function should be a callable, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) was passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func))\n\u001b[1;32m    405\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[1;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/utils/validation.py:761\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m ensure_2d:\n\u001b[1;32m    759\u001b[0m     \u001b[39m# If input is scalar raise error\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 761\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    762\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got scalar array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=<class 'nibabel.nifti1.Nifti1Image'>\ndata shape (97, 115, 97, 601)\naffine: \n[[   2.    0.    0.  -96.]\n [   0.    2.    0. -132.]\n [   0.    0.    2.  -78.]\n [   0.    0.    0.    1.]]\nmetadata:\n<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\nsizeof_hdr      : 348\ndata_type       : b''\ndb_name         : b''\nextents         : 0\nsession_error   : 0\nregular         : b''\ndim_info        : 0\ndim             : [  4  97 115  97 601   1   1   1]\nintent_p1       : 0.0\nintent_p2       : 0.0\nintent_p3       : 0.0\nintent_code     : none\ndatatype        : float32\nbitpix          : 32\nslice_start     : 0\npixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\nvox_offset      : 0.0\nscl_slope       : nan\nscl_inter       : nan\nslice_end       : 0\nslice_code      : unknown\nxyzt_units      : 0\ncal_max         : 0.0\ncal_min         : 0.0\nslice_duration  : 0.0\ntoffset         : 0.0\nglmax           : 0\nglmin           : 0\ndescrip         : b''\naux_file        : b''\nqform_code      : unknown\nsform_code      : aligned\nquatern_b       : 0.0\nquatern_c       : 0.0\nquatern_d       : 0.0\nqoffset_x       : -96.0\nqoffset_y       : -132.0\nqoffset_z       : -78.0\nsrow_x          : [  2.   0.   0. -96.]\nsrow_y          : [   0.    2.    0. -132.]\nsrow_z          : [  0.   0.   2. -78.]\nintent_name     : b''\nmagic           : b'n+1'.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "k_fit = SelectKBest(f_classif, k=1000).fit(selected_subjs['X'],y=np.array(selected_subjs['y_int']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups are the same.\n",
      "fold 1 of 3\n",
      "In order to test on a training group of 4 items, holding out the following subjects:['DEV005' 'DEV010']. prepping fold data.... fitting.... 3.3 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=<class 'nibabel.nifti1.Nifti1Image'>\ndata shape (97, 115, 97, 409)\naffine: \n[[   2.    0.    0.  -96.]\n [   0.    2.    0. -132.]\n [   0.    0.    2.  -78.]\n [   0.    0.    0.    1.]]\nmetadata:\n<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\nsizeof_hdr      : 348\ndata_type       : b''\ndb_name         : b''\nextents         : 0\nsession_error   : 0\nregular         : b''\ndim_info        : 0\ndim             : [  4  97 115  97 409   1   1   1]\nintent_p1       : 0.0\nintent_p2       : 0.0\nintent_p3       : 0.0\nintent_code     : none\ndatatype        : float32\nbitpix          : 32\nslice_start     : 0\npixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\nvox_offset      : 0.0\nscl_slope       : nan\nscl_inter       : nan\nslice_end       : 0\nslice_code      : unknown\nxyzt_units      : 0\ncal_max         : 0.0\ncal_min         : 0.0\nslice_duration  : 0.0\ntoffset         : 0.0\nglmax           : 0\nglmin           : 0\ndescrip         : b''\naux_file        : b''\nqform_code      : unknown\nsform_code      : aligned\nquatern_b       : 0.0\nquatern_c       : 0.0\nquatern_d       : 0.0\nqoffset_x       : -96.0\nqoffset_y       : -132.0\nqoffset_z       : -78.0\nsrow_x          : [  2.   0.   0. -96.]\nsrow_y          : [   0.    2.    0. -132.]\nsrow_z          : [  0.   0.   2. -78.]\nintent_name     : b''\nmagic           : b'n+1'.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m cv_results \u001b[39m=\u001b[39m cv_train_test_sets(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     trainset_X \u001b[39m=\u001b[39;49m selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     trainset_y \u001b[39m=\u001b[39;49m selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39my_int\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     trainset_groups \u001b[39m=\u001b[39;49m selected_subjs[\u001b[39m'\u001b[39;49m\u001b[39mmetadata\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39;49m\u001b[39msubject\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     decoders \u001b[39m=\u001b[39;49m [ewp],\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     cv\u001b[39m=\u001b[39;49mKFold(n_splits\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m) \u001b[39m# we use KFold, not GroupKfold, because it's splitting on Group anyway\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/benjaminsmith/Google%20Drive/oregon/code/DEV_scripts/fMRI/ml/SST/classify_trialwise_gng.ipynb#X51sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     )\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/fMRI/ml/dev_wtp_io_utils.py:729\u001b[0m, in \u001b[0;36mcv_train_test_sets\u001b[0;34m(trainset_X, trainset_y, trainset_groups, decoders, testset_X, testset_y, testset_groups, param_grid, cpus_to_use, cv, regressors)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtrying decoder \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(r_i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m of \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(decoders)),end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    727\u001b[0m \u001b[39m#if there is nested CV within this function the best hyper-paramters are already being chosen\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m#we need only to finish the job by identifying the best overall decoder, as the final hyper-parameter\u001b[39;00m\n\u001b[0;32m--> 729\u001b[0m reg\u001b[39m.\u001b[39;49mfit(y\u001b[39m=\u001b[39;49mtrain_y,X\u001b[39m=\u001b[39;49mtrain_X,groups\u001b[39m=\u001b[39;49mtrain_groups)\n\u001b[1;32m    730\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mpredicting\u001b[39m\u001b[39m\"\u001b[39m,end\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    731\u001b[0m \u001b[39m#hyper_score = reg.score(train_X,train_y)\u001b[39;00m\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/fMRI/ml/EstimatorWithPreprocessing.py:46\u001b[0m, in \u001b[0;36mEstimatorWithPreprocessor.fit\u001b[0;34m(self, y, X, groups)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, y, X, groups):\n\u001b[1;32m     34\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39m    Fit the model to the data.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39m        The group labels.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpreprocessor\u001b[39m.\u001b[39;49mfit(X\u001b[39m=\u001b[39;49mX, y\u001b[39m=\u001b[39;49my)\n\u001b[1;32m     47\u001b[0m     X_pp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpreprocessor\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m     49\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39mfit(X\u001b[39m=\u001b[39mX_pp, y\u001b[39m=\u001b[39my, groups\u001b[39m=\u001b[39mgroups)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/feature_selection/_univariate_selection.py:397\u001b[0m, in \u001b[0;36m_BaseFilter.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y):\n\u001b[1;32m    381\u001b[0m     \u001b[39m\"\"\"Run score function on (X, y) and get the appropriate features.\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \n\u001b[1;32m    383\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[39m        Returns the instance itself.\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 397\u001b[0m     X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    398\u001b[0m         X, y, accept_sparse\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m], multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    401\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func):\n\u001b[1;32m    402\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[1;32m    403\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe score function should be a callable, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) was passed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    404\u001b[0m             \u001b[39m%\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func, \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscore_func))\n\u001b[1;32m    405\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/base.py:581\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    580\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 581\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    582\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/utils/validation.py:964\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39my cannot be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 964\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m    965\u001b[0m     X,\n\u001b[1;32m    966\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49maccept_sparse,\n\u001b[1;32m    967\u001b[0m     accept_large_sparse\u001b[39m=\u001b[39;49maccept_large_sparse,\n\u001b[1;32m    968\u001b[0m     dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    969\u001b[0m     order\u001b[39m=\u001b[39;49morder,\n\u001b[1;32m    970\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    971\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49mforce_all_finite,\n\u001b[1;32m    972\u001b[0m     ensure_2d\u001b[39m=\u001b[39;49mensure_2d,\n\u001b[1;32m    973\u001b[0m     allow_nd\u001b[39m=\u001b[39;49mallow_nd,\n\u001b[1;32m    974\u001b[0m     ensure_min_samples\u001b[39m=\u001b[39;49mensure_min_samples,\n\u001b[1;32m    975\u001b[0m     ensure_min_features\u001b[39m=\u001b[39;49mensure_min_features,\n\u001b[1;32m    976\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    977\u001b[0m )\n\u001b[1;32m    979\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric)\n\u001b[1;32m    981\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/sklearn/utils/validation.py:761\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    758\u001b[0m \u001b[39mif\u001b[39;00m ensure_2d:\n\u001b[1;32m    759\u001b[0m     \u001b[39m# If input is scalar raise error\u001b[39;00m\n\u001b[1;32m    760\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 761\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    762\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got scalar array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    763\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    765\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[1;32m    766\u001b[0m         )\n\u001b[1;32m    767\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=<class 'nibabel.nifti1.Nifti1Image'>\ndata shape (97, 115, 97, 409)\naffine: \n[[   2.    0.    0.  -96.]\n [   0.    2.    0. -132.]\n [   0.    0.    2.  -78.]\n [   0.    0.    0.    1.]]\nmetadata:\n<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\nsizeof_hdr      : 348\ndata_type       : b''\ndb_name         : b''\nextents         : 0\nsession_error   : 0\nregular         : b''\ndim_info        : 0\ndim             : [  4  97 115  97 409   1   1   1]\nintent_p1       : 0.0\nintent_p2       : 0.0\nintent_p3       : 0.0\nintent_code     : none\ndatatype        : float32\nbitpix          : 32\nslice_start     : 0\npixdim          : [1. 2. 2. 2. 1. 1. 1. 1.]\nvox_offset      : 0.0\nscl_slope       : nan\nscl_inter       : nan\nslice_end       : 0\nslice_code      : unknown\nxyzt_units      : 0\ncal_max         : 0.0\ncal_min         : 0.0\nslice_duration  : 0.0\ntoffset         : 0.0\nglmax           : 0\nglmin           : 0\ndescrip         : b''\naux_file        : b''\nqform_code      : unknown\nsform_code      : aligned\nquatern_b       : 0.0\nquatern_c       : 0.0\nquatern_d       : 0.0\nqoffset_x       : -96.0\nqoffset_y       : -132.0\nqoffset_z       : -78.0\nsrow_x          : [  2.   0.   0. -96.]\nsrow_y          : [   0.    2.    0. -132.]\nsrow_z          : [  0.   0.   2. -78.]\nintent_name     : b''\nmagic           : b'n+1'.\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "#dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\n",
    "cv_results = cv_train_test_sets(\n",
    "    trainset_X = selected_subjs['X'],\n",
    "    trainset_y = selected_subjs['y_int'],\n",
    "    trainset_groups = selected_subjs['metadata']['subject'],\n",
    "    decoders = [ewp],\n",
    "    cv=KFold(n_splits=3) # we use KFold, not GroupKfold, because it's splitting on Group anyway\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_dict = {\n",
    "    'test_scores':cv_results[0],\n",
    "    'results':cv_results[1],\n",
    "    'results_by_trainset_item':cv_results[2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_dict['results_by_trainset_item']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is derived from 3-fold cross-validation, and should indicate train/test performance classifying trials across subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "#get precision and recall\n",
    "print(precision_recall_fscore_support(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "cv_results_dict['results_by_trainset_item']['y_pred'].astype(int),average='macro'))\n",
    "\n",
    "#get roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(\n",
    "    cv_results_dict['results_by_trainset_item']['y'],\n",
    "    cv_results_dict['results_by_trainset_item']['y_pred']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralsignature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cca8238de402a161b34e58e1e3b4d299a0bf48c5783c9dc7c173d82c36576a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
