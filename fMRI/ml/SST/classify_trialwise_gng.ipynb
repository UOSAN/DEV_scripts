{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying trialwise CorrectGo and NoGo trials\n",
    "\n",
    "There are a number of steps to this. Hopefully we can recycle previous code and be up fairly quickly!\n",
    "\n",
    "1. Load beta data. Ideally this process should include a cache into a pure python object so we don't have to reload it each time.\n",
    "2. Preprocess the data.\n",
    "3. Do cross-validated training and testing. Ideally an inner loop to select best parameters, an outer loop to get cross-validated performance, and final training over all the data to get an image. The inner loop can be probably be handled within the package we use probably."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n",
      "cpus available; cpus to use:\n",
      "10 9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "from apply_loocv_and_save import load_and_preprocess\n",
    "from dev_utils import read_yaml_for_host\n",
    "import warnings\n",
    "\n",
    "\n",
    "config_data = read_yaml_for_host(\"sst_config.yml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import math\n",
    "import nibabel as nib\n",
    "import nilearn as nl\n",
    "from nilearn.decoding import DecoderRegressor,Decoder\n",
    "from sklearn.model_selection import KFold,GroupKFold,LeaveOneOut\n",
    "cpus_available = multiprocessing.cpu_count()\n",
    "\n",
    "cpus_to_use = min(cpus_available-1,math.floor(0.9*cpus_available))\n",
    "print(cpus_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_wtp_io_utils import cv_train_test_sets, asizeof_fmt\n",
    "from nilearn.decoding import DecoderRegressor,Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = config_data['nonbids_data_path']\n",
    "ml_data_folderpath = nonbids_data_path + \"fMRI/ml\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the paradigm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading beta data\n",
    "\n",
    "beta data is generally written in `load_multisubject_brain_data_sst_w1.ipynb`.\n",
    "\n",
    "We just have to load it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_25653/256071196.py:2: UserWarning: not sure if this file holds up--it was created in 2021; need to see if it's still valid\n",
      "  warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n"
     ]
    }
   ],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_30subs_correct_cond_pfc.pkl'\n",
    "warnings.warn(\"not sure if this file holds up--it was created in 2021; need to see if it's still valid\")\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20220818T144138.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/neuralsignature/lib/python3.10/site-packages/nilearn/input_data/__init__.py:27: FutureWarning: The import path 'nilearn.input_data' is deprecated in version 0.9. Importing from 'nilearn.input_data' will be possible at least until release 0.13.0. Please import from 'nilearn.maskers' instead.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 30 subjects overlapping between the subjects marked for train data and the training dump file itself.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:217: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train_set: 62918\n",
      "brain_data_filepath: 173\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 158\n",
      "response_transform_func: 144\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n",
      "3171\n",
      "3171\n",
      "cleaning memory\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_25653/1474138623.py:8: UserWarning: the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\n",
      "  warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "warnings.warn(\"the data hasn't been cleaned at any point. the fMRIPrep cleaning pipeline has been applied; nothing else has been.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the PFC mask\n",
    "mask_nifti = nib.load(ml_data_folderpath + '/prefrontal_cortex.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the y array to an integer array representing the string values of the y array\n",
    "all_subjects['y_cat'] = all_subjects['y'].astype('category')\n",
    "all_subjects['y_int']=all_subjects['y_cat'].cat.codes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "I'm going to start with `cv_train_test_sets` and see how that goes. It sems likely it'll have to be re-written somewhat, but it might be a good starting point."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think I need to run this without all the extra scaffolding--just tresting the Decoder on the data until I get something sensible. At the very least we need to know the Decoder object is handling balanced classes correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use add PFC mask.ipynb to figure out how to get a PFC mask onto this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groups are the same.\n",
      "fold 1 of 3\n",
      "In order to test on a training group of 20 items, holding out the following subjects:['DEV041' 'DEV006' 'DEV023' 'DEV024' 'DEV009' 'DEV010' 'DEV012' 'DEV021'\n",
      " 'DEV014' 'DEV015']. prepping fold data.... fitting.... 17.1 GiB. trying decoder 1 of 1. "
     ]
    }
   ],
   "source": [
    "dec_main = Decoder(standardize=True,cv=GroupKFold(3),scoring='roc_auc',n_jobs=cpus_to_use,mask=mask_nifti)\n",
    "cv_results = cv_train_test_sets(\n",
    "    trainset_X = all_subjects['X'],\n",
    "    trainset_y = all_subjects['y_int'],\n",
    "    trainset_groups = all_subjects['metadata']['subject'],\n",
    "    decoders = [dec_main],\n",
    "    cv=KFold(n_splits=3) # we use KFold, not GroupKfold, because it's splitting on Group anyway\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_prediction = dec_main.predict(trainset_X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.5804711445017567, 0.6827315628209372, 0.5669378446968172, None)\n",
      "0.6827315628209372\n"
     ]
    }
   ],
   "source": [
    "pd.DataFrame({'obs':trainset_y,'pred':final_prediction}).value_counts()\n",
    "#get precision and recall\n",
    "print(precision_recall_fscore_support(trainset_y,final_prediction,average='macro'))\n",
    "\n",
    "#get roc_auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print(roc_auc_score(trainset_y,final_prediction))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aren't going to get train/test results from this. We need to figure out how to pull the observations from the data and get those."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralsignature",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cca8238de402a161b34e58e1e3b4d299a0bf48c5783c9dc7c173d82c36576a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
