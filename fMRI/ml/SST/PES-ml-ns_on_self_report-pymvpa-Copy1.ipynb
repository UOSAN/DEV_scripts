{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "angry-conspiracy",
   "metadata": {
    "tags": []
   },
   "source": [
    "This builds on TESQ-ml-ns-nogo-go\n",
    "\n",
    "> **proposal 1**\n",
    "> \n",
    "> Two class (e.g., CorrectStop vs. CorrectGo)\n",
    "> \n",
    "> Leave-One-Out classifier...\n",
    "> \n",
    "> Neural similarity of a subject to the group with a Stop vs. Go contrast might actually be indicative of performance.\n",
    "> \n",
    "> subjects will naturally differ across the task as to how much their average signal responds to that, and the ones with better response might have better response inhibition.\n",
    "\n",
    "We use the same neural data, but instead of regressing on classifying these classes, we take one class or the other or we combine them in some way and we regress on our self report variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-discretion",
   "metadata": {},
   "source": [
    "So there are a couple of steps here...\n",
    "\n",
    "1. iterate through subjects, holding out one at a time, and do the following steps.\n",
    "2. Train a regressor across all the training subjects, regressing CorrectStop and CorrectGo on TESQ-E and other self report measures including FFQ either (a) independently (b) contrasted with each other (c) concatenated in a single image.\n",
    "3. If a link can be established, we've shown there is a relevant link between TESQ-E or other self-report measure, and the neural signature.\n",
    "4. ...that seems like a publication in itself!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taken-certification",
   "metadata": {},
   "source": [
    "As a first pass, we can simplify this a bit just trying that single classifier on all subjects. This means that we're using train for tes tset but it will give us an initial measure of feasibility.\n",
    "\n",
    "We probably do need to restrict to a specific brain region though, and that means retraining. - I think that prefrontal cortex mask we have works well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-glucose",
   "metadata": {},
   "source": [
    "## Data already generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-oxford",
   "metadata": {},
   "source": [
    "Can we use data already generated in `SST_inhibition_cv.ipynb`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mineral-pillow",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14189/659417397.py:2: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import display, HTML, Markdown\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from IPython.core.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mechanical-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "economic-hartford",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_filepath=ml_data_folderpath + \"/SST/train_test_results_conditions_40subs_twoclasses.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "romance-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_2c = pickle.load(open(results_filepath,'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "popular-myrtle",
   "metadata": {},
   "source": [
    "Not quite--we need a PFC mask I think. But we can use the script already written to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "falling-queue",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "limiting-galaxy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "\n",
    "#from apply_loocv_and_save import *\n",
    "#from dev_wtp_io_utils import *\n",
    "import gc\n",
    "import nibabel as nib\n",
    "\n",
    "from os import path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-punch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import ttest_1samp, pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sealed-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymvpa2_ml_library import *\n",
    "from generic_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "natural-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/mvpa2/datasets/base.py:465: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, shape=None, sid=None, fid=None, dtype=np.float):\n"
     ]
    }
   ],
   "source": [
    "from mvpa_pipeline_utils import get_Brain_Data_betas_as_mvpa_for_sub, import_beta_series_pymvpa2, sa_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "located-longitude",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from analyze_results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "greater-colorado",
   "metadata": {},
   "source": [
    "## condition_contrast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-conjunction",
   "metadata": {},
   "source": [
    "## stitching contrasts together in different ways\n",
    "\n",
    "We'd want:\n",
    "\n",
    " - contrast of the two conditions\n",
    " - each of the two conditions alone.\n",
    " \n",
    "The contrast is a little tricky. Easiest thing is to try each of the conditions alone. Stitching the two together might not be too hard. Let's try doing CorrectStop first, and then we'll try concatenating the images. Doing a contrast is actually the most difficult becuase I have to backtrack in the process to generate new betas (see https://docs.google.com/presentation/d/1K-nFrZYE6rR8t0myNyacB7frBzV3B1--nMqPhVkwL8E/edit#slide=id.geeff6890fb_0_16)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-omaha",
   "metadata": {},
   "source": [
    "See `different ways of combining images.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-africa",
   "metadata": {},
   "source": [
    "## template"
   ]
  },
  {
   "cell_type": "raw",
   "id": "clinical-victorian",
   "metadata": {},
   "source": [
    "do_complete_analysis_for_mask('goal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-baseball",
   "metadata": {},
   "source": [
    "## regressing on self report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "superior-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\"\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20210601T183243.csv\"\n",
    "test_train_df = pd.read_csv(train_test_markers_filepath)\n",
    "\n",
    "all_sst_events= pd.read_csv(ml_data_folderpath +\"/SST/\" + \"all_sst_events.csv\")\n",
    "\n",
    "\n",
    "script_path = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml'\n",
    "# HRF 2s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passive-brunei",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## additional masks\n",
    "\n",
    "all_masks = get_all_masks(ml_data_folderpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "comparable-adobe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_metadata(bd,target_val,standardize=True):\n",
    "    #set up chunks and targets so we can do the learning.\n",
    "    attribute_df = sa_to_df(bd.sa)\n",
    "    pd.concat([attribute_df['subject'],attribute_df['wave']],axis=1)\n",
    "    chunk = attribute_df['subject']+\"_\" + attribute_df['wave'].astype(str)\n",
    "    bd.sa['chunks'] = list(chunk)\n",
    "    if standardize:\n",
    "        target_data = bd.sa[target_val].value\n",
    "        target_data_mean = np.nanmean(target_data)\n",
    "        target_data_std = np.nanstd(target_data)\n",
    "        target_data_norm = (target_data-target_data_mean)/target_data_std\n",
    "        bd.sa['targets'] = list(target_data_norm)\n",
    "    else:\n",
    "        bd.sa['targets'] = list(bd.sa[target_val].value)\n",
    "    return(bd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "quantitative-hayes",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=2.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "optimum-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.svm import *\n",
    "from sklearn.linear_model import *\n",
    "\n",
    "def do_Ridge(train_X,train_y,test_X,test_y):\n",
    "    sklearn_regress = Ridge(alpha=5.0)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    return(predict_y,sklearn_regress)\n",
    "    \n",
    "def do_regression(dataset,normalization=None,get_prediction=None,verbose=False,require_mean_centered=True):\n",
    "    if get_prediction is None:\n",
    "        get_prediction = do_Ridge\n",
    "    logo=LeaveOneGroupOut()\n",
    "\n",
    "    group_scores = {}\n",
    "    sample_wise_results = []\n",
    "\n",
    "    items_to_eliminate_count = np.sum(np.isnan(dataset.sa.targets))\n",
    "    items_total = len(dataset.sa.targets)\n",
    "    print(\"eliminating \" + str(items_to_eliminate_count) + \" of \" + \n",
    "          str(items_total) + \" items due to null input values.\")\n",
    "    \n",
    "    dataset=dataset[np.isnan(dataset.sa.targets)==False]\n",
    "    \n",
    "    #ensure data is standardized\n",
    "    if abs(np.nanmean(dataset.sa.targets)>0.001) and require_mean_centered:\n",
    "        raise Exception(\"target data is not mean-centred, but mean centering is required.\")\n",
    "\n",
    "    for train_index, test_index in logo.split(\n",
    "        dataset.samples, dataset.sa.targets, dataset.sa.chunks):\n",
    "        iteration_label = np.unique(dataset.sa.chunks[test_index])[0]\n",
    "\n",
    "        #print(iteration_label, \"; TRAIN:\", len(train_index), \" items; TEST:\", test_index)\n",
    "        print(\".\",end=\"\",flush=True)\n",
    "\n",
    "        #do train-test split\n",
    "        train_X=dataset.samples[train_index]\n",
    "        test_X = dataset.samples[test_index]\n",
    "        train_y=dataset.sa.targets[train_index]\n",
    "        test_y = dataset.sa.targets[test_index]\n",
    "        #clf_svc = SVC()\n",
    "        \n",
    "        if normalization==\"train_set_based\":\n",
    "            #get mean based on train set alone\n",
    "            voxel_mean = np.mean(train_X,axis=0)\n",
    "            voxel_sd = np.std(train_X,axis=0)\n",
    "            #apply it to all.\n",
    "            train_X=(train_X-voxel_mean)/voxel_sd\n",
    "            test_X=(test_X-voxel_mean)/voxel_sd\n",
    "            raise Exception(\"this is obsolete--think this method is completely wrong.\")\n",
    "            #print(\"normalizing\")\n",
    "#         print(train_y)\n",
    "#         print(sum(np.isnan(train_y)))\n",
    "#         print(test_y)\n",
    "        predict_y, sklearn_clf = get_prediction(train_X,train_y,test_X,test_y)\n",
    "        predict_y_train = sklearn_clf.predict(train_X)\n",
    "#         print(pearsonr(predict_y_train,train_y))\n",
    "#         print(predict_y)\n",
    "#         print(predict_y_train)\n",
    "        \n",
    "        sample_wise_results_iter = pd.DataFrame({\n",
    "            'chunks':[iteration_label]*len(test_y),\n",
    "            'target_y':test_y,\n",
    "            'pred_y':predict_y,\n",
    "        })\n",
    "            \n",
    "        sample_wise_results = sample_wise_results + [sample_wise_results_iter]\n",
    "        \n",
    "    #need to create one more classifier to return.\n",
    "    #we test and train on the same here, which is OK, because we don't use this to assess performance\n",
    "    y_predict, model_final =get_prediction(\n",
    "        dataset.samples,dataset.sa.targets,dataset.samples,dataset.sa.targets)\n",
    "            \n",
    "    sample_wise_results_df = pd.concat(sample_wise_results)\n",
    "    return({'sample_wise':sample_wise_results_df,#'group_wise':group_scores,\n",
    "            'model':model_final})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-weapon",
   "metadata": {},
   "source": [
    "# Method fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "quarterly-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_posterror_conditions_84subs_post_stop_cg.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "presidential-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data_folderpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "arabic-negative",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "immune-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'TESQ_E_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "sufficient-vault",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CorrectGoFollowingCorrectStop', 'CorrectGoFollowingFailedStop'],\n",
       "      dtype='<U29')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Brain_Data_allsubs.sa.condition_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "significant-minutes",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_CorrectGoFollowingCorrectStop = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGoFollowingCorrectStop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-gasoline",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "built-water",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_CorrectGoFollowingFailedStop = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGoFollowingFailedStop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "forty-paragraph",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa2.measures.rsa import Regression\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "moral-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 12 of 162 items due to null input values.\n",
      "..........................................................................."
     ]
    }
   ],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "geographic-restriction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "from scipy.stats import ttest_1samp, pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "automated-berry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0742045878296486, 0.3668129918504953)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-establishment",
   "metadata": {},
   "source": [
    "That's pretty good considering that we are regressing over all images whether they're Stop or Go signal. need to change this so that we alternately regress over stop or go only, or possibly, the difference between them.\n",
    "\n",
    "The contrast between them is probably best, which means we go to generate a new series based on that.\n",
    "\n",
    "Though, wait--why is it _negative_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "complete-crowd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 6 of 81 items due to null input values.\n",
      "..........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05564655686335038, 0.6353666837185526)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results_CS = do_regression(Brain_Data_CorrectGoFollowingFailedStop)\n",
    "pearsonr(regression_results_CS['sample_wise']['target_y'],regression_results_CS['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vital-attempt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.05564655686335038, 0.6353666837185526)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results_CS['sample_wise']['target_y'],regression_results_CS['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "british-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunks</th>\n",
       "      <th>target_y</th>\n",
       "      <th>pred_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>-0.314867</td>\n",
       "      <td>0.511084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>1.328669</td>\n",
       "      <td>0.037375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV010_1</td>\n",
       "      <td>-0.747377</td>\n",
       "      <td>-0.757483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV011_1</td>\n",
       "      <td>-1.352890</td>\n",
       "      <td>-0.025431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV013_1</td>\n",
       "      <td>0.031141</td>\n",
       "      <td>0.180333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV197_1</td>\n",
       "      <td>0.550152</td>\n",
       "      <td>-0.071238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV206_1</td>\n",
       "      <td>-0.487871</td>\n",
       "      <td>-0.397298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV215_1</td>\n",
       "      <td>-0.833878</td>\n",
       "      <td>0.450203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV216_1</td>\n",
       "      <td>-1.093384</td>\n",
       "      <td>-0.793119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV217_1</td>\n",
       "      <td>-0.141863</td>\n",
       "      <td>0.263249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      chunks  target_y    pred_y\n",
       "0   DEV005_1 -0.314867  0.511084\n",
       "0   DEV006_1  1.328669  0.037375\n",
       "0   DEV010_1 -0.747377 -0.757483\n",
       "0   DEV011_1 -1.352890 -0.025431\n",
       "0   DEV013_1  0.031141  0.180333\n",
       "..       ...       ...       ...\n",
       "0   DEV197_1  0.550152 -0.071238\n",
       "0   DEV206_1 -0.487871 -0.397298\n",
       "0   DEV215_1 -0.833878  0.450203\n",
       "0   DEV216_1 -1.093384 -0.793119\n",
       "0   DEV217_1 -0.141863  0.263249\n",
       "\n",
       "[75 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results_CS['sample_wise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "superb-twenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "accepting-phrase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aab0313cdf0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD4CAYAAADvsV2wAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAYqklEQVR4nO3dfWxdZ30H8O837t16gWoGxdDmNmmqKTOQdcXUCq3yTyhjbrOuCX3RChMghhSBWgkkZpGABOEP1EiZ2NYWEUVQsWpdK0ZSE0SYKTSo0C1Vr/PSNE29Rd3a2o6GaXFKFW847m9/3BvHvj7Hvuee57w+348UxT735J4nx9ff85zn7dDMICIi5bci6wKIiEg6FPgiIp5Q4IuIeEKBLyLiCQW+iIgnLsm6AEtZuXKlrV27NutiiIgUxsjIyK/NrCfotVwH/tq1a1Gv17MuhohIYZB8Kew1NemIiHhCgS8i4gkFvoiIJxT4IiKeUOCLiHgi16N0imzo6Dh2D49iYmoaq7qrGBzoxda+WtbFEhGPKfATMHR0HDv2n8D0zCwAYHxqGjv2nwAAhb6IZEZNOgnYPTw6F/YXTM/MYvfwaEYlEhFR4CdiYmo60nYRkTQo8BOwqrsaabuISBoU+AkYHOhFtdK1YFu10oXBgd6MSiQi4iDwSa4meYjkKZInSX4uYJ9NJM+SPNb885W4x82zrX013HvbNah1V0EAte4q7r3tGnXYikimXIzSOQ/gC2Z2hORlAEZIPm5mz7fs9wszu8XB8Qpha19NAS8iuRK7hm9mZ8zsSPPr3wI4BUBJJyKSM07b8EmuBdAH4OmAl28geZzkj0muX+I9tpGsk6xPTk66LJ6IiNecBT7JtwHYB+DzZvZ6y8tHAFxlZtcCuB/AUNj7mNleM+s3s/6ensA1/EVEpANOAp9kBY2wf9jM9re+bmavm9kbza8PAqiQXOni2CIi0h4Xo3QI4DsATpnZN0L2uby5H0huaB731bjHFhGR9rkYpbMRwMcBnCB5rLntSwDWAICZ7QFwB4DPkjwPYBrAXWZmDo4tIiJtih34ZvZLAFxmnwcAPBD3WCIi0jnNtBUR8YQCX0TEEwp8ERFPKPBFRDyhwBcR8YQCX0TEEwp8ERFPKPBFRDyhwBcR8YQCX0TEEwp8ERFPKPBFRDyhwBcR8YQCX0TEEwp8ERFPKPBFRDyhwBcR8YQCX0TEEwp8ERFPKPBFRDwRO/BJriZ5iOQpkidJfi5gH5K8j+Rpks+SfH/c44qISDSXOHiP8wC+YGZHSF4GYITk42b2/Lx9bgawrvnnAwC+1fxbRERSEruGb2ZnzOxI8+vfAjgFoNay2xYAD1nDYQDdJK+Ie2wREWmf0zZ8kmsB9AF4uuWlGoBX5n0/hsUXhQvvsY1knWR9cnLSZfFERLzmLPBJvg3APgCfN7PXW18O+CcW9D5mttfM+s2sv6enx1XxRES85yTwSVbQCPuHzWx/wC5jAFbP+/5KABMuji0iIu1xMUqHAL4D4JSZfSNktwMAPtEcrXM9gLNmdibusUVEpH0uRulsBPBxACdIHmtu+xKANQBgZnsAHASwGcBpAOcAfMrBcUVEJILYgW9mv0RwG/38fQzA3XGPJSIindNMWxERTyjwRUQ8ocAXEfGEi05bES8NHR3H7uFRTExNY1V3FYMDvdjaFzifUCQXFPgiHRg6Oo4d+09gemYWADA+NY0d+08AgEJfcktNOiId2D08Ohf2F0zPzGL38GhGJRJZngJfpAMTU9ORtovkgQJfpAOruquRtovkgQJfpAODA72oVroWbKtWujA40JtRiUSWp05bkQ5c6JjVKB0pEgW+SIe29tUU8FIoatIREfGEAl9ExBMKfBERTyjwRUQ8ocAXEfGEAl9ExBMKfBERTyjwRUQ84STwST5I8lcknwt5fRPJsySPNf98xcVxRUSkfa5m2n4XwAMAHlpin1+Y2S2OjiciIhE5qeGb2ZMAXnPxXiIikow02/BvIHmc5I9Jrg/bieQ2knWS9cnJyRSLJyJSbmkF/hEAV5nZtQDuBzAUtqOZ7TWzfjPr7+npSal4IiLll0rgm9nrZvZG8+uDACokV6ZxbBERaUgl8EleTpLNrzc0j/tqGscWEZEGJ6N0SD4CYBOAlSTHAHwVQAUAzGwPgDsAfJbkeQDTAO4yM3NxbBERaY+TwDezjy7z+gNoDNsUEZGMaKatiIgnFPgiIp5Q4IuIeEKBLyLiCQW+iIgnFPgiIp5Q4IuIeEKBLyLiCQW+iIgnFPgiIp5Q4IuIeEKBLyLiCQW+iIgnFPgiIp5Q4IuIeEKBLyLiCQW+iIgnFPgiIp5Q4IuIeMJJ4JN8kOSvSD4X8jpJ3kfyNMlnSb7fxXFFRKR9rmr43wVw0xKv3wxgXfPPNgDfcnRcERFpk5PAN7MnAby2xC5bADxkDYcBdJO8wsWxRUSkPWm14dcAvDLv+7HmtkVIbiNZJ1mfnJxMpXAiIj5IK/AZsM2CdjSzvWbWb2b9PT09CRdLRMQfaQX+GIDV876/EsBESscWERGkF/gHAHyiOVrnegBnzexMSscWEREAl7h4E5KPANgEYCXJMQBfBVABADPbA+AggM0ATgM4B+BTLo4rIiLtcxL4ZvbRZV43AHe7OJYka+joOHYPj2JiahqruqsYHOjF1r7A/nVxQOdb0uQk8KUcho6OY8f+E5iemQUAjE9NY8f+EwCgEEqAzrekTUsryJzdw6Nz4XPB9Mwsdg+PZlSictP5zo+ho+PYuOsJXL39R9i46wkMHR3PukiJUA1f5kxMTUfaLvHofOeDT3daquHLnFXd1UjbJR6d73zw6U5LgS9zBgd6Ua10LdhWrXRhcKA3oxKVm853Pvh0p6UmHZlz4fZVo0bSofOdD6u6qxgPCPcy3mmxMWIyn/r7+61er2ddDBEpsdY2fKBxp3XvbdcU8uJLcsTM+oNeUw1fRLzm052WAl9EvLe1r1bKgG+lwBcRyYmkZ14r8EVEciCN+QAKfJEC0do75bXUfAAFvohnfJoR6qM05gNo4pVIQfg0I9RHacy8VuCLFIRPM0J9lMbMawW+SEFo7Z1y29pXw723XYNadxUEUOuuOp/8pTZ8kYIYHOgNnBGqtXfKI+n5AAp8kYLwaUaoJEOBL1IgvswIlWQo8CW3NOZcxC0nnbYkbyI5SvI0ye0Br28ieZbkseafr7g4rq98eBzbhTHn41PTMFwcc17G/6tIWmLX8El2AfgmgA8DGAPwDMkDZvZ8y66/MLNb4h7Pd0WefBOlxp7GrMM45RMpIhdNOhsAnDazFwGA5KMAtgBoDXxxIIsgdCHqhSrtMedFvpC6ogte+bkI/BqAV+Z9PwbgAwH73UDyOIAJAH9jZieD3ozkNgDbAGDNmjUOilcuSQdhUr/0US9UaT+FqKgXUlfCLnj1l17DoRcmdREoCRdt+AzY1voYrSMArjKzawHcD2Ao7M3MbK+Z9ZtZf09Pj4PilUuSk2+SbDcPCu+ltqf9vFffZ7GGXfAePvyy+lFKxEXgjwFYPe/7K9Goxc8xs9fN7I3m1wcBVEiudHDsVLnoLI37HkkGYZJrtXQxqF4Qvj2NWYfzLXUh9aGTPOzC1lpz09o9xeaiSecZAOtIXg1gHMBdAD42fweSlwP4HzMzkhvQuNC86uDYqXHRxuviPZKcfJNkLXc25NnJYduBdMech81i/eC7ewrbth+leS6sCS2IL3c9ZRS7hm9m5wHcA2AYwCkA3zOzkyQ/Q/Izzd3uAPBcsw3/PgB3WZ6fnh7ARe3XVQ16a18NT22/Ef+168/x1PYbnQVPks1FtZD3CNuetq19Ndx+XW3ujqOLxO3X1XDohclCrlAZtXku6M4x+N5La/cUmZNx+GZ20Mz+yMz+0My+3ty2x8z2NL9+wMzWm9m1Zna9mf2bi+OmyUXtN+/txEk2F6XdJh/V0NFx7BsZn7vjmDXDvpHx0FpvXn5mYaJWLoKa0P7q+jW5/plJdJpp2yYXo0bSHnkSVZLNRXlfByYsILvIwGanvPzMwnRSuQhqQuu/6h2BPzMN4SwmBX6bXKxUWITVDpNsN8/zOjBhQThrhmqlK9c/syCuKhdBPzPNWSgurYffJhejRtIeeSLtCwvCCz+jov3MijqaS5KlGn4ELmqoea7l+uyD7+7BPx1+OXB7kj+zpJpGijqaS5KlwJdSCAvOdgP10AuTge8btt1VmZNsGknqQtVJc5GLC5v6DeJT4EvhLbUswL6R8bYCNYtaq6vlHNIOwsGBXgx+/zhmZi92Zle6GNpclJc5LKI2fCmBsOB85OlX2m5r7mQOQtwZuC4uMpktI906cGmJWTV5msPiO9XwpfCWGmHT7v5RR1C5qHG6aBo597vzqS/6tnt4FDNvLjy3M29a6DF9mMNSFKrhS+GFBWTYOj1B+0cdQeWixhl1JE1Qbf4352YC900yCKOGr4sZ3EnOAvdJ6Wr46tjxT1jt/Pbragva8C9sHxzoDf2ctPtZcVHjjDqSJugiE6aTIGz3dyfqnYkvc1iKoFSBr44dPy0VnEEzRQFk0hwTVva4F5lWnQRhlN+dqOHrYoho3mdqFwXzvIZZf3+/1ev1tvffuOuJwF/CWncVT22/0WXRCkV3PQu5+Jy0BiTQCL0kJ2WFlbu7WsFbf/+SWD/fqOdEn6n8IjliZv1Br5Wqhq+OncV017NYFs0xLoTVrHfeuj72caOeE00gLKZSBX7eFyfLgu+P7guSRXOMC0leZPS744dSjdLJ+xK8WdBdz2JF/pwk9SyEIp8TaV+pavjq2FlMNbfF9DlZTOfED6UKfEBti62KPJwtyY5BfU7ER6ULfFmoqDU3dTany9X51uidfCvVsEwpDw2xTVdRh6pG5cMFaalhmU46bUneRHKU5GmS2wNeJ8n7mq8/S/L9Lo4rC8VdzMvVe7igzuZ0uTjfeV/gLLOF5nIkdpMOyS4A3wTwYQBjAJ4hecDMnp+3280A1jX/fADAt5p/S1OUmkfQvkD82aOd3NYnVWPyvbM57Zqoi/Od94u0hii7qeFvAHDazF40s98BeBTAlpZ9tgB4yBoOA+gmeYWDY+dC3Frx0NFxDH7/+IKax+D3jwe+T1gtZeeBk6kvQZtkjcnnYYJZ1ERdnO+8L3CW9wtSGlwEfg3AK/O+H2tui7oPAIDkNpJ1kvXJyeSeNuSKi1/Or/3w5IKHSQDAzKzhaz88uWjfsFCemo6/amLUX4hOLhBBF8ag7WGrVwLIRZNTkrJoGnHxvOW8X6TzfkFKg4tROkFr0Lb2BLezT2Oj2V4Ae4FGp228oiXPxW1i2BK3Qduj1kaiLkEb5bY+ygWik6dStYryBKuiCGq6cVUTjdosFHeoat5HhBV5iLIrLgJ/DMDqed9fCWCig30KKe3bxLBQfvtbKvjfmTdTXYI2ygViqadStT6oZHpmFjsPnMT/nX9zQbg/fPjlRbWEorTBRul3+YNqJfCOLcrFO6thrXme35D3C1IaXAT+MwDWkbwawDiAuwB8rGWfAwDuIfkoGp21Z83sjINjZ85FZ1d3yC94d7WyaFtYKH/1L9YDiL8Ebf2l1+ZCuIvE7deF/wJHuUBEfSpV0PkIu93LextsWPheWlkReBG8tLIC1UpXrIu3OiiD5fmClIbYgW9m50neA2AYQBeAB83sJMnPNF/fA+AggM0ATgM4B+BTcY+bFy5uE3feuh6D/3J8wWPjKiuInbeuX7TvcrWUOB/moaPj2DcyPhfCs2bYNzKO/qveEfi+UWpMYRfGLjI09NuV9zbYsPANe5jJ1LkZ/N1fvi/WxVsdlBLEyUxbMzuIRqjP37Zn3tcG4G4Xx8qbLB7ukFQtpZNaYbtlifpUqksrKwL7MIiFNf0itMF20u8S92fs+7BWCaalFRxwEcB5uNVMslYY96lUwMULxKEXJgvVBhsWvt3VyoJ+CsDdBUwdlBJEgS9zut9SCaxVd79lcV9CJ8Iuaktd7MrQwbbUg0uAZP6P6qCUIAp8mRPWlJ7Vckt5uOtxIcl+l+WOW4bzJ+4o8GXO2ZDJW2HbpX0KX8mDUj3xSuLRTESRclMNX+Z00tGX9+Vm814+kTQp8GVO1I6+vD+kJO/lE0mbAl8WiNLW7Go2Z1K1cM02FVlIgS8dczFuP8lauGabiiykTlvpmItO3iSXAnbVCZ2Xp4CJxKXAl465WP88aAbqUtujcFG+pB9GoouJpEmBLx1z8dCMLgY9KiF8e9rlS/IORM9YlbSpDV9iiTuhKGylzLgraF4Qt3xJ9gOoU1nSphq+ZKoW0p4etj1tSU5GU6eypE2BL6kJaq/O+3NQkyyfZjZL2hT4koqw9moAsdvZk+SiHyBM3i92Uj60rJZCbEN/f7/V6/WsiyEObNz1RODIm1p3FU9tvzGDEuWDln4Q10iOmFl/0GvqtJVUqL06mFbRXEwXweSoSUdSofZqaYeGqiYrVuCTfAfJx0n+Z/Pvt4fs998kT5A8RlJtNB5Se7W0I8l5DxK/hr8dwM/MbB2AnzW/D/NBM3tfWNuSlFuSnZ9SHmr6S1bcNvwtADY1v/5HAD8H8MWY7yklpfZqWU7YA9/V9OdG3Br+u8zsDAA0/35nyH4G4CckR0hui3lMESkpNf0la9kaPsmfArg84KUvRzjORjObIPlOAI+TfMHMngw53jYA2wBgzZo1EQ4hIkUX9SE8Ek2scfgkRwFsMrMzJK8A8HMzW/JSTHIngDfM7G+Xe3+NwxcRiWapcfhxm3QOAPhk8+tPAvhBwMHfSvKyC18D+DMAz8U8rsSkZXlF/BO303YXgO+R/DSAlwHcCQAkVwH4tpltBvAuAI+xsdztJQD+2cz+NeZxJQY961WTe8RPsQLfzF4F8KGA7RMANje/fhHAtXGOI275viyvLnjiK8209ZDvY501uUd8pcD3kO/LHPh+wRN/KfA9NDjQi8qKhY8QrKygN2Odfb/gib+0WmYALzr0Wh8ZG/8RsoUxONC7oA0f6GxyjxefEykVBX4LHzr0dg+PYmZ24fyLmVnzptM26uSeoGAHUPrPiUu6OOaDAr+FDyNY1Ibd/ro+YRWASysrSv85ccWHSlRRqA2/hQ9h2Ekbtq8TtcIqAL85NxO4f5k+J65oVFR+KPBb+NChF3WBKp8fShG0cuNSyvQ5ccWHSlRRKPBbFHm1vnZr4VHXpve5htbF4N5sEoX9nKTNh0pUUagNv0VRV+uL2k4aZW16n2tosyGLC5oB9952TeE+J1lwNSpK4lPgByjigzqS7Gz2+aEUtZD/e627WsjPSRaKWokqIwV+SSRZC/e5hubz/90lXRzzQYFfEknWwn2uofn8f5fyifUAlKTpASjta23DBxo1UT0ovPw0qUnmW+oBKKrhl4Rqon7SpCaJQoFfImon9Y8PM8PFHY3DFykwn4fMSnQKfJEC06QmiUKBL1JgRZ4ZLulTG75IgamzXqKIFfgk7wSwE8B7AGwws8AxlCRvAvAPALoAfNvMdsU5rohcpM56aVfcJp3nANwG4MmwHUh2AfgmgJsBvBfAR0m+N+ZxRUQkolg1fDM7BQAMWVGwaQOA02b2YnPfRwFsAfB8nGOLiEg0aXTa1gC8Mu/7sea2QCS3kayTrE9OTiZeOBERXyxbwyf5UwCXB7z0ZTP7QRvHCKr+h67nYGZ7AewFGksrtPH+IiLShmUD38z+NOYxxgCsnvf9lQAmYr6niIhElMawzGcArCN5NYBxAHcB+Fg7/3BkZOTXJF9yUIaVAH7t4H2KTufhIp2LBp2HhjKdh6vCXoi1WibJjwC4H0APgCkAx8xsgOQqNIZfbm7utxnA36MxLPNBM/t6xwftrJz1sNXjfKLzcJHORYPOQ4Mv5yHuKJ3HADwWsH0CwOZ53x8EcDDOsUREJB4trSAi4glfAn9v1gXICZ2Hi3QuGnQeGrw4D7l+4pWIiLjjSw1fRMR7CnwREU94E/gkd5N8geSzJB8j2Z11mbJA8k6SJ0m+SbL0w9BakbyJ5CjJ0yS3Z12erJB8kOSvSD6XdVmyRHI1yUMkTzV/Lz6XdZmS5E3gA3gcwB+b2Z8A+A8AOzIuT1aWXeG0rLRy6wLfBXBT1oXIgfMAvmBm7wFwPYC7y/yZ8CbwzewnZna++e1hNJZ48I6ZnTKz0azLkZG5lVvN7HcALqzc6h0zexLAa1mXI2tmdsbMjjS//i2AU1hiccei8ybwW/w1gB9nXQhJXaSVW8UvJNcC6APwdMZFSUypHnHYzsqeJL+Mxm3cw2mWLU0OVjgtq0grt4o/SL4NwD4Anzez17MuT1JKFfjLrexJ8pMAbgHwISvxBAQHK5yWlVZulUVIVtAI+4fNbH/W5UmSN006zefqfhHArWZ2LuvySCbmVm4l+XtorNx6IOMySYbYeFzfdwCcMrNvZF2epHkT+AAeAHAZgMdJHiO5J+sCZYHkR0iOAbgBwI9IDmddprQ0O+3vATCMRufc98zsZLalygbJRwD8O4BekmMkP511mTKyEcDHAdzYzIVjzdV9S0lLK4iIeMKnGr6IiNcU+CIinlDgi4h4QoEvIuIJBb6IiCcU+CIinlDgi4h44v8Bx3ga0zHi/bQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(regression_results_CS['sample_wise']['target_y'],regression_results_CS['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-thread",
   "metadata": {},
   "source": [
    "And really odd--why does it perform equally well for one class as for two? I thought two class analysis would be really nonsensical...which it is...considering the negative correlation for targets vs. pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fuzzy-devices",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 0 of 0 items due to null input values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19030/4091791375.py:32: RuntimeWarning: Mean of empty slice\n",
      "  if abs(np.nanmean(dataset.sa.targets)>0.001) and require_mean_centered:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m Brain_Data_CorrectGo \u001b[38;5;241m=\u001b[39m Brain_Data_allsubs[Brain_Data_allsubs\u001b[38;5;241m.\u001b[39msa\u001b[38;5;241m.\u001b[39mcondition_label\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrectGo\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m regression_results_CG \u001b[38;5;241m=\u001b[39m \u001b[43mdo_regression\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBrain_Data_CorrectGo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m pearsonr(regression_results_CG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget_y\u001b[39m\u001b[38;5;124m'\u001b[39m],regression_results_CG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample_wise\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_y\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mdo_regression\u001b[0;34m(dataset, normalization, get_prediction, verbose, require_mean_centered)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(np\u001b[38;5;241m.\u001b[39mnanmean(dataset\u001b[38;5;241m.\u001b[39msa\u001b[38;5;241m.\u001b[39mtargets)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.001\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m require_mean_centered:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtarget data is not mean-centred, but mean centering is required.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 35\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_index, test_index \u001b[38;5;129;01min\u001b[39;00m logo\u001b[38;5;241m.\u001b[39msplit(\n\u001b[1;32m     36\u001b[0m     dataset\u001b[38;5;241m.\u001b[39msamples, dataset\u001b[38;5;241m.\u001b[39msa\u001b[38;5;241m.\u001b[39mtargets, dataset\u001b[38;5;241m.\u001b[39msa\u001b[38;5;241m.\u001b[39mchunks):\n\u001b[1;32m     37\u001b[0m     iteration_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(dataset\u001b[38;5;241m.\u001b[39msa\u001b[38;5;241m.\u001b[39mchunks[test_index])[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m#print(iteration_label, \"; TRAIN:\", len(train_index), \" items; TEST:\", test_index)\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/model_selection/_split.py:86\u001b[0m, in \u001b[0;36mBaseCrossValidator.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m     84\u001b[0m X, y, groups \u001b[38;5;241m=\u001b[39m indexable(X, y, groups)\n\u001b[1;32m     85\u001b[0m indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(_num_samples(X))\n\u001b[0;32m---> 86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter_test_masks(X, y, groups):\n\u001b[1;32m     87\u001b[0m     train_index \u001b[38;5;241m=\u001b[39m indices[np\u001b[38;5;241m.\u001b[39mlogical_not(test_index)]\n\u001b[1;32m     88\u001b[0m     test_index \u001b[38;5;241m=\u001b[39m indices[test_index]\n",
      "File \u001b[0;32m~/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/model_selection/_split.py:1147\u001b[0m, in \u001b[0;36mLeaveOneGroupOut._iter_test_masks\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgroups\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m parameter should not be None.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;66;03m# We make a copy of groups to avoid side-effects during iteration\u001b[39;00m\n\u001b[0;32m-> 1147\u001b[0m groups \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m unique_groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(groups)\n\u001b[1;32m   1149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_groups) \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/py3_mvpa/lib/python3.8/site-packages/sklearn/utils/validation.py:805\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    803\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n\u001b[1;32m    804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_samples \u001b[38;5;241m<\u001b[39m ensure_min_samples:\n\u001b[0;32m--> 805\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    806\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m) while a\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    807\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    808\u001b[0m             \u001b[38;5;241m%\u001b[39m (n_samples, array\u001b[38;5;241m.\u001b[39mshape, ensure_min_samples, context)\n\u001b[1;32m    809\u001b[0m         )\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    812\u001b[0m     n_features \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "Brain_Data_CorrectGo = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGo']\n",
    "regression_results_CG = do_regression(Brain_Data_CorrectGo)\n",
    "pearsonr(regression_results_CG['sample_wise']['target_y'],regression_results_CG['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-bubble",
   "metadata": {},
   "source": [
    "## try lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "native-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broken-titanium",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results['sample_wise']['pred_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caroline-norway",
   "metadata": {},
   "source": [
    "Yes OK, because there's no variance ther ebecause we have both stop and go there."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-while",
   "metadata": {},
   "source": [
    "## stop minus go contrast"
   ]
  },
  {
   "cell_type": "raw",
   "id": "varied-anchor",
   "metadata": {},
   "source": [
    "from analyze_results import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polished-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_posterror_conditions_84subs_post_stop_cg_contrast.pkl'\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'TESQ_E_sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-revolution",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs,get_prediction = do_Ridge)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results['sample_wise']['pred_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-illustration",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results['sample_wise']['target_y']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "round-albany",
   "metadata": {},
   "source": [
    "## Trial dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "durable-regard",
   "metadata": {},
   "source": [
    "We select a linear mix of voxels and try to predict that. should be easy to do with regression..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpreted-payroll",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_posterror_conditions_84subs_post_stop_cg_contrast.pkl'\n",
    "#mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "religious-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15010],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precious-guess",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'mix_target')\n",
    "\n",
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Ridge)\n",
    "\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-hudson",
   "metadata": {},
   "source": [
    "That's interesting--something like it should be, but not very good considering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15100],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'mix_target')\n",
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Ridge)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-season",
   "metadata": {},
   "source": [
    "aahhh got it--if the pattern is spread over several voxels, we'll have a better time detecting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chief-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15100],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-anchor",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-blackberry",
   "metadata": {},
   "source": [
    "OK, so if there's a pattern representing a linear combination of voxels then we should be able to detect it using ridge regression. How about lasso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intensive-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latin-gibraltar",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-monthly",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso2(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=True)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-integrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso2)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparative-right",
   "metadata": {},
   "outputs": [],
   "source": [
    "mix_target = np.sum(Brain_Data_allsubs.samples[:,15000:15100],axis=1)\n",
    "Brain_Data_allsubs.sa['mix_target']=list(mix_target)\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'mix_target',standardize=False)\n",
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso2, require_mean_centered=False)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-celebrity",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso2)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-brooklyn",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)\n",
    "print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "equipped-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-director",
   "metadata": {},
   "source": [
    "So in summary--we can't predict TESQ-E-Sum using Ridge or Lasso regression. Because prediction is `greedy' in a sense--it'll take voxels anywhere in the image and emphasize them until they're useful--there's no point in trying different masks. We might try different scales, bu there's no use in doing a regression on masks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-timeline",
   "metadata": {},
   "source": [
    "#### Elastic net?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "velvet-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "def do_ElasticNet(train_X,train_y,test_X,test_y):\n",
    "    sklearn_regress = ElasticNet(alpha=10.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alive-raising",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "elastic_regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_ElasticNet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caring-heavy",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scatter(elastic_regression_results['sample_wise']['target_y'],elastic_regression_results['sample_wise']['pred_y'])\n",
    "pearsonr(elastic_regression_results['sample_wise']['target_y'],elastic_regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-commons",
   "metadata": {},
   "source": [
    "OK, of the three (Ridge, Elastic, Lasso), Lasso performs best on the dummy data, so we'll use that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "announced-gasoline",
   "metadata": {},
   "source": [
    "## PCA?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-marina",
   "metadata": {},
   "source": [
    "# Main analysis: Cycle through relevant variables...\n",
    "\n",
    "We'll cycle through:\n",
    "\n",
    " - TESQ-E subscales\n",
    " - BF%\n",
    " - SSRT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-whole",
   "metadata": {},
   "source": [
    "### Stop Minus Go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "athletic-insider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time_indices, time_coords, condition_index, condition_label, raw_beta_description, beta, subject, wave, cancer_promoting_minus_preventing_FCI, cancer_promoting_minus_preventing_FFQ, cancer_promoting_minus_preventing_craved_FCI, cancer_promoting_minus_preventing_craved_FFQ, cancer_promoting_minus_preventing_liked_FCI, cancer_promoting_minus_preventing_liked_FFQ, cancer_promoting_FCI, cancer_promoting_FFQ, cancer_preventing_FCI, cancer_preventing_FFQ, BSCS, cSES, EDM, BIS_11, PCS, RS, TRSQ, bf_1, weight_0, height_0, birthsex, age365, bmi_0, bmi_1, bmi, bf_1_controlled, bf_1_bsexnormedzs, ACES_sum, ACES_household_dysfunction, ACES_neglectful_parenting, ACES_abuse, ACES_divorced_separated, BFI_agreeableness, BFI_conscientiousness, BFI_extraversion, BFI_neuroticism, BFI_openness, DEMO_mcarthur_social_standing, IMI_effort_importance, IMI_interest_enjoyment, IMI_perceived_choice, IMI_perceived_competence, IMI_value_usefulness, IPAQ_moderateminutes, IPAQ_sittinghours, IPAQ_vigorousminutes, IPAQ_walkingminutes, NCS_get_job_done, NCS_deliberating_issues, NCS_prefer_complex, NCS_prefer_little_thought, NCS_intellectual_task, NCS_relief_not_satisfaction, NCS_like_responsibility, NCS_new_solutions_to_problems, NCS_avoid_depth, NCS_tasks_little_thought, NCS_think_minimally, NCS_satisfaction_in_deliberating, NCS_small_daily_projects, NCS_solve_puzzles, NCS_total, NCS_thinking_not_exciting, NCS_abstract_thinking, NCS_thought_appealing, NCS_thinking_not_fun, PLAN_cognitive_strategies, PLAN_temporal_orientation, PLAN_mental_forecasting, RMQ_assessment, RMQ_lie, RMQ_locomotion, RTFS_factor_1, RTFS_factor_2, SRHI_sum, SRHI_healthy, SRHI_unhealthy, TESQ_E_avoidance_of_temptations, TESQ_E_goal_deliberation, TESQ_E_distraction, TESQ_E_goal_and_rule_setting, TESQ_E_sum, TESQ_E_controlling_temptations, TESQ_E_suppression, education_own, zipcode_median_income_acs, household_income_level_medamount, household_income_per_person, ses_aggregate, SST_CorrectGo, SST_CorrectStop, SST_Cue, SST_FailedGo, SST_FailedStop, SST_prop_successful_stops, SST_reaction_time, SST_go_trial_reaction_time, SST_GRTint, SST_GRTmean, SST_GRTmedian, SST_GRTquant, SST_NRCount, SST_PctInhib, SST_SSD, SST_SSRT, SST_SSRTint, SST_SSRTquant, SST_pes_mean_limited, SST_PECG_mean, SST_PCCG_mean, SST_PostErrorSlowW1_mean, SST_PECG_median, SST_PCCG_median, SST_PostErrorSlowW1_median, ROC_Crave_Look, ROC_Crave_Regulate, ROC_Neutral_Look, ROC_No Crave_Look, ROC_Crave_Regulate_Minus_Look, ROC_Crave_Minus_Neutral, ROC_Crave_Minus_NoCrave, WTP_healthy, WTP_unhealthy, WTP_unhealthy_minus_healthy, SRHI_healthy_minus_unhealthy, RTFS_f1_minus_f2, IPAQ_walkingMETminutes, IPAQ_moderateMETminutes, IPAQ_vigorousMETminutes, IPAQ_total_METminutes, IPAQ_MET_kCal, birthsex_factor, FFQ_v2_Mean_Weighted_Nutrient_Density, FFQ_v2_Mean_Weighted_percent_daily_value, FFQ_v2_Mean_Dietary_Nutrient_Density, FFQ_v2_Mean_Energy_Density, FFQ_v2_Mean_Energy, chunks, targets'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\", \".join(sa_to_df(Brain_Data_allsubs.sa).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "simple-button",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eliminating 8 of 81 items due to null input values.\n",
      "........................................................................."
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-0.22230173762044284, 0.05871900289544976)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_posterror_conditions_84subs_post_stop_cg_contrast.pkl'\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n",
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,'FFQ_v2_Mean_Weighted_Nutrient_Density')\n",
    "\n",
    "regression_results = do_regression(Brain_Data_allsubs,do_Lasso)\n",
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "overall-variety",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_posterror_conditions_84subs_post_stop_cg_contrast.pkl'\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "characteristic-salem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FFQ_v2_Mean_Weighted_Nutrient_Density\n",
      "eliminating 8 of 81 items due to null input values.\n",
      ".........................................................................(-0.1432150784222959, 0.2267577179364377)\n",
      "---\n",
      "SST_pes_mean_limited\n",
      "eliminating 15 of 81 items due to null input values.\n",
      "..................................................................(-0.09079193424666142, 0.46844986440702807)\n",
      "---\n",
      "SST_PostErrorSlowW1_mean\n",
      "eliminating 16 of 81 items due to null input values.\n",
      ".................................................................(0.16705888041230982, 0.18348299519293643)\n",
      "---\n",
      "RTFS_factor_1\n",
      "eliminating 30 of 81 items due to null input values.\n",
      "...................................................(0.04786458620847692, 0.7387277441848147)\n",
      "---\n",
      "RTFS_factor_2\n",
      "eliminating 30 of 81 items due to null input values.\n",
      "...................................................(0.22507741662535566, 0.11229162427140402)\n",
      "---\n",
      "RTFS_f1_minus_f2\n",
      "eliminating 32 of 81 items due to null input values.\n",
      ".................................................(-0.20305515476652072, 0.16171733237562125)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "regression_results_dict = {}\n",
    "for regression_var in [\n",
    "    'FFQ_v2_Mean_Weighted_Nutrient_Density',\n",
    "    'SST_pes_mean_limited',\n",
    "    'SST_PostErrorSlowW1_mean',\n",
    "    'RTFS_factor_1',\n",
    "    'RTFS_factor_2','RTFS_f1_minus_f2'\n",
    "                      ]:\n",
    "    print(regression_var)\n",
    "    Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs,regression_var)\n",
    "    regression_results = do_regression(Brain_Data_allsubs, get_prediction = do_Lasso)\n",
    "    regression_results_dict[regression_var] = regression_results\n",
    "    print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-vitamin",
   "metadata": {},
   "source": [
    "No signficant results here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-credits",
   "metadata": {},
   "source": [
    "### two conditions separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "sudden-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_posterror_conditions_84subs_post_stop_cg.pkl'\n",
    "#mvpa_Dataset_conditions_84subs_cor_stop_minus_go_contrast\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "violent-defensive",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_CorrectGoFollowingCorrectStop = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGoFollowingCorrectStop']\n",
    "Brain_Data_CorrectGoFollowingFailedStop = Brain_Data_allsubs[Brain_Data_allsubs.sa.condition_label=='CorrectGoFollowingFailedStop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "deadly-exclusive",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_Ridge(train_X,train_y,test_X,test_y):\n",
    "    sklearn_regress = Ridge(alpha=2.0)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "mounted-thread",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=False)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "    predict_train_y = sklearn_regress.predict(train_X)\n",
    "    pearsonr(predict_train_y,)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "specific-insured",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "def do_Lasso2(train_X,train_y,test_X,test_y):\n",
    "    #if we fit intercept, it actually uses the y values to refit the items, \n",
    "    #adjusting everything up and down, and it can introduce _anticorrelation_ with the predicted value\n",
    "    #may need to mean-center the predicted variable _before_ analysis.\n",
    "    sklearn_regress = Lasso(alpha=1.0,fit_intercept=True)\n",
    "    \n",
    "    sklearn_regress.fit(train_X, train_y)\n",
    "    \n",
    "    predict_y = sklearn_regress.predict(test_X)\n",
    "#    print(predict_y,test_y)\n",
    "    return(predict_y,sklearn_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "handled-stocks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CorrectGoFollowingCorrectStop']\n",
      "FFQ_v2_Mean_Weighted_Nutrient_Density\n",
      "eliminating 8 of 81 items due to null input values.\n",
      ".........................................................................(-0.30011621879321265, 0.009888657989672912)\n",
      "---\n",
      "SST_pes_mean_limited\n",
      "eliminating 15 of 81 items due to null input values.\n",
      "..................................................................(nan, nan)\n",
      "---\n",
      "SST_PostErrorSlowW1_mean\n",
      "eliminating 16 of 81 items due to null input values.\n",
      "."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/scipy/stats/stats.py:3913: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................................................(0.05323298519018589, 0.6736459649612041)\n",
      "---\n",
      "RTFS_factor_1\n",
      "eliminating 30 of 81 items due to null input values.\n",
      "...................................................(-0.45607727688272515, 0.0007695946729048088)\n",
      "---\n",
      "RTFS_factor_2\n",
      "eliminating 30 of 81 items due to null input values.\n",
      "...................................................(0.2623669722447763, 0.06289194320407067)\n",
      "---\n",
      "RTFS_f1_minus_f2\n",
      "eliminating 32 of 81 items due to null input values.\n",
      ".................................................(-0.04979495235856285, 0.7340242673822558)\n",
      "---\n",
      "['CorrectGoFollowingFailedStop']\n",
      "FFQ_v2_Mean_Weighted_Nutrient_Density\n",
      "eliminating 8 of 81 items due to null input values.\n",
      ".........................................................................(-0.3480589314735139, 0.0025491622451461766)\n",
      "---\n",
      "SST_pes_mean_limited\n",
      "eliminating 15 of 81 items due to null input values.\n",
      "..................................................................(-0.1474417027913058, 0.23744164792708422)\n",
      "---\n",
      "SST_PostErrorSlowW1_mean\n",
      "eliminating 16 of 81 items due to null input values.\n",
      ".................................................................(-0.14351965439243608, 0.25405412711075775)\n",
      "---\n",
      "RTFS_factor_1\n",
      "eliminating 30 of 81 items due to null input values.\n",
      "...................................................(-0.25790743052522974, 0.06766752037478309)\n",
      "---\n",
      "RTFS_factor_2\n",
      "eliminating 30 of 81 items due to null input values.\n",
      "...................................................(0.09346311471593406, 0.5141797474766746)\n",
      "---\n",
      "RTFS_f1_minus_f2\n",
      "eliminating 32 of 81 items due to null input values.\n",
      ".................................................(-0.23567550913462623, 0.10306033862920526)\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for bd in [Brain_Data_CorrectGoFollowingCorrectStop, Brain_Data_CorrectGoFollowingFailedStop]:\n",
    "    print(np.unique(bd.sa.condition_label))\n",
    "    for regression_var in [\n",
    "    'FFQ_v2_Mean_Weighted_Nutrient_Density',\n",
    "    'SST_pes_mean_limited',\n",
    "    'SST_PostErrorSlowW1_mean',\n",
    "    'RTFS_factor_1',\n",
    "    'RTFS_factor_2',\n",
    "        'RTFS_f1_minus_f2'\n",
    "                          ]:\n",
    "        print(regression_var)\n",
    "        \n",
    "        bd = setup_metadata(bd,regression_var)\n",
    "        regression_results = do_regression(bd, get_prediction = do_Lasso)\n",
    "        regression_results_dict[regression_var] = regression_results\n",
    "        print(pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y']))\n",
    "        print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "color-uganda",
   "metadata": {},
   "source": [
    "Predictions passing the threshold of r>=0.25:\n",
    "    \n",
    " - RTFS_factor_2 * CorrectGoFollowingCorrectStop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "divine-professional",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.6252180395923476e-17"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression_results['sample_wise'].target_y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "challenging-radiation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([        nan,         nan,         nan,         nan,  2.01547744,\n",
       "               nan,         nan,         nan, -2.33438633,  0.77265922,\n",
       "               nan,         nan,  0.42467012,         nan,         nan,\n",
       "       -0.470159  ,         nan, -1.26556266,         nan,         nan,\n",
       "               nan,         nan,         nan,         nan,         nan,\n",
       "       -0.04760081,         nan,  0.82237195,         nan,         nan,\n",
       "       -0.84300447,         nan, -1.83725905,  1.59291924,  1.06070062,\n",
       "               nan, -0.53117008, -0.79329174, -1.21224756, -1.19099357,\n",
       "       -0.81814811,  1.09579195,  0.05182465, -0.24844555, -0.76843538,\n",
       "        0.37495739,  0.94665377,         nan,  0.27553193, -0.24645172,\n",
       "        0.16028878,         nan,  0.69809012, -2.02616742,  0.15125011,\n",
       "       -0.84300447,  0.79751558,  0.49923921,  0.59866467,         nan,\n",
       "       -0.59444083,         nan, -0.53407537,  0.25067556,  0.20096284,\n",
       "        0.82237195, -1.51412631,  0.69809012,  0.58091012, -0.12472431,\n",
       "        0.27814839,         nan, -1.16613721,         nan,  1.59291924,\n",
       "       -0.74357901,         nan,  0.67323376,  0.60258936,  2.11490289,\n",
       "               nan])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bd.sa.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "disciplinary-punch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2aaaf941bf10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import scatter\n",
    "scatter(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "selective-virtue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.23567550913462623, 0.10306033862920526)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonr(regression_results['sample_wise']['target_y'],regression_results['sample_wise']['pred_y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "lucky-observer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finishsed\n"
     ]
    }
   ],
   "source": [
    "print('finishsed')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ambient-thing",
   "metadata": {},
   "source": [
    "## Correct STop and Correct Go spatially concatenated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-terminal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3_mvpa]",
   "language": "python",
   "name": "conda-env-.conda-py3_mvpa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
