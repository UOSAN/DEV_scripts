{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-campbell",
   "metadata": {},
   "source": [
    "This notebook exists to explore the input and output for SST\n",
    "\n",
    "`multiconds.py` contains the following outputs:\n",
    "\n",
    " - create_masks\n",
    " - ONE OF the following two:\n",
    "     - write_bids_events, or\n",
    "     - the following two:\n",
    "         - write_betaseries\n",
    "         - write_conditions\n",
    "\n",
    "         \n",
    "Basically, if we pass `multiconds.py` a bids path, it'll output to the bids directory; otherwise it'll write betaseries and conditions.\n",
    "\n",
    "So I guess it has two modes and is designed to be run twice, once to generate events files to bids, and the other time to create betaseries and conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-terry",
   "metadata": {},
   "source": [
    "## bids data\n",
    "\n",
    "### write_bids_events\n",
    "\n",
    "e.g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "moral-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_tsv_file_path = '/gpfs/projects/sanlab/shared/DEV/bids_data/sub-DEV085/ses-wave1/func/sub-DEV085_ses-wave1_task-SST_acq-1_events.tsv'\n",
    "bids_json_file_path = '/gpfs/projects/sanlab/shared/DEV/bids_data/sub-DEV085/ses-wave1/func/sub-DEV085_ses-wave1_task-SST_acq-1_events.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "surrounded-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial-bridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.25834</td>\n",
       "      <td>failed-stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.25834</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.75834</td>\n",
       "      <td>2.00556</td>\n",
       "      <td>failed-go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.76390</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.51390</td>\n",
       "      <td>0.47261</td>\n",
       "      <td>correct-go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>412.82572</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>414.57572</td>\n",
       "      <td>0.54468</td>\n",
       "      <td>correct-go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>417.08682</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>417.83682</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>correct-stop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255</th>\n",
       "      <td>419.33682</td>\n",
       "      <td>1.25000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>256 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         onset  duration    trial_type\n",
       "0      0.00000   2.25834   failed-stop\n",
       "1      2.25834   0.50000           NaN\n",
       "2      2.75834   2.00556     failed-go\n",
       "3      4.76390   0.75000           NaN\n",
       "4      5.51390   0.47261    correct-go\n",
       "..         ...       ...           ...\n",
       "251  412.82572   1.75000           NaN\n",
       "252  414.57572   0.54468    correct-go\n",
       "253  417.08682   0.75000           NaN\n",
       "254  417.83682   1.50000  correct-stop\n",
       "255  419.33682   1.25000           NaN\n",
       "\n",
       "[256 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(bids_tsv_file_path,sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "complicated-cleanup",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_file_contents = pd.read_json(bids_json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accessible-capitol",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LongName</th>\n",
       "      <td>Onset</td>\n",
       "      <td>Duration</td>\n",
       "      <td>Categorization of a response inhibition task</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <td>Onset of the event measured from the beginning...</td>\n",
       "      <td>Duration of the event, measured from onset.</td>\n",
       "      <td>Education level, self-rated by participant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Units</th>\n",
       "      <td>s</td>\n",
       "      <td>s</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Levels</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>{'correct-go': 'Go trial, correct response', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         onset  \\\n",
       "LongName                                                 Onset   \n",
       "Description  Onset of the event measured from the beginning...   \n",
       "Units                                                        s   \n",
       "Levels                                                     NaN   \n",
       "\n",
       "                                                duration  \\\n",
       "LongName                                        Duration   \n",
       "Description  Duration of the event, measured from onset.   \n",
       "Units                                                  s   \n",
       "Levels                                               NaN   \n",
       "\n",
       "                                                    trial_type  \n",
       "LongName          Categorization of a response inhibition task  \n",
       "Description         Education level, self-rated by participant  \n",
       "Units                                                      NaN  \n",
       "Levels       {'correct-go': 'Go trial, correct response', '...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "careful-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'correct-go': 'Go trial, correct response',\n",
       " 'failed-go': 'Go trial, incorrect or no response',\n",
       " 'correct-stop': 'No-go or stop trial, correct response',\n",
       " 'failed-stop': 'No-go or stop trial, incorrect response',\n",
       " 'null': 'Null trial where cue stimulus is presented for duration'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_contents.loc['Levels','trial_type']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "voluntary-registration",
   "metadata": {},
   "source": [
    "Good, so this information in the bids folder contains data about the trials. So if we can use that to move around the output, we have exactly what we need. we just need to work out what exactly is in the betaseries files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-strategy",
   "metadata": {},
   "source": [
    "## nonbids data\n",
    "\n",
    "### write_betaseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "meaning-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiconds_sst_dir = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/fx/multiconds/SST/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "basic-recall",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions_output_filename = multiconds_sst_dir + 'conditions/DEV085_1_SST1.mat'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "blessed-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extended-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_085_conditions_mat = scipy.io.loadmat(\n",
    "    conditions_output_filename,\n",
    "    simplify_cells=True            \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alike-austria",
   "metadata": {},
   "source": [
    "Obviously a design file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "metric-coating",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'names', 'onsets', 'durations'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_085_conditions_mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "nominated-arkansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CorrectGo', 'CorrectStop', 'FailedStop', 'Cue', 'FailedGo'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_085_conditions_mat['names']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-prison",
   "metadata": {},
   "source": [
    "How do these look like compared to the betaseries files genreated for WTP?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dying-composite",
   "metadata": {},
   "source": [
    "#### The schema MAT file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "associate-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "spm_schema_filepath = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/fx/multiconds/SST/conditions/DEV004_1_SST1.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "integral-taiwan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'names', 'onsets', 'durations'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spm_schema = scipy.io.loadmat(spm_schema_filepath)\n",
    "spm_schema.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "thousand-uniform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__header__:\n",
      "__version__:\n",
      "__globals__:\n",
      "names:\n",
      "onsets:\n",
      "durations:\n"
     ]
    }
   ],
   "source": [
    "for key in spm_schema.keys():\n",
    "    print(key + \":\")\n",
    "    #print(spm_schema[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-weekly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opened-somewhere",
   "metadata": {},
   "source": [
    "### take a look at the output mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "large-perfume",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_mat = '/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/fx/models/SST/wave1/conditions/sub-DEV005/SPM.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stylish-monaco",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daily-water",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "headed-suggestion",
   "metadata": {},
   "source": [
    "So this MAT file lists the onsets and durations of items by their class...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fewer-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_005_mat = scipy.io.loadmat(\n",
    "    output_mat,\n",
    "    simplify_cells=True            \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "victorian-stationery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'SPM'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_005_mat.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "positive-showcase",
   "metadata": {},
   "source": [
    "all the pertinent data is in Vbeta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "enormous-board",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fname', 'dim', 'dt', 'mat', 'pinfo', 'descrip', 'n', 'private'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_005_mat['SPM']['Vbeta'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "continent-index",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spm_spm:beta (0001) - Sn(1) CorrectGo*bf(1)\n",
      "spm_spm:beta (0002) - Sn(1) CorrectStop*bf(1)\n",
      "spm_spm:beta (0003) - Sn(1) FailedStop*bf(1)\n",
      "spm_spm:beta (0004) - Sn(1) Cue*bf(1)\n",
      "spm_spm:beta (0005) - Sn(1) FailedGo*bf(1)\n",
      "spm_spm:beta (0006) - Sn(1) R1\n",
      "spm_spm:beta (0007) - Sn(1) R2\n",
      "spm_spm:beta (0008) - Sn(1) R3\n",
      "spm_spm:beta (0009) - Sn(1) R4\n",
      "spm_spm:beta (0010) - Sn(1) R5\n",
      "spm_spm:beta (0011) - Sn(1) constant\n"
     ]
    }
   ],
   "source": [
    "for beta in dev_005_mat['SPM']['Vbeta']:\n",
    "    print(beta['descrip'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adult-harmony",
   "metadata": {},
   "source": [
    "OK, so where do we generate the SPM inputs?\n",
    "\n",
    "The general info flow for DEV is in: https://docs.google.com/presentation/d/1K-nFrZYE6rR8t0myNyacB7frBzV3B1--nMqPhVkwL8E/edit#slide=id.p\n",
    "\n",
    "\n",
    "For WTP, betaseries.m generates mat files that then "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invisible-validation",
   "metadata": {},
   "source": [
    "### Load beta design from the dir\n",
    "\n",
    "This operates a bit differently from previously. We'll simply pull out "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "harmful-pleasure",
   "metadata": {},
   "source": [
    "## Bids data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "impaired-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "paperback-sympathy",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dense-harbor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV033: wave1, wave5, wave4, wave3, wave2, ; DEV079: wave1, wave4, wave3, wave2, ; DEV017: wave1, wave3, wave2, ; DEV207: wave1, wave3, wave2, ; DEV131: wave1, ; DEV122: wave1, wave5, wave3, wave2, ; DEV115: wave1, wave5, wave4, wave3, wave2, ; DEV138: wave1, wave5, wave3, wave2, ; DEV054: wave1, wave5, wave4, wave3, wave2, ; DEV194: wave1, wave3, wave2, ; DEV147: wave1, wave5, wave3, wave2, ; DEV047: wave1, wave4, wave3, wave2, ; DEV220: wave1, ; DEV215: wave1, wave2, ; DEV224: wave1, ; DEV111: wave1, ; DEV014: wave1, wave5, wave4, wave3, wave2, ; DEV083: wave1, wave4, wave3, wave2, ; DEV190: wave1, wave4, wave3, wave2, ; DEV161: wave1, wave5, wave2, ; DEV151: wave1, wave5, wave3, wave2, ; DEV026: wave1, wave5, wave4, wave3, wave2, ; DEV225: wave1, ; DEV044: wave1, wave2, ; DEV200: wave1, wave3, wave2, ; DEV132: wave1, wave5, wave3, wave2, ; DEV143: wave1, wave3, wave2, ; DEV005: wave1, wave3, wave2, ; DEV095: wave1, ; DEV085: wave1, wave2, ; DEV195: wave1, wave4, wave3, wave2, ; DEV182: wave1, wave4, wave3, wave2, ; DEV112: wave1, wave4, wave3, wave2, ; DEV223: wave1, ; DEV128: wave1, wave5, wave3, wave2, ; DEV025: wave1, wave5, wave4, wave3, wave2, ; DEV029: wave1, wave2, ; DEV082: wave1, ; DEV064: wave1, wave3, wave2, ; DEV042: wave1, wave5, wave4, wave3, wave2, ; DEV117: wave1, wave3, wave2, ; DEV196: wave1, wave3, wave2, ; DEV169: wave1, ; DEV159: wave1, wave5, wave2, ; DEV217: wave1, ; DEV154: wave1, wave3, wave2, ; DEV180: wave1, wave4, wave3, wave2, ; DEV108: wave1, wave4, wave3, wave2, ; DEV119: wave1, wave5, wave3, wave2, ; DEV222: wave1, ; DEV171: wave1, ; DEV193: wave1, wave3, wave2, ; DEV120: wave1, wave5, wave3, wave2, ; DEV076: wave1, wave4, wave3, wave2, ; DEV105: wave1, ; DEV208: wave1, wave3, wave2, ; DEV019: wave1, wave5, wave4, wave3, wave2, ; DEV140: wave1, wave3, wave2, ; DEV068: wave1, wave5, wave4, wave3, wave2, ; DEV008: wave1, wave2, ; DEV043: wave1, wave5, wave4, wave3, wave2, ; DEV107: wave1, wave4, wave3, wave2, ; DEV221: wave1, ; DEV170: wave1, ; DEV177: wave1, wave4, wave3, wave2, ; DEV114: wave1, wave4, wave3, wave2, ; DEV203: wave1, wave2, ; DEV038: wave1, wave5, wave4, wave3, wave2, ; DEV090: wave1, wave4, wave3, wave2, ; DEV028: wave1, wave5, wave4, wave3, wave2, ; DEV133: wave1, wave5, wave4, wave3, wave2, ; DEV060: wave1, wave5, wave4, wave3, wave2, ; DEV067: wave1, wave5, wave4, wave3, wave2, ; DEV197: wave1, wave3, wave2, ; DEV075: wave1, wave4, wave3, wave2, ; DEV185: wave1, wave4, wave3, wave2, ; DEV219: wave1, ; DEV091: wave1, wave4, wave3, wave2, ; DEV059: wave1, wave5, wave4, wave3, wave2, ; DEV110: wave1, wave4, wave3, wave2, ; DEV061: wave1, wave5, wave4, wave3, wave2, ; DEV191: wave1, wave3, wave2, ; DEV099: wave1, wave4, wave3, wave2, ; DEV037: wave1, ; DEV012: wave1, wave5, wave4, wave3, wave2, ; DEV130: wave1, wave5, wave4, wave3, wave2, ; DEV027: wave1, wave5, wave4, wave3, wave2, ; DEV056: wave1, wave5, wave4, wave3, wave2, ; DEV098: wave1, wave5, wave3, wave2, ; DEV088: wave1, wave4, wave3, wave2, ; DEV149: wave1, wave5, wave3, wave2, ; DEV022: wave1, ; DEV102: wave1, wave2, ; DEV016: wave1, wave5, wave4, wave3, wave2, ; DEV070: wave1, wave5, wave4, wave3, wave2, ; DEV166: wave1, ; DEV178: wave1, wave4, wave3, wave2, ; DEV046: wave1, wave5, wave4, wave3, wave2, ; DEV187: wave1, wave4, wave3, wave2, ; DEV055: wave1, wave4, wave3, wave2, ; DEV097: wave1, wave4, wave3, wave2, ; DEV125: wave1, wave4, wave3, wave2, ; DEV080: wave1, ; DEV087: wave1, wave4, wave3, wave2, ; DEV063: wave1, wave5, wave4, wave3, wave2, ; DEV052: wave1, wave5, wave4, wave3, wave2, ; DEV181: wave1, wave4, wave3, wave2, ; DEV152: wave1, ; DEV071: wave1, wave4, wave3, wave2, ; DEV174: wave1, ; DEV081: wave1, wave4, wave3, wave2, ; DEV040: wave1, wave5, wave4, wave3, wave2, ; DEV126: wave1, wave4, wave3, wave2, ; DEV139: wave1, wave5, wave4, wave3, wave2, ; DEV015: wave1, wave5, wave4, wave3, wave2, ; DEV066: wave1, wave5, wave4, wave3, wave2, ; DEV163: wave1, wave2, ; DEV089: wave1, wave4, wave3, wave2, ; DEV045: wave1, ; DEV218: wave1, wave2, ; DEV039: wave1, wave4, wave3, wave2, ; DEV127: wave1, wave4, wave3, wave2, ; DEV011: wave1, wave5, wave4, wave3, wave2, ; DEV141: wave1, wave5, wave3, wave2, ; DEV041: wave1, wave5, wave4, wave3, wave2, ; DEV134: wave1, wave5, wave3, wave2, ; DEV188: wave1, wave2, ; DEV049: wave1, wave5, wave4, wave3, wave2, ; DEV007: wave1, ; DEV065: wave1, wave5, wave4, wave3, wave2, ; DEV073: wave1, wave4, wave3, wave2, ; DEV123: wave1, ; DEV168: wave1, ; DEV158: wave1, wave5, wave2, ; DEV192: wave1, wave3, wave2, ; DEV004: wave1, wave5, wave4, wave3, wave2, ; DEV211: wave1, wave2, ; DEV032: wave1, ; DEV153: wave1, wave5, wave3, wave2, ; DEV135: wave1, wave5, wave3, wave2, ; DEV094: wave1, wave4, wave3, wave2, ; DEV093: wave1, wave4, wave3, wave2, ; DEV164: wave1, wave5, wave4, wave2, ; DEV084: wave1, wave4, wave3, wave2, ; DEV124: wave1, wave5, wave4, wave3, wave2, ; DEV176: wave1, ; DEV021: wave1, wave5, wave4, wave3, wave2, ; DEV009: wave1, wave5, wave4, wave3, wave2, ; DEV034: wave1, ; DEV024: wave1, wave5, wave4, wave3, wave2, ; DEV144: wave1, wave2, ; DEV183: wave1, wave4, wave3, wave2, ; DEV078: wave1, wave3, wave2, ; DEV118: wave1, wave4, wave3, wave2, ; DEV074: wave1, wave4, wave3, wave2, ; DEV062: wave1, wave4, wave3, wave2, ; DEV150: wave1, wave2, ; DEV101: wave1, wave4, wave3, wave2, ; DEV106: wave1, ; DEV173: wave1, ; DEV050: wave1, wave5, wave4, wave3, wave2, ; DEV156: wave1, wave5, wave2, ; DEV036: wave1, wave5, wave4, wave3, wave2, ; DEV155: wave1, wave5, wave3, wave2, ; DEV031: wave1, wave5, wave4, wave3, wave2, ; DEV206: wave1, wave3, wave2, ; DEV209: wave1, wave2, ; DEV077: wave1, wave4, wave3, wave2, ; DEV051: wave1, wave5, wave4, wave3, wave2, ; DEV113: wave1, wave4, wave3, wave2, ; DEV100: wave1, wave4, wave3, wave2, ; DEV172: wave1, ; DEV121: wave1, wave3, wave2, ; DEV072: wave1, wave4, wave3, wave2, ; DEV205: wave1, wave3, wave2, ; DEV013: wave1, wave5, wave4, wave3, wave2, ; DEV023: wave1, wave5, wave4, wave3, wave2, ; DEV001: wave1, wave2, ; DEV058: wave1, wave5, wave4, wave3, wave2, ; DEV035: wave1, wave5, wave3, wave2, ; DEV020: wave1, wave5, wave4, wave3, wave2, ; DEV069: wave1, wave5, wave4, wave3, wave2, ; DEV137: wave1, wave5, wave3, wave2, ; DEV189: wave1, wave2, ; DEV096: wave1, wave3, wave2, ; DEV129: wave1, wave5, wave3, wave2, ; DEV086: wave1, wave4, wave3, wave2, ; DEV198: wave1, wave3, wave2, ; DEV018: wave1, wave4, wave3, wave2, ; DEV202: wave1, ; DEV145: wave1, wave5, wave3, wave2, ; DEV048: wave1, wave5, wave4, wave3, wave2, ; DEV057: wave1, wave5, wave4, wave3, wave2, ; DEV109: wave1, wave5, wave3, wave2, ; DEV053: wave1, wave5, wave4, wave3, wave2, ; DEV103: wave1, wave4, wave3, wave2, ; DEV010: wave1, wave5, wave4, wave3, wave2, ; DEV186: wave1, wave3, wave2, ; DEV199: wave1, wave2, ; DEV167: wave1, wave5, wave4, wave2, ; DEV201: wave1, wave2, ; DEV104: wave1, wave4, wave3, wave2, ; DEV157: wave1, wave5, wave2, ; DEV030: wave1, wave5, wave4, wave3, wave2, ; DEV204: wave1, wave2, ; DEV006: wave1, ; DEV216: wave1, ; DEV179: wave1, wave4, wave3, wave2, ; DEV116: wave1, wave3, wave2, ; "
     ]
    }
   ],
   "source": [
    "bids_data_folder_path = '/gpfs/projects/sanlab/shared/DEV/bids_data/'\n",
    "subject_folder_pattern = 'sub-DEV*'\n",
    "\n",
    "\n",
    "# get subjects in the folder path\n",
    "dataframe_list = []\n",
    "subject_folderpaths = glob.glob(bids_data_folder_path + subject_folder_pattern)\n",
    "for subj_folderpath in subject_folderpaths:\n",
    "    wave_folder_pattern = \"ses-wave*\"\n",
    "    #loop through waves\n",
    "    subj_wave_folderpaths = glob.glob(subj_folderpath + \"/\" + wave_folder_pattern) \n",
    "    #get the subject ID\n",
    "\n",
    "    subj_id = re.search('sub-(DEV\\d\\d\\d)',subj_folderpath).group(1)\n",
    "    print(subj_id,end=\": \")\n",
    "    \n",
    "    for wave_folderpath in subj_wave_folderpaths:\n",
    "        #print(wave_folderpath)\n",
    "        #get the wave ID\n",
    "        wave_name = re.search('ses-(wave\\d+)',wave_folderpath).group(1)\n",
    "        print(wave_name, end= \", \")\n",
    "        \n",
    "        tsv_name_pattern = 'func/sub-' + subj_id + '_ses-' + wave_name + '_task-SST_acq-*_events.tsv'\n",
    "        #I think we need to ensure there aren't more than one acquisition for each SSt\n",
    "        #that would indicate improper data processing in earlier steps\n",
    "\n",
    "        acquisition_filepath_list = glob.glob(wave_folderpath + \"/\" + tsv_name_pattern)\n",
    "        if(len(acquisition_filepath_list)==0):\n",
    "            #no acquisition for this wave; pass on this wave\n",
    "            #this will happen often. no need to do anything about it.\n",
    "            next\n",
    "        elif (len(acquisition_filepath_list)>1):\n",
    "            raise Exception(\"more than one acquisition for subject \" + subjid + \" wave \" + wave_name + \".\" +\n",
    "                            \"We only expect ONE SST for wave 1 and wave 2 and none for further waves.\" +\n",
    "                            \"Further waves contain SST but should not contain fMRI records of such.\"\n",
    "                           )\n",
    "        else: #len(acquisition_filepath_list)==1\n",
    "            #get the file\n",
    "            acquisition_filepath = acquisition_filepath_list[0]\n",
    "            tsv_filesize = os.path.getsize(acquisition_filepath)\n",
    "            if (tsv_filesize==0):\n",
    "                warning_message = (\"Filesize was zero for subject \" + subj_id + \" wave \" + wave_name + \".\" +\n",
    "                              \" This indicates a problem with the SST behaivoral data. Unclear whether the data was not properly recorded originally \" +\n",
    "                              \"or whether there was a problem in processing. Could have been processing problem in fx/multiconds/.../multiconds.py. \" +\n",
    "                              \"For now, skipping this wave and continuing, but it's important to investigate further.\")\n",
    "                print(\"\\n\" + warning_message+ \"\\n\")\n",
    "                #raise Warning()\n",
    "                break\n",
    "            sst_acquisition_record = pd.read_csv(acquisition_filepath,sep='\\t')\n",
    "            sst_acquisition_record['subject'] = subj_id\n",
    "            sst_acquisition_record['wave'] = wave_name\n",
    "            #add it to the list\n",
    "            dataframe_list = dataframe_list + [sst_acquisition_record]\n",
    "            #print(sst_acquisition_record)\n",
    "    print(\";\", end=\" \")\n",
    "    #break\n",
    "\n",
    "    \n",
    "all_sst_events = pd.concat(dataframe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "russian-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sst_events.to_csv(ml_data_folderpath + \"/SST/\"+\"all_sst_events.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "established-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(bids_tsv_file_path,sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
