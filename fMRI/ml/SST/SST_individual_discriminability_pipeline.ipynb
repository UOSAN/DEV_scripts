{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "referenced-ability",
   "metadata": {},
   "source": [
    "# SST Individual Discriminability\n",
    "\n",
    "This notebook measures discriminability of conditions for each subject, within runs.\n",
    "\n",
    "It then takes the average discriminability across any multiple runs (I don't think we have them though).\n",
    "\n",
    "Then we can compare discriminability against other subject-level variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handy-parade",
   "metadata": {},
   "source": [
    "Something similar was previously been done in `rsa_within_subj.ipynb`; it took similarity between matrices representing the averages of GNG and compared them intra-class similarity.\n",
    "\n",
    "That file doesn't take the next step of trying to see how that similarity score might measure up against across-subject variables; it seems, because I did not find good evidence that intrasimilarity was actually higher than interclass similarity.\n",
    "\n",
    "Conclusions:\n",
    "\n",
    " - maybe I should have tried discriminability, not just similarity\n",
    " - If we're interested in discriminability, then running an ML algorithm should be superior?\n",
    " - But don't rule out going back to similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "explicit-worker",
   "metadata": {},
   "source": [
    "## TESQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "circular-timing",
   "metadata": {},
   "source": [
    "### Machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "personal-nevada",
   "metadata": {},
   "source": [
    "First set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "compound-sense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from IPython.core.display import display, HTML, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "recreational-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "computational-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from random import randint\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "historical-problem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "\n",
    "from apply_loocv_and_save import *\n",
    "from dev_wtp_io_utils import *\n",
    "import gc\n",
    "import nibabel as nib\n",
    "\n",
    "from os import path\n",
    "\n",
    "\n",
    "\n",
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\"\n",
    "train_test_markers_filepath = ml_data_folderpath + \"/train_test_markers_20210601T183243.csv\"\n",
    "test_train_df = pd.read_csv(train_test_markers_filepath)\n",
    "\n",
    "all_sst_events= pd.read_csv(ml_data_folderpath +\"/SST/\" + \"all_sst_events.csv\")\n",
    "\n",
    "\n",
    "dataset_name = 'conditions'\n",
    "\n",
    "from nilearn.decoding import DecoderRegressor, Decoder\n",
    "\n",
    "script_path = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml'\n",
    "# HRF 2s\n",
    "\n",
    "#get a PFC mask\n",
    "#pfc_mask = create_mask_from_images(get_pfc_image_filepaths(ml_data_folderpath + \"/\"),threshold=10)\n",
    "\n",
    "\n",
    "def trialtype_resp_trans_func(X):\n",
    "    return(X.trial_type)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "amazing-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_name = 'conditions'\n",
    "\n",
    "\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_40subs_correct_cond.pkl'\n",
    "#brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_conditions_43subs_correct_cond.pkl'\n",
    "\n",
    "def decoderConstructor(*args, **kwargs):\n",
    "    return(Decoder(scoring='accuracy',verbose=0, *args, **kwargs))\n",
    "\n",
    "\n",
    "relevant_mask = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sacred-monroe",
   "metadata": {},
   "source": [
    " `load_and_preprocess` has problems but I\"m going to continue using it because I'm having problems with the standardization in the nilearn package. So there's not much point in deviating. We can also use the slicer in load_and_preprocess, if we get teh subject list first.\n",
    " \n",
    "To get the subject list, we'll load the data once, get the list, and then load each subject individually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "variable-theater",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "clean: 16\n",
      "subjs_to_use: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "all_subjects['groups']\n",
    "\n",
    "subj_list = np.unique(all_subjects['groups'])\n",
    "\n",
    "del all_subjects\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-yorkshire",
   "metadata": {},
   "source": [
    "This takes too long. For that reason, even though there are accuracy challenges, I'd like to proceed with a short-cut--we do 10-fold cross validation using the LeaveOneGroupOut feature, and ensure that Go and NoGo values are as evenly distributed across the groups as possible.\n",
    "\n",
    "But we'll leave the capacity to do full LeaveOneOut in there because it's probably good to go back to in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-fairy",
   "metadata": {},
   "source": [
    "First to test the technical process, let's try doing just three manually-generated groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-submission",
   "metadata": {},
   "source": [
    "OK, so this isn't very good for actually closely understanding what is being classified as what; we're not getting predictions for the scores under the hood. But we can take a look at the overall predictive accuracy on a non-held-out set. Note that we can't use this for asssessing model fit (to do that we better take the average of the prediction accuracies for the folds, or run an independent test-train analysis) but we can use this to understand things like class bias or look at the image being predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stable-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_discriminability(sample_subject):\n",
    "    min_splits = 2\n",
    "    # iterate through each subject; for each subject:\n",
    "    display(\"loading subject \" + sample_subject)\n",
    "\n",
    "    subj_i_processed_data = load_and_preprocess(\n",
    "        brain_data_filepath,\n",
    "        train_test_markers_filepath,\n",
    "        subjs_to_use = [sample_subject],\n",
    "        response_transform_func = trialtype_resp_trans_func,\n",
    "        clean=\"standardize\")\n",
    "    \n",
    "    display(subj_i_processed_data['y'].value_counts())\n",
    "    \n",
    "    display(\"setting up decoder...\")\n",
    "    #we use stratified Kfold\n",
    "    correct_stop_count =np.sum(subj_i_processed_data['y']=='correct-stop')\n",
    "    \n",
    "    if correct_stop_count< min_splits:\n",
    "        return(None)\n",
    "        #could do one split per correct-stop\n",
    "        #because there are generally very few of them\n",
    "    skf = StratifiedKFold(n_splits = 3,random_state= randint(0,math.pow(2,32)),\n",
    "                          shuffle=True)\n",
    "        #for testing for now we'll use 3\n",
    "        \n",
    "    #do this separately for each outcome group\n",
    "    decoder = Decoder(standardize=True, \n",
    "                      cv = skf, #mask = mask,\n",
    "                      n_jobs = cpus_to_use,#verbose=10,\n",
    "                      scoring='accuracy'\n",
    "                     )\n",
    "\n",
    "    display(\"fitting\")\n",
    "    #get overfit individual predictions--only way we can assess individual predictions\n",
    "    decoder_result = decoder.fit(X=subj_i_processed_data['X'],y=subj_i_processed_data['y'])\n",
    "    \n",
    "    display(\"evaluating\")\n",
    "    \n",
    "    predictions = decoder.predict(subj_i_processed_data['X'])\n",
    "    y_pred_vs_obs = pd.DataFrame({'y_obs':subj_i_processed_data['y'],'y_pred':predictions})\n",
    "    overfit_accuracy = np.sum(y_pred_vs_obs['y_obs']==y_pred_vs_obs['y_pred'])/len(y_pred_vs_obs['y_obs'])\n",
    "    \n",
    "    #get mean_cv_scores - cross-validated scores but I'm not sure what they mean becuase the package is vague\n",
    "    mean_cv_scores = np.mean([np.mean(c_scores) for c_name, c_scores in decoder.cv_scores_.items()])\n",
    "    \n",
    "    #alternative to this is to do our own cv stuff\n",
    "    subj_discrim_results = {\n",
    "        'mean_cv_scores':mean_cv_scores,\n",
    "        'overfit_accuracy':overfit_accuracy,\n",
    "        'overfit_y_pred_vs_obs': y_pred_vs_obs,\n",
    "        'decoder_object' : decoder\n",
    "    }\n",
    "    display(subj_discrim_results)\n",
    "\n",
    "\n",
    "    return(subj_discrim_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thermal-repeat",
   "metadata": {},
   "source": [
    "Not sure it actually matters to overfit here? We're interested in discriminability not to see if we really can discriminate above chance, but as an individual difference; to see if relative discriminability relates to other things we care about.\n",
    "\n",
    "In that sense, we probably don't have to worry about overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "innocent-handbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_function_with_cache(function_to_run,function_path):\n",
    "#     if path.exists(function_path) is False:\n",
    "#         results = function_to_run()\n",
    "#     else:\n",
    "#         results=pickle.load(open(function_path,'rb'))\n",
    "        \n",
    "#     return(results)\n",
    "    \n",
    "def get_subject_discriminability_with_cache(sample_subject,run_desc):\n",
    "    results_filepath = ml_data_folderpath + \"/SST/discriminability_tt_results_\" + run_desc + \"_\" + sample_subject + \".pkl\"\n",
    "    if path.exists(results_filepath) is False:\n",
    "        subj_discrim_results = get_subject_discriminability(sample_subject)\n",
    "        with open(results_filepath, 'wb') as handle:\n",
    "            pickle.dump(subj_discrim_results,handle)\n",
    "    else:\n",
    "        subj_discrim_results=pickle.load(open(results_filepath,'rb'))\n",
    "        \n",
    "    \n",
    "    return(subj_discrim_results)\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "experimental-ballot",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subjs_discriminability_whole_brain():\n",
    "    results_dict = {}\n",
    "\n",
    "    for sample_subject in subj_list:\n",
    "        run_desc = 'v1_whole_brain'\n",
    "        results_dict[sample_subject] = get_subject_discriminability_with_cache(sample_subject,run_desc)\n",
    "        \n",
    "    summary_results = pd.concat([pd.DataFrame({\n",
    "        'subid':k,\n",
    "        'overfit_accuracy':[v['overfit_accuracy']],\n",
    "        'mean_cv_scores':[v['mean_cv_scores']]}) \n",
    "\n",
    "                                 for k,v in results_dict.items()])\n",
    "    \n",
    "    return(summary_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'loading subject DEV005'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "subjs_to_use: 64\n",
      "clean: 60\n",
      "Brain_Data_allsubs: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correct-go      80\n",
       "correct-stop     5\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'setting up decoder...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fitting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'evaluating'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_cv_scores': 0.35303776683087024,\n",
       " 'overfit_accuracy': 0.6352941176470588,\n",
       " 'overfit_y_pred_vs_obs':            y_obs        y_pred\n",
       " 0   correct-stop  correct-stop\n",
       " 1     correct-go  correct-stop\n",
       " 2     correct-go    correct-go\n",
       " 3     correct-go    correct-go\n",
       " 4     correct-go    correct-go\n",
       " ..           ...           ...\n",
       " 80    correct-go    correct-go\n",
       " 81    correct-go    correct-go\n",
       " 82    correct-go    correct-go\n",
       " 83    correct-go  correct-stop\n",
       " 84    correct-go  correct-stop\n",
       " \n",
       " [85 rows x 2 columns],\n",
       " 'decoder_object': Decoder(cv=StratifiedKFold(n_splits=3, random_state=2984842438, shuffle=True),\n",
       "         estimator=LinearSVC(max_iter=10000.0), memory=Memory(location=None),\n",
       "         n_jobs=3, scoring='accuracy')}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loading subject DEV006'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "subjs_to_use: 64\n",
      "clean: 60\n",
      "Brain_Data_allsubs: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correct-go      92\n",
       "correct-stop    18\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'setting up decoder...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fitting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'evaluating'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_cv_scores': 0.4364364364364364,\n",
       " 'overfit_accuracy': 0.7272727272727273,\n",
       " 'overfit_y_pred_vs_obs':             y_obs        y_pred\n",
       " 85     correct-go  correct-stop\n",
       " 86     correct-go    correct-go\n",
       " 87     correct-go    correct-go\n",
       " 88     correct-go    correct-go\n",
       " 89     correct-go    correct-go\n",
       " ..            ...           ...\n",
       " 190    correct-go    correct-go\n",
       " 191  correct-stop  correct-stop\n",
       " 192    correct-go    correct-go\n",
       " 193  correct-stop  correct-stop\n",
       " 194    correct-go    correct-go\n",
       " \n",
       " [110 rows x 2 columns],\n",
       " 'decoder_object': Decoder(cv=StratifiedKFold(n_splits=3, random_state=1486360763, shuffle=True),\n",
       "         estimator=LinearSVC(max_iter=10000.0), memory=Memory(location=None),\n",
       "         n_jobs=3, scoring='accuracy')}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loading subject DEV009'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "subjs_to_use: 64\n",
      "clean: 60\n",
      "Brain_Data_allsubs: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correct-go    96\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'setting up decoder...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loading subject DEV010'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "subjs_to_use: 64\n",
      "clean: 60\n",
      "Brain_Data_allsubs: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correct-go      94\n",
       "correct-stop    13\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'setting up decoder...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fitting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'evaluating'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_cv_scores': 0.3457671957671957,\n",
       " 'overfit_accuracy': 0.7009345794392523,\n",
       " 'overfit_y_pred_vs_obs':             y_obs        y_pred\n",
       " 291  correct-stop  correct-stop\n",
       " 292    correct-go    correct-go\n",
       " 293    correct-go    correct-go\n",
       " 294    correct-go  correct-stop\n",
       " 295    correct-go  correct-stop\n",
       " ..            ...           ...\n",
       " 393    correct-go    correct-go\n",
       " 394    correct-go    correct-go\n",
       " 395    correct-go    correct-go\n",
       " 396    correct-go    correct-go\n",
       " 397    correct-go  correct-stop\n",
       " \n",
       " [107 rows x 2 columns],\n",
       " 'decoder_object': Decoder(cv=StratifiedKFold(n_splits=3, random_state=3050342173, shuffle=True),\n",
       "         estimator=LinearSVC(max_iter=10000.0), memory=Memory(location=None),\n",
       "         n_jobs=3, scoring='accuracy')}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loading subject DEV012'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "subjs_to_use: 64\n",
      "clean: 60\n",
      "Brain_Data_allsubs: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correct-go    95\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'setting up decoder...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'loading subject DEV013'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "brain_data_filepath: 152\n",
      "train_test_markers_filepath: 141\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "subjs_to_use: 64\n",
      "clean: 60\n",
      "Brain_Data_allsubs: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:202: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229\n",
      "4229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "correct-go      94\n",
       "correct-stop    11\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'setting up decoder...'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fitting'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'evaluating'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mean_cv_scores': 0.3333333333333333,\n",
       " 'overfit_accuracy': 0.6761904761904762,\n",
       " 'overfit_y_pred_vs_obs':             y_obs        y_pred\n",
       " 493  correct-stop  correct-stop\n",
       " 494    correct-go    correct-go\n",
       " 495    correct-go  correct-stop\n",
       " 496    correct-go  correct-stop\n",
       " 497    correct-go  correct-stop\n",
       " ..            ...           ...\n",
       " 593    correct-go  correct-stop\n",
       " 594    correct-go    correct-go\n",
       " 595    correct-go    correct-go\n",
       " 596    correct-go  correct-stop\n",
       " 597    correct-go  correct-stop\n",
       " \n",
       " [105 rows x 2 columns],\n",
       " 'decoder_object': Decoder(cv=StratifiedKFold(n_splits=3, random_state=888671607, shuffle=True),\n",
       "         estimator=LinearSVC(max_iter=10000.0), memory=Memory(location=None),\n",
       "         n_jobs=3, scoring='accuracy')}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary_results = get_all_subjs_discriminability_whole_brain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "middle-creek",
   "metadata": {},
   "source": [
    "How to deal with imbalanced classes?\n",
    "We're using svc. One solution: https://chrisalbon.com/code/machine_learning/support_vector_machines/imbalanced_classes_in_svm/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-contact",
   "metadata": {},
   "source": [
    "### analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analyze_results import remove_selected_outliers\n",
    "from scipy.stats import pearsonr,spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "injured-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate discriminability against shit we care about.\n",
    "\n",
    "summary_results2 = summary_results.rename(columns={\n",
    "    'mean_cv_scores':'discriminability_mean_cv_scores',\n",
    "    'overfit_accuracy':'discriminability_overfit_accuracy'})\n",
    "\n",
    "\n",
    "individual_differences = pd.read_csv(ml_data_folderpath + \"/\" + data_by_ppt_name)\n",
    "individual_differences = individual_differences.rename(columns={'SID':'subid'})\n",
    "individual_differences['wave']=1\n",
    "#individual_differences['wave'] = individual_differences['wave'].astype(object) # for compatibility with the wave column in the dataset\n",
    "ind_div_combined = summary_results2.merge(individual_differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_selected_outliers_tesq_study(ind_div_combined,show_plot=False):\n",
    "    idc_outliers_removed = remove_selected_outliers(ind_div_combined,\n",
    "    ['discriminability_overfit_accuracy','discriminability_mean_cv_scores',\n",
    "        'BFI_extraversion','RMQ_locomotion','ses_aggregate','PLAN_cognitive_strategies',\n",
    "     'SST_SSRT','BIS_11','BSCS','TESQ_E_suppression', 'TESQ_E_avoidance_of_temptations', \n",
    "     'TESQ_E_goal_deliberation', 'TESQ_E_controlling_temptations', 'TESQ_E_distraction',\n",
    "     'TESQ_E_goal_and_rule_setting','EDM','RS','TRSQ','ROC_Crave_Regulate_Minus_Look',\n",
    "     'SRHI_unhealthy',\n",
    "     'cancer_promoting_minus_preventing_FFQ','bf_1'],\n",
    "    show_plot=show_plot)\n",
    "    return(idc_outliers_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "healthy-jamaica",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_div_combined_3sd = remove_selected_outliers_tesq_study(\n",
    "    ind_div_combined,\n",
    "    show_plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-russian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_discriminability_correlations(ind_div_combined_3sd):\n",
    "    for neural_var in ['discriminability_overfit_accuracy','discriminability_mean_cv_scores']:\n",
    "        display(Markdown(\"### \" + neural_var))\n",
    "        for correlate in ['BFI_extraversion','RMQ_locomotion','ses_aggregate','PLAN_cognitive_strategies',\n",
    "                          'SST_SSRT','BIS_11','BSCS',\n",
    "                          'TESQ_E_suppression', 'TESQ_E_avoidance_of_temptations', \n",
    "                          'TESQ_E_goal_deliberation', 'TESQ_E_controlling_temptations', 'TESQ_E_distraction',\n",
    "                          'TESQ_E_goal_and_rule_setting',\n",
    "                        'EDM','RS','TRSQ','ROC_Crave_Regulate_Minus_Look','SRHI_unhealthy']:\n",
    "            display(Markdown(\"#### \" + correlate))\n",
    "            nan_rows = np.isnan(ind_div_combined_3sd[correlate]) | np.isnan(ind_div_combined_3sd[neural_var])\n",
    "            cor2way_df = ind_div_combined_3sd.loc[nan_rows==False,]\n",
    "            pearson_result = pearsonr(cor2way_df[neural_var],cor2way_df[correlate])\n",
    "            display(HTML(\"r=\" + format(pearson_result[0],\".2f\") +\"; p-value=\" + format(pearson_result[1],\".4f\")))\n",
    "            spearman_result = spearmanr(cor2way_df[neural_var],cor2way_df[correlate])\n",
    "            display(HTML(\"rho=\" + format(spearman_result[0],\".2f\") +\"; p-value=\" + format(spearman_result[1],\".4f\")))\n",
    "            cplot = pyplot.scatter(cor2way_df[neural_var],cor2way_df[correlate])\n",
    "            cplot.axes.set_xlabel(neural_var)\n",
    "            cplot.axes.ylabel=correlate\n",
    "            pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-strike",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_discriminability_correlations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-legend",
   "metadata": {},
   "source": [
    "### Next steps\n",
    "\n",
    "probably repeat the whole process with some masks excluding, at a minimum, movement and visual cortices. We also are using a 40-subject dataset. It needs to be extended to 84-subject, even though this is going to be difficult because the dataset is so much more detailed. We need to get good at only storing a minimal amount of data at a time.\n",
    "\n",
    "In fact, extending to 84-subjects is probably the very first thing we need to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-maple",
   "metadata": {},
   "source": [
    "### Repeating the above with 84 subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-chocolate",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'conditions'\n",
    "\n",
    "\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_betaseries_84subs_correct_cond.pkl'\n",
    "#brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_conditions_43subs_correct_cond.pkl'\n",
    "\n",
    "def decoderConstructor(*args, **kwargs):\n",
    "    return(Decoder(scoring='accuracy',verbose=0, *args, **kwargs))\n",
    "\n",
    "\n",
    "relevant_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = load_and_preprocess(\n",
    "    brain_data_filepath,\n",
    "    train_test_markers_filepath,\n",
    "    subjs_to_use = None,\n",
    "    response_transform_func = trialtype_resp_trans_func,\n",
    "    clean=None)\n",
    "\n",
    "all_subjects['groups']\n",
    "\n",
    "subj_list = np.unique(all_subjects['groups'])\n",
    "\n",
    "del all_subjects\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_subjs_discriminability_whole_brain_v_1_1():\n",
    "    results_dict = {}\n",
    "\n",
    "    for sample_subject in subj_list:\n",
    "        run_desc = 'v1_1_whole_brain_84subjs'\n",
    "        results_dict[sample_subject] = get_subject_discriminability_with_cache(sample_subject,run_desc)\n",
    "        \n",
    "    summary_results = pd.concat([pd.DataFrame({\n",
    "        'subid':k,\n",
    "        'overfit_accuracy':[v['overfit_accuracy']],\n",
    "        'mean_cv_scores':[v['mean_cv_scores']]}) \n",
    "\n",
    "                                 for k,v in results_dict.items()])\n",
    "    \n",
    "    return(summary_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-characterization",
   "metadata": {},
   "outputs": [],
   "source": [
    "## pfc only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominant-mobility",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfc_mask = create_mask_from_images(get_pfc_image_filepaths(ml_data_folderpath + \"/\"),threshold=10)\n",
    "relevant_mask = pfc_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-harrison",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
