{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "soviet-scientist",
   "metadata": {},
   "source": [
    "### Basic subject-level\n",
    "\n",
    "Let's try to imitate what we've already done at the subject level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dental-representative",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python initialized for apply_loocv_and_save\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/datasets/__init__.py:87: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "\n",
    "from apply_loocv_and_save import *\n",
    "import gc\n",
    "import nibabel as nib\n",
    "\n",
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\"\n",
    "test_train_df = pd.read_csv(nonbids_data_path + \"fMRI/ml/train_test_markers_20210601T183243.csv\")\n",
    "\n",
    "all_sst_events= pd.read_csv(ml_data_folderpath +\"/SST/\" + \"all_sst_events.csv\")\n",
    "\n",
    "\n",
    "dataset_name = 'conditions'\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_' + dataset_name + '_40subs.pkl'\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "from nilearn.decoding import DecoderRegressor, Decoder\n",
    "\n",
    "script_path = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml'\n",
    "data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/\"\n",
    "# HRF 2s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "endless-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def condition_resp_trans_func(X):\n",
    "    return(X.condition_label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "remarkable-vampire",
   "metadata": {},
   "source": [
    "### Repeating test measuring precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hispanic-mathematics",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import DecoderRegressor  \n",
    "\n",
    "def apply_single_fit_and_save(\n",
    "    results_filepath,\n",
    "    brain_data_filepath = '../data/Brain_Data_2sns_60subs.pkl',\n",
    "    train_test_markers_filepath = \"../data/train_test_markers_20210601T183243.csv\",\n",
    "    subjs_to_use = None, #set this to get a subset, otherwise use all of them.\n",
    "    response_transform_func = None,\n",
    "    decoder = None,\n",
    "    mask=None,\n",
    "    cpus_to_use=1\n",
    "    ):\n",
    "    \n",
    "    preprocessed_data = load_and_preprocess(brain_data_filepath,train_test_markers_filepath,subjs_to_use,response_transform_func)\n",
    "\n",
    "    train_y = preprocessed_data['y']\n",
    "    train_X = preprocessed_data['X']\n",
    "    train_groups = preprocessed_data['groups']\n",
    "\n",
    "    if decoder is None:\n",
    "        decoder = decoderConstructor(\n",
    "                standardize= True,cv=LeaveOneGroupOut(),\n",
    "                mask=mask,\n",
    "                n_jobs=cpus_to_use,verbose=1)\n",
    "\n",
    "    print(\"starting LeaveOneOut\")\n",
    "    #in this design, we're actually dealing with groups\n",
    "    #we select group IDs and then grab the subjects\n",
    "    #so we don't need to use LeaveOneGroupOut\n",
    "    #the grouping is implicit\n",
    "\n",
    "    print('Fitting decoder')\n",
    "    decoder.fit(\n",
    "    y=train_y,X=train_X,groups=train_groups)\n",
    "\n",
    "    print(\"predicting\")\n",
    "    train_score = decoder.score(train_X,train_y)\n",
    "    train_y_pred = decoder.predict(train_X)\n",
    "\n",
    "    if type(decoder)==DecoderRegressor:\n",
    "        weight_img = decoder.coef_img_['beta']\n",
    "    else:\n",
    "        weight_img = decoder.coef_img_\n",
    "\n",
    "    print('finished learning')\n",
    "\n",
    "    print(\"saving\")\n",
    "\n",
    "    result_package = {\n",
    "            'decoder':decoder,\n",
    "            'weight_img':weight_img,\n",
    "            'obs':train_y,\n",
    "            'train_train_score':train_score,\n",
    "            'train_y_pred': train_y_pred,\n",
    "            'metadata':preprocessed_data['metadata']\n",
    "        }\n",
    "    with open(results_filepath, 'wb') as handle:\n",
    "        pickle.dump(result_package,handle)\n",
    "        \n",
    "    return(result_package)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-google",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unnecessary-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import get_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-diving",
   "metadata": {},
   "source": [
    "from  https://nilearn.github.io/modules/generated/nilearn.decoding.Decoder.html\n",
    "\n",
    "here's how to define a callable scorer:\n",
    "\n",
    "scoring: str, callable or None, optional. Default: ‘roc_auc’\n",
    "\n",
    "The scoring strategy to use. See the scikit-learn documentation at https://scikit-learn.org/stable/modules/model_evaluation.html#the-scoring-parameter-defining-model-evaluation-rules If callable, takes as arguments the fitted estimator, the test data (X_test) and the test target (y_test) if y is not None. e.g. scorer(estimator, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "broad-anthony",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_multiclass_score(estimator,X_test,y_test):\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(\"y_pred:\")\n",
    "    print(y_pred)\n",
    "    print(\"y_test:\")\n",
    "    print(y_test)\n",
    "    return(recall_score(y_test,y_pred,average='micro'))\n",
    "    #return(1)\n",
    "\n",
    "\n",
    "#recall_multiclass_score(decoder,[0,1,1],[0,0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-reviewer",
   "metadata": {},
   "source": [
    "## test accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "wrapped-prairie",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set vars for the function\n",
    "\n",
    "brain_data_filepath = brain_data_filepath\n",
    "train_test_markers_filepath = data_path + \"train_test_markers_20210601T183243.csv\"\n",
    "subjs_to_use = 10\n",
    "response_transform_func=condition_resp_trans_func\n",
    "mask=None\n",
    "\n",
    "results_filepath=data_path + \"SST/train_test_results_recall_\" + dataset_name + \"_40subs.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-sunset",
   "metadata": {},
   "source": [
    "### custom accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "inclusive-glasgow",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def custom_accuracy_score(estimator,X_test,y_test):\n",
    "    #aim is to emulate the results of the default accuracy measure\n",
    "    y_pred = estimator.predict(X_test)\n",
    "    print(\"y_pred:\")\n",
    "    print(y_pred)\n",
    "    print(\"y_test:\")\n",
    "    print(y_test)\n",
    "    return(accuracy_score(y_test,y_pred))\n",
    "    #return(1)\n",
    "\n",
    "\n",
    "#recall_multiclass_score(decoder,[0,1,1],[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cardiac-latter",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_custom_accuracy = Decoder(scoring=custom_accuracy_score,\n",
    "                         standardize= True,\n",
    "                         cv=LeaveOneGroupOut(),verbose=1,n_jobs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "passive-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "FailedStop     40\n",
      "Cue            40\n",
      "CorrectGo      40\n",
      "CorrectStop    37\n",
      "FailedGo       26\n",
      "Name: condition_label, dtype: int64\n",
      "FailedStop     40\n",
      "Cue            40\n",
      "CorrectGo      40\n",
      "CorrectStop    37\n",
      "FailedGo       26\n",
      "Name: condition_label, dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 141\n",
      "brain_data_filepath: 139\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 28\n",
      "False    183\n",
      "Name: condition_label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "183\n",
      "using 10 subjects\n",
      "starting LeaveOneOut\n",
      "Fitting decoder\n",
      "[NiftiMasker.fit] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py:143: UserWarning: Use a custom estimator at your own risk of the process not working as intended.\n",
      "  warnings.warn('Use a custom estimator at your own risk '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "y_pred:\n",
      "['CorrectGo' 'CorrectStop' 'FailedStop' 'Cue' 'FailedGo' 'CorrectGo'\n",
      " 'CorrectStop' 'FailedStop' 'Cue' 'FailedGo' 'CorrectGo' 'FailedStop'\n",
      " 'Cue' 'CorrectGo' 'CorrectStop' 'FailedStop' 'Cue' 'FailedGo' 'CorrectGo'\n",
      " 'FailedStop' 'Cue' 'FailedGo' 'CorrectGo' 'CorrectStop' 'FailedStop'\n",
      " 'Cue' 'FailedGo' 'CorrectGo' 'CorrectStop' 'FailedStop' 'Cue' 'CorrectGo'\n",
      " 'CorrectStop' 'FailedStop' 'Cue' 'FailedGo' 'CorrectGo' 'CorrectStop'\n",
      " 'FailedStop' 'Cue' 'FailedGo' 'CorrectGo' 'CorrectStop' 'FailedStop'\n",
      " 'Cue' 'FailedGo']\n",
      "y_test:\n",
      "0       CorrectGo\n",
      "1     CorrectStop\n",
      "2      FailedStop\n",
      "3             Cue\n",
      "4        FailedGo\n",
      "5       CorrectGo\n",
      "6     CorrectStop\n",
      "7      FailedStop\n",
      "8             Cue\n",
      "9        FailedGo\n",
      "10      CorrectGo\n",
      "11     FailedStop\n",
      "12            Cue\n",
      "13      CorrectGo\n",
      "14    CorrectStop\n",
      "15     FailedStop\n",
      "16            Cue\n",
      "17       FailedGo\n",
      "18      CorrectGo\n",
      "19     FailedStop\n",
      "20            Cue\n",
      "21       FailedGo\n",
      "22      CorrectGo\n",
      "23    CorrectStop\n",
      "24     FailedStop\n",
      "25            Cue\n",
      "26       FailedGo\n",
      "27      CorrectGo\n",
      "28    CorrectStop\n",
      "29     FailedStop\n",
      "30            Cue\n",
      "31      CorrectGo\n",
      "32    CorrectStop\n",
      "33     FailedStop\n",
      "34            Cue\n",
      "35       FailedGo\n",
      "36      CorrectGo\n",
      "37    CorrectStop\n",
      "38     FailedStop\n",
      "39            Cue\n",
      "40       FailedGo\n",
      "41      CorrectGo\n",
      "42    CorrectStop\n",
      "43     FailedStop\n",
      "44            Cue\n",
      "45       FailedGo\n",
      "Name: condition_label, dtype: object\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "finished learning\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "res_custom_accuracy = apply_single_fit_and_save(\n",
    "    results_filepath =results_filepath,\n",
    "    brain_data_filepath = brain_data_filepath,\n",
    "    train_test_markers_filepath = train_test_markers_filepath,\n",
    "    subjs_to_use = subjs_to_use,\n",
    "    response_transform_func = condition_resp_trans_func,\n",
    "    decoder = decoder_custom_accuracy\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-david",
   "metadata": {},
   "source": [
    "### default accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "pleasant-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "narrow-chemistry",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_accuracy_default = Decoder(scoring='accuracy',\n",
    "                         standardize= True,\n",
    "                         cv=LeaveOneGroupOut(),verbose=1,n_jobs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "rotary-sailing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 40 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "FailedStop     40\n",
      "Cue            40\n",
      "CorrectGo      40\n",
      "CorrectStop    37\n",
      "FailedGo       26\n",
      "Name: condition_label, dtype: int64\n",
      "FailedStop     40\n",
      "Cue            40\n",
      "CorrectGo      40\n",
      "CorrectStop    37\n",
      "FailedGo       26\n",
      "Name: condition_label, dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 141\n",
      "brain_data_filepath: 139\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 28\n",
      "False    183\n",
      "Name: condition_label, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183\n",
      "183\n",
      "using 10 subjects\n",
      "starting LeaveOneOut\n",
      "Fitting decoder\n",
      "[NiftiMasker.fit] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.fit] Computing the mask\n",
      "[NiftiMasker.fit] Resampling mask\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=10)]: Done  21 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=10)]: Done  50 out of  50 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "[NiftiMasker.transform_single_imgs] Loading data from Nifti1Image(\n",
      "shape=(97, 115, 97, 46),\n",
      "affine=array([[   2.,    0.,    0.,  -96.],\n",
      "       [   0.,    2.,    0., -132.],\n",
      "       [   0.,    0.,    2.,  -78.],\n",
      "       [   0.,    0.,    0.,    1.]])\n",
      ")\n",
      "[NiftiMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiMasker.transform_single_imgs] Cleaning extracted signals\n",
      "finished learning\n",
      "saving\n"
     ]
    }
   ],
   "source": [
    "res_default_accuracy = apply_single_fit_and_save(\n",
    "    results_filepath =results_filepath,\n",
    "    brain_data_filepath = brain_data_filepath,\n",
    "    train_test_markers_filepath = train_test_markers_filepath,\n",
    "    subjs_to_use = subjs_to_use,\n",
    "    response_transform_func = condition_resp_trans_func,\n",
    "    decoder = decoder_accuracy_default\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "military-jacksonville",
   "metadata": {},
   "source": [
    "## Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "verbal-intersection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CorrectGo': [0.4, 0.4, 1.0, 0.4, 0.5, 0.8, 1.0, 0.2, 0.2, 0.8],\n",
       " 'CorrectStop': [0.2, 0.2, 0.0, 0.2, 0.0, 0.2, 0.25, 0.2, 0.2, 0.2],\n",
       " 'Cue': [0.2, 0.2, 0.3333333333333333, 0.2, 0.25, 0.2, 0.25, 0.2, 0.2, 0.2],\n",
       " 'FailedGo': [0.2,\n",
       "  0.2,\n",
       "  0.3333333333333333,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.6],\n",
       " 'FailedStop': [0.2,\n",
       "  0.2,\n",
       "  0.3333333333333333,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.2]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_custom_accuracy['decoder'].cv_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "handy-right",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CorrectGo': [0.4, 0.4, 1.0, 0.4, 0.5, 0.8, 1.0, 0.2, 0.2, 0.8],\n",
       " 'CorrectStop': [0.2, 0.2, 0.0, 0.2, 0.0, 0.2, 0.25, 0.2, 0.2, 0.2],\n",
       " 'Cue': [0.2, 0.2, 0.3333333333333333, 0.2, 0.25, 0.2, 0.25, 0.2, 0.2, 0.2],\n",
       " 'FailedGo': [0.2,\n",
       "  0.2,\n",
       "  0.3333333333333333,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.6],\n",
       " 'FailedStop': [0.2,\n",
       "  0.2,\n",
       "  0.3333333333333333,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.2,\n",
       "  0.2,\n",
       "  0.2]}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_default_accuracy['decoder'].cv_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-cancer",
   "metadata": {},
   "source": [
    "Yep those look similar so I'm confident I am doing the right thing setting up this scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulated-daisy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
