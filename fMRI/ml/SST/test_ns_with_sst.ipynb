{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "modified-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n",
    "\n",
    "from apply_loocv_and_save import *\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "involved-screen",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\"\n",
    "test_train_df_raw = pd.read_csv(nonbids_data_path + \"fMRI/ml/train_test_markers_20210601T183243.csv\")\n",
    "\n",
    "all_sst_events= pd.read_csv(ml_data_folderpath +\"/SST/\" + \"all_sst_events.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chubby-distinction",
   "metadata": {},
   "source": [
    "We're going to exclude a few subjects because their data is not useable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "restricted-width",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_df_raw['IncludeInSST'] = True\n",
    "test_train_df_raw.loc[test_train_df_raw.sub_label=='DEV001','IncludeInSST']=False\n",
    "\n",
    "test_train_df = test_train_df_raw[test_train_df_raw.IncludeInSST==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "constitutional-logistics",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/SST/Brain_Data_conditions_2subs.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9837451e655c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mbrain_data_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml_data_folderpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/SST/Brain_Data_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_2subs.pkl'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbrain_data_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mBrain_Data_allsubs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkl_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/SST/Brain_Data_conditions_2subs.pkl'"
     ]
    }
   ],
   "source": [
    "dataset_name = 'conditions'\n",
    "brain_data_filepath = ml_data_folderpath + '/SST/Brain_Data_' + dataset_name + '_2subs.pkl'\n",
    "\n",
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "express-textbook",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>onset</th>\n",
       "      <th>duration</th>\n",
       "      <th>trial_type</th>\n",
       "      <th>subject</th>\n",
       "      <th>wave</th>\n",
       "      <th>beta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.25834</td>\n",
       "      <td>correct-stop</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0001.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>2.25834</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>ITI</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0002.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>2.75834</td>\n",
       "      <td>0.40082</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0003.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>4.76390</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>ITI</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0004.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>5.51390</td>\n",
       "      <td>0.66191</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV005</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0005.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2555</th>\n",
       "      <td>412.82572</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>ITI</td>\n",
       "      <td>DEV013</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0252.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>414.57572</td>\n",
       "      <td>0.56873</td>\n",
       "      <td>correct-go</td>\n",
       "      <td>DEV013</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0253.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2557</th>\n",
       "      <td>417.08682</td>\n",
       "      <td>0.75000</td>\n",
       "      <td>ITI</td>\n",
       "      <td>DEV013</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0254.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2558</th>\n",
       "      <td>417.83682</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>failed-stop</td>\n",
       "      <td>DEV013</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0255.nii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2559</th>\n",
       "      <td>419.33682</td>\n",
       "      <td>1.25000</td>\n",
       "      <td>ITI</td>\n",
       "      <td>DEV013</td>\n",
       "      <td>wave1</td>\n",
       "      <td>beta_0256.nii</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1536 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          onset  duration    trial_type subject   wave           beta\n",
       "256     0.00000   2.25834  correct-stop  DEV005  wave1  beta_0001.nii\n",
       "257     2.25834   0.50000           ITI  DEV005  wave1  beta_0002.nii\n",
       "258     2.75834   0.40082    correct-go  DEV005  wave1  beta_0003.nii\n",
       "259     4.76390   0.75000           ITI  DEV005  wave1  beta_0004.nii\n",
       "260     5.51390   0.66191    correct-go  DEV005  wave1  beta_0005.nii\n",
       "...         ...       ...           ...     ...    ...            ...\n",
       "2555  412.82572   1.75000           ITI  DEV013  wave1  beta_0252.nii\n",
       "2556  414.57572   0.56873    correct-go  DEV013  wave1  beta_0253.nii\n",
       "2557  417.08682   0.75000           ITI  DEV013  wave1  beta_0254.nii\n",
       "2558  417.83682   1.50000   failed-stop  DEV013  wave1  beta_0255.nii\n",
       "2559  419.33682   1.25000           ITI  DEV013  wave1  beta_0256.nii\n",
       "\n",
       "[1536 rows x 6 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Brain_Data_allsubs.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "def response_transform_func(X):\n",
    "    return(X.trial_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "combined-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.decoding import DecoderRegressor, Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "legitimate-values",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ITI             768\n",
       "correct-go      551\n",
       "failed-stop     145\n",
       "correct-stop     47\n",
       "failed-go        25\n",
       "Name: trial_type, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_transform_func(Brain_Data_allsubs.X).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "entitled-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sub_label</th>\n",
       "      <th>SplitGroup</th>\n",
       "      <th>IncludeInSST</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV005</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEV006</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DEV009</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DEV012</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DEV013</td>\n",
       "      <td>Train</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sub_label SplitGroup  IncludeInSST\n",
       "2    DEV005      Train          True\n",
       "3    DEV006      Train          True\n",
       "5    DEV009      Train          True\n",
       "6    DEV010      Train          True\n",
       "7    DEV012      Train          True\n",
       "8    DEV013      Train          True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_6_subjs = test_train_df[test_train_df.SplitGroup=='Train'][0:6]\n",
    "first_6_subjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "electric-pickup",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df=Brain_Data_allsubs.X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-bibliography",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "religious-grass",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEV005\n",
      "ITI             128\n",
      "correct-go       80\n",
      "failed-stop      27\n",
      "failed-go        16\n",
      "correct-stop      5\n",
      "Name: trial_type, dtype: int64\n",
      "DEV006\n",
      "ITI             128\n",
      "correct-go       92\n",
      "correct-stop     18\n",
      "failed-stop      14\n",
      "failed-go         4\n",
      "Name: trial_type, dtype: int64\n",
      "DEV009\n",
      "ITI            128\n",
      "correct-go      96\n",
      "failed-stop     32\n",
      "Name: trial_type, dtype: int64\n",
      "DEV010\n",
      "ITI             128\n",
      "correct-go       94\n",
      "failed-stop      19\n",
      "correct-stop     13\n",
      "failed-go         2\n",
      "Name: trial_type, dtype: int64\n",
      "DEV012\n",
      "ITI            128\n",
      "correct-go      95\n",
      "failed-stop     32\n",
      "failed-go        1\n",
      "Name: trial_type, dtype: int64\n",
      "DEV013\n",
      "ITI             128\n",
      "correct-go       94\n",
      "failed-stop      21\n",
      "correct-stop     11\n",
      "failed-go         2\n",
      "Name: trial_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for subj in first_6_subjs.sub_label:\n",
    "    print(subj)\n",
    "    print(\n",
    "        response_transform_func(X_df[X_df.subject==subj]).value_counts()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "corporate-california",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checked for intersection and no intersection between the brain data and the subjects was found.\n",
      "there were 6 subjects overlapping between the subjects marked for train data and the training dump file itself.\n",
      "ITI             768\n",
      "correct-go      551\n",
      "failed-stop     145\n",
      "correct-stop     47\n",
      "failed-go        25\n",
      "Name: trial_type, dtype: int64\n",
      "ITI             768\n",
      "correct-go      551\n",
      "failed-stop     145\n",
      "correct-stop     47\n",
      "failed-go        25\n",
      "Name: trial_type, dtype: int64\n",
      "test_train_set: 9549\n",
      "pkl_file: 168\n",
      "train_test_markers_filepath: 141\n",
      "brain_data_filepath: 138\n",
      "response_transform_func: 136\n",
      "sys: 72\n",
      "Brain_Data_allsubs: 48\n",
      "subjs_to_use: 28\n",
      "False    1536\n",
      "Name: trial_type, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py:191: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Brain_Data_allsubs.Y[Brain_Data_allsubs.Y=='NULL']=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n",
      "1536\n",
      "using 6 subjects\n",
      "starting LeaveOneOut\n",
      "finished preprocessing\n",
      "Groups are the same.\n",
      "fold 1 of 6\n",
      "In order to test on a training group of 5 items, holding out the following subjects:['DEV013']. prepping fold data.... fitting.... 10.3 GiB. trying decoder 1 of 1. "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 431, in _process_worker\n    r = call_item()\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 285, in __call__\n    return self.fn(*self.args, **self.kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n    return [func(*args, **kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n    return [func(*args, **kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/memory.py\", line 352, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py\", line 194, in _parallel_fit\n    score = scorer(estimator, X_test, y_test)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 199, in __call__\n    return self._score(partial(_cached_call, None), estimator, X, y_true,\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/sklearn/metrics/_scorer.py\", line 362, in _score\n    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 63, in inner_f\n    return f(*args, **kwargs)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\", line 542, in roc_auc_score\n    return _average_binary_score(partial(_binary_roc_auc_score,\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/sklearn/metrics/_base.py\", line 77, in _average_binary_score\n    return binary_metric(y_true, y_score, sample_weight=sample_weight)\n  File \"/home/bsmith16/.conda/envs/neuralsignature/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\", line 327, in _binary_roc_auc_score\n    raise ValueError(\"Only one class present in y_true. ROC AUC score \"\nValueError: Only one class present in y_true. ROC AUC score is not defined in that case.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8a4bce948904>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# HRF 2s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'betaseries'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m apply_loocv_and_save(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresults_filepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"SST/train_test_results_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_6subs.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mbrain_data_filepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'SST/Brain_Data_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_6subs.pkl'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/apply_loocv_and_save.py\u001b[0m in \u001b[0;36mapply_loocv_and_save\u001b[0;34m(results_filepath, brain_data_filepath, train_test_markers_filepath, subjs_to_use, response_transform_func, mask, decoderConstructor)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     test_scores_same,tt_results,results_by_trainset_item = cv_train_test_sets(\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mtrainset_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_subs_nifti\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtrainset_y\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_subs_nifti_Y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml/dev_wtp_io_utils.py\u001b[0m in \u001b[0;36mcv_train_test_sets\u001b[0;34m(trainset_X, trainset_y, trainset_groups, decoders, testset_X, testset_y, testset_groups, param_grid, cpus_to_use, cv, regressors)\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;31m#if there is nested CV within this function the best hyper-paramters are already being chosen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0;31m#we need only to finish the job by identifying the best overall decoder, as the final hyper-parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m             \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_groups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"predicting\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'. '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m             \u001b[0;31m#hyper_score = reg.score(train_X,train_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuralsignature/lib/python3.8/site-packages/nilearn/decoding/decoder.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0mparallel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         parallel_fit_outputs = parallel(\n\u001b[0m\u001b[1;32m    561\u001b[0m             delayed(self._cache(_parallel_fit))(\n\u001b[1;32m    562\u001b[0m                 \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuralsignature/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuralsignature/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/neuralsignature/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    386\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 388\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "script_path = '/gpfs/projects/sanlab/shared/DEV/DEV_scripts/fMRI/ml'\n",
    "data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml/\"\n",
    "# HRF 2s\n",
    "dataset_name = 'betaseries'\n",
    "apply_loocv_and_save(\n",
    "    results_filepath=data_path + \"SST/train_test_results_\" + dataset_name + \"_6subs.pkl\",\n",
    "    brain_data_filepath = data_path + 'SST/Brain_Data_' + dataset_name + '_6subs.pkl',\n",
    "    train_test_markers_filepath = data_path + \"train_test_markers_20210601T183243.csv\",\n",
    "    subjs_to_use = 6,\n",
    "    response_transform_func = response_transform_func,\n",
    "    decoderConstructor=Decoder #for classification\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-valley",
   "metadata": {},
   "source": [
    "So what do we actually want to measure here?\n",
    "\n",
    " - For the Response to Failure study we want error related negativity. That means we probably want the period immediately *following* an action. Ideally that means we create another set of betas that measure time following the error, and we relate that to post-error follows.\n",
    " - For the TESQ-E Self Control study we want the measure of inhibition. Probably we want to classify stop signal reaction time given people's behavioral responses. We will need to _control_ for the actual moment of the reaction. Mainly, we are interested in different processing techniques that lead to faster or slower stop signal reaction times. Need to look at those results and how this task actually relates; but we don't have those results yet because we're still waiting on the process Bryan is doing. But it is unclear to me whehter stop signal reaction time will actually relate to self control. Does faster stop signal reaction time mean better performance? or is it _slower_ stop signal reaction time? I don't know.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flush-caribbean",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-neuralsignature]",
   "language": "python",
   "name": "conda-env-.conda-neuralsignature-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
