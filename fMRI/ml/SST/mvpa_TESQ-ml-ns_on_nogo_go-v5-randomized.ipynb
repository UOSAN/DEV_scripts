{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "determined-reynolds",
   "metadata": {},
   "source": [
    "Randomly rename target labels in order to check the classification isn't completely spurious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "smooth-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fixed-signal",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to import duecredit due to No module named 'duecredit'\n",
      "/home/bsmith16/.conda/envs/py3_mvpa/lib/python3.8/site-packages/mvpa2/datasets/base.py:465: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  def __init__(self, shape=None, sid=None, fid=None, dtype=np.float):\n"
     ]
    }
   ],
   "source": [
    "from mvpa2.datasets.mri import fmri_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cordless-stamp",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BehavioralDataNotFoundForBrainDataException(Exception):\n",
    "    \"\"\"Behavioral data could not be matched to a subject.\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-british",
   "metadata": {},
   "source": [
    "Replicating earlier work on mvpa. Try not to overly complicate it--the main point is just to verify we get similar results on a different package to validate prior work. ANd we are primarily interested in validating the very high cross-validation results I got with nltools. Should aim for readable code.\n",
    "\n",
    "\n",
    "Version 5 uses scikit-learn directly, bypassing mvpa2's framework altogether. We also implement a 'forced choice' scorer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "generic-north",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mvpa2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "surrounded-telescope",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.abspath(\"../../ml/\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-lighting",
   "metadata": {},
   "source": [
    "## Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "latest-rainbow",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nonbids_data_path = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/\"\n",
    "ml_data_folderpath = \"/gpfs/projects/sanlab/shared/DEV/nonbids_data/fMRI/ml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "intimate-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "include_exclude_list = pd.read_csv(\"../nsc_subject_exclusions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "level-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_train_df_raw = pd.read_csv(nonbids_data_path + \"fMRI/ml/train_test_markers_20211027T173724.csv\")\n",
    "test_train_df_raw = test_train_df_raw.merge(include_exclude_list[include_exclude_list.Task=='SST'],left_on='sub_label',right_on='SubjectId',how='left')\n",
    "test_train_df_raw.loc[test_train_df_raw.Include.isna(),'Include'] = True\n",
    "test_train_df = test_train_df_raw[test_train_df_raw.Include==True]\n",
    "exclude_subjects = ['DEV061','DEV185','DEV187','DEV189','DEV190','DEV192','DEV198','DEV203','DEV220','DEV221']\n",
    "train_subjs = test_train_df.loc[test_train_df.SplitGroup=='Train','sub_label'].tolist()#only get the train subjects; ignore those previously marked hold-out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caroline-representative",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subjs_selected = [ts for ts in train_subjs if (ts not in exclude_subjects)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "continued-correction",
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_differences = pd.read_csv(ml_data_folderpath + \"/data_by_ppt.csv\")\n",
    "individual_differences = individual_differences.rename(columns={'SID':'subject'})\n",
    "individual_differences['wave']=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "olympic-explosion",
   "metadata": {},
   "source": [
    "We probably actually want to start the pipeline from the betas rather than loading from pickle. to be continued..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "african-cooking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mvpa_pipeline_utils import get_Brain_Data_betas_as_mvpa_for_sub, import_beta_series_pymvpa2, sa_to_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-screw",
   "metadata": {},
   "source": [
    "## new code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "weekly-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "juvenile-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_forced_choice(dataset):\n",
    "    logo=LeaveOneGroupOut()\n",
    "\n",
    "    group_scores = {}\n",
    "    sample_wise_results = []\n",
    "    for train_index, test_index in logo.split(\n",
    "        dataset.samples, dataset.sa.targets, dataset.sa.chunks):\n",
    "        iteration_label = np.unique(dataset.sa.chunks[test_index])[0]\n",
    "\n",
    "        #print(iteration_label, \"; TRAIN:\", len(train_index), \" items; TEST:\", test_index)\n",
    "        print(\".\",end=\"\",flush=True)\n",
    "\n",
    "        #do train-test split\n",
    "        train_X=dataset.samples[train_index]\n",
    "        test_X = dataset.samples[test_index]\n",
    "        train_y=dataset.sa.targets[train_index]\n",
    "        test_y = dataset.sa.targets[test_index]\n",
    "        clf_svc = SVC()\n",
    "\n",
    "        #create the classifier with a probability function\n",
    "        #https://mmuratarat.github.io/2019-10-12/probabilistic-output-of-svm#:~:text=SVMs%20don't%20output%20probabilities,the%20output%20to%20class%20probabilities.&text=For%20many%20problems%2C%20it%20is,of%20certainty%20about%20the%20answer.\n",
    "        sklearn_clf = CalibratedClassifierCV(clf_svc)\n",
    "        #train\n",
    "        sklearn_clf.fit(train_X, train_y)\n",
    "\n",
    "        #get the _probability_ we fall into each class\n",
    "        predict_y_prob = sklearn_clf.predict_proba(test_X)\n",
    "        predict_y = sklearn_clf.predict(test_X)\n",
    "        #need to label the output of the probability as CorrectStop and CorrectGo based on the classnames\n",
    "        #iterate through each class\n",
    "        proba_dict = {}\n",
    "        for i, cls in enumerate(sklearn_clf.classes_):\n",
    "            proba_dict[cls] = [x[i] for x in predict_y_prob]\n",
    "            \n",
    "        class_0 = sklearn_clf.classes_[0]\n",
    "        class_1 = sklearn_clf.classes_[1]\n",
    "\n",
    "        #find out which one of the two images is most likely to be CorrectGo\n",
    "        class_0_choice_index = np.argmax(proba_dict[class_0])\n",
    "        #now put that into a vector\n",
    "        forced_choice_predictions = [class_1]*2\n",
    "        forced_choice_predictions[class_0_choice_index] = class_0\n",
    "        accuracy_score = np.sum([pred==target for pred,target in zip(forced_choice_predictions,test_y)])/len(test_y)\n",
    "        #print(predict_y)\n",
    "        #print(proba_dict)\n",
    "        #print(forced_choice_predictions)\n",
    "        print(accuracy_score)\n",
    "        #can we do a sample-wise table?\n",
    "\n",
    "        group_scores[iteration_label] = accuracy_score\n",
    "        sample_wise_results_iter = pd.DataFrame({\n",
    "            'chunk':[iteration_label]*len(test_y),\n",
    "            'target_y':test_y,\n",
    "            'pred_y':predict_y,\n",
    "            'pred_y_forced_choice':forced_choice_predictions\n",
    "        })\n",
    "        #add the class-wise probabilities\n",
    "        for cls in sklearn_clf.classes_:\n",
    "            sample_wise_results_iter['pred_prob_' + cls] = proba_dict[cls]\n",
    "            \n",
    "        sample_wise_results = sample_wise_results + [sample_wise_results_iter]\n",
    "            \n",
    "    sample_wise_results_df = pd.concat(sample_wise_results)\n",
    "    return({'sample_wise':sample_wise_results_df,'group_wise':group_scores})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "exciting-weather",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_metadata(Brain_Data_allsubs):\n",
    "    #set up chunks and targets so we can do the learning.\n",
    "    attribute_df = sa_to_df(Brain_Data_allsubs.sa)\n",
    "    pd.concat([attribute_df['subject'],attribute_df['wave']],axis=1)\n",
    "    chunk = attribute_df['subject']+\"_\" + attribute_df['wave'].astype(str)\n",
    "    Brain_Data_allsubs.sa['chunks'] = list(chunk)\n",
    "    Brain_Data_allsubs.sa['targets'] = list(Brain_Data_allsubs.sa['condition_label'].value)\n",
    "    return(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unlimited-audio",
   "metadata": {},
   "source": [
    "## whole brain"
   ]
  },
  {
   "cell_type": "raw",
   "id": "compliant-incidence",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "from mvpa2.measures.base import CrossValidation\n",
    "from mvpa2.clfs.meta import NFoldPartitioner\n",
    "from mvpa2.clfs.svm import LinearCSVMC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "metallic-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "hispanic-mozambique",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from mvpa2.measures.base import CrossValidation\n",
    "#from mvpa2.clfs.meta import NFoldPartitioner\n",
    "#from mvpa2.clfs.svm import LinearCSVMC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relevant-pocket",
   "metadata": {},
   "source": [
    "Now let's scale that up to the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "express-impact",
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_data_filepath = ml_data_folderpath + '/SST/mvpa_Dataset_conditions_84subs_correct_cond.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "wrong-specialist",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_filepath=ml_data_folderpath + \"/SST/ttr_mvpa2_res_v3_conditions_84subs_twoclasses_wholebrain.pkl\"\n",
    "#results_filepath=ml_data_folderpath + \"/SST/train_test_results_\" + dataset_name + \"_58subs_twoclasses_pfcmask_repeat1.pkl\"\n",
    "\n",
    "def decoderConstructor(*args, **kwargs):\n",
    "    return(Decoder(scoring='accuracy',verbose=0, *args, **kwargs))\n",
    "\n",
    "\n",
    "relevant_mask = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "traditional-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(brain_data_filepath, 'rb') as pkl_file:\n",
    "    Brain_Data_allsubs = pickle.load(pkl_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "sixth-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brain_Data_allsubs = setup_metadata(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "indian-western",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_shuffled = sa_to_df(Brain_Data_allsubs.sa).loc[:,['chunks','targets']].groupby('chunks').sample(2,replace=False).targets.reset_index(drop=True)\n",
    "Brain_Data_allsubs.sa.targets_old = Brain_Data_allsubs.sa.targets\n",
    "Brain_Data_allsubs.sa.targets = list(targets_shuffled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-teach",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".0.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".0.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      ".1.0\n",
      "."
     ]
    }
   ],
   "source": [
    "forced_choice_results = do_forced_choice(Brain_Data_allsubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "promising-former",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk</th>\n",
       "      <th>target_y</th>\n",
       "      <th>pred_y</th>\n",
       "      <th>pred_y_forced_choice</th>\n",
       "      <th>pred_prob_CorrectGo</th>\n",
       "      <th>pred_prob_CorrectStop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.903737</td>\n",
       "      <td>0.096263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.125309</td>\n",
       "      <td>0.874691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.972710</td>\n",
       "      <td>0.027290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV006_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.218002</td>\n",
       "      <td>0.781998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV010_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.967692</td>\n",
       "      <td>0.032308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV216_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.294775</td>\n",
       "      <td>0.705225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV217_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.940275</td>\n",
       "      <td>0.059725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV217_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.107911</td>\n",
       "      <td>0.892089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV218_1</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectGo</td>\n",
       "      <td>0.488167</td>\n",
       "      <td>0.511833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV218_1</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>CorrectStop</td>\n",
       "      <td>0.058411</td>\n",
       "      <td>0.941589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>162 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chunk     target_y       pred_y pred_y_forced_choice  \\\n",
       "0   DEV005_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "1   DEV005_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV006_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "1   DEV006_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV010_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "..       ...          ...          ...                  ...   \n",
       "1   DEV216_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV217_1    CorrectGo    CorrectGo            CorrectGo   \n",
       "1   DEV217_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "0   DEV218_1    CorrectGo  CorrectStop            CorrectGo   \n",
       "1   DEV218_1  CorrectStop  CorrectStop          CorrectStop   \n",
       "\n",
       "    pred_prob_CorrectGo  pred_prob_CorrectStop  \n",
       "0              0.903737               0.096263  \n",
       "1              0.125309               0.874691  \n",
       "0              0.972710               0.027290  \n",
       "1              0.218002               0.781998  \n",
       "0              0.967692               0.032308  \n",
       "..                  ...                    ...  \n",
       "1              0.294775               0.705225  \n",
       "0              0.940275               0.059725  \n",
       "1              0.107911               0.892089  \n",
       "0              0.488167               0.511833  \n",
       "1              0.058411               0.941589  \n",
       "\n",
       "[162 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forced_choice_results['sample_wise']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "christian-settle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9876543209876543"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_score = np.mean(list(forced_choice_results['group_wise'].values()))\n",
    "total_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleased-supervisor",
   "metadata": {},
   "source": [
    "Alright--and how about if we don't do the forced-choice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "retained-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y'])\n",
    "forced_choice_prediction = np.mean(forced_choice_results['sample_wise']['target_y']==forced_choice_results['sample_wise']['pred_y_forced_choice'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py3_mvpa]",
   "language": "python",
   "name": "conda-env-.conda-py3_mvpa-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
