{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dev_interaction_util import *\n",
    "from DevCvAnalysis import DevCvAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config.yml\") \n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic structure is the following:\n",
    "\n",
    "1. Run the following cross-validated analyses:\n",
    "   1. Predicting change by condition only\n",
    "   2. Predicting change by condition and neural and behavioral measures\n",
    "   3. Predicting change by condition, neural and behavioral measures, and their interactions\n",
    "2. Measure the predictivity of the three models above using anova\n",
    "3. Repeat the steps above separately for three outcome variables, change in: FFQ, ASA-24, and BFP\n",
    "4. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks to do to get this job done (not in order):\n",
    "\n",
    "1. Write the analysis pipeline above\n",
    "2. Get the neural data\n",
    "3. Get the behavioral data\n",
    "\n",
    "\n",
    "We have the behavioral data. Do we have the neural data already?\n",
    "\n",
    "What could we delegate here? Behavioral data we already have. We have mostly writen the analysis pipeline. The neural data could be passed on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from InterventionCVManager import *\n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n",
    "\n",
    "icvm = InterventionCVManager(dropbox_data_dir)\n",
    "#icvm.mode = 'full_pipeline_test'\n",
    "#icvm.mode = 'fast_pipeline_test'\n",
    "icvm.mode = 'full_analysis'\n",
    "\n",
    "#dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict change"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sets of variables to run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up a function that loops runs the scoring loop above (which does one cross-validation analysis), and the nadditionally:\n",
    "- selects the best model based on the overall results\n",
    "- Runs a final fit\n",
    "- presents model results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we include functions that compare models with and without individual differences and interactions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should manually verify that in the following list, the intervention_group allocations are randomized (if we're running a test run) or that they are accurate (if it's not a test run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>intervention_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV004</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV008</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEV009</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>willamette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>willamette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID intervention_group\n",
       "0    DEV004             umpqua\n",
       "1    DEV005             umpqua\n",
       "2    DEV008             umpqua\n",
       "3    DEV009             umpqua\n",
       "4    DEV010           mckenzie\n",
       "..      ...                ...\n",
       "238  DEV308         willamette\n",
       "239  DEV309             umpqua\n",
       "240  DEV310           mckenzie\n",
       "241  DEV311         willamette\n",
       "242  DEV312           mckenzie\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    dev_cv_analysis.outcome_measures['SID'],\n",
    "      dev_cv_analysis.group_assignments\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SID', 'bf', 'NUTRIENT_DENSITY_2wkAverage',\n",
       "       'ANTINUTRIENT_DENSITY_2wkAverage', 'total_calorie'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_cv_analysis.outcome_measures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_cols = dev_cv_analysis.group_assignment_onehots.columns.tolist()\n",
    "inddiff_cols = dev_cv_analysis.get_predictors_main_names()\n",
    "\n",
    "interaction_cols = [id + \"*\" + cond for id in inddiff_cols for cond in condition_cols]\n",
    "\n",
    "predictor_sets = {\n",
    "    'condition_only': condition_cols,\n",
    "    'condition_inddiff': condition_cols + inddiff_cols,\n",
    "    'condition_inddiff_interactions': condition_cols + inddiff_cols + interaction_cols\n",
    "}\n",
    "\n",
    "\n",
    "outcome_vars_to_try = [ 'bf','cancer_promoting_FFQ',\n",
    "       'NUTRIENT_DENSITY_2wkAverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDM, BIS_11, PCS, ACES_sum, BFI_agreeableness, BFI_conscientiousness, BFI_extraversion, BFI_neuroticism, BFI_openness, NCS_total, TESQ_E_sum, SRHI_healthy_minus_unhealthy, RTFS_f1_minus_f2, cancer_promoting_minus_preventing_FCI, age365, education_own, household_income_per_person, SST_PostErrorSlowW1_mean, SST_mean_ssrt_0, ROC_Crave_Regulate_Minus_Look, ROC_Crave_Minus_Neutral, WTP_unhealthy_minus_healthy, wtp_liked_value_association-test_z_FDR_0.01, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01, roc_reappraiseCrave_multivariate_regulation, sst_CorrectGo_striatum_joint_mask, sst_FailedStop_motor_control_striatum_joint_mask, sst_CorrectGoFollowingFailedStop_striatum_joint_mask, Planning_aggregate, Restraint_aggregate, IMI_effort_importance_aggregate, wtp_roc_koban_kober_craving_combined, birthsex_factor_Male, umpqua, mckenzie, EDM*umpqua, BIS_11*umpqua, PCS*umpqua, ACES_sum*umpqua, BFI_agreeableness*umpqua, BFI_conscientiousness*umpqua, BFI_extraversion*umpqua, BFI_neuroticism*umpqua, BFI_openness*umpqua, NCS_total*umpqua, TESQ_E_sum*umpqua, SRHI_healthy_minus_unhealthy*umpqua, RTFS_f1_minus_f2*umpqua, cancer_promoting_minus_preventing_FCI*umpqua, age365*umpqua, education_own*umpqua, household_income_per_person*umpqua, SST_PostErrorSlowW1_mean*umpqua, SST_mean_ssrt_0*umpqua, ROC_Crave_Regulate_Minus_Look*umpqua, ROC_Crave_Minus_Neutral*umpqua, WTP_unhealthy_minus_healthy*umpqua, wtp_liked_value_association-test_z_FDR_0.01*umpqua, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua, roc_reappraiseCrave_multivariate_regulation*umpqua, sst_CorrectGo_striatum_joint_mask*umpqua, sst_FailedStop_motor_control_striatum_joint_mask*umpqua, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua, Planning_aggregate*umpqua, Restraint_aggregate*umpqua, IMI_effort_importance_aggregate*umpqua, wtp_roc_koban_kober_craving_combined*umpqua, birthsex_factor_Male*umpqua, EDM*mckenzie, BIS_11*mckenzie, PCS*mckenzie, ACES_sum*mckenzie, BFI_agreeableness*mckenzie, BFI_conscientiousness*mckenzie, BFI_extraversion*mckenzie, BFI_neuroticism*mckenzie, BFI_openness*mckenzie, NCS_total*mckenzie, TESQ_E_sum*mckenzie, SRHI_healthy_minus_unhealthy*mckenzie, RTFS_f1_minus_f2*mckenzie, cancer_promoting_minus_preventing_FCI*mckenzie, age365*mckenzie, education_own*mckenzie, household_income_per_person*mckenzie, SST_PostErrorSlowW1_mean*mckenzie, SST_mean_ssrt_0*mckenzie, ROC_Crave_Regulate_Minus_Look*mckenzie, ROC_Crave_Minus_Neutral*mckenzie, WTP_unhealthy_minus_healthy*mckenzie, wtp_liked_value_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_multivariate_regulation*mckenzie, sst_CorrectGo_striatum_joint_mask*mckenzie, sst_FailedStop_motor_control_striatum_joint_mask*mckenzie, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie, Planning_aggregate*mckenzie, Restraint_aggregate*mckenzie, IMI_effort_importance_aggregate*mckenzie, wtp_roc_koban_kober_craving_combined*mckenzie, birthsex_factor_Male*mckenzie\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.get_predictor_data().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SID, bf, NUTRIENT_DENSITY_2wkAverage, ANTINUTRIENT_DENSITY_2wkAverage, total_calorie\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.outcome_measures.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total calories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.67 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 4.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.32 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.13 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.68 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.41 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.00 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.08 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.98 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.10 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.59 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.63 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.82 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.10 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.14 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "scores:\n",
      "[-0.015165505655045486, -0.01818108525676343, -0.09404942309886888, -2.44575049590523e-05, -0.012552923902261925]\n",
      "overall_score:\n",
      "-0.027994679083579756\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031067</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.018364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031067</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.018364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031067</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.018364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031069</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.018362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031069</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.018362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031069</td>\n",
       "      <td>0.022537</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.018362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031106</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031106</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031106</td>\n",
       "      <td>0.022572</td>\n",
       "      <td>0.027639</td>\n",
       "      <td>0.018287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031148</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.018254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031148</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.018254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.031148</td>\n",
       "      <td>0.022679</td>\n",
       "      <td>0.027756</td>\n",
       "      <td>0.018254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031166</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031166</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.031166</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.027825</td>\n",
       "      <td>0.018301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031188</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.018798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031188</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.018798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031188</td>\n",
       "      <td>0.022644</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.018798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.031192</td>\n",
       "      <td>0.022643</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.018797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.031192</td>\n",
       "      <td>0.022643</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.018797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>0.000312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>-0.000201</td>\n",
       "      <td>0.000201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 35 predictors in the set condition_inddiff\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.68 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.00 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 14.68 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.21 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.87 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 11.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 17.00 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 17.61 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 5.52 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 7.85 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.11 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 18.07 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 38.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 26.69 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 5.64 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.85 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 32.69 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 25.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 34.62 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 16.66 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.64 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 2.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 18.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 19.91 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 14.62 seconds\n",
      "scores:\n",
      "[-0.11620607263191118, -0.11819615734229849, -0.0944315003598899, -0.5996663384465901, -0.019778835564578046]\n",
      "overall_score:\n",
      "-0.18965578086905355\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.027891</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.032327</td>\n",
       "      <td>0.016962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.027894</td>\n",
       "      <td>0.023291</td>\n",
       "      <td>0.032325</td>\n",
       "      <td>0.016951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.029390</td>\n",
       "      <td>0.023140</td>\n",
       "      <td>0.033117</td>\n",
       "      <td>0.023063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.029535</td>\n",
       "      <td>0.024515</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.024326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029688</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.032166</td>\n",
       "      <td>0.018264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029692</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.032165</td>\n",
       "      <td>0.018262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030469</td>\n",
       "      <td>0.022667</td>\n",
       "      <td>0.028290</td>\n",
       "      <td>0.019227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030471</td>\n",
       "      <td>0.022668</td>\n",
       "      <td>0.028295</td>\n",
       "      <td>0.019224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030674</td>\n",
       "      <td>0.023258</td>\n",
       "      <td>0.027475</td>\n",
       "      <td>0.018854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030762</td>\n",
       "      <td>0.022649</td>\n",
       "      <td>0.028317</td>\n",
       "      <td>0.018815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030765</td>\n",
       "      <td>0.022651</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.018813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030771</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.027833</td>\n",
       "      <td>0.017306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030774</td>\n",
       "      <td>0.022896</td>\n",
       "      <td>0.027834</td>\n",
       "      <td>0.017309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030805</td>\n",
       "      <td>0.021940</td>\n",
       "      <td>0.032627</td>\n",
       "      <td>0.018494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030810</td>\n",
       "      <td>0.021947</td>\n",
       "      <td>0.032632</td>\n",
       "      <td>0.018500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030861</td>\n",
       "      <td>0.023024</td>\n",
       "      <td>0.028107</td>\n",
       "      <td>0.018988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030863</td>\n",
       "      <td>0.023026</td>\n",
       "      <td>0.028111</td>\n",
       "      <td>0.018986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030870</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.018984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030872</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.018982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030883</td>\n",
       "      <td>0.022992</td>\n",
       "      <td>0.028088</td>\n",
       "      <td>0.018963</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BFI_neuroticism</td>\n",
       "      <td>None</td>\n",
       "      <td>0.026053</td>\n",
       "      <td>0.026053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ROC_Crave_Minus_Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.022453</td>\n",
       "      <td>0.022453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021647</td>\n",
       "      <td>0.021647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.021178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BFI_openness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.020475</td>\n",
       "      <td>0.020475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 101 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*umpqua EDM*mckenzie BIS_11*umpqua BIS_11*mckenzie PCS*umpqua PCS*mckenzie ACES_sum*umpqua ACES_sum*mckenzie BFI_agreeableness*umpqua BFI_agreeableness*mckenzie BFI_conscientiousness*umpqua BFI_conscientiousness*mckenzie BFI_extraversion*umpqua BFI_extraversion*mckenzie BFI_neuroticism*umpqua BFI_neuroticism*mckenzie BFI_openness*umpqua BFI_openness*mckenzie NCS_total*umpqua NCS_total*mckenzie TESQ_E_sum*umpqua TESQ_E_sum*mckenzie SRHI_healthy_minus_unhealthy*umpqua SRHI_healthy_minus_unhealthy*mckenzie RTFS_f1_minus_f2*umpqua RTFS_f1_minus_f2*mckenzie cancer_promoting_minus_preventing_FCI*umpqua cancer_promoting_minus_preventing_FCI*mckenzie age365*umpqua age365*mckenzie education_own*umpqua education_own*mckenzie household_income_per_person*umpqua household_income_per_person*mckenzie SST_PostErrorSlowW1_mean*umpqua SST_PostErrorSlowW1_mean*mckenzie SST_mean_ssrt_0*umpqua SST_mean_ssrt_0*mckenzie ROC_Crave_Regulate_Minus_Look*umpqua ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Minus_Neutral*umpqua ROC_Crave_Minus_Neutral*mckenzie WTP_unhealthy_minus_healthy*umpqua WTP_unhealthy_minus_healthy*mckenzie wtp_liked_value_association-test_z_FDR_0.01*umpqua wtp_liked_value_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_multivariate_regulation*umpqua roc_reappraiseCrave_multivariate_regulation*mckenzie sst_CorrectGo_striatum_joint_mask*umpqua sst_CorrectGo_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*umpqua sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie Planning_aggregate*umpqua Planning_aggregate*mckenzie Restraint_aggregate*umpqua Restraint_aggregate*mckenzie IMI_effort_importance_aggregate*umpqua IMI_effort_importance_aggregate*mckenzie wtp_roc_koban_kober_craving_combined*umpqua wtp_roc_koban_kober_craving_combined*mckenzie birthsex_factor_Male*umpqua birthsex_factor_Male*mckenzie\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 73.65 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.771e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.611e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.591e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.426e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.741e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.545e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.402e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.685e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.571e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.299e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.551e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.592e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.229e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.270e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.550e+08, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.493e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+08, tolerance: 1.605e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.954e+08, tolerance: 1.936e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.430e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.940e+07, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.091e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.425e+08, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e+07, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.094e+05, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.560e+06, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.371e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.671e+07, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.551e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.442e+07, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.292e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.899e+06, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.735e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.341e+07, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.875e+07, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.310e+06, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.170e+07, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.166e+07, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.358e+06, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.739e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.937e+06, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.565e+07, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.094e+05, tolerance: 1.558e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.423e+08, tolerance: 1.154e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.560e+06, tolerance: 1.486e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 105.85 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 50.72 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 405.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 787.93 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 388.24 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 104.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.407e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.214e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.694e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.140e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.378e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.199e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.680e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.118e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.321e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.168e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.653e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.100e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.266e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.136e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.629e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.083e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.211e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.606e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.066e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+08, tolerance: 1.546e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.069e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.582e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.583e+08, tolerance: 2.037e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.008e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.181e+05, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.076e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.397e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.329e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.372e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+06, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+07, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.061e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.279e+08, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.810e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.072e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.306e+07, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.601e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.360e+07, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.640e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.670e+08, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.634e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.237e+06, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.734e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.933e+07, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.723e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.893e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.223e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.786e+06, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.948e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.856e+07, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.302e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.216e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.887e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.579e+06, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.288e+07, tolerance: 1.686e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+08, tolerance: 1.215e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.061e+07, tolerance: 1.633e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 87.82 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 98.25 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 391.83 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 477.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 458.32 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 64.83 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.022e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.659e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.995e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.170e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.234e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.646e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.936e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.135e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.213e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.617e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.886e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.096e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.194e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.586e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.839e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.051e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.558e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.999e+08, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.538e+08, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.749e+08, tolerance: 1.964e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.783e+07, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.771e+06, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.839e+05, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.159e+07, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.021e+08, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.101e+06, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.976e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.792e+07, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e+05, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+06, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+07, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+06, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.642e+06, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.511e+05, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.589e+05, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.291e+06, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.507e+07, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.443e+06, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.451e+07, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.489e+06, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.042e+05, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.807e+05, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.542e+07, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.092e+05, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.018e+08, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.583e+06, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.202e+06, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.071e+05, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.820e+07, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.071e+05, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.222e+07, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.669e+06, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.298e+05, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.391e+05, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.103e+07, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.350e+05, tolerance: 1.202e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.190e+07, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.186e+06, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.056e+05, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.396e+06, tolerance: 1.641e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.014e+07, tolerance: 1.389e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.472e+06, tolerance: 1.649e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 67.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 44.73 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 265.17 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 499.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 511.77 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 80.97 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.826e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.058e+08, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.319e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.830e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+07, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.809e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.049e+08, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.285e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.815e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.774e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.023e+08, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.218e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.787e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.738e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.962e+07, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.758e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.701e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.736e+07, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.080e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.730e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.663e+08, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.601e+07, tolerance: 1.317e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.010e+08, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.700e+08, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.512e+08, tolerance: 2.011e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.298e+05, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.400e+06, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.939e+05, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.148e+06, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.115e+07, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.250e+05, tolerance: 1.754e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.472e+05, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+05, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.228e+05, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.147e+05, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.363e+07, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.529e+05, tolerance: 1.489e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.989e+06, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.893e+06, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.116e+06, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.472e+05, tolerance: 1.470e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 93.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 80.67 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 293.88 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 475.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 485.74 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 65.25 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.388e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.501e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.916e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.943e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.393e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.446e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.863e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.905e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.403e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.348e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.753e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.827e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.409e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.258e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.637e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.734e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.413e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.162e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.532e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.613e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.417e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.062e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.430e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.510e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.515e+08, tolerance: 1.662e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.261e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.840e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.203e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.008e+07, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.148e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.825e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.880e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.115e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+06, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+06, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.438e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+07, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.651e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.894e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.722e+06, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.685e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.793e+08, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.394e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.162e+08, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.750e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.340e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.483e+07, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.441e+05, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.953e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.961e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.559e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.995e+07, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.130e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.692e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.362e+07, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.588e+05, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.407e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.303e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.882e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.744e+07, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.687e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.441e+07, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.301e+05, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.991e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.475e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.333e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.726e+07, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.361e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.525e+06, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.643e+06, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.666e+08, tolerance: 1.178e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.438e+07, tolerance: 1.230e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.885e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.183e+07, tolerance: 1.217e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 82.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 47.89 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 307.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 424.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 338.91 seconds\n",
      "scores:\n",
      "[0.06422272780050986, -0.04938813248433527, -0.09571607731866782, -0.050619407944705985, -0.02051699841093968]\n",
      "overall_score:\n",
      "-0.03040357767162778\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.028558</td>\n",
       "      <td>0.023654</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.019307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.028562</td>\n",
       "      <td>0.023658</td>\n",
       "      <td>0.030389</td>\n",
       "      <td>0.019308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.028932</td>\n",
       "      <td>0.026034</td>\n",
       "      <td>0.030082</td>\n",
       "      <td>0.017825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.028941</td>\n",
       "      <td>0.026043</td>\n",
       "      <td>0.030097</td>\n",
       "      <td>0.017819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030482</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>0.028076</td>\n",
       "      <td>0.018355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030487</td>\n",
       "      <td>0.023901</td>\n",
       "      <td>0.028079</td>\n",
       "      <td>0.018353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030870</td>\n",
       "      <td>0.023034</td>\n",
       "      <td>0.028085</td>\n",
       "      <td>0.018984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030872</td>\n",
       "      <td>0.023035</td>\n",
       "      <td>0.028090</td>\n",
       "      <td>0.018982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030879</td>\n",
       "      <td>0.023073</td>\n",
       "      <td>0.028065</td>\n",
       "      <td>0.018920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.030882</td>\n",
       "      <td>0.023075</td>\n",
       "      <td>0.028070</td>\n",
       "      <td>0.018917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030887</td>\n",
       "      <td>0.022735</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.018654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030891</td>\n",
       "      <td>0.022737</td>\n",
       "      <td>0.028756</td>\n",
       "      <td>0.018652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030909</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.027513</td>\n",
       "      <td>0.017944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030912</td>\n",
       "      <td>0.021390</td>\n",
       "      <td>0.027512</td>\n",
       "      <td>0.017943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030927</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.027994</td>\n",
       "      <td>0.018036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030927</td>\n",
       "      <td>0.022860</td>\n",
       "      <td>0.028364</td>\n",
       "      <td>0.017685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030929</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.027993</td>\n",
       "      <td>0.018036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.030931</td>\n",
       "      <td>0.022866</td>\n",
       "      <td>0.028371</td>\n",
       "      <td>0.017697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031004</td>\n",
       "      <td>0.022270</td>\n",
       "      <td>0.027124</td>\n",
       "      <td>0.019059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031009</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.019053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ROC_Crave_Minus_Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.027028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BFI_neuroticism</td>\n",
       "      <td>None</td>\n",
       "      <td>0.025836</td>\n",
       "      <td>0.025836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI</td>\n",
       "      <td>None</td>\n",
       "      <td>0.025618</td>\n",
       "      <td>0.025618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WTP_unhealthy_minus_healthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.024670</td>\n",
       "      <td>0.024670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.023311</td>\n",
       "      <td>0.023311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.022967</td>\n",
       "      <td>0.022967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.016475</td>\n",
       "      <td>0.016475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015572</td>\n",
       "      <td>0.015572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>0.015261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015073</td>\n",
       "      <td>0.015073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.027994679083579756, 'condition_inddiff': -0.18965578086905355, 'condition_inddiff_interactions': -0.03040357767162778}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'total_calorie', dev_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANTINUTRIENT_DENSITY_2wkAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 1.32 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 1.31 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 4.89 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 6.77 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 1.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.56 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 6.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.23 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.95 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.95 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.82 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.41 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.28 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.98 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.90 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.15 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.10 seconds\n",
      "scores:\n",
      "[-0.001942775491300397, -0.021202645703794376, -0.038552520386679445, -0.013317128349009444, -0.05851411114287486]\n",
      "overall_score:\n",
      "-0.026705836214731705\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040089</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.030243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.040089</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.030243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040089</td>\n",
       "      <td>0.028294</td>\n",
       "      <td>0.036896</td>\n",
       "      <td>0.030243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040960</td>\n",
       "      <td>0.030527</td>\n",
       "      <td>0.036586</td>\n",
       "      <td>0.031493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.040960</td>\n",
       "      <td>0.030527</td>\n",
       "      <td>0.036586</td>\n",
       "      <td>0.031493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040960</td>\n",
       "      <td>0.030527</td>\n",
       "      <td>0.036586</td>\n",
       "      <td>0.031493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.042475</td>\n",
       "      <td>0.030855</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>0.030898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042475</td>\n",
       "      <td>0.030855</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>0.030898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.042475</td>\n",
       "      <td>0.030855</td>\n",
       "      <td>0.036194</td>\n",
       "      <td>0.030898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.044585</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.029343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.044585</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.029343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.044585</td>\n",
       "      <td>0.030535</td>\n",
       "      <td>0.035968</td>\n",
       "      <td>0.029343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.047262</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.036229</td>\n",
       "      <td>0.026287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.047262</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.036229</td>\n",
       "      <td>0.026287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.047262</td>\n",
       "      <td>0.030318</td>\n",
       "      <td>0.036229</td>\n",
       "      <td>0.026287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.049176</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>0.036565</td>\n",
       "      <td>0.024208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.049176</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>0.036565</td>\n",
       "      <td>0.024208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.049176</td>\n",
       "      <td>0.030476</td>\n",
       "      <td>0.036565</td>\n",
       "      <td>0.024208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.050251</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>0.032702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.050251</td>\n",
       "      <td>0.024432</td>\n",
       "      <td>0.052785</td>\n",
       "      <td>0.032702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 35 predictors in the set condition_inddiff\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.06 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 7.22 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 22.36 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 19.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 16.47 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 5.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.30 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 10.93 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 17.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 20.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 45.26 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 4.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 7.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 17.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 22.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 18.97 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 7.86 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.16 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 10.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 24.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 23.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 16.83 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 4.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.77 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 6.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 18.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 21.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 26.92 seconds\n",
      "scores:\n",
      "[0.004775079237232416, -0.02721618935772052, -0.02715368615955649, -0.014750936767963685, -0.4799803560148117]\n",
      "overall_score:\n",
      "-0.108865217812564\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038486</td>\n",
       "      <td>0.028888</td>\n",
       "      <td>0.038109</td>\n",
       "      <td>0.032843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038521</td>\n",
       "      <td>0.029059</td>\n",
       "      <td>0.038113</td>\n",
       "      <td>0.033411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.038671</td>\n",
       "      <td>0.028929</td>\n",
       "      <td>0.037781</td>\n",
       "      <td>0.032929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.038712</td>\n",
       "      <td>0.029077</td>\n",
       "      <td>0.037808</td>\n",
       "      <td>0.033582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.038791</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>0.032892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.038832</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.037947</td>\n",
       "      <td>0.033562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.039096</td>\n",
       "      <td>0.028817</td>\n",
       "      <td>0.042889</td>\n",
       "      <td>0.023766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.039309</td>\n",
       "      <td>0.028325</td>\n",
       "      <td>0.043103</td>\n",
       "      <td>0.022635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040626</td>\n",
       "      <td>0.024978</td>\n",
       "      <td>0.041478</td>\n",
       "      <td>0.019759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041394</td>\n",
       "      <td>0.023836</td>\n",
       "      <td>0.042282</td>\n",
       "      <td>0.019174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041798</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.039879</td>\n",
       "      <td>0.025789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041822</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>0.040002</td>\n",
       "      <td>0.025889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.041934</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.039883</td>\n",
       "      <td>0.025602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.042336</td>\n",
       "      <td>0.026330</td>\n",
       "      <td>0.040645</td>\n",
       "      <td>0.025707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042376</td>\n",
       "      <td>0.026178</td>\n",
       "      <td>0.040796</td>\n",
       "      <td>0.025828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.042488</td>\n",
       "      <td>0.026295</td>\n",
       "      <td>0.040648</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.043454</td>\n",
       "      <td>0.024201</td>\n",
       "      <td>0.043659</td>\n",
       "      <td>0.037495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.043966</td>\n",
       "      <td>0.024111</td>\n",
       "      <td>0.044178</td>\n",
       "      <td>0.036817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.044931</td>\n",
       "      <td>0.024653</td>\n",
       "      <td>0.042613</td>\n",
       "      <td>0.022731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.045649</td>\n",
       "      <td>0.026647</td>\n",
       "      <td>0.047737</td>\n",
       "      <td>0.026766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>None</td>\n",
       "      <td>0.472166</td>\n",
       "      <td>0.472166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>None</td>\n",
       "      <td>0.459347</td>\n",
       "      <td>0.459347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.457854</td>\n",
       "      <td>0.457854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.454475</td>\n",
       "      <td>0.454475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>age365</td>\n",
       "      <td>None</td>\n",
       "      <td>0.453072</td>\n",
       "      <td>0.453072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCS</td>\n",
       "      <td>None</td>\n",
       "      <td>0.450468</td>\n",
       "      <td>0.450468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.442022</td>\n",
       "      <td>0.442022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.441172</td>\n",
       "      <td>0.441172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.432881</td>\n",
       "      <td>0.432881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>WTP_unhealthy_minus_healthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.431576</td>\n",
       "      <td>0.431576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>None</td>\n",
       "      <td>0.422574</td>\n",
       "      <td>0.422574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>household_income_per_person</td>\n",
       "      <td>None</td>\n",
       "      <td>0.417226</td>\n",
       "      <td>0.417226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.417124</td>\n",
       "      <td>0.417124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wtp_liked_value_association-test_z_FDR_0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.416262</td>\n",
       "      <td>0.416262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>IMI_effort_importance_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.413961</td>\n",
       "      <td>0.413961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 101 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*umpqua EDM*mckenzie BIS_11*umpqua BIS_11*mckenzie PCS*umpqua PCS*mckenzie ACES_sum*umpqua ACES_sum*mckenzie BFI_agreeableness*umpqua BFI_agreeableness*mckenzie BFI_conscientiousness*umpqua BFI_conscientiousness*mckenzie BFI_extraversion*umpqua BFI_extraversion*mckenzie BFI_neuroticism*umpqua BFI_neuroticism*mckenzie BFI_openness*umpqua BFI_openness*mckenzie NCS_total*umpqua NCS_total*mckenzie TESQ_E_sum*umpqua TESQ_E_sum*mckenzie SRHI_healthy_minus_unhealthy*umpqua SRHI_healthy_minus_unhealthy*mckenzie RTFS_f1_minus_f2*umpqua RTFS_f1_minus_f2*mckenzie cancer_promoting_minus_preventing_FCI*umpqua cancer_promoting_minus_preventing_FCI*mckenzie age365*umpqua age365*mckenzie education_own*umpqua education_own*mckenzie household_income_per_person*umpqua household_income_per_person*mckenzie SST_PostErrorSlowW1_mean*umpqua SST_PostErrorSlowW1_mean*mckenzie SST_mean_ssrt_0*umpqua SST_mean_ssrt_0*mckenzie ROC_Crave_Regulate_Minus_Look*umpqua ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Minus_Neutral*umpqua ROC_Crave_Minus_Neutral*mckenzie WTP_unhealthy_minus_healthy*umpqua WTP_unhealthy_minus_healthy*mckenzie wtp_liked_value_association-test_z_FDR_0.01*umpqua wtp_liked_value_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_multivariate_regulation*umpqua roc_reappraiseCrave_multivariate_regulation*mckenzie sst_CorrectGo_striatum_joint_mask*umpqua sst_CorrectGo_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*umpqua sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie Planning_aggregate*umpqua Planning_aggregate*mckenzie Restraint_aggregate*umpqua Restraint_aggregate*mckenzie IMI_effort_importance_aggregate*umpqua IMI_effort_importance_aggregate*mckenzie wtp_roc_koban_kober_craving_combined*umpqua wtp_roc_koban_kober_craving_combined*mckenzie birthsex_factor_Male*umpqua birthsex_factor_Male*mckenzie\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 68.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 64.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 59.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 315.63 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 453.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 368.48 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 114.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.641e+00, tolerance: 1.264e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 84.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 70.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 314.64 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 330.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 313.65 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 60.40 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.274e+00, tolerance: 1.263e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 54.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 46.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 248.88 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 325.85 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 390.82 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 73.52 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 73.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 55.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 236.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 303.87 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 259.28 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 51.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 55.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 45.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 278.19 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 376.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 286.04 seconds\n",
      "scores:\n",
      "[-0.09403776836473687, -0.0244033673457138, -0.036417324918633254, 0.0013158919311293538, -0.03618713661188688]\n",
      "overall_score:\n",
      "-0.03794594106196829\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035622</td>\n",
       "      <td>0.020334</td>\n",
       "      <td>0.037274</td>\n",
       "      <td>0.027058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.036722</td>\n",
       "      <td>0.016379</td>\n",
       "      <td>0.040770</td>\n",
       "      <td>0.027155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.038791</td>\n",
       "      <td>0.029042</td>\n",
       "      <td>0.037931</td>\n",
       "      <td>0.032892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.038832</td>\n",
       "      <td>0.029204</td>\n",
       "      <td>0.037947</td>\n",
       "      <td>0.033562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040707</td>\n",
       "      <td>0.029654</td>\n",
       "      <td>0.035739</td>\n",
       "      <td>0.030768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040778</td>\n",
       "      <td>0.030547</td>\n",
       "      <td>0.036317</td>\n",
       "      <td>0.031850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.041934</td>\n",
       "      <td>0.026901</td>\n",
       "      <td>0.039883</td>\n",
       "      <td>0.025602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042044</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.044896</td>\n",
       "      <td>0.025128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042106</td>\n",
       "      <td>0.030344</td>\n",
       "      <td>0.035999</td>\n",
       "      <td>0.029326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.042488</td>\n",
       "      <td>0.026295</td>\n",
       "      <td>0.040648</td>\n",
       "      <td>0.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042793</td>\n",
       "      <td>0.032455</td>\n",
       "      <td>0.035938</td>\n",
       "      <td>0.030141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042821</td>\n",
       "      <td>0.029751</td>\n",
       "      <td>0.038061</td>\n",
       "      <td>0.029120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.043344</td>\n",
       "      <td>0.031445</td>\n",
       "      <td>0.036763</td>\n",
       "      <td>0.027478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.043635</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.036947</td>\n",
       "      <td>0.031846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.044048</td>\n",
       "      <td>0.029032</td>\n",
       "      <td>0.037136</td>\n",
       "      <td>0.030683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046505</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>0.040334</td>\n",
       "      <td>0.024355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.047720</td>\n",
       "      <td>0.025020</td>\n",
       "      <td>0.041363</td>\n",
       "      <td>0.024084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.048182</td>\n",
       "      <td>0.021890</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>0.030278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.048388</td>\n",
       "      <td>0.022954</td>\n",
       "      <td>0.050941</td>\n",
       "      <td>0.027987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.048566</td>\n",
       "      <td>0.022894</td>\n",
       "      <td>0.051215</td>\n",
       "      <td>0.027321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua</td>\n",
       "      <td>0.280675</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.005904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EDM*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>BIS_11*mckenzie</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>PCS*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>BFI_openness*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>BFI_openness*mckenzie</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>NCS_total*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TESQ_E_sum*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>TESQ_E_sum*mckenzie</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>sst_CorrectGo_striatum_joint_mask*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Planning_aggregate*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Restraint_aggregate*mckenzie</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IMI_effort_importance_aggregate*umpqua</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.026705836214731705, 'condition_inddiff': -0.108865217812564, 'condition_inddiff_interactions': -0.03794594106196829}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'ANTINUTRIENT_DENSITY_2wkAverage', dev_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NUTRIENT_DENSITY_2wkAverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.67 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.87 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.95 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.40 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 4.14 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.81 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.78 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.08 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.68 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.12 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "scores:\n",
      "[0.04392208933989716, -0.028137394290918882, -0.014454066698666779, -0.01817552415051038, -0.005045457115460783]\n",
      "overall_score:\n",
      "-0.004378070583131932\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040517</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.040517</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040517</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.040526</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040526</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040526</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.041038</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.034670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041038</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.034670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041038</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.034670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041752</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.041752</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041752</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.041854</td>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>0.043332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041854</td>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>0.043332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>2.442942</td>\n",
       "      <td>0.038606</td>\n",
       "      <td>0.038606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>-0.266588</td>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.001864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 35 predictors in the set condition_inddiff\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.97 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 5.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 17.36 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.37 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.07 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.34 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 4.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 22.16 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 11.90 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.68 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 1.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.88 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.27 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.60 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 4.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 13.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.97 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.01 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.30 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 5.22 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.78 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 20.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.28 seconds\n",
      "scores:\n",
      "[-0.042483116989998404, 0.0038038545551630776, 0.006185702822778749, 0.011255821458688198, -0.11248584119674021]\n",
      "overall_score:\n",
      "-0.026744715870021717\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030559</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.054266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030815</td>\n",
       "      <td>0.042775</td>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.052979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.046155</td>\n",
       "      <td>0.053954</td>\n",
       "      <td>0.044059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.034914</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.053641</td>\n",
       "      <td>0.043894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.036116</td>\n",
       "      <td>0.043759</td>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.049537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.036117</td>\n",
       "      <td>0.043792</td>\n",
       "      <td>0.051278</td>\n",
       "      <td>0.049520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.036537</td>\n",
       "      <td>0.050965</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>0.042848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.037802</td>\n",
       "      <td>0.052022</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.043827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039095</td>\n",
       "      <td>0.053209</td>\n",
       "      <td>0.089103</td>\n",
       "      <td>0.048804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039173</td>\n",
       "      <td>0.047178</td>\n",
       "      <td>0.080647</td>\n",
       "      <td>0.054629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039771</td>\n",
       "      <td>0.045667</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>0.051915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040691</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>0.072465</td>\n",
       "      <td>0.036511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041023</td>\n",
       "      <td>0.041339</td>\n",
       "      <td>0.056494</td>\n",
       "      <td>0.056061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041683</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>0.051831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042223</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>0.055022</td>\n",
       "      <td>0.052959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042359</td>\n",
       "      <td>0.040735</td>\n",
       "      <td>0.052956</td>\n",
       "      <td>0.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042364</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.053186</td>\n",
       "      <td>0.051373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042561</td>\n",
       "      <td>0.054343</td>\n",
       "      <td>0.092156</td>\n",
       "      <td>0.051829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042668</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>0.065010</td>\n",
       "      <td>0.049578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.043599</td>\n",
       "      <td>0.043342</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>0.049022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.033480</td>\n",
       "      <td>0.033480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.027537</td>\n",
       "      <td>0.027537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019864</td>\n",
       "      <td>0.019864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCS</td>\n",
       "      <td>None</td>\n",
       "      <td>0.011884</td>\n",
       "      <td>0.011884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.011170</td>\n",
       "      <td>0.011170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 101 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*umpqua EDM*mckenzie BIS_11*umpqua BIS_11*mckenzie PCS*umpqua PCS*mckenzie ACES_sum*umpqua ACES_sum*mckenzie BFI_agreeableness*umpqua BFI_agreeableness*mckenzie BFI_conscientiousness*umpqua BFI_conscientiousness*mckenzie BFI_extraversion*umpqua BFI_extraversion*mckenzie BFI_neuroticism*umpqua BFI_neuroticism*mckenzie BFI_openness*umpqua BFI_openness*mckenzie NCS_total*umpqua NCS_total*mckenzie TESQ_E_sum*umpqua TESQ_E_sum*mckenzie SRHI_healthy_minus_unhealthy*umpqua SRHI_healthy_minus_unhealthy*mckenzie RTFS_f1_minus_f2*umpqua RTFS_f1_minus_f2*mckenzie cancer_promoting_minus_preventing_FCI*umpqua cancer_promoting_minus_preventing_FCI*mckenzie age365*umpqua age365*mckenzie education_own*umpqua education_own*mckenzie household_income_per_person*umpqua household_income_per_person*mckenzie SST_PostErrorSlowW1_mean*umpqua SST_PostErrorSlowW1_mean*mckenzie SST_mean_ssrt_0*umpqua SST_mean_ssrt_0*mckenzie ROC_Crave_Regulate_Minus_Look*umpqua ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Minus_Neutral*umpqua ROC_Crave_Minus_Neutral*mckenzie WTP_unhealthy_minus_healthy*umpqua WTP_unhealthy_minus_healthy*mckenzie wtp_liked_value_association-test_z_FDR_0.01*umpqua wtp_liked_value_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_multivariate_regulation*umpqua roc_reappraiseCrave_multivariate_regulation*mckenzie sst_CorrectGo_striatum_joint_mask*umpqua sst_CorrectGo_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*umpqua sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie Planning_aggregate*umpqua Planning_aggregate*mckenzie Restraint_aggregate*umpqua Restraint_aggregate*mckenzie IMI_effort_importance_aggregate*umpqua IMI_effort_importance_aggregate*mckenzie wtp_roc_koban_kober_craving_combined*umpqua wtp_roc_koban_kober_craving_combined*mckenzie birthsex_factor_Male*umpqua birthsex_factor_Male*mckenzie\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 58.40 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+03, tolerance: 5.469e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.610e+02, tolerance: 5.146e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e+02, tolerance: 4.585e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.981e+02, tolerance: 5.778e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e+01, tolerance: 5.146e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 56.36 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 46.91 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 245.66 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 319.28 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 314.15 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 58.91 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e+01, tolerance: 5.226e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.937e+02, tolerance: 5.346e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+02, tolerance: 5.064e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.181e+02, tolerance: 5.570e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.159e+00, tolerance: 5.064e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+01, tolerance: 5.570e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 52.54 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 46.86 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 237.96 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 332.87 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 298.34 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 54.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.989e+01, tolerance: 5.619e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+02, tolerance: 5.109e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e+02, tolerance: 4.825e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.038e+02, tolerance: 5.756e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+02, tolerance: 5.619e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 58.34 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 48.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 239.95 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 355.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 282.77 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 54.63 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+02, tolerance: 4.597e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.565e+01, tolerance: 4.693e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+02, tolerance: 4.237e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.080e+02, tolerance: 4.182e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 57.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 46.12 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 233.78 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 326.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 284.89 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 59.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.676e+02, tolerance: 4.600e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.437e+01, tolerance: 4.901e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+02, tolerance: 4.709e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 3.963e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+01, tolerance: 4.709e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 61.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 45.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 269.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 324.82 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 283.49 seconds\n",
      "scores:\n",
      "[-0.10001439510266241, -0.03780431345304791, 0.04105006803902789, -0.013242022953906085, -0.03563203213369315]\n",
      "overall_score:\n",
      "-0.029128539120856334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.037503</td>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.036135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038285</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>0.031836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038331</td>\n",
       "      <td>0.031672</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>0.034640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038848</td>\n",
       "      <td>0.034645</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>0.032866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039284</td>\n",
       "      <td>0.031748</td>\n",
       "      <td>0.060553</td>\n",
       "      <td>0.049697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039936</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.028006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040153</td>\n",
       "      <td>0.031727</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.046183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040349</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.070842</td>\n",
       "      <td>0.033423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040684</td>\n",
       "      <td>0.031953</td>\n",
       "      <td>0.058270</td>\n",
       "      <td>0.046008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040915</td>\n",
       "      <td>0.032856</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>0.047222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041176</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.058940</td>\n",
       "      <td>0.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041548</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>0.045761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041626</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.052086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041715</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.062130</td>\n",
       "      <td>0.046276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041765</td>\n",
       "      <td>0.031476</td>\n",
       "      <td>0.058735</td>\n",
       "      <td>0.044589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041769</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.055043</td>\n",
       "      <td>0.046685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041796</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.064880</td>\n",
       "      <td>0.044730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041847</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.057705</td>\n",
       "      <td>0.033519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041948</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.062146</td>\n",
       "      <td>0.047172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041979</td>\n",
       "      <td>0.034024</td>\n",
       "      <td>0.057392</td>\n",
       "      <td>0.045267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_sum*mckenzie</td>\n",
       "      <td>1.449145</td>\n",
       "      <td>0.025430</td>\n",
       "      <td>0.025430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Planning_aggregate*umpqua</td>\n",
       "      <td>0.739333</td>\n",
       "      <td>0.007863</td>\n",
       "      <td>0.007863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Restraint_aggregate*mckenzie</td>\n",
       "      <td>-0.835481</td>\n",
       "      <td>0.007591</td>\n",
       "      <td>0.007591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EDM*umpqua</td>\n",
       "      <td>0.552099</td>\n",
       "      <td>0.004342</td>\n",
       "      <td>0.004342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look*umpqua</td>\n",
       "      <td>-0.378407</td>\n",
       "      <td>0.003079</td>\n",
       "      <td>0.003079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IMI_effort_importance_aggregate*umpqua</td>\n",
       "      <td>0.360889</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.002348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BIS_11*umpqua</td>\n",
       "      <td>0.381820</td>\n",
       "      <td>0.002310</td>\n",
       "      <td>0.002310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*umpqua</td>\n",
       "      <td>-0.078163</td>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.000214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Restraint_aggregate*umpqua</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BFI_extraversion*umpqua</td>\n",
       "      <td>-0.023823</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>0.000036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.004378070583131932, 'condition_inddiff': -0.026744715870021717, 'condition_inddiff_interactions': -0.029128539120856334}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'NUTRIENT_RICH_FOODS_INDEX_2wkAverage', dev_cv_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Fat Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict bf with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 1.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 1.16 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 2.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 4.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.86 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.72 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.76 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.30 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 5.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.34 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.65 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.81 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.09 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 5.02 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.08 seconds\n",
      "scores:\n",
      "[-0.004865573443926241, -0.013803364019908226, -0.0003450623419718468, -0.04127987204266237, -0.0998667589724096]\n",
      "overall_score:\n",
      "-0.03203212616417565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.019546</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.019546</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019546</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.019549</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.008392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019549</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.008392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.019549</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.021891</td>\n",
       "      <td>0.008392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019578</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.008391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.019578</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.008391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.019578</td>\n",
       "      <td>0.004635</td>\n",
       "      <td>0.021897</td>\n",
       "      <td>0.008391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.020021</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.008348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020021</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.008348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020021</td>\n",
       "      <td>0.004578</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.008348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020030</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.010153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.020030</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.010153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020030</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.018481</td>\n",
       "      <td>0.010153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020051</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.009934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.020051</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.009934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020051</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.018541</td>\n",
       "      <td>0.009934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020052</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.009941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020052</td>\n",
       "      <td>0.004458</td>\n",
       "      <td>0.018540</td>\n",
       "      <td>0.009941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict bf with 35 predictors in the set condition_inddiff\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 26.21 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 35.00 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 18.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 13.75 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 24.32 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 30.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 17.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.77 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 22.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 31.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 17.91 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.41 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 4.63 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 22.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 31.63 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 17.46 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 22.76 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 33.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 22.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 13.62 seconds\n",
      "scores:\n",
      "[-0.03197763305593604, -0.0059418623666895876, -0.1500515305348642, -0.11538278763211784, -0.13201397558217653]\n",
      "overall_score:\n",
      "-0.08707355783435684\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.014354</td>\n",
       "      <td>0.007782</td>\n",
       "      <td>0.044322</td>\n",
       "      <td>0.007004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.015325</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.033203</td>\n",
       "      <td>0.007905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.015778</td>\n",
       "      <td>0.013198</td>\n",
       "      <td>0.038747</td>\n",
       "      <td>0.011055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016192</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.038714</td>\n",
       "      <td>0.009396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016785</td>\n",
       "      <td>0.010152</td>\n",
       "      <td>0.032449</td>\n",
       "      <td>0.009643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016987</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.028315</td>\n",
       "      <td>0.008904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.017161</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.034558</td>\n",
       "      <td>0.007119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017256</td>\n",
       "      <td>0.005015</td>\n",
       "      <td>0.026112</td>\n",
       "      <td>0.009378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.017513</td>\n",
       "      <td>0.006368</td>\n",
       "      <td>0.031501</td>\n",
       "      <td>0.008265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017596</td>\n",
       "      <td>0.008805</td>\n",
       "      <td>0.028747</td>\n",
       "      <td>0.009145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017702</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.030393</td>\n",
       "      <td>0.009810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017714</td>\n",
       "      <td>0.010607</td>\n",
       "      <td>0.027762</td>\n",
       "      <td>0.013451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018040</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.027644</td>\n",
       "      <td>0.009662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018194</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>0.032953</td>\n",
       "      <td>0.008675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018370</td>\n",
       "      <td>0.010524</td>\n",
       "      <td>0.033268</td>\n",
       "      <td>0.013121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018415</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.025521</td>\n",
       "      <td>0.010938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018424</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.036358</td>\n",
       "      <td>0.012670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018445</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>0.026193</td>\n",
       "      <td>0.010412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018539</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.026134</td>\n",
       "      <td>0.011395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018544</td>\n",
       "      <td>0.011026</td>\n",
       "      <td>0.023545</td>\n",
       "      <td>0.013068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>household_income_per_person</td>\n",
       "      <td>None</td>\n",
       "      <td>0.012063</td>\n",
       "      <td>0.012063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.009910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>IMI_effort_importance_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009903</td>\n",
       "      <td>0.009903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sst_CorrectGo_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009275</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009064</td>\n",
       "      <td>0.009064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008850</td>\n",
       "      <td>0.008850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wtp_liked_value_association-test_z_FDR_0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008619</td>\n",
       "      <td>0.008619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.008127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sst_CorrectGoFollowingFailedStop_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007603</td>\n",
       "      <td>0.007603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.007347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006988</td>\n",
       "      <td>0.006988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SST_PostErrorSlowW1_mean</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>0.006379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.006096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006022</td>\n",
       "      <td>0.006022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BFI_openness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005848</td>\n",
       "      <td>0.005848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TESQ_E_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005617</td>\n",
       "      <td>0.005617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Planning_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005511</td>\n",
       "      <td>0.005511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005310</td>\n",
       "      <td>0.005310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005262</td>\n",
       "      <td>0.005262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BFI_conscientiousness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005131</td>\n",
       "      <td>0.005131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict bf with 101 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*umpqua EDM*mckenzie BIS_11*umpqua BIS_11*mckenzie PCS*umpqua PCS*mckenzie ACES_sum*umpqua ACES_sum*mckenzie BFI_agreeableness*umpqua BFI_agreeableness*mckenzie BFI_conscientiousness*umpqua BFI_conscientiousness*mckenzie BFI_extraversion*umpqua BFI_extraversion*mckenzie BFI_neuroticism*umpqua BFI_neuroticism*mckenzie BFI_openness*umpqua BFI_openness*mckenzie NCS_total*umpqua NCS_total*mckenzie TESQ_E_sum*umpqua TESQ_E_sum*mckenzie SRHI_healthy_minus_unhealthy*umpqua SRHI_healthy_minus_unhealthy*mckenzie RTFS_f1_minus_f2*umpqua RTFS_f1_minus_f2*mckenzie cancer_promoting_minus_preventing_FCI*umpqua cancer_promoting_minus_preventing_FCI*mckenzie age365*umpqua age365*mckenzie education_own*umpqua education_own*mckenzie household_income_per_person*umpqua household_income_per_person*mckenzie SST_PostErrorSlowW1_mean*umpqua SST_PostErrorSlowW1_mean*mckenzie SST_mean_ssrt_0*umpqua SST_mean_ssrt_0*mckenzie ROC_Crave_Regulate_Minus_Look*umpqua ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Minus_Neutral*umpqua ROC_Crave_Minus_Neutral*mckenzie WTP_unhealthy_minus_healthy*umpqua WTP_unhealthy_minus_healthy*mckenzie wtp_liked_value_association-test_z_FDR_0.01*umpqua wtp_liked_value_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_multivariate_regulation*umpqua roc_reappraiseCrave_multivariate_regulation*mckenzie sst_CorrectGo_striatum_joint_mask*umpqua sst_CorrectGo_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*umpqua sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie Planning_aggregate*umpqua Planning_aggregate*mckenzie Restraint_aggregate*umpqua Restraint_aggregate*mckenzie IMI_effort_importance_aggregate*umpqua IMI_effort_importance_aggregate*mckenzie wtp_roc_koban_kober_craving_combined*umpqua wtp_roc_koban_kober_craving_combined*mckenzie birthsex_factor_Male*umpqua birthsex_factor_Male*mckenzie\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 61.06 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 59.14 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 124.81 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 309.25 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 352.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 326.47 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 35.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 33.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 71.22 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 155.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 191.07 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 169.77 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 32.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 33.32 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 65.78 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 177.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 196.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 169.67 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 33.20 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 33.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 63.56 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 154.90 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 192.36 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 176.10 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 36.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 34.23 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 113.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 281.72 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 377.12 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 299.90 seconds\n",
      "scores:\n",
      "[-0.011580328051793431, 0.015601453407046328, -0.058215751483468026, -0.5151464844796534, -0.16224329747794397]\n",
      "overall_score:\n",
      "-0.1463168816171625\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.032095</td>\n",
       "      <td>0.065939</td>\n",
       "      <td>0.017948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.000295</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.048346</td>\n",
       "      <td>0.015307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.004660</td>\n",
       "      <td>0.011963</td>\n",
       "      <td>0.031688</td>\n",
       "      <td>0.011246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.006810</td>\n",
       "      <td>0.027628</td>\n",
       "      <td>0.055149</td>\n",
       "      <td>0.010920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.006882</td>\n",
       "      <td>0.037419</td>\n",
       "      <td>0.075092</td>\n",
       "      <td>0.014601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.009066</td>\n",
       "      <td>0.008996</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.013376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.010278</td>\n",
       "      <td>0.039358</td>\n",
       "      <td>0.062585</td>\n",
       "      <td>0.013327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.013091</td>\n",
       "      <td>0.032410</td>\n",
       "      <td>0.010068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.012054</td>\n",
       "      <td>0.017255</td>\n",
       "      <td>0.044418</td>\n",
       "      <td>0.015450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.012535</td>\n",
       "      <td>0.010685</td>\n",
       "      <td>0.027817</td>\n",
       "      <td>0.009178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.015831</td>\n",
       "      <td>0.006094</td>\n",
       "      <td>0.032462</td>\n",
       "      <td>0.011203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.016080</td>\n",
       "      <td>0.015426</td>\n",
       "      <td>0.040083</td>\n",
       "      <td>0.013746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.016910</td>\n",
       "      <td>0.025346</td>\n",
       "      <td>0.060182</td>\n",
       "      <td>0.018725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.017541</td>\n",
       "      <td>0.009308</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.009650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.018538</td>\n",
       "      <td>0.004079</td>\n",
       "      <td>0.024241</td>\n",
       "      <td>0.008263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.019248</td>\n",
       "      <td>0.049877</td>\n",
       "      <td>0.077492</td>\n",
       "      <td>0.013325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.019300</td>\n",
       "      <td>0.011520</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.009553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.019467</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.008408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.019498</td>\n",
       "      <td>0.004639</td>\n",
       "      <td>0.022142</td>\n",
       "      <td>0.008800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.019550</td>\n",
       "      <td>0.004612</td>\n",
       "      <td>0.022057</td>\n",
       "      <td>0.008728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>household_income_per_person*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.027706</td>\n",
       "      <td>0.027706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>wtp_liked_value_association-test_z_FDR_0.01*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.025488</td>\n",
       "      <td>0.025488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.022318</td>\n",
       "      <td>0.022318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021318</td>\n",
       "      <td>0.021318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019453</td>\n",
       "      <td>0.019453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>household_income_per_person*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019002</td>\n",
       "      <td>0.019002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>roc_reappraiseCrave_multivariate_regulation*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.018331</td>\n",
       "      <td>0.018331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>birthsex_factor_Male*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.018212</td>\n",
       "      <td>0.018212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>education_own*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.018066</td>\n",
       "      <td>0.018066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.017030</td>\n",
       "      <td>0.017030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>RTFS_f1_minus_f2*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.016800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>household_income_per_person</td>\n",
       "      <td>None</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.016759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>birthsex_factor_Male*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>0.015968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015739</td>\n",
       "      <td>0.015739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SST_PostErrorSlowW1_mean*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015624</td>\n",
       "      <td>0.015624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>roc_reappraiseCrave_multivariate_regulation</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.015262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.014739</td>\n",
       "      <td>0.014739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>None</td>\n",
       "      <td>0.014654</td>\n",
       "      <td>0.014654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>RTFS_f1_minus_f2*umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.014128</td>\n",
       "      <td>0.014128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask*mckenzie</td>\n",
       "      <td>None</td>\n",
       "      <td>0.013521</td>\n",
       "      <td>0.013521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.03203212616417565, 'condition_inddiff': -0.08707355783435684, 'condition_inddiff_interactions': -0.1463168816171625}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'bf', dev_cv_analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutrient density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are umpqua mckenzie\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.73 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.85 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.94 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.52 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.40 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.69 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 3.98 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.10 seconds\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 5.24 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.08 seconds\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.54 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.77 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.69 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.76 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.65 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 4.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Time elapsed for DecisionTreeRegressor: 0.11 seconds\n",
      "scores:\n",
      "[0.04392208933989716, -0.028137394290918882, -0.014454066698666779, -0.01817552415051038, -0.005045457115460783]\n",
      "overall_score:\n",
      "-0.004378070583131932\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040289</td>\n",
       "      <td>0.033230</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>0.033874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040517</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.040517</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040517</td>\n",
       "      <td>0.031182</td>\n",
       "      <td>0.065708</td>\n",
       "      <td>0.032516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.040526</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040526</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040526</td>\n",
       "      <td>0.033344</td>\n",
       "      <td>0.070671</td>\n",
       "      <td>0.034001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.041038</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.034670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041038</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.034670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041038</td>\n",
       "      <td>0.033517</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.034670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041752</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.041752</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041752</td>\n",
       "      <td>0.033168</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.043392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041791</td>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.035941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.041854</td>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>0.043332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041854</td>\n",
       "      <td>0.033045</td>\n",
       "      <td>0.059533</td>\n",
       "      <td>0.043332</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>2.442942</td>\n",
       "      <td>0.041545</td>\n",
       "      <td>0.041545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>-0.266588</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 35 predictors in the set condition_inddiff\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.31 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 4.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 16.32 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.14 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.20 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.59 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 13.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.56 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 16.49 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.31 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.98 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.89 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.54 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.28 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 4.71 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 17.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 17.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.20 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 4.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 13.15 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 17.12 seconds\n",
      "scores:\n",
      "[-0.042483116989998404, 0.0038038545551630776, 0.006185702822778749, 0.011255821458688198, -0.11248584119674021]\n",
      "overall_score:\n",
      "-0.026744715870021717\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030559</td>\n",
       "      <td>0.043862</td>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.054266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030815</td>\n",
       "      <td>0.042775</td>\n",
       "      <td>0.066149</td>\n",
       "      <td>0.052979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.034736</td>\n",
       "      <td>0.046155</td>\n",
       "      <td>0.053954</td>\n",
       "      <td>0.044059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.034914</td>\n",
       "      <td>0.046071</td>\n",
       "      <td>0.053641</td>\n",
       "      <td>0.043894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.036116</td>\n",
       "      <td>0.043759</td>\n",
       "      <td>0.051515</td>\n",
       "      <td>0.049537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.036117</td>\n",
       "      <td>0.043792</td>\n",
       "      <td>0.051278</td>\n",
       "      <td>0.049520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.036537</td>\n",
       "      <td>0.050965</td>\n",
       "      <td>0.059517</td>\n",
       "      <td>0.042848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.037802</td>\n",
       "      <td>0.052022</td>\n",
       "      <td>0.061069</td>\n",
       "      <td>0.043827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039095</td>\n",
       "      <td>0.053209</td>\n",
       "      <td>0.089103</td>\n",
       "      <td>0.048804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039173</td>\n",
       "      <td>0.047178</td>\n",
       "      <td>0.080647</td>\n",
       "      <td>0.054629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039771</td>\n",
       "      <td>0.045667</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>0.051915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.040691</td>\n",
       "      <td>0.055799</td>\n",
       "      <td>0.072465</td>\n",
       "      <td>0.036511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041023</td>\n",
       "      <td>0.041339</td>\n",
       "      <td>0.056494</td>\n",
       "      <td>0.056061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041683</td>\n",
       "      <td>0.039118</td>\n",
       "      <td>0.058152</td>\n",
       "      <td>0.051831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042223</td>\n",
       "      <td>0.047028</td>\n",
       "      <td>0.055022</td>\n",
       "      <td>0.052959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042359</td>\n",
       "      <td>0.040735</td>\n",
       "      <td>0.052956</td>\n",
       "      <td>0.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042364</td>\n",
       "      <td>0.040698</td>\n",
       "      <td>0.053186</td>\n",
       "      <td>0.051373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042561</td>\n",
       "      <td>0.054343</td>\n",
       "      <td>0.092156</td>\n",
       "      <td>0.051829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042668</td>\n",
       "      <td>0.041593</td>\n",
       "      <td>0.065010</td>\n",
       "      <td>0.049578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.043599</td>\n",
       "      <td>0.043342</td>\n",
       "      <td>0.048054</td>\n",
       "      <td>0.049022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.043284</td>\n",
       "      <td>0.043284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021837</td>\n",
       "      <td>0.021837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>umpqua</td>\n",
       "      <td>None</td>\n",
       "      <td>0.017132</td>\n",
       "      <td>0.017132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PCS</td>\n",
       "      <td>None</td>\n",
       "      <td>0.011041</td>\n",
       "      <td>0.011041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009619</td>\n",
       "      <td>0.009619</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV032', 'DEV007', 'DEV002', 'DEV280', 'DEV022'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 101 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are umpqua mckenzie EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*umpqua EDM*mckenzie BIS_11*umpqua BIS_11*mckenzie PCS*umpqua PCS*mckenzie ACES_sum*umpqua ACES_sum*mckenzie BFI_agreeableness*umpqua BFI_agreeableness*mckenzie BFI_conscientiousness*umpqua BFI_conscientiousness*mckenzie BFI_extraversion*umpqua BFI_extraversion*mckenzie BFI_neuroticism*umpqua BFI_neuroticism*mckenzie BFI_openness*umpqua BFI_openness*mckenzie NCS_total*umpqua NCS_total*mckenzie TESQ_E_sum*umpqua TESQ_E_sum*mckenzie SRHI_healthy_minus_unhealthy*umpqua SRHI_healthy_minus_unhealthy*mckenzie RTFS_f1_minus_f2*umpqua RTFS_f1_minus_f2*mckenzie cancer_promoting_minus_preventing_FCI*umpqua cancer_promoting_minus_preventing_FCI*mckenzie age365*umpqua age365*mckenzie education_own*umpqua education_own*mckenzie household_income_per_person*umpqua household_income_per_person*mckenzie SST_PostErrorSlowW1_mean*umpqua SST_PostErrorSlowW1_mean*mckenzie SST_mean_ssrt_0*umpqua SST_mean_ssrt_0*mckenzie ROC_Crave_Regulate_Minus_Look*umpqua ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Minus_Neutral*umpqua ROC_Crave_Minus_Neutral*mckenzie WTP_unhealthy_minus_healthy*umpqua WTP_unhealthy_minus_healthy*mckenzie wtp_liked_value_association-test_z_FDR_0.01*umpqua wtp_liked_value_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*umpqua roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_multivariate_regulation*umpqua roc_reappraiseCrave_multivariate_regulation*mckenzie sst_CorrectGo_striatum_joint_mask*umpqua sst_CorrectGo_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*umpqua sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*umpqua sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie Planning_aggregate*umpqua Planning_aggregate*mckenzie Restraint_aggregate*umpqua Restraint_aggregate*mckenzie IMI_effort_importance_aggregate*umpqua IMI_effort_importance_aggregate*mckenzie wtp_roc_koban_kober_craving_combined*umpqua wtp_roc_koban_kober_craving_combined*mckenzie birthsex_factor_Male*umpqua birthsex_factor_Male*mckenzie\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 56.72 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.150e+03, tolerance: 5.469e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.610e+02, tolerance: 5.146e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.054e+02, tolerance: 4.585e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.981e+02, tolerance: 5.778e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.352e+01, tolerance: 5.146e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 52.86 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 45.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 233.65 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 316.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 319.53 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 52.28 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.123e+01, tolerance: 5.226e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.937e+02, tolerance: 5.346e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.150e+02, tolerance: 5.064e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.181e+02, tolerance: 5.570e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.159e+00, tolerance: 5.064e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.913e+01, tolerance: 5.570e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 57.76 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 53.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 232.71 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 324.15 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 297.44 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 55.87 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.989e+01, tolerance: 5.619e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.546e+02, tolerance: 5.109e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.897e+02, tolerance: 4.825e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.038e+02, tolerance: 5.756e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.930e+02, tolerance: 5.619e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 59.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 43.90 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 246.97 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 357.36 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 295.80 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 55.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.860e+02, tolerance: 4.597e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.565e+01, tolerance: 4.693e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.707e+02, tolerance: 4.237e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.080e+02, tolerance: 4.182e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 59.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 46.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 232.22 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 314.12 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 282.99 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 58.88 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.676e+02, tolerance: 4.600e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.437e+01, tolerance: 4.901e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.152e+02, tolerance: 4.709e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.033e+01, tolerance: 3.963e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.450e+01, tolerance: 4.709e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 54.76 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 46.65 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 276.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 329.30 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x181be9b20>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 310.95 seconds\n",
      "scores:\n",
      "[-0.10001439510266241, -0.03780431345304791, 0.04105006803902789, -0.013242022953906085, -0.03563203213369315]\n",
      "overall_score:\n",
      "-0.029128539120856334\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.037503</td>\n",
       "      <td>0.028242</td>\n",
       "      <td>0.062959</td>\n",
       "      <td>0.036135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038285</td>\n",
       "      <td>0.032636</td>\n",
       "      <td>0.065546</td>\n",
       "      <td>0.031836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038331</td>\n",
       "      <td>0.031672</td>\n",
       "      <td>0.056473</td>\n",
       "      <td>0.034640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038848</td>\n",
       "      <td>0.034645</td>\n",
       "      <td>0.067638</td>\n",
       "      <td>0.032866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039284</td>\n",
       "      <td>0.031748</td>\n",
       "      <td>0.060553</td>\n",
       "      <td>0.049697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.039936</td>\n",
       "      <td>0.028973</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.028006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040153</td>\n",
       "      <td>0.031727</td>\n",
       "      <td>0.060703</td>\n",
       "      <td>0.046183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040349</td>\n",
       "      <td>0.035414</td>\n",
       "      <td>0.070842</td>\n",
       "      <td>0.033423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040684</td>\n",
       "      <td>0.031953</td>\n",
       "      <td>0.058270</td>\n",
       "      <td>0.046008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040915</td>\n",
       "      <td>0.032856</td>\n",
       "      <td>0.055812</td>\n",
       "      <td>0.047222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041176</td>\n",
       "      <td>0.030637</td>\n",
       "      <td>0.058940</td>\n",
       "      <td>0.029704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041548</td>\n",
       "      <td>0.035035</td>\n",
       "      <td>0.063884</td>\n",
       "      <td>0.045761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041626</td>\n",
       "      <td>0.035549</td>\n",
       "      <td>0.058588</td>\n",
       "      <td>0.052086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041715</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.062130</td>\n",
       "      <td>0.046276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041765</td>\n",
       "      <td>0.031476</td>\n",
       "      <td>0.058735</td>\n",
       "      <td>0.044589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041769</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.055043</td>\n",
       "      <td>0.046685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x181be9b20&gt;}</th>\n",
       "      <td>-0.041796</td>\n",
       "      <td>0.034668</td>\n",
       "      <td>0.064880</td>\n",
       "      <td>0.044730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041847</td>\n",
       "      <td>0.028592</td>\n",
       "      <td>0.057705</td>\n",
       "      <td>0.033519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041948</td>\n",
       "      <td>0.033346</td>\n",
       "      <td>0.062146</td>\n",
       "      <td>0.047172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041979</td>\n",
       "      <td>0.034024</td>\n",
       "      <td>0.057392</td>\n",
       "      <td>0.045267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_sum*mckenzie</td>\n",
       "      <td>1.449145</td>\n",
       "      <td>0.018393</td>\n",
       "      <td>0.018393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Restraint_aggregate*mckenzie</td>\n",
       "      <td>-0.835481</td>\n",
       "      <td>0.012204</td>\n",
       "      <td>0.012204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Planning_aggregate*umpqua</td>\n",
       "      <td>0.739333</td>\n",
       "      <td>0.007302</td>\n",
       "      <td>0.007302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>EDM*umpqua</td>\n",
       "      <td>0.552099</td>\n",
       "      <td>0.003970</td>\n",
       "      <td>0.003970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look*umpqua</td>\n",
       "      <td>-0.378407</td>\n",
       "      <td>0.003056</td>\n",
       "      <td>0.003056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>BIS_11*umpqua</td>\n",
       "      <td>0.381820</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.002845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>IMI_effort_importance_aggregate*umpqua</td>\n",
       "      <td>0.360889</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>0.002272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*umpqua</td>\n",
       "      <td>-0.078163</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>0.000270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>BFI_extraversion*umpqua</td>\n",
       "      <td>-0.023823</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>0.000067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Restraint_aggregate*umpqua</td>\n",
       "      <td>0.019615</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.004378070583131932, 'condition_inddiff': -0.026744715870021717, 'condition_inddiff_interactions': -0.029128539120856334}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'NUTRIENT_DENSITY_2wkAverage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
