{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_interaction_util import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config.yml\") \n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic structure is the following:\n",
    "\n",
    "1. Run the following cross-validated analyses:\n",
    "   1. Predicting change by condition only\n",
    "   2. Predicting change by condition and neural and behavioral measures\n",
    "   3. Predicting change by condition, neural and behavioral measures, and their interactions\n",
    "2. Measure the predictivity of the three models above using anova\n",
    "3. Repeat the steps above separately for three outcome variables, change in: FFQ, ASA-24, and BFP\n",
    "4. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks to do to get this job done (not in order):\n",
    "\n",
    "1. Write the analysis pipeline above\n",
    "2. Get the neural data\n",
    "3. Get the behavioral data\n",
    "\n",
    "\n",
    "We have the behavioral data. Do we have the neural data already?\n",
    "\n",
    "What could we delegate here? Behavioral data we already have. We have mostly writen the analysis pipeline. The neural data could be passed on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behavioral data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dropbox_data_dir \u001b[39m=\u001b[39m config[\u001b[39m'\u001b[39m\u001b[39mdropbox_data_dir\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m----> 2\u001b[0m analysis_data, outcome_measures \u001b[39m=\u001b[39m load_and_preprocess_data(dropbox_data_dir)\n\u001b[1;32m      3\u001b[0m \u001b[39m#analysis_data_imputed = impute_data(analysis_data)\u001b[39;00m\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:639\u001b[0m, in \u001b[0;36mload_and_preprocess_data\u001b[0;34m(dropbox_data_dir)\u001b[0m\n\u001b[1;32m    636\u001b[0m data_by_ppt_path \u001b[39m=\u001b[39m dropbox_data_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/data_by_ppt.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    637\u001b[0m data_codebook_path \u001b[39m=\u001b[39m dropbox_data_dir \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mdata_codebook.csv\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 639\u001b[0m data_by_ppt \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(data_by_ppt_path)\n\u001b[1;32m    640\u001b[0m data_codebook \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data_codebook_path)\n\u001b[1;32m    642\u001b[0m \u001b[39m#find out which columns in data_by_ppt are missing from the codebook\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1753\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1752\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1753\u001b[0m     \u001b[39mreturn\u001b[39;00m mapping[engine](f, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions)\n\u001b[1;32m   1754\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m   1755\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/io/parsers/c_parser_wrapper.py:79\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m     kwds\u001b[39m.\u001b[39mpop(key, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m     78\u001b[0m kwds[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ensure_dtype_objs(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m---> 79\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m parsers\u001b[39m.\u001b[39;49mTextReader(src, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m     81\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munnamed_cols \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader\u001b[39m.\u001b[39munnamed_cols\n\u001b[1;32m     83\u001b[0m \u001b[39m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/pandas/_libs/parsers.pyx:554\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n",
    "analysis_data, outcome_measures = load_and_preprocess_data(dropbox_data_dir)\n",
    "#analysis_data_imputed = impute_data(analysis_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural data\n",
    "TBD!\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcome data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "                   feature_name  interaction_effect\n",
      "0                          BSCS                0.15\n",
      "3                           PCS               -0.15\n",
      "1                           EDM                0.15\n",
      "2                        BIS_11               -0.15\n",
      "74  WTP_unhealthy_minus_healthy                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.15\n",
      "5                       TRSQ                0.15\n",
      "6  ACES_neglectful_parenting               -0.15\n",
      "7                 ACES_abuse               -0.15\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n"
     ]
    }
   ],
   "source": [
    "synthetic_data, group_assignments = generate_synthetic_dev_outcomes_and_interactions(outcome_measures, analysis_data)\n",
    "\n",
    "interaction_effect_df = synthetic_data['X_weights']\n",
    "outcome_measures = synthetic_data['y']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 76)\n",
      "(275, 76)\n"
     ]
    }
   ],
   "source": [
    "outcome_nas,outcome_measures_nona, predictor_data_nona, group_assignment_onehots_nonan, group_assignments_nona = get_outcome_changes(outcome_measures, analysis_data, group_assignments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cancer_promoting_minus_preventing_FFQ_w1', 'bf_1',\n",
       "       'FFQ_v2_Mean_Energy_w1', 'bf_2',\n",
       "       'cancer_promoting_minus_preventing_FFQ_w2', 'FFQ_v2_Mean_Energy_w2',\n",
       "       'd_bf', 'd_cancer_promoting_minus_preventing_FFQ',\n",
       "       'd_FFQ_v2_Mean_Energy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_measures_nona.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome_measure\n",
       "d_bf                                       0.091314\n",
       "d_cancer_promoting_minus_preventing_FFQ    0.303603\n",
       "Name: correlation, dtype: float64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so. probably that correlation has something to do with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the correlations between outcome measures and the predictors; do this from scratch using a suitable correlation function\n",
    "#do this pairwise, ignoring na values in each paring\n",
    "outcome_measure_correlations = pd.DataFrame(columns=['outcome_measure','predictor','correlation'])\n",
    "for predictor in predictor_data_nona.columns:\n",
    "    for outcome_measure in ['d_bf', 'd_cancer_promoting_minus_preventing_FFQ']:\n",
    "        measured_corr = outcome_measures_nona[outcome_measure].corr(predictor_data_nona[predictor],method='pearson')\n",
    "        #print(\"Correlation between \" + outcome_measure + \" and \" + predictor + \" is \" + str(measured_corr))\n",
    "        measured_corr_df = {'outcome_measure':outcome_measure,'predictor':predictor,'correlation':measured_corr}\n",
    "        #append the df using concat\n",
    "        outcome_measure_correlations = pd.concat([outcome_measure_correlations,pd.DataFrame([measured_corr_df])])\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "outcome_measure\n",
       "d_bf                                       0.091314\n",
       "d_cancer_promoting_minus_preventing_FFQ    0.303603\n",
       "Name: correlation, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#group correlations by outcome_measure and get the mean of the absolutes of all of them\n",
    "outcome_measure_correlations.groupby('outcome_measure').correlation.apply(lambda x: np.mean(np.abs(x)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to add imputation in the dataset below!\n",
    "\n",
    "\n",
    "def score_and_present(predictor_data,\n",
    "                      outcome_measure,\n",
    "                      group_assignments\n",
    "                      ):\n",
    "    scoring_data = do_scoring_loop(X=predictor_data, y= outcome_measure, \n",
    "                groups = group_assignments_nona, \n",
    "                hyperparameter_selection_on_fold=do_hyperparameter_selection_loop_fast,\n",
    "                outer_folds=5)\n",
    "\n",
    "    scores = scoring_data['scores']\n",
    "    best_models = scoring_data['best_models']\n",
    "    best_params_df_list = scoring_data['best_params_df_list']\n",
    "    raw_cv_results_list = scoring_data['raw_cv_results_list']\n",
    "\n",
    "    print(\"scores:\")\n",
    "    print(scores)\n",
    "    overall_score = np.mean(scores)\n",
    "    print(\"overall_score:\")\n",
    "    print(overall_score)\n",
    "\n",
    "\n",
    "    \n",
    "    best_model = get_best_model(summarize_overall_df_results(raw_cv_results_list))\n",
    "    final_fit = do_final_fit(X=predictor_data, y= outcome_measure, final_model=best_model, impute_missing=True)\n",
    "\n",
    "    pd_imputed, X_was_imputed = apply_imputer(predictor_data)\n",
    "\n",
    "    final_results = present_model_results(X=pd_imputed, final_fit=final_fit, y=outcome_measure)\n",
    "\n",
    "    #print rows of final_results where feature_name is the list of features to check\n",
    "    base_regressors = interaction_effect_df.predictor[interaction_effect_df.interaction_effect!=0]\n",
    "    regressors_to_check = [x+y for y in ['','*ni','*san'] for x in base_regressors]\n",
    "    final_results['planned_regression'] = final_results['predictor'].isin(regressors_to_check)\n",
    "\n",
    "    #this is only for synethetic analysis\n",
    "    #present_results_vs_ground_truth_cors(pd_imputed,outcome_measure,group_assignments,final_results,base_regressors)\n",
    "\n",
    "    return({\n",
    "        'final_results':final_results,\n",
    "        'final_fit':final_fit,\n",
    "        'overall_score':overall_score\n",
    "        })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next: automate this flow into the different analyses we need to run, with different predictors and different DVs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_cols = ['ni','san']\n",
    "inddiff_cols = [\n",
    "        'ACES_sum',\n",
    "'BFI_agreeableness',\n",
    "'BFI_conscientiousness',\n",
    "'BFI_extraversion',\n",
    "'BFI_neuroticism',\n",
    "'BFI_openness',\n",
    "'IMI_effort_importance',\n",
    "'IMI_interest_enjoyment',\n",
    "'NCS_total',\n",
    "'PLAN_cognitive_strategies',\n",
    "'PLAN_mental_forecasting',\n",
    "'PLAN_temporal_orientation',\n",
    "'RMQ_assessment',\n",
    "'TESQ_E_sum',\n",
    "'SRHI_healthy_minus_unhealthy',\n",
    "'RTFS_f1_minus_f2',\n",
    "'cancer_promoting_minus_preventing_craved_FCI',\n",
    "'cancer_promoting_minus_preventing_liked_FCI',\n",
    "'cSES',\n",
    "'age365',\n",
    "'birthsex_factor_Male',\n",
    "'education_own',\n",
    "'SST_SSD',\n",
    "'SST_mean_ssrt_0',\n",
    "'ROC_Crave_Regulate_Minus_Look',\n",
    "'WTP_unhealthy_minus_healthy'\n",
    "    ]\n",
    "interaction_cols = [id + \"*\" + cond for id in inddiff_cols for cond in condition_cols]\n",
    "\n",
    "predictor_sets = {\n",
    "    'condition_only': condition_cols,\n",
    "    'condition_inddiff': condition_cols + inddiff_cols,\n",
    "    'condition_inddiff_interactions': condition_cols + inddiff_cols + interaction_cols\n",
    "}\n",
    "\n",
    "\n",
    "outcome_vars_to_try = [ 'd_bf', 'd_cancer_promoting_minus_preventing_FFQ'\n",
    "                       #,'d_ASA24'\n",
    "                       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "scores:\n",
      "[-0.018853697441670647, -0.005958228289782763, -0.039870089791836705, 0.03673646037941081, 0.028349319531920436]\n",
      "overall_score:\n",
      "8.075287760822558e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.649552</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.331564</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.649552</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.331564</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.649703</td>\n",
       "      <td>0.086995</td>\n",
       "      <td>0.331473</td>\n",
       "      <td>0.071671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.649703</td>\n",
       "      <td>0.086995</td>\n",
       "      <td>0.331473</td>\n",
       "      <td>0.071671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.656100</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.335264</td>\n",
       "      <td>0.059408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.656100</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.335264</td>\n",
       "      <td>0.059408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.676739</td>\n",
       "      <td>0.068765</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.058343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.676739</td>\n",
       "      <td>0.068765</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.058343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>0.087663</td>\n",
       "      <td>0.087663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>san</td>\n",
       "      <td>0.307429</td>\n",
       "      <td>0.006227</td>\n",
       "      <td>0.006227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "final_results = score_and_present(\n",
    "            predictor_data_nona[condition_cols],\n",
    "            outcome_measures_nona['d_bf'],\n",
    "            group_assignments_nona\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.075287760822558e-05"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results['overall_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_full_analysis(outcome_var):\n",
    "    model_outcomes = {}\n",
    "    for psk in predictor_sets.keys():\n",
    "        predictor_set = predictor_sets[psk]\n",
    "        print(\" attempting to predict \" + outcome_var + \" with \" + str(len(predictor_set)) + \" predictors in the set \" + psk)\n",
    "        print('predictors in that set are ' + \" \".join(predictor_set))\n",
    "        model_outcomes[psk] = score_and_present(\n",
    "            predictor_data_nona[predictor_set],\n",
    "            outcome_measures_nona[outcome_var],\n",
    "            group_assignments_nona\n",
    "                  )\n",
    "        \n",
    "    #get a dictionary of the overall scores for each model\n",
    "    model_outcomes_comparison = { k:\n",
    "        model_outcomes[k]['overall_score'] for k in model_outcomes.keys()}\n",
    "\n",
    "    print(model_outcomes_comparison)\n",
    "        \n",
    "    return(model_outcomes)\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Fat Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d_bf', 'd_cancer_promoting_minus_preventing_FFQ']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_vars_to_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempting to predict d_bf with 2 predictors in the set condition_only\n",
      "predictors in that set are ni san\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "scores:\n",
      "[-0.018853697441670647, -0.005958228289782763, -0.039870089791836705, 0.03673646037941081, 0.028349319531920436]\n",
      "overall_score:\n",
      "8.075287760822558e-05\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.649552</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.331564</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.649552</td>\n",
       "      <td>0.086856</td>\n",
       "      <td>0.331564</td>\n",
       "      <td>0.071333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.649703</td>\n",
       "      <td>0.086995</td>\n",
       "      <td>0.331473</td>\n",
       "      <td>0.071671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.649703</td>\n",
       "      <td>0.086995</td>\n",
       "      <td>0.331473</td>\n",
       "      <td>0.071671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.656100</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.335264</td>\n",
       "      <td>0.059408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.656100</td>\n",
       "      <td>0.080088</td>\n",
       "      <td>0.335264</td>\n",
       "      <td>0.059408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.676739</td>\n",
       "      <td>0.068765</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.058343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.676739</td>\n",
       "      <td>0.068765</td>\n",
       "      <td>0.329497</td>\n",
       "      <td>0.058343</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.897607</td>\n",
       "      <td>0.07771</td>\n",
       "      <td>0.07771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>san</td>\n",
       "      <td>0.307429</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.01290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempting to predict d_bf with 28 predictors in the set condition_inddiff\n",
      "predictors in that set are ni san ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_forecasting PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 birthsex_factor_Male education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "scores:\n",
      "[0.08668978398891969, 0.07343540779499014, 0.07759905930106603, 0.012296190365315152, -0.30008703257274094]\n",
      "overall_score:\n",
      "-0.010013318224489986\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.555001</td>\n",
       "      <td>0.122486</td>\n",
       "      <td>0.351906</td>\n",
       "      <td>0.090741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.558739</td>\n",
       "      <td>0.101061</td>\n",
       "      <td>0.369250</td>\n",
       "      <td>0.078620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.562920</td>\n",
       "      <td>0.104754</td>\n",
       "      <td>0.387915</td>\n",
       "      <td>0.096195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.564090</td>\n",
       "      <td>0.104446</td>\n",
       "      <td>0.388349</td>\n",
       "      <td>0.096544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.565569</td>\n",
       "      <td>0.124775</td>\n",
       "      <td>0.325057</td>\n",
       "      <td>0.109952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.604936</td>\n",
       "      <td>0.148808</td>\n",
       "      <td>0.347141</td>\n",
       "      <td>0.097712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.606448</td>\n",
       "      <td>0.104110</td>\n",
       "      <td>0.347573</td>\n",
       "      <td>0.075854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.607546</td>\n",
       "      <td>0.149040</td>\n",
       "      <td>0.346490</td>\n",
       "      <td>0.097474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.627831</td>\n",
       "      <td>0.122853</td>\n",
       "      <td>0.343038</td>\n",
       "      <td>0.091685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.628522</td>\n",
       "      <td>0.123308</td>\n",
       "      <td>0.342846</td>\n",
       "      <td>0.091762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.671383</td>\n",
       "      <td>0.064055</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.054173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.671383</td>\n",
       "      <td>0.064055</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.054173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.671383</td>\n",
       "      <td>0.064055</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.054173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.671383</td>\n",
       "      <td>0.064055</td>\n",
       "      <td>0.331465</td>\n",
       "      <td>0.054173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.722778</td>\n",
       "      <td>0.127366</td>\n",
       "      <td>0.356666</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.732443</td>\n",
       "      <td>0.125877</td>\n",
       "      <td>0.357712</td>\n",
       "      <td>0.109496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>-0.615437</td>\n",
       "      <td>0.049966</td>\n",
       "      <td>0.049966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.567028</td>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.043147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RTFS_f1_minus_f2</td>\n",
       "      <td>-0.559742</td>\n",
       "      <td>0.042899</td>\n",
       "      <td>0.042899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>-0.494141</td>\n",
       "      <td>0.036578</td>\n",
       "      <td>0.036578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PLAN_temporal_orientation</td>\n",
       "      <td>0.266626</td>\n",
       "      <td>0.012571</td>\n",
       "      <td>0.012571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>0.265023</td>\n",
       "      <td>0.009661</td>\n",
       "      <td>0.009661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>WTP_unhealthy_minus_healthy</td>\n",
       "      <td>-0.149803</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFI_conscientiousness</td>\n",
       "      <td>0.115133</td>\n",
       "      <td>0.003380</td>\n",
       "      <td>0.003380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BFI_openness</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PLAN_cognitive_strategies</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>PLAN_mental_forecasting</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cancer_promoting_minus_preventing_craved_FCI</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cSES</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SST_SSD</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempting to predict d_bf with 80 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are ni san ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_forecasting PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 birthsex_factor_Male education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy ACES_sum*ni ACES_sum*san BFI_agreeableness*ni BFI_agreeableness*san BFI_conscientiousness*ni BFI_conscientiousness*san BFI_extraversion*ni BFI_extraversion*san BFI_neuroticism*ni BFI_neuroticism*san BFI_openness*ni BFI_openness*san IMI_effort_importance*ni IMI_effort_importance*san IMI_interest_enjoyment*ni IMI_interest_enjoyment*san NCS_total*ni NCS_total*san PLAN_cognitive_strategies*ni PLAN_cognitive_strategies*san PLAN_mental_forecasting*ni PLAN_mental_forecasting*san PLAN_temporal_orientation*ni PLAN_temporal_orientation*san RMQ_assessment*ni RMQ_assessment*san TESQ_E_sum*ni TESQ_E_sum*san SRHI_healthy_minus_unhealthy*ni SRHI_healthy_minus_unhealthy*san RTFS_f1_minus_f2*ni RTFS_f1_minus_f2*san cancer_promoting_minus_preventing_craved_FCI*ni cancer_promoting_minus_preventing_craved_FCI*san cancer_promoting_minus_preventing_liked_FCI*ni cancer_promoting_minus_preventing_liked_FCI*san cSES*ni cSES*san age365*ni age365*san birthsex_factor_Male*ni birthsex_factor_Male*san education_own*ni education_own*san SST_SSD*ni SST_SSD*san SST_mean_ssrt_0*ni SST_mean_ssrt_0*san ROC_Crave_Regulate_Minus_Look*ni ROC_Crave_Regulate_Minus_Look*san WTP_unhealthy_minus_healthy*ni WTP_unhealthy_minus_healthy*san\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "scores:\n",
      "[0.07304008232451886, 0.05126581910485806, -0.0947576385546729, 0.03808883979223032, -0.11380943962934698]\n",
      "overall_score:\n",
      "-0.009234467392482525\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.557802</td>\n",
       "      <td>0.111059</td>\n",
       "      <td>0.340074</td>\n",
       "      <td>0.144265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.634482</td>\n",
       "      <td>0.087783</td>\n",
       "      <td>0.364166</td>\n",
       "      <td>0.101297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.649714</td>\n",
       "      <td>0.098135</td>\n",
       "      <td>0.360734</td>\n",
       "      <td>0.096859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.659224</td>\n",
       "      <td>0.106462</td>\n",
       "      <td>0.340564</td>\n",
       "      <td>0.032032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-3.663259</td>\n",
       "      <td>0.058110</td>\n",
       "      <td>0.334126</td>\n",
       "      <td>0.052707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.663259</td>\n",
       "      <td>0.058110</td>\n",
       "      <td>0.334126</td>\n",
       "      <td>0.052707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.663259</td>\n",
       "      <td>0.058110</td>\n",
       "      <td>0.334126</td>\n",
       "      <td>0.052707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.663675</td>\n",
       "      <td>0.058542</td>\n",
       "      <td>0.334329</td>\n",
       "      <td>0.052470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.712892</td>\n",
       "      <td>0.109274</td>\n",
       "      <td>0.380463</td>\n",
       "      <td>0.136605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.713506</td>\n",
       "      <td>0.117829</td>\n",
       "      <td>0.347065</td>\n",
       "      <td>0.043635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.722629</td>\n",
       "      <td>0.120538</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.046837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.729460</td>\n",
       "      <td>0.112649</td>\n",
       "      <td>0.380347</td>\n",
       "      <td>0.142805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.739904</td>\n",
       "      <td>0.127397</td>\n",
       "      <td>0.348120</td>\n",
       "      <td>0.152003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-3.772277</td>\n",
       "      <td>0.137743</td>\n",
       "      <td>0.341098</td>\n",
       "      <td>0.162573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-4.334869</td>\n",
       "      <td>0.323940</td>\n",
       "      <td>0.365084</td>\n",
       "      <td>0.029763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.644226</td>\n",
       "      <td>0.388821</td>\n",
       "      <td>0.380261</td>\n",
       "      <td>0.063270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.727862</td>\n",
       "      <td>0.067076</td>\n",
       "      <td>0.067076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.719851</td>\n",
       "      <td>0.063594</td>\n",
       "      <td>0.063594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>PLAN_mental_forecasting*ni</td>\n",
       "      <td>0.684014</td>\n",
       "      <td>0.054243</td>\n",
       "      <td>0.054243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RTFS_f1_minus_f2</td>\n",
       "      <td>-0.527450</td>\n",
       "      <td>0.038589</td>\n",
       "      <td>0.038589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>-0.471688</td>\n",
       "      <td>0.031311</td>\n",
       "      <td>0.031311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>PLAN_temporal_orientation</td>\n",
       "      <td>0.278116</td>\n",
       "      <td>0.018155</td>\n",
       "      <td>0.018155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>-0.260162</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>0.009643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI*san</td>\n",
       "      <td>-0.216391</td>\n",
       "      <td>0.008606</td>\n",
       "      <td>0.008606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>WTP_unhealthy_minus_healthy*ni</td>\n",
       "      <td>-0.191974</td>\n",
       "      <td>0.008370</td>\n",
       "      <td>0.008370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>TESQ_E_sum*san</td>\n",
       "      <td>0.215864</td>\n",
       "      <td>0.007778</td>\n",
       "      <td>0.007778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>0.187944</td>\n",
       "      <td>0.007077</td>\n",
       "      <td>0.007077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>-0.137178</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.005500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>education_own*san</td>\n",
       "      <td>-0.140102</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.003655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PLAN_cognitive_strategies*ni</td>\n",
       "      <td>0.124623</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.003644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFI_conscientiousness</td>\n",
       "      <td>0.031620</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look</td>\n",
       "      <td>-0.018711</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>RMQ_assessment*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>cancer_promoting_minus_preventing_craved_FCI*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>RMQ_assessment*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>TESQ_E_sum*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': 8.075287760822558e-05, 'condition_inddiff': -0.010013318224489986, 'condition_inddiff_interactions': -0.009234467392482525}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = do_full_analysis('d_bf')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempting to predict d_cancer_promoting_minus_preventing_FFQ with 2 predictors in the set condition_only\n",
      "predictors in that set are ni san\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [2], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "scores:\n",
      "[0.6990126906755044, 0.758032244900301, 0.7422542590807824, 0.6876633135763623, 0.8174025903225415]\n",
      "overall_score:\n",
      "0.7408730197110983\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.244620</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.013104</td>\n",
       "      <td>0.005042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.244620</td>\n",
       "      <td>0.006656</td>\n",
       "      <td>0.013104</td>\n",
       "      <td>0.005042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.244836</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.244836</td>\n",
       "      <td>0.006703</td>\n",
       "      <td>0.013186</td>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.335773</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.335773</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.605600</td>\n",
       "      <td>1.889327</td>\n",
       "      <td>1.889327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>san</td>\n",
       "      <td>0.189365</td>\n",
       "      <td>0.194790</td>\n",
       "      <td>0.194790</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempting to predict d_cancer_promoting_minus_preventing_FFQ with 28 predictors in the set condition_inddiff\n",
      "predictors in that set are ni san ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_forecasting PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 birthsex_factor_Male education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "scores:\n",
      "[0.7008058826159052, 0.7462036674027154, 0.7541321960777643, 0.7267490695212159, 0.806284117586014]\n",
      "overall_score:\n",
      "0.7468349866407229\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.242995</td>\n",
       "      <td>0.008875</td>\n",
       "      <td>0.014497</td>\n",
       "      <td>0.003331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.243012</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>0.003379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.245442</td>\n",
       "      <td>0.009412</td>\n",
       "      <td>0.016530</td>\n",
       "      <td>0.006185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.245551</td>\n",
       "      <td>0.009571</td>\n",
       "      <td>0.016550</td>\n",
       "      <td>0.006276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.245657</td>\n",
       "      <td>0.006492</td>\n",
       "      <td>0.014580</td>\n",
       "      <td>0.004529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.246035</td>\n",
       "      <td>0.006491</td>\n",
       "      <td>0.014784</td>\n",
       "      <td>0.004850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.255752</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.017870</td>\n",
       "      <td>0.008412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.256120</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.018014</td>\n",
       "      <td>0.008296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.335773</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.335773</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.335773</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.335773</td>\n",
       "      <td>0.006246</td>\n",
       "      <td>0.024351</td>\n",
       "      <td>0.015417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.592811</td>\n",
       "      <td>1.847839</td>\n",
       "      <td>1.847839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>san</td>\n",
       "      <td>0.190092</td>\n",
       "      <td>0.183634</td>\n",
       "      <td>0.183634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>-0.066084</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.024155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>-0.033571</td>\n",
       "      <td>0.005103</td>\n",
       "      <td>0.005103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cSES</td>\n",
       "      <td>0.024605</td>\n",
       "      <td>0.003365</td>\n",
       "      <td>0.003365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>IMI_effort_importance</td>\n",
       "      <td>0.018645</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.001219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>education_own</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.000885</td>\n",
       "      <td>0.000885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SST_SSD</td>\n",
       "      <td>-0.014351</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>0.000859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>age365</td>\n",
       "      <td>0.010558</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.000331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy</td>\n",
       "      <td>0.002262</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " attempting to predict d_cancer_promoting_minus_preventing_FFQ with 80 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are ni san ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_forecasting PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 birthsex_factor_Male education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy ACES_sum*ni ACES_sum*san BFI_agreeableness*ni BFI_agreeableness*san BFI_conscientiousness*ni BFI_conscientiousness*san BFI_extraversion*ni BFI_extraversion*san BFI_neuroticism*ni BFI_neuroticism*san BFI_openness*ni BFI_openness*san IMI_effort_importance*ni IMI_effort_importance*san IMI_interest_enjoyment*ni IMI_interest_enjoyment*san NCS_total*ni NCS_total*san PLAN_cognitive_strategies*ni PLAN_cognitive_strategies*san PLAN_mental_forecasting*ni PLAN_mental_forecasting*san PLAN_temporal_orientation*ni PLAN_temporal_orientation*san RMQ_assessment*ni RMQ_assessment*san TESQ_E_sum*ni TESQ_E_sum*san SRHI_healthy_minus_unhealthy*ni SRHI_healthy_minus_unhealthy*san RTFS_f1_minus_f2*ni RTFS_f1_minus_f2*san cancer_promoting_minus_preventing_craved_FCI*ni cancer_promoting_minus_preventing_craved_FCI*san cancer_promoting_minus_preventing_liked_FCI*ni cancer_promoting_minus_preventing_liked_FCI*san cSES*ni cSES*san age365*ni age365*san birthsex_factor_Male*ni birthsex_factor_Male*san education_own*ni education_own*san SST_SSD*ni SST_SSD*san SST_mean_ssrt_0*ni SST_mean_ssrt_0*san ROC_Crave_Regulate_Minus_Look*ni ROC_Crave_Regulate_Minus_Look*san WTP_unhealthy_minus_healthy*ni WTP_unhealthy_minus_healthy*san\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e7ed4e0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': [0.2, 0.99]}\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "scores:\n",
      "[0.5945050144441404, 0.71258069396158, 0.618988106840048, 0.7215664222781956, 0.7036816107536239]\n",
      "overall_score:\n",
      "0.6702643696555176\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.274694</td>\n",
       "      <td>0.007608</td>\n",
       "      <td>0.022981</td>\n",
       "      <td>0.006966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.275146</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>0.023113</td>\n",
       "      <td>0.007343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.278060</td>\n",
       "      <td>0.008788</td>\n",
       "      <td>0.021375</td>\n",
       "      <td>0.005775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.279498</td>\n",
       "      <td>0.009344</td>\n",
       "      <td>0.021890</td>\n",
       "      <td>0.005613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.279985</td>\n",
       "      <td>0.008762</td>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.281748</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.020063</td>\n",
       "      <td>0.006459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.294765</td>\n",
       "      <td>0.009422</td>\n",
       "      <td>0.023381</td>\n",
       "      <td>0.006957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.313728</td>\n",
       "      <td>0.006711</td>\n",
       "      <td>0.025499</td>\n",
       "      <td>0.010582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.332054</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.015973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.332179</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.023935</td>\n",
       "      <td>0.016053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.332179</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.023935</td>\n",
       "      <td>0.016053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.332183</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.023941</td>\n",
       "      <td>0.016050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.99, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17e7ed4e0&gt;}</th>\n",
       "      <td>-0.531094</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.026833</td>\n",
       "      <td>0.010754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model_outcomes \u001b[39m=\u001b[39m do_full_analysis(\u001b[39m'\u001b[39;49m\u001b[39md_cancer_promoting_minus_preventing_FFQ\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[45], line 7\u001b[0m, in \u001b[0;36mdo_full_analysis\u001b[0;34m(outcome_var)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m attempting to predict \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m outcome_var \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m with \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mlen\u001b[39m(predictor_set)) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m predictors in the set \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m psk)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mpredictors in that set are \u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(predictor_set))\n\u001b[0;32m----> 7\u001b[0m     model_outcomes[psk] \u001b[39m=\u001b[39m score_and_present(\n\u001b[1;32m      8\u001b[0m         predictor_data_nona[predictor_set],\n\u001b[1;32m      9\u001b[0m         outcome_measures_nona[outcome_var],\n\u001b[1;32m     10\u001b[0m         group_assignments_nona\n\u001b[1;32m     11\u001b[0m               )\n\u001b[1;32m     13\u001b[0m \u001b[39m#get a dictionary of the overall scores for each model\u001b[39;00m\n\u001b[1;32m     14\u001b[0m model_outcomes_comparison \u001b[39m=\u001b[39m { k:\n\u001b[1;32m     15\u001b[0m     model_outcomes[k][\u001b[39m'\u001b[39m\u001b[39moverall_score\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m model_outcomes\u001b[39m.\u001b[39mkeys()}\n",
      "Cell \u001b[0;32mIn[26], line 29\u001b[0m, in \u001b[0;36mscore_and_present\u001b[0;34m(predictor_data, outcome_measure, group_assignments)\u001b[0m\n\u001b[1;32m     26\u001b[0m best_model \u001b[39m=\u001b[39m get_best_model(summarize_overall_df_results(raw_cv_results_list))\n\u001b[1;32m     27\u001b[0m final_fit \u001b[39m=\u001b[39m do_final_fit(X\u001b[39m=\u001b[39mpredictor_data, y\u001b[39m=\u001b[39m outcome_measure, final_model\u001b[39m=\u001b[39mbest_model, impute_missing\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 29\u001b[0m pd_imputed, X_was_imputed \u001b[39m=\u001b[39m apply_imputer(predictor_data)\n\u001b[1;32m     31\u001b[0m final_results \u001b[39m=\u001b[39m present_model_results(X\u001b[39m=\u001b[39mpd_imputed, final_fit\u001b[39m=\u001b[39mfinal_fit, y\u001b[39m=\u001b[39moutcome_measure)\n\u001b[1;32m     33\u001b[0m \u001b[39m#print rows of final_results where feature_name is the list of features to check\u001b[39;00m\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:240\u001b[0m, in \u001b[0;36mapply_imputer\u001b[0;34m(data, imputer)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mif\u001b[39;00m imputer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     imputer \u001b[39m=\u001b[39m IterativeImputer(estimator\u001b[39m=\u001b[39mlinear_model\u001b[39m.\u001b[39mRidge(),n_nearest_features\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m,max_iter\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m--> 240\u001b[0m data_imputed \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(imputer\u001b[39m.\u001b[39;49mfit_transform(get_data_for_imputation(data)))\n\u001b[1;32m    241\u001b[0m imputed_datapoints \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39misna()\n\u001b[1;32m    242\u001b[0m data_imputed\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcolumns\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:750\u001b[0m, in \u001b[0;36mIterativeImputer.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[39mfor\u001b[39;00m feat_idx \u001b[39min\u001b[39;00m ordered_idx:\n\u001b[1;32m    747\u001b[0m     neighbor_feat_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_neighbor_feat_idx(\n\u001b[1;32m    748\u001b[0m         n_features, feat_idx, abs_corr_mat\n\u001b[1;32m    749\u001b[0m     )\n\u001b[0;32m--> 750\u001b[0m     Xt, estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_impute_one_feature(\n\u001b[1;32m    751\u001b[0m         Xt,\n\u001b[1;32m    752\u001b[0m         mask_missing_values,\n\u001b[1;32m    753\u001b[0m         feat_idx,\n\u001b[1;32m    754\u001b[0m         neighbor_feat_idx,\n\u001b[1;32m    755\u001b[0m         estimator\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    756\u001b[0m         fit_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    757\u001b[0m     )\n\u001b[1;32m    758\u001b[0m     estimator_triplet \u001b[39m=\u001b[39m _ImputerTriplet(\n\u001b[1;32m    759\u001b[0m         feat_idx, neighbor_feat_idx, estimator\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimputation_sequence_\u001b[39m.\u001b[39mappend(estimator_triplet)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:401\u001b[0m, in \u001b[0;36mIterativeImputer._impute_one_feature\u001b[0;34m(self, X_filled, mask_missing_values, feat_idx, neighbor_feat_idx, estimator, fit_mode)\u001b[0m\n\u001b[1;32m    391\u001b[0m     X_train \u001b[39m=\u001b[39m _safe_indexing(\n\u001b[1;32m    392\u001b[0m         _safe_indexing(X_filled, neighbor_feat_idx, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    393\u001b[0m         \u001b[39m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    394\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    395\u001b[0m     )\n\u001b[1;32m    396\u001b[0m     y_train \u001b[39m=\u001b[39m _safe_indexing(\n\u001b[1;32m    397\u001b[0m         _safe_indexing(X_filled, feat_idx, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[1;32m    398\u001b[0m         \u001b[39m~\u001b[39mmissing_row_mask,\n\u001b[1;32m    399\u001b[0m         axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m,\n\u001b[1;32m    400\u001b[0m     )\n\u001b[0;32m--> 401\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m    403\u001b[0m \u001b[39m# if no missing values, don't predict\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39msum(missing_row_mask) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:1126\u001b[0m, in \u001b[0;36mRidge.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1125\u001b[0m _accept_sparse \u001b[39m=\u001b[39m _get_valid_accept_sparse(sparse\u001b[39m.\u001b[39missparse(X), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msolver)\n\u001b[0;32m-> 1126\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m   1127\u001b[0m     X,\n\u001b[1;32m   1128\u001b[0m     y,\n\u001b[1;32m   1129\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m_accept_sparse,\n\u001b[1;32m   1130\u001b[0m     dtype\u001b[39m=\u001b[39;49m[np\u001b[39m.\u001b[39;49mfloat64, np\u001b[39m.\u001b[39;49mfloat32],\n\u001b[1;32m   1131\u001b[0m     multi_output\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1132\u001b[0m     y_numeric\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1133\u001b[0m )\n\u001b[1;32m   1134\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mfit(X, y, sample_weight\u001b[39m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py:584\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m         y \u001b[39m=\u001b[39m check_array(y, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39my\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_y_params)\n\u001b[1;32m    583\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 584\u001b[0m         X, y \u001b[39m=\u001b[39m check_X_y(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    585\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    587\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/validation.py:1124\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1106\u001b[0m X \u001b[39m=\u001b[39m check_array(\n\u001b[1;32m   1107\u001b[0m     X,\n\u001b[1;32m   1108\u001b[0m     accept_sparse\u001b[39m=\u001b[39maccept_sparse,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1119\u001b[0m     input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1120\u001b[0m )\n\u001b[1;32m   1122\u001b[0m y \u001b[39m=\u001b[39m _check_y(y, multi_output\u001b[39m=\u001b[39mmulti_output, y_numeric\u001b[39m=\u001b[39my_numeric, estimator\u001b[39m=\u001b[39mestimator)\n\u001b[0;32m-> 1124\u001b[0m check_consistent_length(X, y)\n\u001b[1;32m   1126\u001b[0m \u001b[39mreturn\u001b[39;00m X, y\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/validation.py:395\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[39mChecks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39m    Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    394\u001b[0m lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m--> 395\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49munique(lengths)\n\u001b[1;32m    396\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    397\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    399\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[1;32m    400\u001b[0m     )\n",
      "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/arraysetops.py:276\u001b[0m, in \u001b[0;36munique\u001b[0;34m(ar, return_index, return_inverse, return_counts, axis, equal_nan)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     ret \u001b[39m=\u001b[39m _unique1d(ar, return_index, return_inverse, return_counts, \n\u001b[1;32m    275\u001b[0m                     equal_nan\u001b[39m=\u001b[39mequal_nan)\n\u001b[0;32m--> 276\u001b[0m     \u001b[39mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[1;32m    278\u001b[0m \u001b[39m# axis was specified and not None\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/arraysetops.py:125\u001b[0m, in \u001b[0;36m_unpack_tuple\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    121\u001b[0m     np\u001b[39m.\u001b[39msubtract(ary[\u001b[39m1\u001b[39m:], ary[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m], result[l_begin:l_begin \u001b[39m+\u001b[39m l_diff])\n\u001b[1;32m    122\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n\u001b[0;32m--> 125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_unpack_tuple\u001b[39m(x):\n\u001b[1;32m    126\u001b[0m     \u001b[39m\"\"\" Unpacks one-element tuples for use as return values \"\"\"\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_outcomes = do_full_analysis('d_cancer_promoting_minus_preventing_FFQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
