{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from socket import gethostname\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from dev_interaction_util import generate_synthetic_dev_outcomes, generate_synthetic_dev_data, set_up_interactions\n",
    "from dev_interaction_util import do_scoring_loop, get_best_model, summarize_overall_df_results, do_final_fit, present_model_results, present_results_vs_ground_truth_cors\n",
    "from dev_interaction_util import load_and_preprocess_data, impute_data\n",
    "from ml_util import *\n",
    "# Imputing with MICE\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn import linear_model\n",
    "from ml_util import get_data_for_imputation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-2.local\n",
      "{'dropbox_data_dir': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "with open('config.yml') as f:\n",
    "    all_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "    if gethostname() in all_yaml.keys():\n",
    "        config = all_yaml[gethostname()]\n",
    "    else:\n",
    "        config = all_yaml['default']\n",
    "        \n",
    "print(config)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is derived from `test_feature_selection.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data, outcome_measures = load_and_preprocess_data(dropbox_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def impute_data(analysis_data,graph_against_col=None):\n",
    "    \"\"\"\n",
    "    Does data imputing. Should not be used for a final analysis, because\n",
    "    imputing of data should occur within the pipeline, so has not to permit data leakage\n",
    "    \"\"\"\n",
    "\n",
    "    imputer = IterativeImputer(estimator=linear_model.Ridge(),n_nearest_features=10,max_iter=100,random_state=0)\n",
    "    analysis_data_imputed = get_data_for_imputation(analysis_data)\n",
    "\n",
    "    #this dataset is already filtered for columns so we don't need to filter those further.\n",
    "    analysis_data_imputed = pd.DataFrame(imputer.fit_transform(analysis_data_imputed), columns=analysis_data_imputed.columns)\n",
    "    imputed_data = analysis_data.isna()\n",
    "    # do_aces_cses_imputation_diagnostic(analysis_data_imputed, imputed_datapoint,'ridge_10')\n",
    "    if graph_against_col is not None:\n",
    "        cols_with_imputed_data = analysis_data_imputed.columns[imputed_data.sum()>0]\n",
    "        for i, col in enumerate(cols_with_imputed_data):\n",
    "            #get a column indicating whether each point in this column was imputed\n",
    "            imputed_datapoint = imputed_data.loc[:,col]\n",
    "            #plot a scatter plot of the outcome measure against the imputed data\n",
    "            #color the columns by whether they were imputed or not\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(analysis_data_imputed.loc[:,col],graph_against_col,c=imputed_datapoint.astype(int))\n",
    "            ax.set_xlabel(col)\n",
    "            ax.set_ylabel(\"outcome\")\n",
    "            ax.set_title('Imputed ' + col + ' vs outcome')\n",
    "            #add a legend to the plot\n",
    "            ax.legend(['not imputed','imputed'])\n",
    "            plt.show()\n",
    "\n",
    "            #only do three columns\n",
    "            if i>2:\n",
    "                break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return(analysis_data_imputed)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/impute/_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "analysis_data_imputed = impute_data(analysis_data, graph_against_col=outcome_measures['bf_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop(X, y,cv):\n",
    "    #alpha parameters for Ridge and Lasso\n",
    "    alpha_10pow_lower = 1\n",
    "    alpha_10pow_upper = 0\n",
    "    alpha_increments=1\n",
    "    alpha_range = np.concatenate([np.power(10,np.linspace(-alpha_10pow_lower,alpha_10pow_upper,(alpha_10pow_lower+alpha_10pow_upper)*alpha_increments+1)),\n",
    "        [0.2,0.4,0.6,0.8,1.0]])\n",
    "\n",
    "    all_cv_results = []\n",
    "\n",
    "    pipeline_estimator_name = 'estimator'\n",
    "    feature_selection_name = 'feature_selection'\n",
    "\n",
    "\n",
    "    #define the param_grid for the estimators\n",
    "    estimators_to_run = {\n",
    "        'Ridge':{\n",
    "            'estimator':linear_model.Ridge,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'Lasso':{\n",
    "            'estimator':linear_model.Lasso,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'DecisionTreeRegressor':{\n",
    "            'estimator':DecisionTreeRegressor,\n",
    "            'parameters':{\n",
    "                'max_depth':[2, 4],\n",
    "                'min_samples_split':[20,50],\n",
    "                'min_samples_leaf':[20,50]\n",
    "            }\n",
    "        }             \n",
    "    }\n",
    "\n",
    "    k_max_val = np.min([50,X.shape[1]])\n",
    "\n",
    "    for estimator_name,estimator_dict in estimators_to_run.items():\n",
    "        #param grid for the feature seelction\n",
    "        #this is here because we need to know the estimator to pass to the feature selector\n",
    "        feature_selectors_to_run = {\n",
    "            'None':None,\n",
    "            'KBest':{\n",
    "                'selector':SelectKBest(),\n",
    "                'parameters':{\n",
    "                    'score_func' : [f_regression], \n",
    "                    'k' : [20,k_max_val]\n",
    "                    }\n",
    "            },\n",
    "            'RFE':{\n",
    "                'selector':RFE(linear_model.LinearRegression()),\n",
    "                'parameters':{\n",
    "                    'n_features_to_select' : [10,25],\n",
    "                    #'verbose':[1],\n",
    "                    'step':[5]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for selector_name, selector_dict in feature_selectors_to_run.items():\n",
    "        #create the estimator\n",
    "            if selector_name == 'None':\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                        (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = {}\n",
    "            else:\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                        (feature_selection_name,selector_dict['selector']), \n",
    "                                        (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = selector_dict['parameters']\n",
    "\n",
    "            estimator_param_grid = {(pipeline_estimator_name + '__'+k):v for k,v in estimator_dict['parameters'].items()}\n",
    "            selector_param_grid = {(feature_selection_name + '__'+k):v for k,v in selector_params.items()}\n",
    "            #combine the two param grid dictionaries\n",
    "            full_param_grid = {**selector_param_grid, **estimator_param_grid}\n",
    "            print(pipeline)\n",
    "            print(full_param_grid)\n",
    "\n",
    "            \n",
    "        \n",
    "            gs_1 = GridSearchCV(estimator=pipeline, \n",
    "                                param_grid = full_param_grid, \n",
    "                                cv=cv,scoring='neg_mean_absolute_error',verbose=1)\n",
    "            gs_1.fit(X,y)\n",
    "            all_cv_results.append(gs_1)\n",
    "\n",
    "    #create a dataframe with the best parameters, best mean_test_score, and name of the model\n",
    "\n",
    "    best_params_df = pd.DataFrame({\n",
    "        'model': [cv_result.estimator for cv_result in all_cv_results],\n",
    "        'model_name': [cv_result.estimator.__class__.__name__ for cv_result in all_cv_results],\n",
    "        'best_params': [extract_estimator_params_from_gridsearch(cv_result.best_params_) for cv_result in all_cv_results],\n",
    "        'best_score': [cv_result.best_score_ for cv_result in all_cv_results],\n",
    "        'best_raw_params' : [cv_result.best_params_ for cv_result in all_cv_results]\n",
    "        })\n",
    "\n",
    "    best_params_df = best_params_df.sort_values('best_score',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    best_model = clone(best_params_df['model'][0])\n",
    "    best_model_params = best_params_df['best_raw_params'][0]\n",
    "    best_model.set_params(**best_model_params)\n",
    "\n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_params_df':best_params_df,\n",
    "        'raw_cv_results':all_cv_results\n",
    "    }\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulator settings\n",
    "interaction_effect_size_as_sd=0.1\n",
    "total_predictor_count=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.1\n",
      "2                          BIS_11                -0.1\n",
      "1                             EDM                 0.1\n",
      "11              BFI_agreeableness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "6       ACES_neglectful_parenting                 0.0\n",
      "5                            TRSQ                 0.0\n",
      "4                              RS                 0.0\n",
      "3                             PCS                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.1\n",
      "5                            TRSQ                 0.1\n",
      "6       ACES_neglectful_parenting                -0.1\n",
      "0                            BSCS                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "11              BFI_agreeableness                 0.0\n",
      "1                             EDM                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "3                             PCS                 0.0\n",
      "2                          BIS_11                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n"
     ]
    }
   ],
   "source": [
    "#def run_full_limited_predictor_analysis(total_predictor_count, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=0.08):\n",
    "\n",
    "\n",
    "#set np random seed\n",
    "np.random.seed(3161527)\n",
    "\n",
    "group_names = ['ichi','ni','san']\n",
    "#assign each row randomly to a group\n",
    "group_assignments = np.random.choice(group_names,analysis_data_imputed.shape[0])\n",
    "\n",
    "\n",
    "#synthetic outcomes\n",
    "outcome_measures = generate_synthetic_dev_outcomes(outcome_measures)\n",
    "\n",
    "#create a limited set of predictors\n",
    "analysis_data_smol = analysis_data_imputed.iloc[:,0:total_predictor_count]\n",
    "\n",
    "# add synthetic primary and interaction effects\n",
    "\n",
    "\n",
    "#set up the interaction effects\n",
    "#0.08 will give us correlations around 0.3 between the interaction effects and the outcome\n",
    "custom_interaction_effects_g1 = [0]*analysis_data_smol.shape[1]\n",
    "custom_interaction_effects_g1[0] = interaction_effect_size_as_sd\n",
    "custom_interaction_effects_g1[1] = interaction_effect_size_as_sd\n",
    "custom_interaction_effects_g1[2] = -interaction_effect_size_as_sd\n",
    "\n",
    "custom_interaction_effects_g2 = [0]*analysis_data_smol.shape[1]\n",
    "custom_interaction_effects_g2[4] = interaction_effect_size_as_sd\n",
    "custom_interaction_effects_g2[5] = interaction_effect_size_as_sd\n",
    "custom_interaction_effects_g2[6] = -interaction_effect_size_as_sd\n",
    "\n",
    "custom_interaction_effects = {'ni':custom_interaction_effects_g1,'san':custom_interaction_effects_g2}\n",
    "\n",
    "\n",
    "\n",
    "synthetic_data = generate_synthetic_dev_data(analysis_data_smol, group_assignments,outcome_measures, group_interaction_effects = custom_interaction_effects)\n",
    "interaction_effect_df = synthetic_data['X_weights']\n",
    "outcome_measures = synthetic_data['y']\n",
    "\n",
    "# Set up outcome measures and group assignment one-hot\n",
    "\n",
    "outcome_measures = calculate_outcome_changes(outcome_measures)\n",
    "group_assignment_onehots = pd.get_dummies(group_assignments).loc[:,['ni','san']]\n",
    "\n",
    "predictor_data = set_up_interactions(analysis_data_smol, group_assignment_onehots)\n",
    "\n",
    "\n",
    "#remove any NA values for this outcome measure in both the predictor data and the outcome data\n",
    "outcome_nas = outcome_measures['d_bf'].isna()\n",
    "\n",
    "outcome_measures_nona = outcome_measures.loc[~outcome_nas,:]\n",
    "predictor_data_nona = predictor_data.loc[~outcome_nas,:]\n",
    "group_assignment_onehots_nonan = group_assignment_onehots.loc[~outcome_nas,:]\n",
    "group_assignments_nona = group_assignments[~outcome_nas]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180f38940>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m### Try out CV with simple gridsearch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m scoring_data \u001b[39m=\u001b[39m do_scoring_loop(X\u001b[39m=\u001b[39;49mpredictor_data_nona, y\u001b[39m=\u001b[39;49m outcome_measures_nona[\u001b[39m'\u001b[39;49m\u001b[39md_bf\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m      4\u001b[0m                 groups \u001b[39m=\u001b[39;49m group_assignments_nona, \n\u001b[1;32m      5\u001b[0m                 hyperparameter_selection_on_fold\u001b[39m=\u001b[39;49mdo_hyperparameter_selection_loop,\n\u001b[1;32m      6\u001b[0m                 outer_folds\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m      8\u001b[0m scores \u001b[39m=\u001b[39m scoring_data[\u001b[39m'\u001b[39m\u001b[39mscores\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      9\u001b[0m best_models \u001b[39m=\u001b[39m scoring_data[\u001b[39m'\u001b[39m\u001b[39mbest_models\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:200\u001b[0m, in \u001b[0;36mdo_scoring_loop\u001b[0;34m(X, y, groups, hyperparameter_selection_on_fold, outer_folds)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39m#print(test_i_y)\u001b[39;00m\n\u001b[1;32m    198\u001b[0m inner_cv \u001b[39m=\u001b[39m IndependentVarStratifiedKFold(independent_vars\u001b[39m=\u001b[39mtrain_i_group_assignments, n_splits\u001b[39m=\u001b[39minner_splits, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m3211050\u001b[39m)\n\u001b[0;32m--> 200\u001b[0m selection_info \u001b[39m=\u001b[39m hyperparameter_selection_on_fold(train_i_X, train_i_y,cv \u001b[39m=\u001b[39;49m inner_cv)\n\u001b[1;32m    201\u001b[0m best_model_i \u001b[39m=\u001b[39m selection_info[\u001b[39m'\u001b[39m\u001b[39mbest_model\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    202\u001b[0m best_params_i \u001b[39m=\u001b[39m selection_info[\u001b[39m'\u001b[39m\u001b[39mbest_params_df\u001b[39m\u001b[39m'\u001b[39m]\n",
      "Cell \u001b[0;32mIn[56], line 84\u001b[0m, in \u001b[0;36mdo_hyperparameter_selection_loop\u001b[0;34m(X, y, cv)\u001b[0m\n\u001b[1;32m     80\u001b[0m         gs_1 \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mpipeline, \n\u001b[1;32m     81\u001b[0m                             param_grid \u001b[39m=\u001b[39m full_param_grid, \n\u001b[1;32m     82\u001b[0m                             cv\u001b[39m=\u001b[39mcv,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m         gs_1\u001b[39m.\u001b[39mfit(X,y)\n\u001b[0;32m---> 84\u001b[0m         all_cv_results\u001b[39m.\u001b[39mappend(gs_1)\n\u001b[1;32m     86\u001b[0m \u001b[39m#create a dataframe with the best parameters, best mean_test_score, and name of the model\u001b[39;00m\n\u001b[1;32m     88\u001b[0m best_params_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     89\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: [cv_result\u001b[39m.\u001b[39mestimator \u001b[39mfor\u001b[39;00m cv_result \u001b[39min\u001b[39;00m all_cv_results],\n\u001b[1;32m     90\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m: [cv_result\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m cv_result \u001b[39min\u001b[39;00m all_cv_results],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbest_raw_params\u001b[39m\u001b[39m'\u001b[39m : [cv_result\u001b[39m.\u001b[39mbest_params_ \u001b[39mfor\u001b[39;00m cv_result \u001b[39min\u001b[39;00m all_cv_results]\n\u001b[1;32m     94\u001b[0m     })\n",
      "Cell \u001b[0;32mIn[56], line 84\u001b[0m, in \u001b[0;36mdo_hyperparameter_selection_loop\u001b[0;34m(X, y, cv)\u001b[0m\n\u001b[1;32m     80\u001b[0m         gs_1 \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mpipeline, \n\u001b[1;32m     81\u001b[0m                             param_grid \u001b[39m=\u001b[39m full_param_grid, \n\u001b[1;32m     82\u001b[0m                             cv\u001b[39m=\u001b[39mcv,scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mneg_mean_absolute_error\u001b[39m\u001b[39m'\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     83\u001b[0m         gs_1\u001b[39m.\u001b[39mfit(X,y)\n\u001b[0;32m---> 84\u001b[0m         all_cv_results\u001b[39m.\u001b[39mappend(gs_1)\n\u001b[1;32m     86\u001b[0m \u001b[39m#create a dataframe with the best parameters, best mean_test_score, and name of the model\u001b[39;00m\n\u001b[1;32m     88\u001b[0m best_params_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame({\n\u001b[1;32m     89\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m: [cv_result\u001b[39m.\u001b[39mestimator \u001b[39mfor\u001b[39;00m cv_result \u001b[39min\u001b[39;00m all_cv_results],\n\u001b[1;32m     90\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mmodel_name\u001b[39m\u001b[39m'\u001b[39m: [cv_result\u001b[39m.\u001b[39mestimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mfor\u001b[39;00m cv_result \u001b[39min\u001b[39;00m all_cv_results],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbest_raw_params\u001b[39m\u001b[39m'\u001b[39m : [cv_result\u001b[39m.\u001b[39mbest_params_ \u001b[39mfor\u001b[39;00m cv_result \u001b[39min\u001b[39;00m all_cv_results]\n\u001b[1;32m     94\u001b[0m     })\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1600\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1834\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.ThreadTracer.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1395\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1344\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2067\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2064\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2066\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[0;32m-> 2067\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2069\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2071\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2072\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/debugpy/_vendored/pydevd/pydevd.py:2103\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2100\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2103\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2105\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2107\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Try out CV with simple gridsearch\n",
    "\n",
    "scoring_data = do_scoring_loop(X=predictor_data_nona, y= outcome_measures_nona['d_bf'], \n",
    "                groups = group_assignments_nona, \n",
    "                hyperparameter_selection_on_fold=do_hyperparameter_selection_loop,\n",
    "                outer_folds=5)\n",
    "\n",
    "scores = scoring_data['scores']\n",
    "best_models = scoring_data['best_models']\n",
    "best_params_df_list = scoring_data['best_params_df_list']\n",
    "raw_cv_results_list = scoring_data['raw_cv_results_list']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.08\n",
      "1                        EDM                0.08\n",
      "2                     BIS_11               -0.08\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.10891340562308183, -0.06003743599259326, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08176779797562309\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255178</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.065261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.262595</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271499</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.084335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277201</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>0.081428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280728</td>\n",
       "      <td>0.079895</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280805</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281511</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.084321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.281915</td>\n",
       "      <td>0.075993</td>\n",
       "      <td>0.344097</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.285971</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.315441</td>\n",
       "      <td>0.048176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286894</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287454</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.340642</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.288578</td>\n",
       "      <td>0.041586</td>\n",
       "      <td>0.286704</td>\n",
       "      <td>0.072516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288602</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.353791</td>\n",
       "      <td>0.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290244</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.254771</td>\n",
       "      <td>0.039511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291442</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.078728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.292087</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>0.070562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292894</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293008</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294424</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.295521</td>\n",
       "      <td>0.065191</td>\n",
       "      <td>0.229453</td>\n",
       "      <td>0.074495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299060</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>0.041387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299651</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.228557</td>\n",
       "      <td>0.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301298</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>0.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301333</td>\n",
       "      <td>0.072146</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.305082</td>\n",
       "      <td>0.067009</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305948</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.282923</td>\n",
       "      <td>0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310575</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.333777</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310993</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312164</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313481</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.067084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.313667</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.228303</td>\n",
       "      <td>0.072135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.320649</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>0.228520</td>\n",
       "      <td>0.071249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327152</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343089</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>0.089983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.343326</td>\n",
       "      <td>0.137883</td>\n",
       "      <td>0.346256</td>\n",
       "      <td>0.098924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.343510</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.340076</td>\n",
       "      <td>0.102899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350813</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.034419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355006</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.311593</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368240</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.258145</td>\n",
       "      <td>0.031309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389879</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.102402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.394979</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.337829</td>\n",
       "      <td>0.123855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411295</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.095744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.422509</td>\n",
       "      <td>0.130699</td>\n",
       "      <td>0.321198</td>\n",
       "      <td>0.129938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.972764</td>\n",
       "      <td>0.119505</td>\n",
       "      <td>0.119505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.049022</td>\n",
       "      <td>0.049022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.392702</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.023960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.015961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.109025</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.003041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:347: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2138921023.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':10,'overall_score':overall_score},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"scores:\")\n",
    "print(scores)\n",
    "overall_score = np.mean(scores)\n",
    "print(\"overall_score:\")\n",
    "print(overall_score)\n",
    "\n",
    "\n",
    "\n",
    "best_model = get_best_model(summarize_overall_df_results(raw_cv_results_list))\n",
    "final_fit = do_final_fit(X=predictor_data_nona, y= outcome_measures_nona['d_bf'], final_model=best_model)\n",
    "final_results = present_model_results(X=predictor_data_nona, final_fit=final_fit, y=outcome_measures_nona['d_bf'])\n",
    "\n",
    "#print rows of final_results where feature_name is the list of features to check\n",
    "base_regressors = interaction_effect_df.predictor[interaction_effect_df.interaction_effect!=0]\n",
    "regressors_to_check = [x+y for y in ['','*ni','*san'] for x in base_regressors]\n",
    "final_results['planned_regression'] = final_results['predictor'].isin(regressors_to_check)\n",
    "\n",
    "result_details = present_results_vs_ground_truth_cors(predictor_data_nona,outcome_measures_nona,group_assignments_nona,final_results,base_regressors)\n",
    "\n",
    "empirical_corr_diff_mean = np.mean(np.abs(result_details['group_correlations']['san_cor']-result_details['group_correlations']['ni_cor']))\n",
    "\n",
    "# return({\n",
    "#     'overall_score':overall_score,\n",
    "#     'empirical_corr_diff_mean':empirical_corr_diff_mean,\n",
    "#     'result_details':result_details\n",
    "# })\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "11              BFI_agreeableness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "6       ACES_neglectful_parenting                0.00\n",
      "5                            TRSQ                0.00\n",
      "4                              RS                0.00\n",
      "3                             PCS                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.08\n",
      "5                            TRSQ                0.08\n",
      "6       ACES_neglectful_parenting               -0.08\n",
      "0                            BSCS                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "11              BFI_agreeableness                0.00\n",
      "1                             EDM                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "3                             PCS                0.00\n",
      "2                          BIS_11                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.019391378692160455, 0.05103383687350138, -0.12333443118999532, -0.04514095692852438, -0.3178977602412687]\n",
      "overall_score:\n",
      "-0.09094613803568949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268368</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.096481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269053</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.333186</td>\n",
       "      <td>0.078243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.280129</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.334510</td>\n",
       "      <td>0.041095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285580</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>0.341224</td>\n",
       "      <td>0.051844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.285924</td>\n",
       "      <td>0.054509</td>\n",
       "      <td>0.336622</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292086</td>\n",
       "      <td>0.054613</td>\n",
       "      <td>0.331360</td>\n",
       "      <td>0.084547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292451</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.352444</td>\n",
       "      <td>0.044752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.292899</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.288927</td>\n",
       "      <td>0.042831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292916</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.060843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294701</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.316998</td>\n",
       "      <td>0.098707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.296873</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.300339</td>\n",
       "      <td>0.052913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297910</td>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.349752</td>\n",
       "      <td>0.023424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298140</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.350294</td>\n",
       "      <td>0.034471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299520</td>\n",
       "      <td>0.070640</td>\n",
       "      <td>0.352882</td>\n",
       "      <td>0.037559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301337</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303547</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.037851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304050</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.335633</td>\n",
       "      <td>0.031791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313860</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.038524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.319412</td>\n",
       "      <td>0.086520</td>\n",
       "      <td>0.345630</td>\n",
       "      <td>0.026971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.334056</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.337450</td>\n",
       "      <td>0.095239</td>\n",
       "      <td>0.363220</td>\n",
       "      <td>0.077932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.337593</td>\n",
       "      <td>0.087906</td>\n",
       "      <td>0.339245</td>\n",
       "      <td>0.027032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343701</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.296362</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345577</td>\n",
       "      <td>0.029533</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.050156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.347661</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>0.291765</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350004</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>0.044666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352859</td>\n",
       "      <td>0.113390</td>\n",
       "      <td>0.262172</td>\n",
       "      <td>0.080464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353069</td>\n",
       "      <td>0.031679</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.040813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354948</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.284664</td>\n",
       "      <td>0.038697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356086</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.378191</td>\n",
       "      <td>0.069583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358045</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>0.072911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363721</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.083742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377219</td>\n",
       "      <td>0.122091</td>\n",
       "      <td>0.261163</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.377618</td>\n",
       "      <td>0.090508</td>\n",
       "      <td>0.346471</td>\n",
       "      <td>0.056866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.378890</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>0.344019</td>\n",
       "      <td>0.051012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382975</td>\n",
       "      <td>0.105867</td>\n",
       "      <td>0.364802</td>\n",
       "      <td>0.059270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385794</td>\n",
       "      <td>0.096559</td>\n",
       "      <td>0.279813</td>\n",
       "      <td>0.096009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.386599</td>\n",
       "      <td>0.102026</td>\n",
       "      <td>0.316222</td>\n",
       "      <td>0.035314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393042</td>\n",
       "      <td>0.101054</td>\n",
       "      <td>0.362567</td>\n",
       "      <td>0.065183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.393614</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.314859</td>\n",
       "      <td>0.040052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394098</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>0.260901</td>\n",
       "      <td>0.082618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.395871</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.264513</td>\n",
       "      <td>0.109018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.402055</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>0.313004</td>\n",
       "      <td>0.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.412225</td>\n",
       "      <td>0.111472</td>\n",
       "      <td>0.310599</td>\n",
       "      <td>0.047198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418324</td>\n",
       "      <td>0.122146</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.418916</td>\n",
       "      <td>0.100508</td>\n",
       "      <td>0.330330</td>\n",
       "      <td>0.061356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.426821</td>\n",
       "      <td>0.112532</td>\n",
       "      <td>0.306588</td>\n",
       "      <td>0.053843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.434039</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.260568</td>\n",
       "      <td>0.081751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.438511</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.304221</td>\n",
       "      <td>0.060014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.457834</td>\n",
       "      <td>0.086374</td>\n",
       "      <td>0.320605</td>\n",
       "      <td>0.050275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.477451</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.334278</td>\n",
       "      <td>0.102502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.500804</td>\n",
       "      <td>0.105517</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.071442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.505197</td>\n",
       "      <td>0.114893</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.095465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.519583</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.228225</td>\n",
       "      <td>0.064166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.538924</td>\n",
       "      <td>0.085158</td>\n",
       "      <td>0.227874</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.542032</td>\n",
       "      <td>0.120523</td>\n",
       "      <td>0.283429</td>\n",
       "      <td>0.055724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.563269</td>\n",
       "      <td>0.087077</td>\n",
       "      <td>0.226925</td>\n",
       "      <td>0.069061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.594981</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>0.069227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.598507</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.048030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.624750</td>\n",
       "      <td>0.152260</td>\n",
       "      <td>0.245901</td>\n",
       "      <td>0.049912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.639746</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.228980</td>\n",
       "      <td>0.067778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657535</td>\n",
       "      <td>0.155708</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>0.050784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.670994</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>0.232621</td>\n",
       "      <td>0.068573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.699242</td>\n",
       "      <td>0.159485</td>\n",
       "      <td>0.251567</td>\n",
       "      <td>0.055429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757841</td>\n",
       "      <td>0.166070</td>\n",
       "      <td>0.259378</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801947</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>0.267642</td>\n",
       "      <td>0.086866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.371292</td>\n",
       "      <td>0.371292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.097368</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.060679</td>\n",
       "      <td>0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>0.011571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.005014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.002590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:347: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4201306047.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':overall_score},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 20\n",
    "\n",
    "overall_score = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed)\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':overall_score},ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The real final test might be how good the predictor is at choosing an intervention for a given individual. But we can't test that."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "38       NCS_small_daily_projects                0.00\n",
      "37                      NCS_total                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "23          NCS_intellectual_task                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "21       IMI_perceived_competence                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.08\n",
      "5                            TRSQ                0.08\n",
      "6       ACES_neglectful_parenting               -0.08\n",
      "0                            BSCS                0.00\n",
      "31             NCS_prefer_complex                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "37                      NCS_total                0.00\n",
      "38       NCS_small_daily_projects                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.0036091107931160993, 0.015382233580734317, -0.03508212446996439, 0.0045933750242519444, -0.33330574000360014]\n",
      "overall_score:\n",
      "-0.06896062901509244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288410</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.347298</td>\n",
       "      <td>0.035489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.293047</td>\n",
       "      <td>0.075910</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.293047</td>\n",
       "      <td>0.075910</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.293667</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>0.349722</td>\n",
       "      <td>0.030411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294777</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.348409</td>\n",
       "      <td>0.039376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298089</td>\n",
       "      <td>0.072020</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.036457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299818</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.313285</td>\n",
       "      <td>0.021087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.300425</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.029175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300433</td>\n",
       "      <td>0.067204</td>\n",
       "      <td>0.350839</td>\n",
       "      <td>0.037694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301463</td>\n",
       "      <td>0.071130</td>\n",
       "      <td>0.351245</td>\n",
       "      <td>0.039034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.302016</td>\n",
       "      <td>0.071682</td>\n",
       "      <td>0.350127</td>\n",
       "      <td>0.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.302430</td>\n",
       "      <td>0.084377</td>\n",
       "      <td>0.348533</td>\n",
       "      <td>0.023347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303563</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.303897</td>\n",
       "      <td>0.089003</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.023626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308423</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.347394</td>\n",
       "      <td>0.033606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308725</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>0.062523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325269</td>\n",
       "      <td>0.056862</td>\n",
       "      <td>0.334962</td>\n",
       "      <td>0.031944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.328481</td>\n",
       "      <td>0.087135</td>\n",
       "      <td>0.337360</td>\n",
       "      <td>0.030854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337441</td>\n",
       "      <td>0.103615</td>\n",
       "      <td>0.361082</td>\n",
       "      <td>0.031338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343193</td>\n",
       "      <td>0.095001</td>\n",
       "      <td>0.360162</td>\n",
       "      <td>0.043794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349665</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0.354225</td>\n",
       "      <td>0.066925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351895</td>\n",
       "      <td>0.117910</td>\n",
       "      <td>0.355717</td>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.352353</td>\n",
       "      <td>0.111412</td>\n",
       "      <td>0.355244</td>\n",
       "      <td>0.027131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.354081</td>\n",
       "      <td>0.090666</td>\n",
       "      <td>0.338806</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.355832</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>0.330398</td>\n",
       "      <td>0.036763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367551</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.316098</td>\n",
       "      <td>0.032528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.369260</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.315976</td>\n",
       "      <td>0.032981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371135</td>\n",
       "      <td>0.037060</td>\n",
       "      <td>0.315886</td>\n",
       "      <td>0.031429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373678</td>\n",
       "      <td>0.035369</td>\n",
       "      <td>0.315083</td>\n",
       "      <td>0.028377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376697</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.314036</td>\n",
       "      <td>0.025253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378476</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>0.313408</td>\n",
       "      <td>0.023845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392350</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.359940</td>\n",
       "      <td>0.037180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.409784</td>\n",
       "      <td>0.167160</td>\n",
       "      <td>0.301032</td>\n",
       "      <td>0.111165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.411008</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.371563</td>\n",
       "      <td>0.054809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415063</td>\n",
       "      <td>0.122209</td>\n",
       "      <td>0.360791</td>\n",
       "      <td>0.042429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.417805</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>0.387993</td>\n",
       "      <td>0.107674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418336</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>0.345614</td>\n",
       "      <td>0.062225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422506</td>\n",
       "      <td>0.185688</td>\n",
       "      <td>0.303132</td>\n",
       "      <td>0.123583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.427162</td>\n",
       "      <td>0.069461</td>\n",
       "      <td>0.398590</td>\n",
       "      <td>0.105313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.433742</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0.346453</td>\n",
       "      <td>0.120398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.435400</td>\n",
       "      <td>0.123250</td>\n",
       "      <td>0.335387</td>\n",
       "      <td>0.110144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.438559</td>\n",
       "      <td>0.195686</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.129856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.441517</td>\n",
       "      <td>0.108116</td>\n",
       "      <td>0.349139</td>\n",
       "      <td>0.085130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.443098</td>\n",
       "      <td>0.122632</td>\n",
       "      <td>0.359686</td>\n",
       "      <td>0.112010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.443733</td>\n",
       "      <td>0.151434</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.071480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.454799</td>\n",
       "      <td>0.096457</td>\n",
       "      <td>0.368405</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.457660</td>\n",
       "      <td>0.101214</td>\n",
       "      <td>0.367982</td>\n",
       "      <td>0.072460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.460660</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>0.309517</td>\n",
       "      <td>0.139231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.461852</td>\n",
       "      <td>0.099810</td>\n",
       "      <td>0.367065</td>\n",
       "      <td>0.069615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.468386</td>\n",
       "      <td>0.097949</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.065708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.475986</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>0.363049</td>\n",
       "      <td>0.060105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.480336</td>\n",
       "      <td>0.136476</td>\n",
       "      <td>0.297415</td>\n",
       "      <td>0.101730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.482390</td>\n",
       "      <td>0.093313</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.056452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.485786</td>\n",
       "      <td>0.137346</td>\n",
       "      <td>0.344748</td>\n",
       "      <td>0.116423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491286</td>\n",
       "      <td>0.211941</td>\n",
       "      <td>0.314959</td>\n",
       "      <td>0.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.499497</td>\n",
       "      <td>0.133567</td>\n",
       "      <td>0.307901</td>\n",
       "      <td>0.068284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.502722</td>\n",
       "      <td>0.064218</td>\n",
       "      <td>0.310633</td>\n",
       "      <td>0.074997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.512404</td>\n",
       "      <td>0.215938</td>\n",
       "      <td>0.319844</td>\n",
       "      <td>0.165234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.513499</td>\n",
       "      <td>0.103826</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.067066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.518518</td>\n",
       "      <td>0.153531</td>\n",
       "      <td>0.326853</td>\n",
       "      <td>0.085935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.574988</td>\n",
       "      <td>0.117961</td>\n",
       "      <td>0.354894</td>\n",
       "      <td>0.042989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.685712</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.071584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.702860</td>\n",
       "      <td>0.111064</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>0.078593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.723904</td>\n",
       "      <td>0.110667</td>\n",
       "      <td>0.384484</td>\n",
       "      <td>0.079806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.752958</td>\n",
       "      <td>0.110592</td>\n",
       "      <td>0.382805</td>\n",
       "      <td>0.076703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.794343</td>\n",
       "      <td>0.107459</td>\n",
       "      <td>0.383762</td>\n",
       "      <td>0.069937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.828454</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.380285</td>\n",
       "      <td>0.056067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.322590</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>0.346501</td>\n",
       "      <td>0.075421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.404271</td>\n",
       "      <td>0.228891</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.082658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.517240</td>\n",
       "      <td>0.262708</td>\n",
       "      <td>0.366153</td>\n",
       "      <td>0.085429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.681205</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.375756</td>\n",
       "      <td>0.093398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.960630</td>\n",
       "      <td>0.371456</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>0.119859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.232267</td>\n",
       "      <td>0.394677</td>\n",
       "      <td>0.384232</td>\n",
       "      <td>0.145442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.080712</td>\n",
       "      <td>0.080712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>0.035082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.194826</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.008660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.059079</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:347: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/3825126050.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':overall_score},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 40\n",
    "\n",
    "overall_score = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed)\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':overall_score},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.081768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.0</td>\n",
       "      <td>-0.090946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.068961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  overall_score\n",
       "0        10.0      -0.081768\n",
       "1        20.0      -0.090946\n",
       "2        40.0      -0.068961"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring how magnitude of interaction effects affects performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.08\n",
      "1                        EDM                0.08\n",
      "2                     BIS_11               -0.08\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.10891340562308183, -0.06003743599259326, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08176779797562309\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255178</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.065261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.262595</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271499</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.084335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277201</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>0.081428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280728</td>\n",
       "      <td>0.079895</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280805</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281511</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.084321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.281915</td>\n",
       "      <td>0.075993</td>\n",
       "      <td>0.344097</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.285971</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.315441</td>\n",
       "      <td>0.048176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286894</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287454</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.340642</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.288578</td>\n",
       "      <td>0.041586</td>\n",
       "      <td>0.286704</td>\n",
       "      <td>0.072516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288602</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.353791</td>\n",
       "      <td>0.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290244</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.254771</td>\n",
       "      <td>0.039511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291442</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.078728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.292087</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>0.070562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292894</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293008</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294424</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.295521</td>\n",
       "      <td>0.065191</td>\n",
       "      <td>0.229453</td>\n",
       "      <td>0.074495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299060</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>0.041387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.299651</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.228557</td>\n",
       "      <td>0.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301298</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>0.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301333</td>\n",
       "      <td>0.072146</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.305082</td>\n",
       "      <td>0.067009</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305948</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.282923</td>\n",
       "      <td>0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310575</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.333777</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310993</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312164</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313481</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.067084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.313667</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.228303</td>\n",
       "      <td>0.072135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.320649</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>0.228520</td>\n",
       "      <td>0.071249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327152</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343089</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>0.089983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.343326</td>\n",
       "      <td>0.137883</td>\n",
       "      <td>0.346256</td>\n",
       "      <td>0.098924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.343510</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.340076</td>\n",
       "      <td>0.102899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350813</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.034419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355006</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.311593</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368240</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.258145</td>\n",
       "      <td>0.031309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389879</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.102402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.394979</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.337829</td>\n",
       "      <td>0.123855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411295</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.095744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.422509</td>\n",
       "      <td>0.130699</td>\n",
       "      <td>0.321198</td>\n",
       "      <td>0.129938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.972764</td>\n",
       "      <td>0.119505</td>\n",
       "      <td>0.119505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.049022</td>\n",
       "      <td>0.049022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.392702</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.023960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.015961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.109025</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.003041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2128795456.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 10\n",
    "\n",
    "analysis_result = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=0.08)\n",
    "\n",
    "\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n",
    "                                        'empirical_group_corr_diff':analysis_result['empirical_corr_diff_mean']\n",
    "                                        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                 0.1\n",
      "1                        EDM                 0.1\n",
      "2                     BIS_11                -0.1\n",
      "3                        PCS                 0.0\n",
      "4                         RS                 0.0\n",
      "5                       TRSQ                 0.0\n",
      "6  ACES_neglectful_parenting                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "1                        EDM                 0.0\n",
      "2                     BIS_11                 0.0\n",
      "3                        PCS                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057500158838832416, 0.0652425453399087, -0.06340593024759178, -0.10007857858537106, -0.233033673622135]\n",
      "overall_score:\n",
      "-0.05475509565527135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280536</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.066271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282740</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.068620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285976</td>\n",
       "      <td>0.075457</td>\n",
       "      <td>0.303230</td>\n",
       "      <td>0.066774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291359</td>\n",
       "      <td>0.075054</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.064125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293160</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.257528</td>\n",
       "      <td>0.035962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294270</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.313554</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300421</td>\n",
       "      <td>0.074639</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.062179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300582</td>\n",
       "      <td>0.060656</td>\n",
       "      <td>0.258034</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.306252</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>0.062085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310130</td>\n",
       "      <td>0.062629</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.038809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.319607</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.077290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.319716</td>\n",
       "      <td>0.056735</td>\n",
       "      <td>0.236580</td>\n",
       "      <td>0.071679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.323386</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.235028</td>\n",
       "      <td>0.075602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324294</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.258747</td>\n",
       "      <td>0.038023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326063</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.341145</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.327872</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>0.233677</td>\n",
       "      <td>0.074882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.333311</td>\n",
       "      <td>0.046846</td>\n",
       "      <td>0.294311</td>\n",
       "      <td>0.068136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.333679</td>\n",
       "      <td>0.062573</td>\n",
       "      <td>0.232698</td>\n",
       "      <td>0.073931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.342525</td>\n",
       "      <td>0.062475</td>\n",
       "      <td>0.232313</td>\n",
       "      <td>0.072567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345193</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.035140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.349577</td>\n",
       "      <td>0.061872</td>\n",
       "      <td>0.231896</td>\n",
       "      <td>0.071387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352848</td>\n",
       "      <td>0.084820</td>\n",
       "      <td>0.348796</td>\n",
       "      <td>0.071307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.357044</td>\n",
       "      <td>0.066266</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.044999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358048</td>\n",
       "      <td>0.078793</td>\n",
       "      <td>0.361033</td>\n",
       "      <td>0.046373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.359976</td>\n",
       "      <td>0.080182</td>\n",
       "      <td>0.354013</td>\n",
       "      <td>0.035563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.360595</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.259809</td>\n",
       "      <td>0.033047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.364699</td>\n",
       "      <td>0.041511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367144</td>\n",
       "      <td>0.134187</td>\n",
       "      <td>0.370470</td>\n",
       "      <td>0.090199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368761</td>\n",
       "      <td>0.078618</td>\n",
       "      <td>0.352578</td>\n",
       "      <td>0.051769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.372953</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.359609</td>\n",
       "      <td>0.043287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373126</td>\n",
       "      <td>0.122264</td>\n",
       "      <td>0.378094</td>\n",
       "      <td>0.082357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.380331</td>\n",
       "      <td>0.075514</td>\n",
       "      <td>0.362062</td>\n",
       "      <td>0.040357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383812</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390169</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.357324</td>\n",
       "      <td>0.035748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390392</td>\n",
       "      <td>0.073656</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.035560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390402</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.349142</td>\n",
       "      <td>0.105288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390518</td>\n",
       "      <td>0.080193</td>\n",
       "      <td>0.348067</td>\n",
       "      <td>0.107437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418096</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.338926</td>\n",
       "      <td>0.107341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.420989</td>\n",
       "      <td>0.145629</td>\n",
       "      <td>0.347551</td>\n",
       "      <td>0.093513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.425335</td>\n",
       "      <td>0.138033</td>\n",
       "      <td>0.358507</td>\n",
       "      <td>0.088399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451667</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>0.313566</td>\n",
       "      <td>0.124625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.456979</td>\n",
       "      <td>0.082932</td>\n",
       "      <td>0.314455</td>\n",
       "      <td>0.113557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.463417</td>\n",
       "      <td>0.127703</td>\n",
       "      <td>0.335019</td>\n",
       "      <td>0.122756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.477298</td>\n",
       "      <td>0.163520</td>\n",
       "      <td>0.345219</td>\n",
       "      <td>0.120798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.499095</td>\n",
       "      <td>0.162325</td>\n",
       "      <td>0.346795</td>\n",
       "      <td>0.123544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.813027</td>\n",
       "      <td>1.682118</td>\n",
       "      <td>1.682118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.033321</td>\n",
       "      <td>1.066090</td>\n",
       "      <td>1.066090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>3.054898</td>\n",
       "      <td>1.049888</td>\n",
       "      <td>1.049888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.389706</td>\n",
       "      <td>0.668081</td>\n",
       "      <td>0.668081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.935767</td>\n",
       "      <td>0.445563</td>\n",
       "      <td>0.445563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.514676</td>\n",
       "      <td>0.272516</td>\n",
       "      <td>0.272516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.425740</td>\n",
       "      <td>0.227481</td>\n",
       "      <td>0.227481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.158152</td>\n",
       "      <td>0.150336</td>\n",
       "      <td>0.150336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-1.102637</td>\n",
       "      <td>0.142949</td>\n",
       "      <td>0.142949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.064189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>1.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.774</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-1.103</td>\n",
       "      <td>1.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/1542116184.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 10\n",
    "\n",
    "analysis_result = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=0.10)\n",
    "\n",
    "\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n",
    "                                        'empirical_group_corr_diff':analysis_result['empirical_corr_diff_mean']\n",
    "                                        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.15\n",
      "1                        EDM                0.15\n",
      "2                     BIS_11               -0.15\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.15\n",
      "5                       TRSQ                0.15\n",
      "6  ACES_neglectful_parenting               -0.15\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.16537611600226076, 0.22360590980202688, 0.10895360443227087, 0.03862980769093127, -0.20680131502929178]\n",
      "overall_score:\n",
      "0.06595282457963961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313291</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.271523</td>\n",
       "      <td>0.038085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.314713</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.042587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.314713</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.042587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.318083</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.270421</td>\n",
       "      <td>0.040601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.318897</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.318897</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.324787</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.254367</td>\n",
       "      <td>0.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.324787</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.254367</td>\n",
       "      <td>0.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325055</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.041189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.334725</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.334725</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334893</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>0.328888</td>\n",
       "      <td>0.081433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334973</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.332893</td>\n",
       "      <td>0.078332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335664</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0.324804</td>\n",
       "      <td>0.079446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.336151</td>\n",
       "      <td>0.063554</td>\n",
       "      <td>0.266503</td>\n",
       "      <td>0.040563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.338583</td>\n",
       "      <td>0.113678</td>\n",
       "      <td>0.320940</td>\n",
       "      <td>0.077627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346590</td>\n",
       "      <td>0.112708</td>\n",
       "      <td>0.315752</td>\n",
       "      <td>0.077662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.348176</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.348176</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.351797</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.251206</td>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.351797</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.251206</td>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352976</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.313138</td>\n",
       "      <td>0.079296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354759</td>\n",
       "      <td>0.045979</td>\n",
       "      <td>0.329881</td>\n",
       "      <td>0.051990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355639</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.366802</td>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.033704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366802</td>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.033704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370572</td>\n",
       "      <td>0.065570</td>\n",
       "      <td>0.260941</td>\n",
       "      <td>0.036324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.392691</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.266645</td>\n",
       "      <td>0.042307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.396044</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.263786</td>\n",
       "      <td>0.046491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.401044</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.260524</td>\n",
       "      <td>0.048475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.407883</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.257376</td>\n",
       "      <td>0.050989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.417785</td>\n",
       "      <td>0.029084</td>\n",
       "      <td>0.255525</td>\n",
       "      <td>0.055044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.422222</td>\n",
       "      <td>0.039881</td>\n",
       "      <td>0.341340</td>\n",
       "      <td>0.055506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.425047</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.255666</td>\n",
       "      <td>0.058205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.433376</td>\n",
       "      <td>0.095087</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>0.091533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.471679</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.056303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.471679</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.056303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472749</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>0.371170</td>\n",
       "      <td>0.074490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.527282</td>\n",
       "      <td>0.084701</td>\n",
       "      <td>0.387274</td>\n",
       "      <td>0.102775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.538155</td>\n",
       "      <td>0.074540</td>\n",
       "      <td>0.367457</td>\n",
       "      <td>0.067556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.566573</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.388973</td>\n",
       "      <td>0.051971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.566573</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.388973</td>\n",
       "      <td>0.051971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.578664</td>\n",
       "      <td>0.088895</td>\n",
       "      <td>0.381797</td>\n",
       "      <td>0.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.583859</td>\n",
       "      <td>0.099309</td>\n",
       "      <td>0.396817</td>\n",
       "      <td>0.053920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.602994</td>\n",
       "      <td>0.143454</td>\n",
       "      <td>0.397971</td>\n",
       "      <td>0.125048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.603928</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.603928</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604194</td>\n",
       "      <td>0.142660</td>\n",
       "      <td>0.400596</td>\n",
       "      <td>0.123536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.608473</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>0.394455</td>\n",
       "      <td>0.129145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.609766</td>\n",
       "      <td>0.154966</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.128182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.609766</td>\n",
       "      <td>0.154966</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.128182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.610032</td>\n",
       "      <td>0.154868</td>\n",
       "      <td>0.395024</td>\n",
       "      <td>0.129202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613091</td>\n",
       "      <td>0.096461</td>\n",
       "      <td>0.379837</td>\n",
       "      <td>0.059097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616944</td>\n",
       "      <td>0.170896</td>\n",
       "      <td>0.363531</td>\n",
       "      <td>0.118143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.617682</td>\n",
       "      <td>0.090644</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>0.045920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.623825</td>\n",
       "      <td>0.182559</td>\n",
       "      <td>0.356952</td>\n",
       "      <td>0.129224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637249</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.379414</td>\n",
       "      <td>0.052483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637975</td>\n",
       "      <td>0.089121</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>0.042431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.646218</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.361509</td>\n",
       "      <td>0.071593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.646218</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.361509</td>\n",
       "      <td>0.071593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650424</td>\n",
       "      <td>0.167471</td>\n",
       "      <td>0.333073</td>\n",
       "      <td>0.124623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.654022</td>\n",
       "      <td>0.094483</td>\n",
       "      <td>0.380363</td>\n",
       "      <td>0.047612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659164</td>\n",
       "      <td>0.084247</td>\n",
       "      <td>0.383653</td>\n",
       "      <td>0.044340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659532</td>\n",
       "      <td>0.147259</td>\n",
       "      <td>0.334754</td>\n",
       "      <td>0.102269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.665857</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.665857</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.667015</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>0.380291</td>\n",
       "      <td>0.043989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.691149</td>\n",
       "      <td>0.135288</td>\n",
       "      <td>0.372285</td>\n",
       "      <td>0.089277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.696987</td>\n",
       "      <td>0.148783</td>\n",
       "      <td>0.362455</td>\n",
       "      <td>0.094980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.719730</td>\n",
       "      <td>0.193939</td>\n",
       "      <td>0.334525</td>\n",
       "      <td>0.150313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.720082</td>\n",
       "      <td>0.169272</td>\n",
       "      <td>0.343955</td>\n",
       "      <td>0.151039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.680527</td>\n",
       "      <td>2.137507</td>\n",
       "      <td>2.137507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.788157</td>\n",
       "      <td>1.405222</td>\n",
       "      <td>1.405222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>3.137986</td>\n",
       "      <td>0.942479</td>\n",
       "      <td>0.942479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.020496</td>\n",
       "      <td>0.878203</td>\n",
       "      <td>0.878203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-2.427224</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>0.577184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-2.250846</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.507167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>2.177965</td>\n",
       "      <td>0.454127</td>\n",
       "      <td>0.454127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>1.802220</td>\n",
       "      <td>0.305329</td>\n",
       "      <td>0.305329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>1.597165</td>\n",
       "      <td>0.257525</td>\n",
       "      <td>0.257525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-1.214756</td>\n",
       "      <td>0.142431</td>\n",
       "      <td>0.142431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.151494</td>\n",
       "      <td>0.133708</td>\n",
       "      <td>0.133708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.037853</td>\n",
       "      <td>0.102181</td>\n",
       "      <td>0.102181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-1.056939</td>\n",
       "      <td>0.098368</td>\n",
       "      <td>0.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.809250</td>\n",
       "      <td>0.063450</td>\n",
       "      <td>0.063450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.722481</td>\n",
       "      <td>0.047984</td>\n",
       "      <td>0.047984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.479662</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>0.022814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>0.022532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.400357</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>0.017881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.374786</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.017299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.424258</td>\n",
       "      <td>0.013982</td>\n",
       "      <td>0.013982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>4.681</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.017</td>\n",
       "      <td>2.138</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>2.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.299</td>\n",
       "      <td>-3.788</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.405</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>1.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>1.597</td>\n",
       "      <td>-2.251</td>\n",
       "      <td>-1.215</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.441</td>\n",
       "      <td>-2.427</td>\n",
       "      <td>1.802</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.178</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-1.057</td>\n",
       "      <td>1.151</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2599327680.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 10\n",
    "\n",
    "analysis_result = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=0.15)\n",
    "\n",
    "\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n",
    "                                        'empirical_group_corr_diff':analysis_result['empirical_corr_diff_mean']\n",
    "                                        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                 0.2\n",
      "1                        EDM                 0.2\n",
      "2                     BIS_11                -0.2\n",
      "3                        PCS                 0.0\n",
      "4                         RS                 0.0\n",
      "5                       TRSQ                 0.0\n",
      "6  ACES_neglectful_parenting                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.2\n",
      "5                       TRSQ                 0.2\n",
      "6  ACES_neglectful_parenting                -0.2\n",
      "0                       BSCS                 0.0\n",
      "1                        EDM                 0.0\n",
      "2                     BIS_11                 0.0\n",
      "3                        PCS                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.42479150955562195, 0.35168783658058655, 0.27644354337590515, 0.1918779999364676, -0.06388611239251407]\n",
      "overall_score:\n",
      "0.23618295541121342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326964</td>\n",
       "      <td>0.060005</td>\n",
       "      <td>0.279462</td>\n",
       "      <td>0.053402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.329412</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.262711</td>\n",
       "      <td>0.047003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.329412</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.262711</td>\n",
       "      <td>0.047003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330073</td>\n",
       "      <td>0.064848</td>\n",
       "      <td>0.277446</td>\n",
       "      <td>0.055342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330193</td>\n",
       "      <td>0.112270</td>\n",
       "      <td>0.291310</td>\n",
       "      <td>0.082583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.330309</td>\n",
       "      <td>0.068737</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>0.048639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.330309</td>\n",
       "      <td>0.068737</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>0.048639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330407</td>\n",
       "      <td>0.114873</td>\n",
       "      <td>0.295051</td>\n",
       "      <td>0.089534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.332108</td>\n",
       "      <td>0.116356</td>\n",
       "      <td>0.298594</td>\n",
       "      <td>0.093863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.333903</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>0.045468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.333903</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>0.045468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334478</td>\n",
       "      <td>0.110366</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.090925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335098</td>\n",
       "      <td>0.066143</td>\n",
       "      <td>0.275252</td>\n",
       "      <td>0.053542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335744</td>\n",
       "      <td>0.110128</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.074078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.341022</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>0.258635</td>\n",
       "      <td>0.041502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.341022</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>0.258635</td>\n",
       "      <td>0.041502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342026</td>\n",
       "      <td>0.109787</td>\n",
       "      <td>0.282190</td>\n",
       "      <td>0.070875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342302</td>\n",
       "      <td>0.067336</td>\n",
       "      <td>0.272749</td>\n",
       "      <td>0.051150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.354809</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>0.254210</td>\n",
       "      <td>0.035973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.354809</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>0.254210</td>\n",
       "      <td>0.035973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357234</td>\n",
       "      <td>0.068175</td>\n",
       "      <td>0.268609</td>\n",
       "      <td>0.046585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.367763</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>0.252494</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.367763</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>0.252494</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370643</td>\n",
       "      <td>0.069662</td>\n",
       "      <td>0.266105</td>\n",
       "      <td>0.042640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.397921</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.313222</td>\n",
       "      <td>0.066544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.397921</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.313222</td>\n",
       "      <td>0.066544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406039</td>\n",
       "      <td>0.034661</td>\n",
       "      <td>0.341289</td>\n",
       "      <td>0.076134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.466504</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.276529</td>\n",
       "      <td>0.085987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.466734</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.271030</td>\n",
       "      <td>0.089951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.468089</td>\n",
       "      <td>0.047679</td>\n",
       "      <td>0.264568</td>\n",
       "      <td>0.087433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.472041</td>\n",
       "      <td>0.047095</td>\n",
       "      <td>0.257225</td>\n",
       "      <td>0.086747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472406</td>\n",
       "      <td>0.109389</td>\n",
       "      <td>0.347610</td>\n",
       "      <td>0.120226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.479350</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.249566</td>\n",
       "      <td>0.085996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.485660</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.247226</td>\n",
       "      <td>0.085528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.528894</td>\n",
       "      <td>0.058696</td>\n",
       "      <td>0.352878</td>\n",
       "      <td>0.064896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576085</td>\n",
       "      <td>0.046248</td>\n",
       "      <td>0.399176</td>\n",
       "      <td>0.086490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.581382</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.379091</td>\n",
       "      <td>0.074947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.581382</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.379091</td>\n",
       "      <td>0.074947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.620905</td>\n",
       "      <td>0.103252</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>0.117771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.699529</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.371851</td>\n",
       "      <td>0.050194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.775611</td>\n",
       "      <td>0.105954</td>\n",
       "      <td>0.403251</td>\n",
       "      <td>0.066581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.775611</td>\n",
       "      <td>0.105954</td>\n",
       "      <td>0.403251</td>\n",
       "      <td>0.066581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.797673</td>\n",
       "      <td>0.107194</td>\n",
       "      <td>0.418345</td>\n",
       "      <td>0.073085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.829561</td>\n",
       "      <td>0.105097</td>\n",
       "      <td>0.394971</td>\n",
       "      <td>0.078443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.853314</td>\n",
       "      <td>0.147370</td>\n",
       "      <td>0.367019</td>\n",
       "      <td>0.123537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.854196</td>\n",
       "      <td>0.146843</td>\n",
       "      <td>0.364017</td>\n",
       "      <td>0.129082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.859053</td>\n",
       "      <td>0.112999</td>\n",
       "      <td>0.389540</td>\n",
       "      <td>0.065896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.880247</td>\n",
       "      <td>0.147479</td>\n",
       "      <td>0.359625</td>\n",
       "      <td>0.132714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.880247</td>\n",
       "      <td>0.147479</td>\n",
       "      <td>0.359625</td>\n",
       "      <td>0.132714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.881867</td>\n",
       "      <td>0.138261</td>\n",
       "      <td>0.332113</td>\n",
       "      <td>0.123108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.883455</td>\n",
       "      <td>0.160674</td>\n",
       "      <td>0.352620</td>\n",
       "      <td>0.116670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.884406</td>\n",
       "      <td>0.159898</td>\n",
       "      <td>0.349554</td>\n",
       "      <td>0.121390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.888058</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.888058</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.891964</td>\n",
       "      <td>0.089509</td>\n",
       "      <td>0.411094</td>\n",
       "      <td>0.074683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.897182</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.365002</td>\n",
       "      <td>0.116320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.897394</td>\n",
       "      <td>0.173510</td>\n",
       "      <td>0.369406</td>\n",
       "      <td>0.112216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.898965</td>\n",
       "      <td>0.176210</td>\n",
       "      <td>0.366449</td>\n",
       "      <td>0.114158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.898965</td>\n",
       "      <td>0.176210</td>\n",
       "      <td>0.366449</td>\n",
       "      <td>0.114158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.899176</td>\n",
       "      <td>0.174466</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>0.110281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.899176</td>\n",
       "      <td>0.174466</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>0.110281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.908627</td>\n",
       "      <td>0.137222</td>\n",
       "      <td>0.322701</td>\n",
       "      <td>0.124140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.909885</td>\n",
       "      <td>0.102565</td>\n",
       "      <td>0.418601</td>\n",
       "      <td>0.067424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.916125</td>\n",
       "      <td>0.153012</td>\n",
       "      <td>0.347779</td>\n",
       "      <td>0.127476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.916125</td>\n",
       "      <td>0.153012</td>\n",
       "      <td>0.347779</td>\n",
       "      <td>0.127476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.932906</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.932906</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.932906</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.936044</td>\n",
       "      <td>0.112087</td>\n",
       "      <td>0.400938</td>\n",
       "      <td>0.068177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.946837</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.051376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963130</td>\n",
       "      <td>0.106598</td>\n",
       "      <td>0.407527</td>\n",
       "      <td>0.072562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.966312</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.966312</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.966312</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.973922</td>\n",
       "      <td>0.091090</td>\n",
       "      <td>0.409398</td>\n",
       "      <td>0.051676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.981268</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.071438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.981479</td>\n",
       "      <td>0.150581</td>\n",
       "      <td>0.348560</td>\n",
       "      <td>0.068686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.984806</td>\n",
       "      <td>0.098318</td>\n",
       "      <td>0.406965</td>\n",
       "      <td>0.067734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.992398</td>\n",
       "      <td>0.143972</td>\n",
       "      <td>0.335512</td>\n",
       "      <td>0.101880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.993084</td>\n",
       "      <td>0.129924</td>\n",
       "      <td>0.335659</td>\n",
       "      <td>0.113346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>6.194726</td>\n",
       "      <td>3.180488</td>\n",
       "      <td>3.180488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.738392</td>\n",
       "      <td>1.890470</td>\n",
       "      <td>1.890470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>3.961708</td>\n",
       "      <td>1.316687</td>\n",
       "      <td>1.316687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.944021</td>\n",
       "      <td>1.259699</td>\n",
       "      <td>1.259699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.911378</td>\n",
       "      <td>0.719387</td>\n",
       "      <td>0.719387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>2.671417</td>\n",
       "      <td>0.603133</td>\n",
       "      <td>0.603133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-2.434931</td>\n",
       "      <td>0.494194</td>\n",
       "      <td>0.494194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.995138</td>\n",
       "      <td>0.328580</td>\n",
       "      <td>0.328580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>1.466134</td>\n",
       "      <td>0.183856</td>\n",
       "      <td>0.183856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-1.220320</td>\n",
       "      <td>0.111067</td>\n",
       "      <td>0.111067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.037504</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.085542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.956758</td>\n",
       "      <td>0.072080</td>\n",
       "      <td>0.072080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.964943</td>\n",
       "      <td>0.071527</td>\n",
       "      <td>0.071527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.900777</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.059961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.828148</td>\n",
       "      <td>0.050718</td>\n",
       "      <td>0.050718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.488216</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.023688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.476118</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>0.019497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.422425</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.337088</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.013883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.426302</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.010604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.426</td>\n",
       "      <td>6.195</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.011</td>\n",
       "      <td>3.180</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>3.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.337</td>\n",
       "      <td>-4.738</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.890</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.317</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.476</td>\n",
       "      <td>-2.435</td>\n",
       "      <td>2.911</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.218</td>\n",
       "      <td>2.671</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>1.466</td>\n",
       "      <td>-1.995</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.957</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2894605151.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 10\n",
    "\n",
    "analysis_result = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=0.20)\n",
    "\n",
    "\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n",
    "                                        'empirical_group_corr_diff':analysis_result['empirical_corr_diff_mean']\n",
    "                                        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                 0.3\n",
      "1                        EDM                 0.3\n",
      "2                     BIS_11                -0.3\n",
      "3                        PCS                 0.0\n",
      "4                         RS                 0.0\n",
      "5                       TRSQ                 0.0\n",
      "6  ACES_neglectful_parenting                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.3\n",
      "5                       TRSQ                 0.3\n",
      "6  ACES_neglectful_parenting                -0.3\n",
      "0                       BSCS                 0.0\n",
      "1                        EDM                 0.0\n",
      "2                     BIS_11                 0.0\n",
      "3                        PCS                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.504e-01, tolerance: 5.796e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.504e-01, tolerance: 5.796e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.752e-01, tolerance: 5.796e-01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.6197173183084714, 0.49885397484454164, 0.6146841433519727, 0.5476410104311844, 0.24090959839835202]\n",
      "overall_score:\n",
      "0.5043612090669044\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.243131</td>\n",
       "      <td>0.090368</td>\n",
       "      <td>0.276332</td>\n",
       "      <td>0.063150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.245526</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>0.277509</td>\n",
       "      <td>0.067725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.247387</td>\n",
       "      <td>0.093234</td>\n",
       "      <td>0.276885</td>\n",
       "      <td>0.058714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.253081</td>\n",
       "      <td>0.087038</td>\n",
       "      <td>0.279509</td>\n",
       "      <td>0.070827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.263933</td>\n",
       "      <td>0.083848</td>\n",
       "      <td>0.283075</td>\n",
       "      <td>0.070291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274971</td>\n",
       "      <td>0.076026</td>\n",
       "      <td>0.287626</td>\n",
       "      <td>0.065217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351903</td>\n",
       "      <td>0.063695</td>\n",
       "      <td>0.279659</td>\n",
       "      <td>0.048523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352385</td>\n",
       "      <td>0.061960</td>\n",
       "      <td>0.283394</td>\n",
       "      <td>0.051351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356831</td>\n",
       "      <td>0.061309</td>\n",
       "      <td>0.286910</td>\n",
       "      <td>0.051223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357698</td>\n",
       "      <td>0.064647</td>\n",
       "      <td>0.273351</td>\n",
       "      <td>0.041473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.358654</td>\n",
       "      <td>0.067964</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>0.049667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.358654</td>\n",
       "      <td>0.067964</td>\n",
       "      <td>0.270459</td>\n",
       "      <td>0.049667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.360625</td>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.274191</td>\n",
       "      <td>0.054453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.360625</td>\n",
       "      <td>0.066663</td>\n",
       "      <td>0.274191</td>\n",
       "      <td>0.054453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362101</td>\n",
       "      <td>0.057438</td>\n",
       "      <td>0.290831</td>\n",
       "      <td>0.046653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.364572</td>\n",
       "      <td>0.067098</td>\n",
       "      <td>0.261886</td>\n",
       "      <td>0.039786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.364572</td>\n",
       "      <td>0.067098</td>\n",
       "      <td>0.261886</td>\n",
       "      <td>0.039786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366373</td>\n",
       "      <td>0.065195</td>\n",
       "      <td>0.267838</td>\n",
       "      <td>0.038720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.367234</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.277256</td>\n",
       "      <td>0.054913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.367234</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.277256</td>\n",
       "      <td>0.054913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.371169</td>\n",
       "      <td>0.066417</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.034250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.371169</td>\n",
       "      <td>0.066417</td>\n",
       "      <td>0.255900</td>\n",
       "      <td>0.034250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.374930</td>\n",
       "      <td>0.061740</td>\n",
       "      <td>0.280259</td>\n",
       "      <td>0.050808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.374930</td>\n",
       "      <td>0.061740</td>\n",
       "      <td>0.280259</td>\n",
       "      <td>0.050808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461614</td>\n",
       "      <td>0.083357</td>\n",
       "      <td>0.360268</td>\n",
       "      <td>0.110388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.503551</td>\n",
       "      <td>0.065573</td>\n",
       "      <td>0.376909</td>\n",
       "      <td>0.073277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.510470</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>0.356587</td>\n",
       "      <td>0.089067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.510470</td>\n",
       "      <td>0.071817</td>\n",
       "      <td>0.356587</td>\n",
       "      <td>0.089067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.708412</td>\n",
       "      <td>0.101939</td>\n",
       "      <td>0.347284</td>\n",
       "      <td>0.040032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.714647</td>\n",
       "      <td>0.095569</td>\n",
       "      <td>0.353644</td>\n",
       "      <td>0.047295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.726975</td>\n",
       "      <td>0.087221</td>\n",
       "      <td>0.365577</td>\n",
       "      <td>0.062273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.740883</td>\n",
       "      <td>0.082886</td>\n",
       "      <td>0.375105</td>\n",
       "      <td>0.076381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.745495</td>\n",
       "      <td>0.038788</td>\n",
       "      <td>0.424330</td>\n",
       "      <td>0.091265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.747800</td>\n",
       "      <td>0.045704</td>\n",
       "      <td>0.402051</td>\n",
       "      <td>0.093391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.747800</td>\n",
       "      <td>0.045704</td>\n",
       "      <td>0.402051</td>\n",
       "      <td>0.093391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.756179</td>\n",
       "      <td>0.082179</td>\n",
       "      <td>0.381701</td>\n",
       "      <td>0.088006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.772110</td>\n",
       "      <td>0.078153</td>\n",
       "      <td>0.386332</td>\n",
       "      <td>0.092101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.785567</td>\n",
       "      <td>0.117843</td>\n",
       "      <td>0.401604</td>\n",
       "      <td>0.121456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.877418</td>\n",
       "      <td>0.092210</td>\n",
       "      <td>0.456116</td>\n",
       "      <td>0.116803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.135954</td>\n",
       "      <td>0.098184</td>\n",
       "      <td>0.509443</td>\n",
       "      <td>0.134638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.225967</td>\n",
       "      <td>0.085501</td>\n",
       "      <td>0.484256</td>\n",
       "      <td>0.097658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.225967</td>\n",
       "      <td>0.085501</td>\n",
       "      <td>0.484256</td>\n",
       "      <td>0.097658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.227883</td>\n",
       "      <td>0.139634</td>\n",
       "      <td>0.435951</td>\n",
       "      <td>0.153705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.230226</td>\n",
       "      <td>0.061233</td>\n",
       "      <td>0.492029</td>\n",
       "      <td>0.109432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.416950</td>\n",
       "      <td>0.121003</td>\n",
       "      <td>0.484987</td>\n",
       "      <td>0.147054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.451465</td>\n",
       "      <td>0.121767</td>\n",
       "      <td>0.465490</td>\n",
       "      <td>0.121941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.451465</td>\n",
       "      <td>0.121767</td>\n",
       "      <td>0.465490</td>\n",
       "      <td>0.121941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.491673</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>0.481493</td>\n",
       "      <td>0.106777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.492159</td>\n",
       "      <td>0.157045</td>\n",
       "      <td>0.368522</td>\n",
       "      <td>0.134203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.496546</td>\n",
       "      <td>0.154328</td>\n",
       "      <td>0.366397</td>\n",
       "      <td>0.130133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.520438</td>\n",
       "      <td>0.105727</td>\n",
       "      <td>0.466673</td>\n",
       "      <td>0.141869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.531025</td>\n",
       "      <td>0.216553</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.180576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.538705</td>\n",
       "      <td>0.211266</td>\n",
       "      <td>0.339243</td>\n",
       "      <td>0.174540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.542787</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.379334</td>\n",
       "      <td>0.215443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.542787</td>\n",
       "      <td>0.217398</td>\n",
       "      <td>0.379334</td>\n",
       "      <td>0.215443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.545099</td>\n",
       "      <td>0.146165</td>\n",
       "      <td>0.447524</td>\n",
       "      <td>0.108903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.550467</td>\n",
       "      <td>0.214938</td>\n",
       "      <td>0.372074</td>\n",
       "      <td>0.209088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.550467</td>\n",
       "      <td>0.214938</td>\n",
       "      <td>0.372074</td>\n",
       "      <td>0.209088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.605512</td>\n",
       "      <td>0.099623</td>\n",
       "      <td>0.464930</td>\n",
       "      <td>0.119094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.605512</td>\n",
       "      <td>0.099623</td>\n",
       "      <td>0.464930</td>\n",
       "      <td>0.119094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.611934</td>\n",
       "      <td>0.203851</td>\n",
       "      <td>0.304566</td>\n",
       "      <td>0.123085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.614011</td>\n",
       "      <td>0.094461</td>\n",
       "      <td>0.461919</td>\n",
       "      <td>0.126806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.616321</td>\n",
       "      <td>0.197222</td>\n",
       "      <td>0.303731</td>\n",
       "      <td>0.121894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.618902</td>\n",
       "      <td>0.182955</td>\n",
       "      <td>0.430734</td>\n",
       "      <td>0.126283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.623440</td>\n",
       "      <td>0.187061</td>\n",
       "      <td>0.318681</td>\n",
       "      <td>0.145388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.623440</td>\n",
       "      <td>0.187061</td>\n",
       "      <td>0.318681</td>\n",
       "      <td>0.145388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.623440</td>\n",
       "      <td>0.187061</td>\n",
       "      <td>0.318681</td>\n",
       "      <td>0.145388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.627827</td>\n",
       "      <td>0.181213</td>\n",
       "      <td>0.317468</td>\n",
       "      <td>0.143334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.627827</td>\n",
       "      <td>0.181213</td>\n",
       "      <td>0.317468</td>\n",
       "      <td>0.143334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.627827</td>\n",
       "      <td>0.181213</td>\n",
       "      <td>0.317468</td>\n",
       "      <td>0.143334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.640103</td>\n",
       "      <td>0.114861</td>\n",
       "      <td>0.469513</td>\n",
       "      <td>0.116478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.644112</td>\n",
       "      <td>0.157383</td>\n",
       "      <td>0.476133</td>\n",
       "      <td>0.158016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.655613</td>\n",
       "      <td>0.158548</td>\n",
       "      <td>0.365779</td>\n",
       "      <td>0.087286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.655613</td>\n",
       "      <td>0.158548</td>\n",
       "      <td>0.365779</td>\n",
       "      <td>0.087286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.655613</td>\n",
       "      <td>0.158548</td>\n",
       "      <td>0.365779</td>\n",
       "      <td>0.087286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.655613</td>\n",
       "      <td>0.158548</td>\n",
       "      <td>0.365779</td>\n",
       "      <td>0.087286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.669407</td>\n",
       "      <td>0.078875</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.097357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.669407</td>\n",
       "      <td>0.078875</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.097357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.669407</td>\n",
       "      <td>0.078875</td>\n",
       "      <td>0.456897</td>\n",
       "      <td>0.097357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.683009</td>\n",
       "      <td>0.142580</td>\n",
       "      <td>0.446201</td>\n",
       "      <td>0.108115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.698613</td>\n",
       "      <td>0.103294</td>\n",
       "      <td>0.456555</td>\n",
       "      <td>0.100167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.709797</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>0.468952</td>\n",
       "      <td>0.132875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.709797</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>0.468952</td>\n",
       "      <td>0.132875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.709797</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>0.468952</td>\n",
       "      <td>0.132875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.709797</td>\n",
       "      <td>0.175950</td>\n",
       "      <td>0.468952</td>\n",
       "      <td>0.132875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.711358</td>\n",
       "      <td>0.150219</td>\n",
       "      <td>0.377299</td>\n",
       "      <td>0.105462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.715746</td>\n",
       "      <td>0.143134</td>\n",
       "      <td>0.375705</td>\n",
       "      <td>0.104999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-4.732227</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>0.441635</td>\n",
       "      <td>0.102885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.768255</td>\n",
       "      <td>0.143027</td>\n",
       "      <td>0.459422</td>\n",
       "      <td>0.119017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.769732</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>0.124126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.769732</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>0.124126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.769732</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>0.124126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.769732</td>\n",
       "      <td>0.146191</td>\n",
       "      <td>0.451277</td>\n",
       "      <td>0.124126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-13.137168</td>\n",
       "      <td>9.392563</td>\n",
       "      <td>9.392563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-9.326741</td>\n",
       "      <td>4.821957</td>\n",
       "      <td>4.821957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>8.220720</td>\n",
       "      <td>3.714779</td>\n",
       "      <td>3.714779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>6.883258</td>\n",
       "      <td>2.593287</td>\n",
       "      <td>2.593287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>5.955569</td>\n",
       "      <td>1.951079</td>\n",
       "      <td>1.951079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>4.864554</td>\n",
       "      <td>1.316959</td>\n",
       "      <td>1.316959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-2.074320</td>\n",
       "      <td>0.225659</td>\n",
       "      <td>0.225659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-1.179043</td>\n",
       "      <td>0.077586</td>\n",
       "      <td>0.077586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.643632</td>\n",
       "      <td>0.025487</td>\n",
       "      <td>0.025487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.414444</td>\n",
       "      <td>0.009439</td>\n",
       "      <td>0.009439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-13.137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-9.327</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.706</td>\n",
       "      <td>0.040</td>\n",
       "      <td>4.822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.179</td>\n",
       "      <td>8.221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078</td>\n",
       "      <td>3.715</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.617</td>\n",
       "      <td>3.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6.883</td>\n",
       "      <td>0.644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.593</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.734</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>2.619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.951</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.288</td>\n",
       "      <td>0.545</td>\n",
       "      <td>1.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.558</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>1.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.226</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.506</td>\n",
       "      <td>0.226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/3316733203.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "predictors = 10\n",
    "\n",
    "analysis_result = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=0.30)\n",
    "\n",
    "\n",
    "\n",
    "overall_scores = overall_scores.append({'n_features':predictors,'overall_score':analysis_result['overall_score'],\n",
    "                                        'empirical_group_corr_diff':analysis_result['empirical_corr_diff_mean']\n",
    "                                        },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "11              BFI_agreeableness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "6       ACES_neglectful_parenting                0.00\n",
      "5                            TRSQ                0.00\n",
      "4                              RS                0.00\n",
      "3                             PCS                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.08\n",
      "5                            TRSQ                0.08\n",
      "6       ACES_neglectful_parenting               -0.08\n",
      "0                            BSCS                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "11              BFI_agreeableness                0.00\n",
      "1                             EDM                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "3                             PCS                0.00\n",
      "2                          BIS_11                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.019391378692160455, 0.05103383687350138, -0.12333443118999532, -0.04514095692852438, -0.3178977602412687]\n",
      "overall_score:\n",
      "-0.09094613803568949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268368</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.096481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269053</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.333186</td>\n",
       "      <td>0.078243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.280129</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.334510</td>\n",
       "      <td>0.041095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285580</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>0.341224</td>\n",
       "      <td>0.051844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.285924</td>\n",
       "      <td>0.054509</td>\n",
       "      <td>0.336622</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292086</td>\n",
       "      <td>0.054613</td>\n",
       "      <td>0.331360</td>\n",
       "      <td>0.084547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292451</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.352444</td>\n",
       "      <td>0.044752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.292899</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.288927</td>\n",
       "      <td>0.042831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292916</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.060843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294701</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.316998</td>\n",
       "      <td>0.098707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.296873</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.300339</td>\n",
       "      <td>0.052913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297910</td>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.349752</td>\n",
       "      <td>0.023424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298140</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.350294</td>\n",
       "      <td>0.034471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299520</td>\n",
       "      <td>0.070640</td>\n",
       "      <td>0.352882</td>\n",
       "      <td>0.037559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301337</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303547</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.037851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304050</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.335633</td>\n",
       "      <td>0.031791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313860</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.038524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.319412</td>\n",
       "      <td>0.086520</td>\n",
       "      <td>0.345630</td>\n",
       "      <td>0.026971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.334056</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.337450</td>\n",
       "      <td>0.095239</td>\n",
       "      <td>0.363220</td>\n",
       "      <td>0.077932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.337593</td>\n",
       "      <td>0.087906</td>\n",
       "      <td>0.339245</td>\n",
       "      <td>0.027032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343701</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.296362</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345577</td>\n",
       "      <td>0.029533</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.050156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.347661</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>0.291765</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350004</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>0.044666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352859</td>\n",
       "      <td>0.113390</td>\n",
       "      <td>0.262172</td>\n",
       "      <td>0.080464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353069</td>\n",
       "      <td>0.031679</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.040813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354948</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.284664</td>\n",
       "      <td>0.038697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356086</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.378191</td>\n",
       "      <td>0.069583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358045</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>0.072911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363721</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.083742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377219</td>\n",
       "      <td>0.122091</td>\n",
       "      <td>0.261163</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.377618</td>\n",
       "      <td>0.090508</td>\n",
       "      <td>0.346471</td>\n",
       "      <td>0.056866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.378890</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>0.344019</td>\n",
       "      <td>0.051012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382975</td>\n",
       "      <td>0.105867</td>\n",
       "      <td>0.364802</td>\n",
       "      <td>0.059270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385794</td>\n",
       "      <td>0.096559</td>\n",
       "      <td>0.279813</td>\n",
       "      <td>0.096009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.386599</td>\n",
       "      <td>0.102026</td>\n",
       "      <td>0.316222</td>\n",
       "      <td>0.035314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393042</td>\n",
       "      <td>0.101054</td>\n",
       "      <td>0.362567</td>\n",
       "      <td>0.065183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.393614</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.314859</td>\n",
       "      <td>0.040052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394098</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>0.260901</td>\n",
       "      <td>0.082618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.395871</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.264513</td>\n",
       "      <td>0.109018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.402055</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>0.313004</td>\n",
       "      <td>0.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.412225</td>\n",
       "      <td>0.111472</td>\n",
       "      <td>0.310599</td>\n",
       "      <td>0.047198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418324</td>\n",
       "      <td>0.122146</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.418916</td>\n",
       "      <td>0.100508</td>\n",
       "      <td>0.330330</td>\n",
       "      <td>0.061356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.426821</td>\n",
       "      <td>0.112532</td>\n",
       "      <td>0.306588</td>\n",
       "      <td>0.053843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.434039</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.260568</td>\n",
       "      <td>0.081751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.438511</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.304221</td>\n",
       "      <td>0.060014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.457834</td>\n",
       "      <td>0.086374</td>\n",
       "      <td>0.320605</td>\n",
       "      <td>0.050275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.477451</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.334278</td>\n",
       "      <td>0.102502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.500804</td>\n",
       "      <td>0.105517</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.071442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.505197</td>\n",
       "      <td>0.114893</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.095465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.519583</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.228225</td>\n",
       "      <td>0.064166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.538924</td>\n",
       "      <td>0.085158</td>\n",
       "      <td>0.227874</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.542032</td>\n",
       "      <td>0.120523</td>\n",
       "      <td>0.283429</td>\n",
       "      <td>0.055724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.563269</td>\n",
       "      <td>0.087077</td>\n",
       "      <td>0.226925</td>\n",
       "      <td>0.069061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.594981</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>0.069227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.598507</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.048030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.624750</td>\n",
       "      <td>0.152260</td>\n",
       "      <td>0.245901</td>\n",
       "      <td>0.049912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.639746</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.228980</td>\n",
       "      <td>0.067778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657535</td>\n",
       "      <td>0.155708</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>0.050784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.670994</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>0.232621</td>\n",
       "      <td>0.068573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.699242</td>\n",
       "      <td>0.159485</td>\n",
       "      <td>0.251567</td>\n",
       "      <td>0.055429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757841</td>\n",
       "      <td>0.166070</td>\n",
       "      <td>0.259378</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801947</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>0.267642</td>\n",
       "      <td>0.086866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.371292</td>\n",
       "      <td>0.371292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.097368</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.060679</td>\n",
       "      <td>0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>0.011571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.005014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.002590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.1\n",
      "2                          BIS_11                -0.1\n",
      "1                             EDM                 0.1\n",
      "11              BFI_agreeableness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "6       ACES_neglectful_parenting                 0.0\n",
      "5                            TRSQ                 0.0\n",
      "4                              RS                 0.0\n",
      "3                             PCS                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.1\n",
      "5                            TRSQ                 0.1\n",
      "6       ACES_neglectful_parenting                -0.1\n",
      "0                            BSCS                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "11              BFI_agreeableness                 0.0\n",
      "1                             EDM                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "3                             PCS                 0.0\n",
      "2                          BIS_11                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.036906016757977333, 0.025163581636640342, 0.04604500169276293, -0.03671511219721468, -0.2969751146633599]\n",
      "overall_score:\n",
      "-0.045115125354638796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304918</td>\n",
       "      <td>0.063440</td>\n",
       "      <td>0.327492</td>\n",
       "      <td>0.108845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.327857</td>\n",
       "      <td>0.051110</td>\n",
       "      <td>0.296022</td>\n",
       "      <td>0.041828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334020</td>\n",
       "      <td>0.065040</td>\n",
       "      <td>0.340143</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.335768</td>\n",
       "      <td>0.053351</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>0.084018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.337082</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.054855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.337902</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.341664</td>\n",
       "      <td>0.040095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.346496</td>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.367956</td>\n",
       "      <td>0.079664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.347777</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.344863</td>\n",
       "      <td>0.033602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350320</td>\n",
       "      <td>0.117292</td>\n",
       "      <td>0.353507</td>\n",
       "      <td>0.102274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351489</td>\n",
       "      <td>0.111644</td>\n",
       "      <td>0.349906</td>\n",
       "      <td>0.099458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358653</td>\n",
       "      <td>0.106210</td>\n",
       "      <td>0.355172</td>\n",
       "      <td>0.088062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366980</td>\n",
       "      <td>0.122583</td>\n",
       "      <td>0.270095</td>\n",
       "      <td>0.111870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367200</td>\n",
       "      <td>0.114957</td>\n",
       "      <td>0.348451</td>\n",
       "      <td>0.071526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367622</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.353349</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.369659</td>\n",
       "      <td>0.116962</td>\n",
       "      <td>0.397206</td>\n",
       "      <td>0.148957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371729</td>\n",
       "      <td>0.077081</td>\n",
       "      <td>0.360293</td>\n",
       "      <td>0.045193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.375474</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.375474</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.377225</td>\n",
       "      <td>0.117343</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.154579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377600</td>\n",
       "      <td>0.131883</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.116884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.379671</td>\n",
       "      <td>0.090425</td>\n",
       "      <td>0.360816</td>\n",
       "      <td>0.014249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.380388</td>\n",
       "      <td>0.113346</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.148274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381142</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>0.356833</td>\n",
       "      <td>0.035260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382589</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>0.360971</td>\n",
       "      <td>0.037757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383239</td>\n",
       "      <td>0.075651</td>\n",
       "      <td>0.359666</td>\n",
       "      <td>0.041389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384915</td>\n",
       "      <td>0.049051</td>\n",
       "      <td>0.323918</td>\n",
       "      <td>0.060162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385893</td>\n",
       "      <td>0.063549</td>\n",
       "      <td>0.342065</td>\n",
       "      <td>0.039767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.387954</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.393366</td>\n",
       "      <td>0.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389257</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.358666</td>\n",
       "      <td>0.038876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390156</td>\n",
       "      <td>0.073377</td>\n",
       "      <td>0.357355</td>\n",
       "      <td>0.035709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390666</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.270984</td>\n",
       "      <td>0.116302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.395265</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.398889</td>\n",
       "      <td>0.094104</td>\n",
       "      <td>0.353345</td>\n",
       "      <td>0.028711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406948</td>\n",
       "      <td>0.133007</td>\n",
       "      <td>0.272066</td>\n",
       "      <td>0.116533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.411962</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.375773</td>\n",
       "      <td>0.078904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.413691</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>0.328533</td>\n",
       "      <td>0.040238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.414383</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.288433</td>\n",
       "      <td>0.074842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415649</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.287326</td>\n",
       "      <td>0.079088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417229</td>\n",
       "      <td>0.045047</td>\n",
       "      <td>0.286014</td>\n",
       "      <td>0.078473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.419315</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.077652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.419564</td>\n",
       "      <td>0.099935</td>\n",
       "      <td>0.327006</td>\n",
       "      <td>0.044877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422146</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.076469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424069</td>\n",
       "      <td>0.051138</td>\n",
       "      <td>0.279994</td>\n",
       "      <td>0.075691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.426593</td>\n",
       "      <td>0.101443</td>\n",
       "      <td>0.325380</td>\n",
       "      <td>0.047330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.427004</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>0.061010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429332</td>\n",
       "      <td>0.133071</td>\n",
       "      <td>0.274467</td>\n",
       "      <td>0.117681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.435419</td>\n",
       "      <td>0.103101</td>\n",
       "      <td>0.323209</td>\n",
       "      <td>0.050025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.439828</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.300332</td>\n",
       "      <td>0.085673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.440957</td>\n",
       "      <td>0.105746</td>\n",
       "      <td>0.375967</td>\n",
       "      <td>0.070364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442223</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>0.377347</td>\n",
       "      <td>0.071956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.445347</td>\n",
       "      <td>0.132983</td>\n",
       "      <td>0.275069</td>\n",
       "      <td>0.118392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.449142</td>\n",
       "      <td>0.105225</td>\n",
       "      <td>0.318572</td>\n",
       "      <td>0.054309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451289</td>\n",
       "      <td>0.121726</td>\n",
       "      <td>0.277875</td>\n",
       "      <td>0.104293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454277</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.367305</td>\n",
       "      <td>0.082260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.457457</td>\n",
       "      <td>0.057614</td>\n",
       "      <td>0.343289</td>\n",
       "      <td>0.067609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.459055</td>\n",
       "      <td>0.106121</td>\n",
       "      <td>0.314673</td>\n",
       "      <td>0.058155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461667</td>\n",
       "      <td>0.095021</td>\n",
       "      <td>0.368599</td>\n",
       "      <td>0.082677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.493914</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.343536</td>\n",
       "      <td>0.191704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.509312</td>\n",
       "      <td>0.103322</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.512424</td>\n",
       "      <td>0.118686</td>\n",
       "      <td>0.312746</td>\n",
       "      <td>0.121671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.521362</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.354846</td>\n",
       "      <td>0.201077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.527624</td>\n",
       "      <td>0.111501</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.087882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.542496</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.322420</td>\n",
       "      <td>0.125426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.550410</td>\n",
       "      <td>0.114304</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.090646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.579715</td>\n",
       "      <td>0.117324</td>\n",
       "      <td>0.236668</td>\n",
       "      <td>0.093520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.599810</td>\n",
       "      <td>0.140503</td>\n",
       "      <td>0.244955</td>\n",
       "      <td>0.050022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.618827</td>\n",
       "      <td>0.120688</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.099021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.625576</td>\n",
       "      <td>0.152676</td>\n",
       "      <td>0.247007</td>\n",
       "      <td>0.052265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.647562</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.240094</td>\n",
       "      <td>0.105328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657793</td>\n",
       "      <td>0.156621</td>\n",
       "      <td>0.248994</td>\n",
       "      <td>0.052303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698816</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.251970</td>\n",
       "      <td>0.056410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757104</td>\n",
       "      <td>0.165911</td>\n",
       "      <td>0.259432</td>\n",
       "      <td>0.070998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801342</td>\n",
       "      <td>0.175274</td>\n",
       "      <td>0.267585</td>\n",
       "      <td>0.086837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.341333</td>\n",
       "      <td>0.648330</td>\n",
       "      <td>0.648330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.260258</td>\n",
       "      <td>0.215655</td>\n",
       "      <td>0.215655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.108059</td>\n",
       "      <td>0.108059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.544510</td>\n",
       "      <td>0.038063</td>\n",
       "      <td>0.038063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.232784</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.010994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.182961</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.085507</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.001820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.341</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.15\n",
      "2                          BIS_11               -0.15\n",
      "1                             EDM                0.15\n",
      "11              BFI_agreeableness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "6       ACES_neglectful_parenting                0.00\n",
      "5                            TRSQ                0.00\n",
      "4                              RS                0.00\n",
      "3                             PCS                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.15\n",
      "5                            TRSQ                0.15\n",
      "6       ACES_neglectful_parenting               -0.15\n",
      "0                            BSCS                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "11              BFI_agreeableness                0.00\n",
      "1                             EDM                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "3                             PCS                0.00\n",
      "2                          BIS_11                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14229584469909184, 0.1879671778025348, 0.04247364456357472, 0.04741943460717779, -0.15101611362189882]\n",
      "overall_score:\n",
      "0.053827997610096066\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377097</td>\n",
       "      <td>0.124330</td>\n",
       "      <td>0.284815</td>\n",
       "      <td>0.087641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383615</td>\n",
       "      <td>0.133127</td>\n",
       "      <td>0.284997</td>\n",
       "      <td>0.090062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.391861</td>\n",
       "      <td>0.134964</td>\n",
       "      <td>0.285635</td>\n",
       "      <td>0.087538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.394726</td>\n",
       "      <td>0.061698</td>\n",
       "      <td>0.308553</td>\n",
       "      <td>0.048312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.404271</td>\n",
       "      <td>0.081683</td>\n",
       "      <td>0.346506</td>\n",
       "      <td>0.127971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.404940</td>\n",
       "      <td>0.135625</td>\n",
       "      <td>0.286143</td>\n",
       "      <td>0.089377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.417786</td>\n",
       "      <td>0.040339</td>\n",
       "      <td>0.326011</td>\n",
       "      <td>0.057091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424432</td>\n",
       "      <td>0.138098</td>\n",
       "      <td>0.286814</td>\n",
       "      <td>0.095462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.438921</td>\n",
       "      <td>0.139859</td>\n",
       "      <td>0.285378</td>\n",
       "      <td>0.099814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.496381</td>\n",
       "      <td>0.075096</td>\n",
       "      <td>0.361540</td>\n",
       "      <td>0.093659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.496963</td>\n",
       "      <td>0.052984</td>\n",
       "      <td>0.365331</td>\n",
       "      <td>0.040388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.520371</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.366708</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.544658</td>\n",
       "      <td>0.156017</td>\n",
       "      <td>0.229578</td>\n",
       "      <td>0.053051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.562335</td>\n",
       "      <td>0.170752</td>\n",
       "      <td>0.229039</td>\n",
       "      <td>0.061278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.568284</td>\n",
       "      <td>0.106801</td>\n",
       "      <td>0.333143</td>\n",
       "      <td>0.078437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.568359</td>\n",
       "      <td>0.094322</td>\n",
       "      <td>0.339527</td>\n",
       "      <td>0.072222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.568495</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.336545</td>\n",
       "      <td>0.077472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.568849</td>\n",
       "      <td>0.110812</td>\n",
       "      <td>0.328276</td>\n",
       "      <td>0.079287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.569042</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.388329</td>\n",
       "      <td>0.048557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.574695</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.323367</td>\n",
       "      <td>0.077858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.580586</td>\n",
       "      <td>0.110869</td>\n",
       "      <td>0.321150</td>\n",
       "      <td>0.076471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.585505</td>\n",
       "      <td>0.175437</td>\n",
       "      <td>0.227299</td>\n",
       "      <td>0.069132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.591659</td>\n",
       "      <td>0.092798</td>\n",
       "      <td>0.387011</td>\n",
       "      <td>0.046857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.591889</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>0.387352</td>\n",
       "      <td>0.173893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.593347</td>\n",
       "      <td>0.094577</td>\n",
       "      <td>0.386532</td>\n",
       "      <td>0.047247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.594498</td>\n",
       "      <td>0.089764</td>\n",
       "      <td>0.385613</td>\n",
       "      <td>0.182849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.606727</td>\n",
       "      <td>0.112672</td>\n",
       "      <td>0.389514</td>\n",
       "      <td>0.172909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.606771</td>\n",
       "      <td>0.141492</td>\n",
       "      <td>0.246404</td>\n",
       "      <td>0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607631</td>\n",
       "      <td>0.096018</td>\n",
       "      <td>0.376481</td>\n",
       "      <td>0.051644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.609336</td>\n",
       "      <td>0.108535</td>\n",
       "      <td>0.388114</td>\n",
       "      <td>0.181784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.609457</td>\n",
       "      <td>0.078423</td>\n",
       "      <td>0.404079</td>\n",
       "      <td>0.130536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.610638</td>\n",
       "      <td>0.091259</td>\n",
       "      <td>0.388787</td>\n",
       "      <td>0.051168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.613089</td>\n",
       "      <td>0.084043</td>\n",
       "      <td>0.399064</td>\n",
       "      <td>0.138116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.615328</td>\n",
       "      <td>0.179682</td>\n",
       "      <td>0.225767</td>\n",
       "      <td>0.079044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.618304</td>\n",
       "      <td>0.086786</td>\n",
       "      <td>0.395546</td>\n",
       "      <td>0.044336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.618692</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.044483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.618692</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.044483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.624523</td>\n",
       "      <td>0.099318</td>\n",
       "      <td>0.380033</td>\n",
       "      <td>0.052112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.626198</td>\n",
       "      <td>0.086321</td>\n",
       "      <td>0.363050</td>\n",
       "      <td>0.065023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.627680</td>\n",
       "      <td>0.166536</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.114289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.630387</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>0.248173</td>\n",
       "      <td>0.057058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.632062</td>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.338714</td>\n",
       "      <td>0.077206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.632285</td>\n",
       "      <td>0.088044</td>\n",
       "      <td>0.376887</td>\n",
       "      <td>0.052557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.633957</td>\n",
       "      <td>0.089411</td>\n",
       "      <td>0.384956</td>\n",
       "      <td>0.047891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.634760</td>\n",
       "      <td>0.044708</td>\n",
       "      <td>0.386109</td>\n",
       "      <td>0.237121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.636089</td>\n",
       "      <td>0.178021</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.122598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.637621</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.390919</td>\n",
       "      <td>0.043028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.637621</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.390919</td>\n",
       "      <td>0.043028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.637621</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.390919</td>\n",
       "      <td>0.043028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.641514</td>\n",
       "      <td>0.084159</td>\n",
       "      <td>0.383577</td>\n",
       "      <td>0.045970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646467</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>0.115490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646578</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.286447</td>\n",
       "      <td>0.114001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646733</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.288402</td>\n",
       "      <td>0.111431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646965</td>\n",
       "      <td>0.099447</td>\n",
       "      <td>0.290084</td>\n",
       "      <td>0.109209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.647238</td>\n",
       "      <td>0.098768</td>\n",
       "      <td>0.291819</td>\n",
       "      <td>0.106835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.647438</td>\n",
       "      <td>0.092545</td>\n",
       "      <td>0.293415</td>\n",
       "      <td>0.098707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650162</td>\n",
       "      <td>0.089909</td>\n",
       "      <td>0.385273</td>\n",
       "      <td>0.046754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655424</td>\n",
       "      <td>0.087476</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.045976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.658162</td>\n",
       "      <td>0.182891</td>\n",
       "      <td>0.227672</td>\n",
       "      <td>0.095573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.659292</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.659292</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.659292</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.660392</td>\n",
       "      <td>0.158067</td>\n",
       "      <td>0.250678</td>\n",
       "      <td>0.057719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.664482</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.382967</td>\n",
       "      <td>0.044177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.665443</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.665443</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.665443</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.665889</td>\n",
       "      <td>0.085404</td>\n",
       "      <td>0.383137</td>\n",
       "      <td>0.044123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.666312</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>0.385650</td>\n",
       "      <td>0.239106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.667279</td>\n",
       "      <td>0.116383</td>\n",
       "      <td>0.385552</td>\n",
       "      <td>0.047387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.669568</td>\n",
       "      <td>0.117112</td>\n",
       "      <td>0.384895</td>\n",
       "      <td>0.048454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.670944</td>\n",
       "      <td>0.117735</td>\n",
       "      <td>0.384419</td>\n",
       "      <td>0.048545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.671405</td>\n",
       "      <td>0.117961</td>\n",
       "      <td>0.384854</td>\n",
       "      <td>0.048460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.672780</td>\n",
       "      <td>0.118686</td>\n",
       "      <td>0.384345</td>\n",
       "      <td>0.048561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.677276</td>\n",
       "      <td>0.155764</td>\n",
       "      <td>0.373750</td>\n",
       "      <td>0.059426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.677276</td>\n",
       "      <td>0.155764</td>\n",
       "      <td>0.373750</td>\n",
       "      <td>0.059426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.689483</td>\n",
       "      <td>0.185062</td>\n",
       "      <td>0.231283</td>\n",
       "      <td>0.109117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.698244</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>0.353675</td>\n",
       "      <td>0.100242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698934</td>\n",
       "      <td>0.161050</td>\n",
       "      <td>0.253547</td>\n",
       "      <td>0.060035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.703784</td>\n",
       "      <td>0.071535</td>\n",
       "      <td>0.384731</td>\n",
       "      <td>0.161808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.704904</td>\n",
       "      <td>0.147275</td>\n",
       "      <td>0.363608</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.706420</td>\n",
       "      <td>0.077552</td>\n",
       "      <td>0.371587</td>\n",
       "      <td>0.096416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.711573</td>\n",
       "      <td>0.189332</td>\n",
       "      <td>0.344245</td>\n",
       "      <td>0.061685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.713781</td>\n",
       "      <td>0.159172</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.099566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.722597</td>\n",
       "      <td>0.211178</td>\n",
       "      <td>0.341019</td>\n",
       "      <td>0.077993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.724182</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>0.372499</td>\n",
       "      <td>0.170920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.755764</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>0.259520</td>\n",
       "      <td>0.071658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.799835</td>\n",
       "      <td>0.174542</td>\n",
       "      <td>0.267441</td>\n",
       "      <td>0.086858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.536738</td>\n",
       "      <td>2.958784</td>\n",
       "      <td>2.958784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.951287</td>\n",
       "      <td>2.423926</td>\n",
       "      <td>2.423926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.551111</td>\n",
       "      <td>2.039284</td>\n",
       "      <td>2.039284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>3.115336</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>0.975236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.647227</td>\n",
       "      <td>0.698057</td>\n",
       "      <td>0.698057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.114774</td>\n",
       "      <td>0.457119</td>\n",
       "      <td>0.457119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.795655</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>0.312005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.776194</td>\n",
       "      <td>0.296678</td>\n",
       "      <td>0.296678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-1.084187</td>\n",
       "      <td>0.123009</td>\n",
       "      <td>0.123009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.961304</td>\n",
       "      <td>0.087602</td>\n",
       "      <td>0.087602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>-0.824600</td>\n",
       "      <td>0.070111</td>\n",
       "      <td>0.070111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.859372</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.069269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.689644</td>\n",
       "      <td>0.050445</td>\n",
       "      <td>0.050445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.485440</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>0.027524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.465924</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.020655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.413256</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.017361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.408485</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.016604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.392714</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0.013255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.312876</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.007965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.212126</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.537</td>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.959</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>2.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>2.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.859</td>\n",
       "      <td>-1.084</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_conscientiousness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.2\n",
      "2                          BIS_11                -0.2\n",
      "1                             EDM                 0.2\n",
      "11              BFI_agreeableness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "6       ACES_neglectful_parenting                 0.0\n",
      "5                            TRSQ                 0.0\n",
      "4                              RS                 0.0\n",
      "3                             PCS                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.2\n",
      "5                            TRSQ                 0.2\n",
      "6       ACES_neglectful_parenting                -0.2\n",
      "0                            BSCS                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "11              BFI_agreeableness                 0.0\n",
      "1                             EDM                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "3                             PCS                 0.0\n",
      "2                          BIS_11                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.3761143969277374, 0.4025350263132723, 0.3692588258740668, 0.1812388781412888, -0.034314831395025225]\n",
      "overall_score:\n",
      "0.258966459172268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393653</td>\n",
       "      <td>0.124741</td>\n",
       "      <td>0.322006</td>\n",
       "      <td>0.113549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.398527</td>\n",
       "      <td>0.134410</td>\n",
       "      <td>0.322792</td>\n",
       "      <td>0.118473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.408048</td>\n",
       "      <td>0.134234</td>\n",
       "      <td>0.323659</td>\n",
       "      <td>0.117048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422657</td>\n",
       "      <td>0.133549</td>\n",
       "      <td>0.324441</td>\n",
       "      <td>0.118868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.447358</td>\n",
       "      <td>0.134488</td>\n",
       "      <td>0.328178</td>\n",
       "      <td>0.128918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.449886</td>\n",
       "      <td>0.076178</td>\n",
       "      <td>0.316158</td>\n",
       "      <td>0.054329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466759</td>\n",
       "      <td>0.134699</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>0.135271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.486821</td>\n",
       "      <td>0.105311</td>\n",
       "      <td>0.361609</td>\n",
       "      <td>0.143869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.491973</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>0.353137</td>\n",
       "      <td>0.070937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.583748</td>\n",
       "      <td>0.148940</td>\n",
       "      <td>0.278037</td>\n",
       "      <td>0.092816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.594770</td>\n",
       "      <td>0.161438</td>\n",
       "      <td>0.274984</td>\n",
       "      <td>0.102435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.609619</td>\n",
       "      <td>0.166159</td>\n",
       "      <td>0.272069</td>\n",
       "      <td>0.106755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.612865</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>0.392516</td>\n",
       "      <td>0.068385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.619262</td>\n",
       "      <td>0.143596</td>\n",
       "      <td>0.250157</td>\n",
       "      <td>0.056558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.632610</td>\n",
       "      <td>0.169002</td>\n",
       "      <td>0.267937</td>\n",
       "      <td>0.110547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.634287</td>\n",
       "      <td>0.101837</td>\n",
       "      <td>0.382237</td>\n",
       "      <td>0.156561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.639392</td>\n",
       "      <td>0.154495</td>\n",
       "      <td>0.249205</td>\n",
       "      <td>0.062056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.660261</td>\n",
       "      <td>0.056913</td>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.068462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.666185</td>\n",
       "      <td>0.158433</td>\n",
       "      <td>0.250703</td>\n",
       "      <td>0.063318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.667758</td>\n",
       "      <td>0.173220</td>\n",
       "      <td>0.264264</td>\n",
       "      <td>0.114018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.695045</td>\n",
       "      <td>0.177956</td>\n",
       "      <td>0.262946</td>\n",
       "      <td>0.116197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.701254</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.254381</td>\n",
       "      <td>0.065113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.709995</td>\n",
       "      <td>0.111616</td>\n",
       "      <td>0.335908</td>\n",
       "      <td>0.117353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.712927</td>\n",
       "      <td>0.110414</td>\n",
       "      <td>0.335778</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.720828</td>\n",
       "      <td>0.108504</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.129701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.730767</td>\n",
       "      <td>0.106025</td>\n",
       "      <td>0.344338</td>\n",
       "      <td>0.130765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.739327</td>\n",
       "      <td>0.104948</td>\n",
       "      <td>0.348945</td>\n",
       "      <td>0.130734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.747199</td>\n",
       "      <td>0.098576</td>\n",
       "      <td>0.351649</td>\n",
       "      <td>0.122402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.754900</td>\n",
       "      <td>0.165720</td>\n",
       "      <td>0.259852</td>\n",
       "      <td>0.073257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.792749</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.408477</td>\n",
       "      <td>0.072217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.798451</td>\n",
       "      <td>0.173796</td>\n",
       "      <td>0.267428</td>\n",
       "      <td>0.087141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.812664</td>\n",
       "      <td>0.108256</td>\n",
       "      <td>0.395411</td>\n",
       "      <td>0.055158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.823370</td>\n",
       "      <td>0.113140</td>\n",
       "      <td>0.402821</td>\n",
       "      <td>0.049510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.855074</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.391647</td>\n",
       "      <td>0.093496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.866604</td>\n",
       "      <td>0.126934</td>\n",
       "      <td>0.405630</td>\n",
       "      <td>0.084350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.871609</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.323674</td>\n",
       "      <td>0.163528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.872997</td>\n",
       "      <td>0.165403</td>\n",
       "      <td>0.320963</td>\n",
       "      <td>0.163777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.877526</td>\n",
       "      <td>0.108248</td>\n",
       "      <td>0.407793</td>\n",
       "      <td>0.087141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.893969</td>\n",
       "      <td>0.103323</td>\n",
       "      <td>0.342129</td>\n",
       "      <td>0.175027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.896667</td>\n",
       "      <td>0.091022</td>\n",
       "      <td>0.367657</td>\n",
       "      <td>0.141774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.900690</td>\n",
       "      <td>0.134981</td>\n",
       "      <td>0.387937</td>\n",
       "      <td>0.139032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.901665</td>\n",
       "      <td>0.093577</td>\n",
       "      <td>0.414882</td>\n",
       "      <td>0.074958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.901665</td>\n",
       "      <td>0.093577</td>\n",
       "      <td>0.414882</td>\n",
       "      <td>0.074958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.904130</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.369567</td>\n",
       "      <td>0.260630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.904407</td>\n",
       "      <td>0.092248</td>\n",
       "      <td>0.415216</td>\n",
       "      <td>0.075398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.909672</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.158235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.909941</td>\n",
       "      <td>0.162754</td>\n",
       "      <td>0.338445</td>\n",
       "      <td>0.164687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910571</td>\n",
       "      <td>0.165398</td>\n",
       "      <td>0.338617</td>\n",
       "      <td>0.160633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.911508</td>\n",
       "      <td>0.168209</td>\n",
       "      <td>0.338571</td>\n",
       "      <td>0.155737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.912567</td>\n",
       "      <td>0.137618</td>\n",
       "      <td>0.387671</td>\n",
       "      <td>0.137479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.913724</td>\n",
       "      <td>0.170166</td>\n",
       "      <td>0.337690</td>\n",
       "      <td>0.149701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.915390</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>0.336918</td>\n",
       "      <td>0.145727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.918373</td>\n",
       "      <td>0.143871</td>\n",
       "      <td>0.314809</td>\n",
       "      <td>0.130354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.922373</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>0.310533</td>\n",
       "      <td>0.125524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.926078</td>\n",
       "      <td>0.122810</td>\n",
       "      <td>0.408286</td>\n",
       "      <td>0.172636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.931998</td>\n",
       "      <td>0.095127</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.086440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.933963</td>\n",
       "      <td>0.132403</td>\n",
       "      <td>0.374821</td>\n",
       "      <td>0.247143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.937087</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.416791</td>\n",
       "      <td>0.055421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.937087</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.416791</td>\n",
       "      <td>0.055421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.937087</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.416791</td>\n",
       "      <td>0.055421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.937955</td>\n",
       "      <td>0.131168</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.166236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.939467</td>\n",
       "      <td>0.103757</td>\n",
       "      <td>0.399936</td>\n",
       "      <td>0.070311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.950417</td>\n",
       "      <td>0.096240</td>\n",
       "      <td>0.399696</td>\n",
       "      <td>0.070326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.961556</td>\n",
       "      <td>0.145503</td>\n",
       "      <td>0.404765</td>\n",
       "      <td>0.276224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.965694</td>\n",
       "      <td>0.120151</td>\n",
       "      <td>0.390521</td>\n",
       "      <td>0.276509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.966138</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.408107</td>\n",
       "      <td>0.061115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.967745</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.967745</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.967745</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.968548</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.360002</td>\n",
       "      <td>0.115834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.968548</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.360002</td>\n",
       "      <td>0.115834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.970875</td>\n",
       "      <td>0.098995</td>\n",
       "      <td>0.406999</td>\n",
       "      <td>0.065718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985781</td>\n",
       "      <td>0.095472</td>\n",
       "      <td>0.407443</td>\n",
       "      <td>0.058732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.989552</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.061059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.991967</td>\n",
       "      <td>0.154973</td>\n",
       "      <td>0.372108</td>\n",
       "      <td>0.145349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.995538</td>\n",
       "      <td>0.109482</td>\n",
       "      <td>0.350315</td>\n",
       "      <td>0.123265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.995749</td>\n",
       "      <td>0.107787</td>\n",
       "      <td>0.353359</td>\n",
       "      <td>0.120802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.998836</td>\n",
       "      <td>0.160676</td>\n",
       "      <td>0.377952</td>\n",
       "      <td>0.141450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.011751</td>\n",
       "      <td>0.128889</td>\n",
       "      <td>0.355385</td>\n",
       "      <td>0.137109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.034906</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>0.362078</td>\n",
       "      <td>0.148489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.037613</td>\n",
       "      <td>0.148533</td>\n",
       "      <td>0.423517</td>\n",
       "      <td>0.095359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.037613</td>\n",
       "      <td>0.148533</td>\n",
       "      <td>0.423517</td>\n",
       "      <td>0.095359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.039157</td>\n",
       "      <td>0.148848</td>\n",
       "      <td>0.422577</td>\n",
       "      <td>0.095368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.039157</td>\n",
       "      <td>0.148848</td>\n",
       "      <td>0.422577</td>\n",
       "      <td>0.095368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-6.186751</td>\n",
       "      <td>3.100877</td>\n",
       "      <td>3.100877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-5.805162</td>\n",
       "      <td>2.692957</td>\n",
       "      <td>2.692957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.979813</td>\n",
       "      <td>2.009547</td>\n",
       "      <td>2.009547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>4.394904</td>\n",
       "      <td>1.502701</td>\n",
       "      <td>1.502701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>3.584174</td>\n",
       "      <td>1.014394</td>\n",
       "      <td>1.014394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>3.016197</td>\n",
       "      <td>0.727310</td>\n",
       "      <td>0.727310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.157135</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.364600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-2.019003</td>\n",
       "      <td>0.334696</td>\n",
       "      <td>0.334696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.980192</td>\n",
       "      <td>0.077247</td>\n",
       "      <td>0.077247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.872308</td>\n",
       "      <td>0.062605</td>\n",
       "      <td>0.062605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.857464</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0.060318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.783099</td>\n",
       "      <td>0.050905</td>\n",
       "      <td>0.050905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.761546</td>\n",
       "      <td>0.042671</td>\n",
       "      <td>0.042671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.701981</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.532389</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.487935</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>0.019748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.418512</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>0.017469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.405992</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.015515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.459389</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.014920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.309849</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.009194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.011</td>\n",
       "      <td>3.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-5.805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.980</td>\n",
       "      <td>0.459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.010</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>2.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.857</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.702</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "38       NCS_small_daily_projects                0.00\n",
      "37                      NCS_total                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "23          NCS_intellectual_task                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "21       IMI_perceived_competence                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.08\n",
      "5                            TRSQ                0.08\n",
      "6       ACES_neglectful_parenting               -0.08\n",
      "0                            BSCS                0.00\n",
      "31             NCS_prefer_complex                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "37                      NCS_total                0.00\n",
      "38       NCS_small_daily_projects                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.0036091107931160993, 0.015382233580734317, -0.03508212446996439, 0.0045933750242519444, -0.33330574000360014]\n",
      "overall_score:\n",
      "-0.06896062901509244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288410</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.347298</td>\n",
       "      <td>0.035489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.293047</td>\n",
       "      <td>0.075910</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.293047</td>\n",
       "      <td>0.075910</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.293667</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>0.349722</td>\n",
       "      <td>0.030411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294777</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.348409</td>\n",
       "      <td>0.039376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298089</td>\n",
       "      <td>0.072020</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.036457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299818</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.313285</td>\n",
       "      <td>0.021087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.300425</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.029175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300433</td>\n",
       "      <td>0.067204</td>\n",
       "      <td>0.350839</td>\n",
       "      <td>0.037694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301463</td>\n",
       "      <td>0.071130</td>\n",
       "      <td>0.351245</td>\n",
       "      <td>0.039034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.302016</td>\n",
       "      <td>0.071682</td>\n",
       "      <td>0.350127</td>\n",
       "      <td>0.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.302430</td>\n",
       "      <td>0.084377</td>\n",
       "      <td>0.348533</td>\n",
       "      <td>0.023347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303563</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.303897</td>\n",
       "      <td>0.089003</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.023626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308423</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.347394</td>\n",
       "      <td>0.033606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308725</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>0.062523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325269</td>\n",
       "      <td>0.056862</td>\n",
       "      <td>0.334962</td>\n",
       "      <td>0.031944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.328481</td>\n",
       "      <td>0.087135</td>\n",
       "      <td>0.337360</td>\n",
       "      <td>0.030854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337441</td>\n",
       "      <td>0.103615</td>\n",
       "      <td>0.361082</td>\n",
       "      <td>0.031338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343193</td>\n",
       "      <td>0.095001</td>\n",
       "      <td>0.360162</td>\n",
       "      <td>0.043794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349665</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0.354225</td>\n",
       "      <td>0.066925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351895</td>\n",
       "      <td>0.117910</td>\n",
       "      <td>0.355717</td>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.352353</td>\n",
       "      <td>0.111412</td>\n",
       "      <td>0.355244</td>\n",
       "      <td>0.027131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.354081</td>\n",
       "      <td>0.090666</td>\n",
       "      <td>0.338806</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.355832</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>0.330398</td>\n",
       "      <td>0.036763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367551</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.316098</td>\n",
       "      <td>0.032528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.369260</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.315976</td>\n",
       "      <td>0.032981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371135</td>\n",
       "      <td>0.037060</td>\n",
       "      <td>0.315886</td>\n",
       "      <td>0.031429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373678</td>\n",
       "      <td>0.035369</td>\n",
       "      <td>0.315083</td>\n",
       "      <td>0.028377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376697</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.314036</td>\n",
       "      <td>0.025253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378476</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>0.313408</td>\n",
       "      <td>0.023845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392350</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.359940</td>\n",
       "      <td>0.037180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.409784</td>\n",
       "      <td>0.167160</td>\n",
       "      <td>0.301032</td>\n",
       "      <td>0.111165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.411008</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.371563</td>\n",
       "      <td>0.054809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415063</td>\n",
       "      <td>0.122209</td>\n",
       "      <td>0.360791</td>\n",
       "      <td>0.042429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.417805</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>0.387993</td>\n",
       "      <td>0.107674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418336</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>0.345614</td>\n",
       "      <td>0.062225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422506</td>\n",
       "      <td>0.185688</td>\n",
       "      <td>0.303132</td>\n",
       "      <td>0.123583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.427162</td>\n",
       "      <td>0.069461</td>\n",
       "      <td>0.398590</td>\n",
       "      <td>0.105313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.433742</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0.346453</td>\n",
       "      <td>0.120398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.435400</td>\n",
       "      <td>0.123250</td>\n",
       "      <td>0.335387</td>\n",
       "      <td>0.110144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.438559</td>\n",
       "      <td>0.195686</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.129856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.441517</td>\n",
       "      <td>0.108116</td>\n",
       "      <td>0.349139</td>\n",
       "      <td>0.085130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.443098</td>\n",
       "      <td>0.122632</td>\n",
       "      <td>0.359686</td>\n",
       "      <td>0.112010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.443733</td>\n",
       "      <td>0.151434</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.071480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.454799</td>\n",
       "      <td>0.096457</td>\n",
       "      <td>0.368405</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.457660</td>\n",
       "      <td>0.101214</td>\n",
       "      <td>0.367982</td>\n",
       "      <td>0.072460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.460660</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>0.309517</td>\n",
       "      <td>0.139231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.461852</td>\n",
       "      <td>0.099810</td>\n",
       "      <td>0.367065</td>\n",
       "      <td>0.069615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.468386</td>\n",
       "      <td>0.097949</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.065708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.475986</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>0.363049</td>\n",
       "      <td>0.060105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.480336</td>\n",
       "      <td>0.136476</td>\n",
       "      <td>0.297415</td>\n",
       "      <td>0.101730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.482390</td>\n",
       "      <td>0.093313</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.056452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.485786</td>\n",
       "      <td>0.137346</td>\n",
       "      <td>0.344748</td>\n",
       "      <td>0.116423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491286</td>\n",
       "      <td>0.211941</td>\n",
       "      <td>0.314959</td>\n",
       "      <td>0.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.499497</td>\n",
       "      <td>0.133567</td>\n",
       "      <td>0.307901</td>\n",
       "      <td>0.068284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.502722</td>\n",
       "      <td>0.064218</td>\n",
       "      <td>0.310633</td>\n",
       "      <td>0.074997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.512404</td>\n",
       "      <td>0.215938</td>\n",
       "      <td>0.319844</td>\n",
       "      <td>0.165234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.513499</td>\n",
       "      <td>0.103826</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.067066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.518518</td>\n",
       "      <td>0.153531</td>\n",
       "      <td>0.326853</td>\n",
       "      <td>0.085935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.574988</td>\n",
       "      <td>0.117961</td>\n",
       "      <td>0.354894</td>\n",
       "      <td>0.042989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.685712</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.071584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.702860</td>\n",
       "      <td>0.111064</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>0.078593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.723904</td>\n",
       "      <td>0.110667</td>\n",
       "      <td>0.384484</td>\n",
       "      <td>0.079806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.752958</td>\n",
       "      <td>0.110592</td>\n",
       "      <td>0.382805</td>\n",
       "      <td>0.076703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.794343</td>\n",
       "      <td>0.107459</td>\n",
       "      <td>0.383762</td>\n",
       "      <td>0.069937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.828454</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.380285</td>\n",
       "      <td>0.056067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.322590</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>0.346501</td>\n",
       "      <td>0.075421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.404271</td>\n",
       "      <td>0.228891</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.082658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.517240</td>\n",
       "      <td>0.262708</td>\n",
       "      <td>0.366153</td>\n",
       "      <td>0.085429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.681205</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.375756</td>\n",
       "      <td>0.093398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.960630</td>\n",
       "      <td>0.371456</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>0.119859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.232267</td>\n",
       "      <td>0.394677</td>\n",
       "      <td>0.384232</td>\n",
       "      <td>0.145442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.080712</td>\n",
       "      <td>0.080712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>0.035082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.194826</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.008660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.059079</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.1\n",
      "2                          BIS_11                -0.1\n",
      "1                             EDM                 0.1\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "23          NCS_intellectual_task                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "21       IMI_perceived_competence                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.1\n",
      "5                            TRSQ                 0.1\n",
      "6       ACES_neglectful_parenting                -0.1\n",
      "0                            BSCS                 0.0\n",
      "31             NCS_prefer_complex                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057337057875583186, 0.035141750540423455, -0.0501571896090387, -0.06248256167243871, -0.4292330285672843]\n",
      "overall_score:\n",
      "-0.08987879428655102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.369094</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.364914</td>\n",
       "      <td>0.031315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.369159</td>\n",
       "      <td>0.078495</td>\n",
       "      <td>0.365044</td>\n",
       "      <td>0.031475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.369159</td>\n",
       "      <td>0.078495</td>\n",
       "      <td>0.365044</td>\n",
       "      <td>0.031475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.374275</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.360296</td>\n",
       "      <td>0.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.374275</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.360296</td>\n",
       "      <td>0.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.374275</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.360296</td>\n",
       "      <td>0.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376130</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>0.300764</td>\n",
       "      <td>0.061430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.376968</td>\n",
       "      <td>0.087257</td>\n",
       "      <td>0.363764</td>\n",
       "      <td>0.030676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.377117</td>\n",
       "      <td>0.095347</td>\n",
       "      <td>0.366040</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381121</td>\n",
       "      <td>0.067086</td>\n",
       "      <td>0.364774</td>\n",
       "      <td>0.040478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.381361</td>\n",
       "      <td>0.099204</td>\n",
       "      <td>0.366837</td>\n",
       "      <td>0.023044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381954</td>\n",
       "      <td>0.070989</td>\n",
       "      <td>0.364618</td>\n",
       "      <td>0.042042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381989</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.358906</td>\n",
       "      <td>0.033402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382317</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>0.323042</td>\n",
       "      <td>0.037528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.384464</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.384464</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.384464</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384834</td>\n",
       "      <td>0.075437</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385091</td>\n",
       "      <td>0.060684</td>\n",
       "      <td>0.364225</td>\n",
       "      <td>0.048840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.388233</td>\n",
       "      <td>0.075238</td>\n",
       "      <td>0.358933</td>\n",
       "      <td>0.038907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389895</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.357872</td>\n",
       "      <td>0.036485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392552</td>\n",
       "      <td>0.082319</td>\n",
       "      <td>0.341998</td>\n",
       "      <td>0.020799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394927</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>0.337620</td>\n",
       "      <td>0.082947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.395394</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>0.355844</td>\n",
       "      <td>0.058322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.404783</td>\n",
       "      <td>0.095919</td>\n",
       "      <td>0.358851</td>\n",
       "      <td>0.036803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.408900</td>\n",
       "      <td>0.084471</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>0.065066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.413660</td>\n",
       "      <td>0.082314</td>\n",
       "      <td>0.333171</td>\n",
       "      <td>0.041834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415023</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.363064</td>\n",
       "      <td>0.047884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417076</td>\n",
       "      <td>0.053332</td>\n",
       "      <td>0.362848</td>\n",
       "      <td>0.048853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.420138</td>\n",
       "      <td>0.051498</td>\n",
       "      <td>0.361941</td>\n",
       "      <td>0.046571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424229</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.360443</td>\n",
       "      <td>0.044648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.428364</td>\n",
       "      <td>0.103487</td>\n",
       "      <td>0.358263</td>\n",
       "      <td>0.045722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429295</td>\n",
       "      <td>0.047067</td>\n",
       "      <td>0.358879</td>\n",
       "      <td>0.044259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.430336</td>\n",
       "      <td>0.120297</td>\n",
       "      <td>0.376583</td>\n",
       "      <td>0.027833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.432541</td>\n",
       "      <td>0.046252</td>\n",
       "      <td>0.358313</td>\n",
       "      <td>0.045278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.444368</td>\n",
       "      <td>0.089932</td>\n",
       "      <td>0.367399</td>\n",
       "      <td>0.055825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.445358</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.382659</td>\n",
       "      <td>0.102536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.448137</td>\n",
       "      <td>0.122636</td>\n",
       "      <td>0.383618</td>\n",
       "      <td>0.069432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.449403</td>\n",
       "      <td>0.122695</td>\n",
       "      <td>0.385069</td>\n",
       "      <td>0.071419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.451370</td>\n",
       "      <td>0.103264</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>0.100942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454054</td>\n",
       "      <td>0.132126</td>\n",
       "      <td>0.315666</td>\n",
       "      <td>0.106882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461523</td>\n",
       "      <td>0.173459</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>0.116615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.461854</td>\n",
       "      <td>0.096370</td>\n",
       "      <td>0.405480</td>\n",
       "      <td>0.090314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.464370</td>\n",
       "      <td>0.086749</td>\n",
       "      <td>0.379242</td>\n",
       "      <td>0.052899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466510</td>\n",
       "      <td>0.117186</td>\n",
       "      <td>0.396555</td>\n",
       "      <td>0.057520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.467866</td>\n",
       "      <td>0.097298</td>\n",
       "      <td>0.402607</td>\n",
       "      <td>0.092475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472557</td>\n",
       "      <td>0.148355</td>\n",
       "      <td>0.302436</td>\n",
       "      <td>0.107734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.473013</td>\n",
       "      <td>0.195662</td>\n",
       "      <td>0.291899</td>\n",
       "      <td>0.126390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.478200</td>\n",
       "      <td>0.119285</td>\n",
       "      <td>0.387366</td>\n",
       "      <td>0.042656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480121</td>\n",
       "      <td>0.100510</td>\n",
       "      <td>0.398473</td>\n",
       "      <td>0.065728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489016</td>\n",
       "      <td>0.207582</td>\n",
       "      <td>0.296340</td>\n",
       "      <td>0.129145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.493577</td>\n",
       "      <td>0.117880</td>\n",
       "      <td>0.312339</td>\n",
       "      <td>0.060948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.499653</td>\n",
       "      <td>0.096259</td>\n",
       "      <td>0.362227</td>\n",
       "      <td>0.097563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.502822</td>\n",
       "      <td>0.100139</td>\n",
       "      <td>0.361978</td>\n",
       "      <td>0.102082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.507049</td>\n",
       "      <td>0.097899</td>\n",
       "      <td>0.361764</td>\n",
       "      <td>0.099570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.511832</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.301636</td>\n",
       "      <td>0.133976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.512380</td>\n",
       "      <td>0.094652</td>\n",
       "      <td>0.361665</td>\n",
       "      <td>0.095136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.518654</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.362942</td>\n",
       "      <td>0.088194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.522704</td>\n",
       "      <td>0.085456</td>\n",
       "      <td>0.364082</td>\n",
       "      <td>0.083227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.523301</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.325794</td>\n",
       "      <td>0.104411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.526495</td>\n",
       "      <td>0.123807</td>\n",
       "      <td>0.320069</td>\n",
       "      <td>0.047102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.536704</td>\n",
       "      <td>0.076729</td>\n",
       "      <td>0.346011</td>\n",
       "      <td>0.100224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.544565</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.310404</td>\n",
       "      <td>0.143766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.545108</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>0.320370</td>\n",
       "      <td>0.083951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.561784</td>\n",
       "      <td>0.173821</td>\n",
       "      <td>0.321289</td>\n",
       "      <td>0.050937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.566935</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>0.317194</td>\n",
       "      <td>0.152693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.596004</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.074140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.713331</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.375372</td>\n",
       "      <td>0.105467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.727017</td>\n",
       "      <td>0.119346</td>\n",
       "      <td>0.374649</td>\n",
       "      <td>0.117402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.746293</td>\n",
       "      <td>0.118352</td>\n",
       "      <td>0.374461</td>\n",
       "      <td>0.123196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.774504</td>\n",
       "      <td>0.116585</td>\n",
       "      <td>0.373094</td>\n",
       "      <td>0.126595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.818049</td>\n",
       "      <td>0.111638</td>\n",
       "      <td>0.372241</td>\n",
       "      <td>0.127303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.850947</td>\n",
       "      <td>0.107508</td>\n",
       "      <td>0.371522</td>\n",
       "      <td>0.120208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.333023</td>\n",
       "      <td>0.195543</td>\n",
       "      <td>0.349056</td>\n",
       "      <td>0.079967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.413131</td>\n",
       "      <td>0.230617</td>\n",
       "      <td>0.355897</td>\n",
       "      <td>0.086493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.525383</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.367714</td>\n",
       "      <td>0.089035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.688133</td>\n",
       "      <td>0.306258</td>\n",
       "      <td>0.378217</td>\n",
       "      <td>0.095781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.964433</td>\n",
       "      <td>0.371450</td>\n",
       "      <td>0.387395</td>\n",
       "      <td>0.121841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.234851</td>\n",
       "      <td>0.394234</td>\n",
       "      <td>0.386955</td>\n",
       "      <td>0.147258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.238603</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.021717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>-0.132500</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.011149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NCS_like_responsibility</td>\n",
       "      <td>-0.068217</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.004660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NCS_thinking_not_exciting</td>\n",
       "      <td>-0.047636</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.003824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NCS_intellectual_task</td>\n",
       "      <td>-0.030438</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.002054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>IMI_perceived_competence*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>IMI_perceived_choice*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>IMI_effort_importance*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BFI_openness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PCS*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NCS_new_solutions_to_problems</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NCS_think_minimally</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NCS_thinking_not_fun</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NCS_deliberating_issues*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_total</th>\n",
       "      <td>-0.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_like_responsibility</th>\n",
       "      <td>-0.068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_thinking_not_exciting</th>\n",
       "      <td>-0.048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_intellectual_task</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.15\n",
      "2                          BIS_11               -0.15\n",
      "1                             EDM                0.15\n",
      "38       NCS_small_daily_projects                0.00\n",
      "37                      NCS_total                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "23          NCS_intellectual_task                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "21       IMI_perceived_competence                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.15\n",
      "5                            TRSQ                0.15\n",
      "6       ACES_neglectful_parenting               -0.15\n",
      "0                            BSCS                0.00\n",
      "31             NCS_prefer_complex                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "37                      NCS_total                0.00\n",
      "38       NCS_small_daily_projects                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14229584469909184, 0.07270145124282834, -0.05946581417025287, 0.1844848755077767, -0.27738575558235135]\n",
      "overall_score:\n",
      "0.012526120339418533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.450054</td>\n",
       "      <td>0.093190</td>\n",
       "      <td>0.368450</td>\n",
       "      <td>0.094423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.485738</td>\n",
       "      <td>0.168661</td>\n",
       "      <td>0.339724</td>\n",
       "      <td>0.156880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.496913</td>\n",
       "      <td>0.185469</td>\n",
       "      <td>0.338385</td>\n",
       "      <td>0.171961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.512106</td>\n",
       "      <td>0.194681</td>\n",
       "      <td>0.338621</td>\n",
       "      <td>0.178575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.514341</td>\n",
       "      <td>0.094782</td>\n",
       "      <td>0.383499</td>\n",
       "      <td>0.069080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.531656</td>\n",
       "      <td>0.204962</td>\n",
       "      <td>0.339684</td>\n",
       "      <td>0.186489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.561325</td>\n",
       "      <td>0.211536</td>\n",
       "      <td>0.344609</td>\n",
       "      <td>0.187964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572432</td>\n",
       "      <td>0.051176</td>\n",
       "      <td>0.409638</td>\n",
       "      <td>0.093495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.577876</td>\n",
       "      <td>0.089977</td>\n",
       "      <td>0.349342</td>\n",
       "      <td>0.068828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.582080</td>\n",
       "      <td>0.214437</td>\n",
       "      <td>0.350583</td>\n",
       "      <td>0.187450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.593261</td>\n",
       "      <td>0.055832</td>\n",
       "      <td>0.404322</td>\n",
       "      <td>0.083083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.593401</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.416855</td>\n",
       "      <td>0.091944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.594110</td>\n",
       "      <td>0.120727</td>\n",
       "      <td>0.391185</td>\n",
       "      <td>0.053993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.595509</td>\n",
       "      <td>0.060297</td>\n",
       "      <td>0.417521</td>\n",
       "      <td>0.097609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598330</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>0.418039</td>\n",
       "      <td>0.098240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598640</td>\n",
       "      <td>0.106847</td>\n",
       "      <td>0.358844</td>\n",
       "      <td>0.103019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.601561</td>\n",
       "      <td>0.061582</td>\n",
       "      <td>0.418732</td>\n",
       "      <td>0.099223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.605215</td>\n",
       "      <td>0.095136</td>\n",
       "      <td>0.389683</td>\n",
       "      <td>0.043027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.605834</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.101190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.606960</td>\n",
       "      <td>0.108673</td>\n",
       "      <td>0.346533</td>\n",
       "      <td>0.115732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.606969</td>\n",
       "      <td>0.096389</td>\n",
       "      <td>0.390540</td>\n",
       "      <td>0.042278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.606969</td>\n",
       "      <td>0.096389</td>\n",
       "      <td>0.390540</td>\n",
       "      <td>0.042278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.608083</td>\n",
       "      <td>0.111107</td>\n",
       "      <td>0.384224</td>\n",
       "      <td>0.061829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.608626</td>\n",
       "      <td>0.063582</td>\n",
       "      <td>0.419247</td>\n",
       "      <td>0.102816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.611634</td>\n",
       "      <td>0.120112</td>\n",
       "      <td>0.393744</td>\n",
       "      <td>0.057486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.612052</td>\n",
       "      <td>0.098766</td>\n",
       "      <td>0.377466</td>\n",
       "      <td>0.052165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.620634</td>\n",
       "      <td>0.068104</td>\n",
       "      <td>0.329741</td>\n",
       "      <td>0.098835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.623286</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.034416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.623286</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.034416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.623286</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.034416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.627416</td>\n",
       "      <td>0.079055</td>\n",
       "      <td>0.386703</td>\n",
       "      <td>0.057161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.634273</td>\n",
       "      <td>0.094338</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>0.049567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.635986</td>\n",
       "      <td>0.122028</td>\n",
       "      <td>0.375689</td>\n",
       "      <td>0.080582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.642580</td>\n",
       "      <td>0.082099</td>\n",
       "      <td>0.389458</td>\n",
       "      <td>0.051180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.643297</td>\n",
       "      <td>0.113259</td>\n",
       "      <td>0.405086</td>\n",
       "      <td>0.076258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.648739</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.382868</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.648739</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.382868</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.648739</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.382868</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.649446</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.429966</td>\n",
       "      <td>0.197280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650667</td>\n",
       "      <td>0.092962</td>\n",
       "      <td>0.386611</td>\n",
       "      <td>0.047898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.651083</td>\n",
       "      <td>0.135278</td>\n",
       "      <td>0.396923</td>\n",
       "      <td>0.063828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.653736</td>\n",
       "      <td>0.072570</td>\n",
       "      <td>0.349982</td>\n",
       "      <td>0.155481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.653814</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>0.346735</td>\n",
       "      <td>0.166604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.655078</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>0.168054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.657487</td>\n",
       "      <td>0.131601</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.089117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.657675</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.338699</td>\n",
       "      <td>0.169848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.657810</td>\n",
       "      <td>0.088641</td>\n",
       "      <td>0.384189</td>\n",
       "      <td>0.047016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.660076</td>\n",
       "      <td>0.146554</td>\n",
       "      <td>0.433561</td>\n",
       "      <td>0.193144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.662239</td>\n",
       "      <td>0.063309</td>\n",
       "      <td>0.333006</td>\n",
       "      <td>0.171985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.663022</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.373532</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.663447</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.382994</td>\n",
       "      <td>0.044348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.665413</td>\n",
       "      <td>0.128366</td>\n",
       "      <td>0.399310</td>\n",
       "      <td>0.087358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.666010</td>\n",
       "      <td>0.059772</td>\n",
       "      <td>0.329161</td>\n",
       "      <td>0.172949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668140</td>\n",
       "      <td>0.087355</td>\n",
       "      <td>0.380062</td>\n",
       "      <td>0.043838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.683902</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>0.364069</td>\n",
       "      <td>0.060008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.683902</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>0.364069</td>\n",
       "      <td>0.060008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.685277</td>\n",
       "      <td>0.131073</td>\n",
       "      <td>0.363593</td>\n",
       "      <td>0.059875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.685664</td>\n",
       "      <td>0.155312</td>\n",
       "      <td>0.312070</td>\n",
       "      <td>0.108024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.685738</td>\n",
       "      <td>0.131213</td>\n",
       "      <td>0.364028</td>\n",
       "      <td>0.059996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.697882</td>\n",
       "      <td>0.150329</td>\n",
       "      <td>0.308626</td>\n",
       "      <td>0.104821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.711148</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.417479</td>\n",
       "      <td>0.090843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.712722</td>\n",
       "      <td>0.132018</td>\n",
       "      <td>0.422825</td>\n",
       "      <td>0.083009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.718950</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.155384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.729862</td>\n",
       "      <td>0.127007</td>\n",
       "      <td>0.396962</td>\n",
       "      <td>0.176899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.730125</td>\n",
       "      <td>0.153334</td>\n",
       "      <td>0.396496</td>\n",
       "      <td>0.209006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.730801</td>\n",
       "      <td>0.153502</td>\n",
       "      <td>0.418317</td>\n",
       "      <td>0.201542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.740770</td>\n",
       "      <td>0.127905</td>\n",
       "      <td>0.406284</td>\n",
       "      <td>0.173822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.745126</td>\n",
       "      <td>0.070340</td>\n",
       "      <td>0.399565</td>\n",
       "      <td>0.151126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.761789</td>\n",
       "      <td>0.071378</td>\n",
       "      <td>0.353640</td>\n",
       "      <td>0.186010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.775468</td>\n",
       "      <td>0.126347</td>\n",
       "      <td>0.387221</td>\n",
       "      <td>0.186813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.787230</td>\n",
       "      <td>0.061684</td>\n",
       "      <td>0.352444</td>\n",
       "      <td>0.189301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.798937</td>\n",
       "      <td>0.128195</td>\n",
       "      <td>0.415114</td>\n",
       "      <td>0.171272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.867541</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>0.401789</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.880687</td>\n",
       "      <td>0.115865</td>\n",
       "      <td>0.400198</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.898135</td>\n",
       "      <td>0.115434</td>\n",
       "      <td>0.398219</td>\n",
       "      <td>0.031898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.920551</td>\n",
       "      <td>0.116131</td>\n",
       "      <td>0.396454</td>\n",
       "      <td>0.041688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.955951</td>\n",
       "      <td>0.124355</td>\n",
       "      <td>0.396553</td>\n",
       "      <td>0.057148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.985552</td>\n",
       "      <td>0.133378</td>\n",
       "      <td>0.397825</td>\n",
       "      <td>0.064584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.364064</td>\n",
       "      <td>0.199810</td>\n",
       "      <td>0.353947</td>\n",
       "      <td>0.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.440828</td>\n",
       "      <td>0.233985</td>\n",
       "      <td>0.359904</td>\n",
       "      <td>0.098834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.547609</td>\n",
       "      <td>0.265410</td>\n",
       "      <td>0.371417</td>\n",
       "      <td>0.100132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.707803</td>\n",
       "      <td>0.306913</td>\n",
       "      <td>0.384993</td>\n",
       "      <td>0.103903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.976005</td>\n",
       "      <td>0.370748</td>\n",
       "      <td>0.395870</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.241799</td>\n",
       "      <td>0.393611</td>\n",
       "      <td>0.393878</td>\n",
       "      <td>0.151201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.041942</td>\n",
       "      <td>1.647198</td>\n",
       "      <td>1.647198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-2.542596</td>\n",
       "      <td>0.700008</td>\n",
       "      <td>0.700008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.166368</td>\n",
       "      <td>0.161784</td>\n",
       "      <td>0.161784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.946608</td>\n",
       "      <td>0.094176</td>\n",
       "      <td>0.094176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.417645</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.023726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.273041</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.012167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.252060</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.011861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.337238</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>0.010134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.180189</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.003167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.173151</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.002656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.064868</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>1.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.543</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.2\n",
      "2                          BIS_11                -0.2\n",
      "1                             EDM                 0.2\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "23          NCS_intellectual_task                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "21       IMI_perceived_competence                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.2\n",
      "5                            TRSQ                 0.2\n",
      "6       ACES_neglectful_parenting                -0.2\n",
      "0                            BSCS                 0.0\n",
      "31             NCS_prefer_complex                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x182d42a70>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.23955957810293216, 0.2878064479899831, 0.3574069788355615, 0.2398166264775432, -0.08179426646722598]\n",
      "overall_score:\n",
      "0.2085590729877588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491394</td>\n",
       "      <td>0.127494</td>\n",
       "      <td>0.376282</td>\n",
       "      <td>0.153759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505468</td>\n",
       "      <td>0.153665</td>\n",
       "      <td>0.396627</td>\n",
       "      <td>0.178225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.514534</td>\n",
       "      <td>0.168815</td>\n",
       "      <td>0.396060</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.528333</td>\n",
       "      <td>0.174366</td>\n",
       "      <td>0.395568</td>\n",
       "      <td>0.188186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.549900</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.398038</td>\n",
       "      <td>0.187624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.581833</td>\n",
       "      <td>0.184607</td>\n",
       "      <td>0.401970</td>\n",
       "      <td>0.183567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604678</td>\n",
       "      <td>0.187035</td>\n",
       "      <td>0.406160</td>\n",
       "      <td>0.178239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.636612</td>\n",
       "      <td>0.153686</td>\n",
       "      <td>0.399966</td>\n",
       "      <td>0.127176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.679815</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.332131</td>\n",
       "      <td>0.113183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.726658</td>\n",
       "      <td>0.103021</td>\n",
       "      <td>0.375983</td>\n",
       "      <td>0.115727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.808584</td>\n",
       "      <td>0.099608</td>\n",
       "      <td>0.456877</td>\n",
       "      <td>0.135156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.810064</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>0.469691</td>\n",
       "      <td>0.165834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.810620</td>\n",
       "      <td>0.071979</td>\n",
       "      <td>0.471945</td>\n",
       "      <td>0.176085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.812255</td>\n",
       "      <td>0.069140</td>\n",
       "      <td>0.473328</td>\n",
       "      <td>0.175221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.815823</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.473605</td>\n",
       "      <td>0.173759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.821358</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.473974</td>\n",
       "      <td>0.170925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.821379</td>\n",
       "      <td>0.135132</td>\n",
       "      <td>0.399167</td>\n",
       "      <td>0.080991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.824956</td>\n",
       "      <td>0.065872</td>\n",
       "      <td>0.474490</td>\n",
       "      <td>0.168904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.832035</td>\n",
       "      <td>0.126823</td>\n",
       "      <td>0.393458</td>\n",
       "      <td>0.108622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.851608</td>\n",
       "      <td>0.115791</td>\n",
       "      <td>0.402772</td>\n",
       "      <td>0.097978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.867071</td>\n",
       "      <td>0.109569</td>\n",
       "      <td>0.427864</td>\n",
       "      <td>0.089494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.879549</td>\n",
       "      <td>0.134879</td>\n",
       "      <td>0.401810</td>\n",
       "      <td>0.093942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.882720</td>\n",
       "      <td>0.135476</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.124233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.882764</td>\n",
       "      <td>0.111225</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.096847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.884657</td>\n",
       "      <td>0.113485</td>\n",
       "      <td>0.415697</td>\n",
       "      <td>0.074714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.888427</td>\n",
       "      <td>0.111840</td>\n",
       "      <td>0.415117</td>\n",
       "      <td>0.075382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.889802</td>\n",
       "      <td>0.151053</td>\n",
       "      <td>0.368624</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.891290</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>0.411330</td>\n",
       "      <td>0.077729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.898470</td>\n",
       "      <td>0.136219</td>\n",
       "      <td>0.419561</td>\n",
       "      <td>0.112609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.909460</td>\n",
       "      <td>0.112347</td>\n",
       "      <td>0.409957</td>\n",
       "      <td>0.112787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.913469</td>\n",
       "      <td>0.117477</td>\n",
       "      <td>0.418868</td>\n",
       "      <td>0.091369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.913469</td>\n",
       "      <td>0.117477</td>\n",
       "      <td>0.418868</td>\n",
       "      <td>0.091369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.914268</td>\n",
       "      <td>0.162547</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>0.148904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.914758</td>\n",
       "      <td>0.161997</td>\n",
       "      <td>0.339352</td>\n",
       "      <td>0.149962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.916009</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.419151</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.916009</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.419151</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.916009</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.419151</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.923370</td>\n",
       "      <td>0.106362</td>\n",
       "      <td>0.379841</td>\n",
       "      <td>0.175472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.923755</td>\n",
       "      <td>0.104621</td>\n",
       "      <td>0.384244</td>\n",
       "      <td>0.175182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.923869</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>0.376990</td>\n",
       "      <td>0.174508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.925684</td>\n",
       "      <td>0.102663</td>\n",
       "      <td>0.387319</td>\n",
       "      <td>0.173821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.927161</td>\n",
       "      <td>0.101264</td>\n",
       "      <td>0.389914</td>\n",
       "      <td>0.172328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.928648</td>\n",
       "      <td>0.094221</td>\n",
       "      <td>0.392161</td>\n",
       "      <td>0.160975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.930199</td>\n",
       "      <td>0.101324</td>\n",
       "      <td>0.416457</td>\n",
       "      <td>0.133898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.935482</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.413982</td>\n",
       "      <td>0.071522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.937043</td>\n",
       "      <td>0.120440</td>\n",
       "      <td>0.424782</td>\n",
       "      <td>0.157504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.940025</td>\n",
       "      <td>0.122883</td>\n",
       "      <td>0.415760</td>\n",
       "      <td>0.154654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.941037</td>\n",
       "      <td>0.182519</td>\n",
       "      <td>0.419582</td>\n",
       "      <td>0.080687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.941804</td>\n",
       "      <td>0.104747</td>\n",
       "      <td>0.410547</td>\n",
       "      <td>0.073061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.941818</td>\n",
       "      <td>0.181094</td>\n",
       "      <td>0.420543</td>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.950385</td>\n",
       "      <td>0.073665</td>\n",
       "      <td>0.413867</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.950385</td>\n",
       "      <td>0.073665</td>\n",
       "      <td>0.413867</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.950385</td>\n",
       "      <td>0.073665</td>\n",
       "      <td>0.413867</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.956908</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.418638</td>\n",
       "      <td>0.069312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.968814</td>\n",
       "      <td>0.106371</td>\n",
       "      <td>0.415526</td>\n",
       "      <td>0.065266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.973879</td>\n",
       "      <td>0.100813</td>\n",
       "      <td>0.418136</td>\n",
       "      <td>0.065604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.979364</td>\n",
       "      <td>0.069568</td>\n",
       "      <td>0.373115</td>\n",
       "      <td>0.135693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.983985</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.374146</td>\n",
       "      <td>0.133729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.988226</td>\n",
       "      <td>0.096973</td>\n",
       "      <td>0.412345</td>\n",
       "      <td>0.058237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.989042</td>\n",
       "      <td>0.137049</td>\n",
       "      <td>0.415411</td>\n",
       "      <td>0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.989523</td>\n",
       "      <td>0.096124</td>\n",
       "      <td>0.410850</td>\n",
       "      <td>0.060024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.999541</td>\n",
       "      <td>0.116340</td>\n",
       "      <td>0.419571</td>\n",
       "      <td>0.227532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.002493</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>0.365666</td>\n",
       "      <td>0.130460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.006431</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.353427</td>\n",
       "      <td>0.119677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.018734</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>0.421983</td>\n",
       "      <td>0.074995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.018734</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>0.421983</td>\n",
       "      <td>0.074995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.020278</td>\n",
       "      <td>0.156566</td>\n",
       "      <td>0.421111</td>\n",
       "      <td>0.074806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.020278</td>\n",
       "      <td>0.156566</td>\n",
       "      <td>0.421111</td>\n",
       "      <td>0.074806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.023935</td>\n",
       "      <td>0.135372</td>\n",
       "      <td>0.383211</td>\n",
       "      <td>0.203799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.030376</td>\n",
       "      <td>0.117116</td>\n",
       "      <td>0.421302</td>\n",
       "      <td>0.088019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.032982</td>\n",
       "      <td>0.123376</td>\n",
       "      <td>0.368956</td>\n",
       "      <td>0.217018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.036510</td>\n",
       "      <td>0.122107</td>\n",
       "      <td>0.425334</td>\n",
       "      <td>0.092250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.047173</td>\n",
       "      <td>0.122408</td>\n",
       "      <td>0.430309</td>\n",
       "      <td>0.091251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.063108</td>\n",
       "      <td>0.128634</td>\n",
       "      <td>0.436813</td>\n",
       "      <td>0.091071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.087965</td>\n",
       "      <td>0.135934</td>\n",
       "      <td>0.445765</td>\n",
       "      <td>0.093907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.096602</td>\n",
       "      <td>0.084163</td>\n",
       "      <td>0.276896</td>\n",
       "      <td>0.130605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.107962</td>\n",
       "      <td>0.139312</td>\n",
       "      <td>0.449717</td>\n",
       "      <td>0.100601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x182d42a70&gt;}</th>\n",
       "      <td>-4.127509</td>\n",
       "      <td>0.086756</td>\n",
       "      <td>0.308495</td>\n",
       "      <td>0.145817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.404505</td>\n",
       "      <td>0.199584</td>\n",
       "      <td>0.358103</td>\n",
       "      <td>0.105365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.476224</td>\n",
       "      <td>0.233541</td>\n",
       "      <td>0.366025</td>\n",
       "      <td>0.111453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.575807</td>\n",
       "      <td>0.265595</td>\n",
       "      <td>0.376426</td>\n",
       "      <td>0.111782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.731985</td>\n",
       "      <td>0.305593</td>\n",
       "      <td>0.392543</td>\n",
       "      <td>0.113139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.991981</td>\n",
       "      <td>0.368549</td>\n",
       "      <td>0.404643</td>\n",
       "      <td>0.132348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.249842</td>\n",
       "      <td>0.393133</td>\n",
       "      <td>0.401434</td>\n",
       "      <td>0.155153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.540987</td>\n",
       "      <td>2.517312</td>\n",
       "      <td>2.517312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.457666</td>\n",
       "      <td>1.640721</td>\n",
       "      <td>1.640721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.321439</td>\n",
       "      <td>0.455755</td>\n",
       "      <td>0.455755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-1.340184</td>\n",
       "      <td>0.162157</td>\n",
       "      <td>0.162157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.492771</td>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.024445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.421082</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.018296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.322238</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.303110</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.010067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.004146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.108653</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.018880</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/4059571660.py:35: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.541</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.517</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>2.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_34325/2265993013.py:8: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n"
     ]
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "for nf in [20,40]:\n",
    "    for sd in [0.08,0.10,0.15,0.20]:\n",
    "        analysis_result = run_full_limited_predictor_analysis(nf, outcome_measures, analysis_data_imputed, interaction_effect_size_as_sd=sd)\n",
    "\n",
    "\n",
    "\n",
    "        overall_scores = overall_scores.append({'n_features':nf,'overall_score':analysis_result['overall_score'],\n",
    "                                                'empirical_group_corr_diff':analysis_result['empirical_corr_diff_mean']\n",
    "                                                },ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>empirical_group_corr_diff</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.413270</td>\n",
       "      <td>-0.054755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.345437</td>\n",
       "      <td>-0.081768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.550798</td>\n",
       "      <td>0.065953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.648581</td>\n",
       "      <td>0.236183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.765053</td>\n",
       "      <td>0.504361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.345437</td>\n",
       "      <td>-0.090946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.413270</td>\n",
       "      <td>-0.045115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.550798</td>\n",
       "      <td>0.053828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.648581</td>\n",
       "      <td>0.258966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.345437</td>\n",
       "      <td>-0.068961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.413270</td>\n",
       "      <td>-0.089879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.550798</td>\n",
       "      <td>0.012526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40.0</td>\n",
       "      <td>0.648581</td>\n",
       "      <td>0.208559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_features  empirical_group_corr_diff  overall_score\n",
       "0         10.0                   0.413270      -0.054755\n",
       "1         10.0                   0.345437      -0.081768\n",
       "2         10.0                   0.550798       0.065953\n",
       "3         10.0                   0.648581       0.236183\n",
       "4         10.0                   0.765053       0.504361\n",
       "5         20.0                   0.345437      -0.090946\n",
       "6         20.0                   0.413270      -0.045115\n",
       "7         20.0                   0.550798       0.053828\n",
       "8         20.0                   0.648581       0.258966\n",
       "9         40.0                   0.345437      -0.068961\n",
       "10        40.0                   0.413270      -0.089879\n",
       "11        40.0                   0.550798       0.012526\n",
       "12        40.0                   0.648581       0.208559"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_scores.loc[:,['n_features','empirical_group_corr_diff','overall_score']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion so far\n",
    "\n",
    "The feature selection applied here hasn't helped very much. That surprises me because in test_limited_predictors, I got clear evidence that cutting down irrelevant predictors improved model performance.\n",
    "\n",
    "One reason might be that we've actually cut down on useful predictors--unlike in `test_limited_predictors.ipynb`, we can't cheat by removing predictors we know to be irrelevant. That means we're left with less information in the model itself.\n",
    "\n",
    "We've only really tried SelectKBest(); there might be other feature selection mechanisms that could do the job. But I don't know yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014247d405695287815678bf9349a8dffb2674e9fe9a5bd4bb9820af018d638d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
