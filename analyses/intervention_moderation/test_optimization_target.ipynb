{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from socket import gethostname\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from dev_interaction_util import generate_synthetic_dev_outcomes, generate_synthetic_dev_data, set_up_interactions\n",
    "from dev_interaction_util import do_scoring_loop, get_best_model, summarize_overall_df_results, do_final_fit, present_model_results, present_results_vs_ground_truth_cors\n",
    "from dev_interaction_util import load_and_preprocess_data, impute_data, run_full_limited_predictor_analysis\n",
    "from ml_util import *\n",
    "# Imputing with MICE\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn import linear_model\n",
    "from ml_util import get_data_for_imputation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-2.local\n",
      "{'dropbox_data_dir': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "with open('config.yml') as f:\n",
    "    all_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "    if gethostname() in all_yaml.keys():\n",
    "        config = all_yaml[gethostname()]\n",
    "    else:\n",
    "        config = all_yaml['default']\n",
    "        \n",
    "print(config)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is derived from `test_feature_selection.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data, outcome_measures = load_and_preprocess_data(dropbox_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/impute/_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "analysis_data_imputed = impute_data(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_hyperparameter_selection_loop_r2(X,y,cv):\n",
    "    return(do_hyperparameter_selection_loop_w_metric(X,y,cv,'r2'))\n",
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop(X, y,cv):\n",
    "    return(do_hyperparameter_selection_loop_w_metric(X,y,cv,'neg_mean_absolute_error'))\n",
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop_w_metric(X, y,cv,metric):\n",
    "    #alpha parameters for Ridge and Lasso\n",
    "    alpha_10pow_lower = 1\n",
    "    alpha_10pow_upper = 0\n",
    "    alpha_increments=1\n",
    "    alpha_range = np.concatenate([np.power(10,np.linspace(-alpha_10pow_lower,alpha_10pow_upper,(alpha_10pow_lower+alpha_10pow_upper)*alpha_increments+1)),\n",
    "        [0.2,0.3,0.4,0.6,0.8,1.0]])\n",
    "    \n",
    "    all_cv_results = []\n",
    "\n",
    "    pipeline_estimator_name = 'estimator'\n",
    "    feature_selection_name = 'feature_selection'\n",
    "\n",
    "\n",
    "    #define the param_grid for the estimators\n",
    "    estimators_to_run = {\n",
    "        'Ridge':{\n",
    "            'estimator':linear_model.Ridge,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'Lasso':{\n",
    "            'estimator':linear_model.Lasso,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'DecisionTreeRegressor':{\n",
    "            'estimator':DecisionTreeRegressor,\n",
    "            'parameters':{\n",
    "                'max_depth':[2, 4],\n",
    "                'min_samples_split':[20,50],\n",
    "                'min_samples_leaf':[20,50]\n",
    "            }\n",
    "        }             \n",
    "    }\n",
    "\n",
    "    k_max_val = np.min([50,X.shape[1]])\n",
    "\n",
    "    for estimator_name,estimator_dict in estimators_to_run.items():\n",
    "        #param grid for the feature seelction\n",
    "        #this is here because we need to know the estimator to pass to the feature selector\n",
    "        feature_selectors_to_run = {\n",
    "            'None':None,\n",
    "            'KBest':{\n",
    "                'selector':SelectKBest(),\n",
    "                'parameters':{\n",
    "                    'score_func' : [f_regression], \n",
    "                    'k' : [10,25,k_max_val]\n",
    "                    }\n",
    "            },\n",
    "            'RFE':{\n",
    "                'selector':RFE(linear_model.LinearRegression()),\n",
    "                'parameters':{\n",
    "                    'n_features_to_select' : [10,25],\n",
    "                    #'verbose':[1],\n",
    "                    'step':[5]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for selector_name, selector_dict in feature_selectors_to_run.items():\n",
    "        #create the estimator\n",
    "            if selector_name == 'None':\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                     (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = {}\n",
    "            else:\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                     (feature_selection_name,selector_dict['selector']), \n",
    "                                     (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = selector_dict['parameters']\n",
    "\n",
    "            estimator_param_grid = {(pipeline_estimator_name + '__'+k):v for k,v in estimator_dict['parameters'].items()}\n",
    "            selector_param_grid = {(feature_selection_name + '__'+k):v for k,v in selector_params.items()}\n",
    "            #combine the two param grid dictionaries\n",
    "            full_param_grid = {**selector_param_grid, **estimator_param_grid}\n",
    "            print(pipeline)\n",
    "            print(full_param_grid)\n",
    "\n",
    "            \n",
    "        \n",
    "            gs_1 = GridSearchCV(estimator=pipeline, \n",
    "                                param_grid = full_param_grid, \n",
    "                                cv=cv,scoring=metric,verbose=1)\n",
    "            gs_1.fit(X,y)\n",
    "            all_cv_results.append(gs_1)\n",
    "\n",
    "    #create a dataframe with the best parameters, best mean_test_score, and name of the model\n",
    "\n",
    "    best_params_df = pd.DataFrame({\n",
    "        'model': [cv_result.estimator for cv_result in all_cv_results],\n",
    "        'model_name': [cv_result.estimator.__class__.__name__ for cv_result in all_cv_results],\n",
    "        'best_params': [extract_estimator_params_from_gridsearch(cv_result.best_params_) for cv_result in all_cv_results],\n",
    "        'best_score': [cv_result.best_score_ for cv_result in all_cv_results],\n",
    "        'best_raw_params' : [cv_result.best_params_ for cv_result in all_cv_results]\n",
    "        })\n",
    "    \n",
    "    best_params_df = best_params_df.sort_values('best_score',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    best_model = clone(best_params_df['model'][0])\n",
    "    best_model_params = best_params_df['best_raw_params'][0]\n",
    "    best_model.set_params(**best_model_params)\n",
    "\n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_params_df':best_params_df,\n",
    "        'raw_cv_results':all_cv_results\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving fit with manual theory-driven feature\n",
    "\n",
    "My past analysis showed that by manually removing some features before the analysis starts, we can improve performance beyond the chance performance otherwise seen.\n",
    "\n",
    "So, it might be useful to understand how much we can improve our performance by manual feature selection before the automatic feature selection applies.\n",
    "\n",
    "This was previously done in `test_limited_predictors.ipynb`. We tested as few as 2 distractor features. In that test, predictor features generally had correlations in the range of |r|=0.06 to 0.53, with most around 0.4 (we should confirm that because it seems fishy that PCS was detegted as an effect, but didn't model as a large predictor). With most `|r|=0.4`, this seems unrealistically high to expect, and we should aim to build a pipeline capable of detecting more subtle effects than that. An approximate `|r|=0.3` can be achieved by mixing in a predictor scaled to 8% of normal scale.\n",
    "\n",
    "I can imagine it is plausible to cut down to as few as two self-report, one behavioral, and one neural measure per intervention, plus sex and age. That would yield 10 different variables. At the other end, we might want 10 self-report, two behavioral, and five neural measures per intervention tested, plus 6 different demographic variables--a total of 40 variables. Let's see how these would perform, as well as mid-range of 20 predictor variables. In each case we'll restrict to three valid predictors per intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.07\n",
      "1          EDM                0.07\n",
      "2       BIS_11               -0.07\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.07\n",
      "5                       TRSQ                0.07\n",
      "6  ACES_neglectful_parenting               -0.07\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.004338427499654518, 0.010347584815784239, -0.13657928531674912, -0.06888567014964586, -0.042464301132595805]\n",
      "overall_score:\n",
      "-0.048384019856572216\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.005115</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>0.012854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.020141</td>\n",
       "      <td>0.032035</td>\n",
       "      <td>0.008993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.023508</td>\n",
       "      <td>0.007619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.015052</td>\n",
       "      <td>0.023495</td>\n",
       "      <td>0.007622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002360</td>\n",
       "      <td>0.014605</td>\n",
       "      <td>0.021899</td>\n",
       "      <td>0.008390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.014411</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>0.008832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.012301</td>\n",
       "      <td>0.022491</td>\n",
       "      <td>0.006020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.032940</td>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>0.001401</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>0.032940</td>\n",
       "      <td>0.008631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>0.001063</td>\n",
       "      <td>0.011832</td>\n",
       "      <td>0.017911</td>\n",
       "      <td>0.006614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001032</td>\n",
       "      <td>0.011456</td>\n",
       "      <td>0.017696</td>\n",
       "      <td>0.006801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.011077</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>0.006976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.000259</td>\n",
       "      <td>0.023942</td>\n",
       "      <td>0.035323</td>\n",
       "      <td>0.021684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000469</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.020847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000469</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.020847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000469</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.020847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000469</td>\n",
       "      <td>0.015361</td>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.020847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000520</td>\n",
       "      <td>0.017513</td>\n",
       "      <td>0.043870</td>\n",
       "      <td>0.007505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000556</td>\n",
       "      <td>0.014359</td>\n",
       "      <td>0.027732</td>\n",
       "      <td>0.005399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000639</td>\n",
       "      <td>0.013502</td>\n",
       "      <td>0.016732</td>\n",
       "      <td>0.006296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001002</td>\n",
       "      <td>0.020520</td>\n",
       "      <td>0.031437</td>\n",
       "      <td>0.008018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001894</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>0.045172</td>\n",
       "      <td>0.008183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003659</td>\n",
       "      <td>0.019001</td>\n",
       "      <td>0.046714</td>\n",
       "      <td>0.008555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.005123</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.034043</td>\n",
       "      <td>0.005334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.006040</td>\n",
       "      <td>0.019545</td>\n",
       "      <td>0.048584</td>\n",
       "      <td>0.009179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.007602</td>\n",
       "      <td>0.020026</td>\n",
       "      <td>0.049688</td>\n",
       "      <td>0.009644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.007751</td>\n",
       "      <td>0.032722</td>\n",
       "      <td>0.045796</td>\n",
       "      <td>0.016277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009060</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009060</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009060</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.009060</td>\n",
       "      <td>0.012189</td>\n",
       "      <td>0.010807</td>\n",
       "      <td>0.005304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.009244</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.005177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009565</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.050954</td>\n",
       "      <td>0.010273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.009926</td>\n",
       "      <td>0.013596</td>\n",
       "      <td>0.011892</td>\n",
       "      <td>0.004302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012174</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.052464</td>\n",
       "      <td>0.011169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012627</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.044774</td>\n",
       "      <td>0.015747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012627</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.044774</td>\n",
       "      <td>0.015747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012627</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.044774</td>\n",
       "      <td>0.015747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012627</td>\n",
       "      <td>0.019074</td>\n",
       "      <td>0.044774</td>\n",
       "      <td>0.015747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.013153</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>0.046157</td>\n",
       "      <td>0.017874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.013153</td>\n",
       "      <td>0.032031</td>\n",
       "      <td>0.046157</td>\n",
       "      <td>0.017874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014056</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.057899</td>\n",
       "      <td>0.031442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014056</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.057899</td>\n",
       "      <td>0.031442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014056</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.057899</td>\n",
       "      <td>0.031442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014056</td>\n",
       "      <td>0.015100</td>\n",
       "      <td>0.057899</td>\n",
       "      <td>0.031442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.015917</td>\n",
       "      <td>0.034902</td>\n",
       "      <td>0.042370</td>\n",
       "      <td>0.010033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.016393</td>\n",
       "      <td>0.016310</td>\n",
       "      <td>0.062033</td>\n",
       "      <td>0.026518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018958</td>\n",
       "      <td>0.013730</td>\n",
       "      <td>0.009912</td>\n",
       "      <td>0.008182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019253</td>\n",
       "      <td>0.013976</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019253</td>\n",
       "      <td>0.013976</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.019253</td>\n",
       "      <td>0.013976</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019253</td>\n",
       "      <td>0.013976</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.008393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019336</td>\n",
       "      <td>0.013852</td>\n",
       "      <td>0.009626</td>\n",
       "      <td>0.008323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.025161</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.023984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.025161</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.023984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.025161</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.023984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.025161</td>\n",
       "      <td>0.027166</td>\n",
       "      <td>0.065299</td>\n",
       "      <td>0.023984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031092</td>\n",
       "      <td>0.035882</td>\n",
       "      <td>0.050668</td>\n",
       "      <td>0.027511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.033875</td>\n",
       "      <td>0.038362</td>\n",
       "      <td>0.050076</td>\n",
       "      <td>0.033850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.040160</td>\n",
       "      <td>0.037114</td>\n",
       "      <td>0.049991</td>\n",
       "      <td>0.027208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.040617</td>\n",
       "      <td>0.035452</td>\n",
       "      <td>0.053151</td>\n",
       "      <td>0.023349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041002</td>\n",
       "      <td>0.032219</td>\n",
       "      <td>0.051801</td>\n",
       "      <td>0.026183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.044885</td>\n",
       "      <td>0.044175</td>\n",
       "      <td>0.048766</td>\n",
       "      <td>0.022141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044911</td>\n",
       "      <td>0.039581</td>\n",
       "      <td>0.053589</td>\n",
       "      <td>0.026655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.045072</td>\n",
       "      <td>0.034528</td>\n",
       "      <td>0.053138</td>\n",
       "      <td>0.028212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.045998</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.066732</td>\n",
       "      <td>0.009152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.045998</td>\n",
       "      <td>0.030121</td>\n",
       "      <td>0.066732</td>\n",
       "      <td>0.009152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.050190</td>\n",
       "      <td>0.035026</td>\n",
       "      <td>0.054801</td>\n",
       "      <td>0.028802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050542</td>\n",
       "      <td>0.032090</td>\n",
       "      <td>0.066130</td>\n",
       "      <td>0.013098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.050542</td>\n",
       "      <td>0.032090</td>\n",
       "      <td>0.066130</td>\n",
       "      <td>0.013098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050686</td>\n",
       "      <td>0.028579</td>\n",
       "      <td>0.066135</td>\n",
       "      <td>0.005434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.055230</td>\n",
       "      <td>0.032051</td>\n",
       "      <td>0.063616</td>\n",
       "      <td>0.013676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.056624</td>\n",
       "      <td>0.029312</td>\n",
       "      <td>0.053939</td>\n",
       "      <td>0.010908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.057015</td>\n",
       "      <td>0.035816</td>\n",
       "      <td>0.057126</td>\n",
       "      <td>0.029613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.061467</td>\n",
       "      <td>0.036433</td>\n",
       "      <td>0.058793</td>\n",
       "      <td>0.030151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.067037</td>\n",
       "      <td>0.037345</td>\n",
       "      <td>0.061138</td>\n",
       "      <td>0.030834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.068269</td>\n",
       "      <td>0.040306</td>\n",
       "      <td>0.075351</td>\n",
       "      <td>0.014820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.074364</td>\n",
       "      <td>0.038819</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>0.031726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.074489</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>0.050937</td>\n",
       "      <td>0.013941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.076510</td>\n",
       "      <td>0.062908</td>\n",
       "      <td>0.057659</td>\n",
       "      <td>0.021342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.076734</td>\n",
       "      <td>0.057548</td>\n",
       "      <td>0.059522</td>\n",
       "      <td>0.024608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.077196</td>\n",
       "      <td>0.043533</td>\n",
       "      <td>0.079018</td>\n",
       "      <td>0.013471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.082023</td>\n",
       "      <td>0.067415</td>\n",
       "      <td>0.059166</td>\n",
       "      <td>0.024913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.084387</td>\n",
       "      <td>0.062010</td>\n",
       "      <td>0.060376</td>\n",
       "      <td>0.029307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.087825</td>\n",
       "      <td>0.025538</td>\n",
       "      <td>0.057387</td>\n",
       "      <td>0.017977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.088399</td>\n",
       "      <td>0.064435</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>0.023340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.088399</td>\n",
       "      <td>0.064435</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>0.023340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.088946</td>\n",
       "      <td>0.068196</td>\n",
       "      <td>0.060995</td>\n",
       "      <td>0.027784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.094152</td>\n",
       "      <td>0.063548</td>\n",
       "      <td>0.061566</td>\n",
       "      <td>0.033220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.095006</td>\n",
       "      <td>0.069551</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.027416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.095006</td>\n",
       "      <td>0.069551</td>\n",
       "      <td>0.063391</td>\n",
       "      <td>0.027416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.097510</td>\n",
       "      <td>0.029363</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>0.022104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.098167</td>\n",
       "      <td>0.069114</td>\n",
       "      <td>0.063310</td>\n",
       "      <td>0.031564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.103561</td>\n",
       "      <td>0.071271</td>\n",
       "      <td>0.064431</td>\n",
       "      <td>0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.103561</td>\n",
       "      <td>0.071271</td>\n",
       "      <td>0.064431</td>\n",
       "      <td>0.030711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.104217</td>\n",
       "      <td>0.069672</td>\n",
       "      <td>0.064786</td>\n",
       "      <td>0.033958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.106294</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.068389</td>\n",
       "      <td>0.030688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.106294</td>\n",
       "      <td>0.037183</td>\n",
       "      <td>0.068389</td>\n",
       "      <td>0.030688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.107316</td>\n",
       "      <td>0.066093</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>0.038230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.111578</td>\n",
       "      <td>0.032047</td>\n",
       "      <td>0.065750</td>\n",
       "      <td>0.021533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.111903</td>\n",
       "      <td>0.070380</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.036819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.115371</td>\n",
       "      <td>0.073979</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.034948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.115371</td>\n",
       "      <td>0.073979</td>\n",
       "      <td>0.066303</td>\n",
       "      <td>0.034948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.115965</td>\n",
       "      <td>0.068004</td>\n",
       "      <td>0.064780</td>\n",
       "      <td>0.041386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.121127</td>\n",
       "      <td>0.026433</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.018381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.122412</td>\n",
       "      <td>0.071469</td>\n",
       "      <td>0.069605</td>\n",
       "      <td>0.040264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.123341</td>\n",
       "      <td>0.076042</td>\n",
       "      <td>0.067897</td>\n",
       "      <td>0.037571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.123341</td>\n",
       "      <td>0.076042</td>\n",
       "      <td>0.067897</td>\n",
       "      <td>0.037571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.126495</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.030071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.126495</td>\n",
       "      <td>0.033454</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>0.030071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.126863</td>\n",
       "      <td>0.070600</td>\n",
       "      <td>0.066753</td>\n",
       "      <td>0.045187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.133686</td>\n",
       "      <td>0.079004</td>\n",
       "      <td>0.070417</td>\n",
       "      <td>0.040644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.133686</td>\n",
       "      <td>0.079004</td>\n",
       "      <td>0.070417</td>\n",
       "      <td>0.040644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.141444</td>\n",
       "      <td>0.074234</td>\n",
       "      <td>0.070008</td>\n",
       "      <td>0.049745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.148255</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>0.074892</td>\n",
       "      <td>0.044266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.148255</td>\n",
       "      <td>0.083672</td>\n",
       "      <td>0.074892</td>\n",
       "      <td>0.044266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.680126</td>\n",
       "      <td>0.072934</td>\n",
       "      <td>0.072934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.200386</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>0.011315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.130812</td>\n",
       "      <td>0.003058</td>\n",
       "      <td>0.003058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.131</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.07\n",
      "1          EDM                0.07\n",
      "2       BIS_11               -0.07\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.07\n",
      "5                       TRSQ                0.07\n",
      "6  ACES_neglectful_parenting               -0.07\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.004338427499654518, 0.010347584815784239, -0.13657928531674912, -0.061400090523058504, -0.042464301132595805]\n",
      "overall_score:\n",
      "-0.04688690393125474\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.233959</td>\n",
       "      <td>0.039356</td>\n",
       "      <td>0.294108</td>\n",
       "      <td>0.062610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.235144</td>\n",
       "      <td>0.053756</td>\n",
       "      <td>0.322062</td>\n",
       "      <td>0.059799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.241219</td>\n",
       "      <td>0.058139</td>\n",
       "      <td>0.313008</td>\n",
       "      <td>0.046330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.241219</td>\n",
       "      <td>0.058139</td>\n",
       "      <td>0.313008</td>\n",
       "      <td>0.046330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.241252</td>\n",
       "      <td>0.077517</td>\n",
       "      <td>0.333877</td>\n",
       "      <td>0.064008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.244126</td>\n",
       "      <td>0.065855</td>\n",
       "      <td>0.333023</td>\n",
       "      <td>0.052317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.244306</td>\n",
       "      <td>0.084762</td>\n",
       "      <td>0.325978</td>\n",
       "      <td>0.076612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.245313</td>\n",
       "      <td>0.066729</td>\n",
       "      <td>0.330068</td>\n",
       "      <td>0.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.245313</td>\n",
       "      <td>0.066729</td>\n",
       "      <td>0.330068</td>\n",
       "      <td>0.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.245508</td>\n",
       "      <td>0.066929</td>\n",
       "      <td>0.330064</td>\n",
       "      <td>0.047530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.245919</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.275018</td>\n",
       "      <td>0.047482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.245919</td>\n",
       "      <td>0.036894</td>\n",
       "      <td>0.275018</td>\n",
       "      <td>0.047482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.246636</td>\n",
       "      <td>0.074293</td>\n",
       "      <td>0.336799</td>\n",
       "      <td>0.054874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.246825</td>\n",
       "      <td>0.071962</td>\n",
       "      <td>0.339730</td>\n",
       "      <td>0.048771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.247679</td>\n",
       "      <td>0.056803</td>\n",
       "      <td>0.315354</td>\n",
       "      <td>0.048220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.247913</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>0.339508</td>\n",
       "      <td>0.048550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.247913</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>0.339508</td>\n",
       "      <td>0.048550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.247913</td>\n",
       "      <td>0.072653</td>\n",
       "      <td>0.339508</td>\n",
       "      <td>0.048550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.248043</td>\n",
       "      <td>0.074094</td>\n",
       "      <td>0.339933</td>\n",
       "      <td>0.048214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.248570</td>\n",
       "      <td>0.074575</td>\n",
       "      <td>0.341762</td>\n",
       "      <td>0.050658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.250228</td>\n",
       "      <td>0.074883</td>\n",
       "      <td>0.334735</td>\n",
       "      <td>0.047851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.255671</td>\n",
       "      <td>0.073446</td>\n",
       "      <td>0.329068</td>\n",
       "      <td>0.047731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255969</td>\n",
       "      <td>0.073803</td>\n",
       "      <td>0.350323</td>\n",
       "      <td>0.043385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.256114</td>\n",
       "      <td>0.032806</td>\n",
       "      <td>0.290911</td>\n",
       "      <td>0.062904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.256288</td>\n",
       "      <td>0.073915</td>\n",
       "      <td>0.349272</td>\n",
       "      <td>0.041744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.256354</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>0.349268</td>\n",
       "      <td>0.041738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.256354</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>0.349268</td>\n",
       "      <td>0.041738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.256354</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>0.349268</td>\n",
       "      <td>0.041738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.256354</td>\n",
       "      <td>0.073943</td>\n",
       "      <td>0.349268</td>\n",
       "      <td>0.041738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.258669</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.321360</td>\n",
       "      <td>0.073759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.258669</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.321360</td>\n",
       "      <td>0.073759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.258669</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.321360</td>\n",
       "      <td>0.073759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.258669</td>\n",
       "      <td>0.087882</td>\n",
       "      <td>0.321360</td>\n",
       "      <td>0.073759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.258890</td>\n",
       "      <td>0.062496</td>\n",
       "      <td>0.294581</td>\n",
       "      <td>0.062981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.261469</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>0.293955</td>\n",
       "      <td>0.068258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.264580</td>\n",
       "      <td>0.066646</td>\n",
       "      <td>0.293345</td>\n",
       "      <td>0.069820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.264960</td>\n",
       "      <td>0.071833</td>\n",
       "      <td>0.322939</td>\n",
       "      <td>0.053958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.267052</td>\n",
       "      <td>0.070291</td>\n",
       "      <td>0.346063</td>\n",
       "      <td>0.039613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.267094</td>\n",
       "      <td>0.064782</td>\n",
       "      <td>0.303055</td>\n",
       "      <td>0.073731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.268345</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.345826</td>\n",
       "      <td>0.039326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268345</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.345826</td>\n",
       "      <td>0.039326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268345</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.345826</td>\n",
       "      <td>0.039326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268345</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.345826</td>\n",
       "      <td>0.039326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268360</td>\n",
       "      <td>0.071195</td>\n",
       "      <td>0.345832</td>\n",
       "      <td>0.039336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268567</td>\n",
       "      <td>0.066257</td>\n",
       "      <td>0.292605</td>\n",
       "      <td>0.071893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268674</td>\n",
       "      <td>0.062044</td>\n",
       "      <td>0.299095</td>\n",
       "      <td>0.076484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268732</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.352964</td>\n",
       "      <td>0.063032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268732</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.352964</td>\n",
       "      <td>0.063032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268732</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.352964</td>\n",
       "      <td>0.063032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268732</td>\n",
       "      <td>0.094547</td>\n",
       "      <td>0.352964</td>\n",
       "      <td>0.063032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.271046</td>\n",
       "      <td>0.065890</td>\n",
       "      <td>0.292200</td>\n",
       "      <td>0.073080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.273415</td>\n",
       "      <td>0.106555</td>\n",
       "      <td>0.357017</td>\n",
       "      <td>0.065563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.274096</td>\n",
       "      <td>0.065446</td>\n",
       "      <td>0.291739</td>\n",
       "      <td>0.074439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274748</td>\n",
       "      <td>0.087493</td>\n",
       "      <td>0.284602</td>\n",
       "      <td>0.065347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.277840</td>\n",
       "      <td>0.064787</td>\n",
       "      <td>0.291390</td>\n",
       "      <td>0.076388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.279366</td>\n",
       "      <td>0.093250</td>\n",
       "      <td>0.284168</td>\n",
       "      <td>0.066308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.279727</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.354106</td>\n",
       "      <td>0.073992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.279727</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.354106</td>\n",
       "      <td>0.073992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.279727</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.354106</td>\n",
       "      <td>0.073992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.279727</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0.354106</td>\n",
       "      <td>0.073992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285323</td>\n",
       "      <td>0.093138</td>\n",
       "      <td>0.284121</td>\n",
       "      <td>0.062916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285362</td>\n",
       "      <td>0.074137</td>\n",
       "      <td>0.331302</td>\n",
       "      <td>0.061577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288369</td>\n",
       "      <td>0.062755</td>\n",
       "      <td>0.250739</td>\n",
       "      <td>0.036691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.290563</td>\n",
       "      <td>0.106446</td>\n",
       "      <td>0.353717</td>\n",
       "      <td>0.089586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.290563</td>\n",
       "      <td>0.106446</td>\n",
       "      <td>0.353717</td>\n",
       "      <td>0.089586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.290888</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.080195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.290888</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.080195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.290888</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.080195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.290888</td>\n",
       "      <td>0.087423</td>\n",
       "      <td>0.343582</td>\n",
       "      <td>0.080195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292546</td>\n",
       "      <td>0.058166</td>\n",
       "      <td>0.326175</td>\n",
       "      <td>0.065543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293723</td>\n",
       "      <td>0.093716</td>\n",
       "      <td>0.283656</td>\n",
       "      <td>0.059205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.295560</td>\n",
       "      <td>0.092570</td>\n",
       "      <td>0.352246</td>\n",
       "      <td>0.091048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.295560</td>\n",
       "      <td>0.092570</td>\n",
       "      <td>0.352246</td>\n",
       "      <td>0.091048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.297804</td>\n",
       "      <td>0.067791</td>\n",
       "      <td>0.251378</td>\n",
       "      <td>0.038796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299214</td>\n",
       "      <td>0.094545</td>\n",
       "      <td>0.283216</td>\n",
       "      <td>0.057222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299682</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.241242</td>\n",
       "      <td>0.037464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.299682</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.241242</td>\n",
       "      <td>0.037464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.303065</td>\n",
       "      <td>0.102377</td>\n",
       "      <td>0.341323</td>\n",
       "      <td>0.068272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305575</td>\n",
       "      <td>0.095628</td>\n",
       "      <td>0.282704</td>\n",
       "      <td>0.055366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.306402</td>\n",
       "      <td>0.068955</td>\n",
       "      <td>0.242249</td>\n",
       "      <td>0.039499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.306402</td>\n",
       "      <td>0.068955</td>\n",
       "      <td>0.242249</td>\n",
       "      <td>0.039499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.308062</td>\n",
       "      <td>0.089239</td>\n",
       "      <td>0.338205</td>\n",
       "      <td>0.072003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310373</td>\n",
       "      <td>0.068686</td>\n",
       "      <td>0.251669</td>\n",
       "      <td>0.037984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.310508</td>\n",
       "      <td>0.088306</td>\n",
       "      <td>0.355987</td>\n",
       "      <td>0.102552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313420</td>\n",
       "      <td>0.096985</td>\n",
       "      <td>0.282086</td>\n",
       "      <td>0.053965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.315242</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.255266</td>\n",
       "      <td>0.061497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.315612</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>0.243611</td>\n",
       "      <td>0.038618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.315612</td>\n",
       "      <td>0.069330</td>\n",
       "      <td>0.243611</td>\n",
       "      <td>0.038618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.316188</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>0.276916</td>\n",
       "      <td>0.074357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.317723</td>\n",
       "      <td>0.094709</td>\n",
       "      <td>0.360527</td>\n",
       "      <td>0.099115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.322301</td>\n",
       "      <td>0.051647</td>\n",
       "      <td>0.256279</td>\n",
       "      <td>0.063669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327038</td>\n",
       "      <td>0.069461</td>\n",
       "      <td>0.252961</td>\n",
       "      <td>0.035836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327124</td>\n",
       "      <td>0.063782</td>\n",
       "      <td>0.283714</td>\n",
       "      <td>0.076714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.329298</td>\n",
       "      <td>0.069921</td>\n",
       "      <td>0.244399</td>\n",
       "      <td>0.036883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329298</td>\n",
       "      <td>0.069921</td>\n",
       "      <td>0.244399</td>\n",
       "      <td>0.036883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.331140</td>\n",
       "      <td>0.051742</td>\n",
       "      <td>0.257798</td>\n",
       "      <td>0.061840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337619</td>\n",
       "      <td>0.069816</td>\n",
       "      <td>0.254313</td>\n",
       "      <td>0.034293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.338395</td>\n",
       "      <td>0.069976</td>\n",
       "      <td>0.245324</td>\n",
       "      <td>0.035818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.338395</td>\n",
       "      <td>0.069976</td>\n",
       "      <td>0.245324</td>\n",
       "      <td>0.035818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.343085</td>\n",
       "      <td>0.050883</td>\n",
       "      <td>0.260778</td>\n",
       "      <td>0.059699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.346823</td>\n",
       "      <td>0.107680</td>\n",
       "      <td>0.328662</td>\n",
       "      <td>0.099484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.348479</td>\n",
       "      <td>0.084239</td>\n",
       "      <td>0.352405</td>\n",
       "      <td>0.102258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.349924</td>\n",
       "      <td>0.069860</td>\n",
       "      <td>0.247147</td>\n",
       "      <td>0.034940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.349924</td>\n",
       "      <td>0.069860</td>\n",
       "      <td>0.247147</td>\n",
       "      <td>0.034940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.351190</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.263172</td>\n",
       "      <td>0.058692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351248</td>\n",
       "      <td>0.069892</td>\n",
       "      <td>0.255847</td>\n",
       "      <td>0.032251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361377</td>\n",
       "      <td>0.047929</td>\n",
       "      <td>0.265929</td>\n",
       "      <td>0.057233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363327</td>\n",
       "      <td>0.111337</td>\n",
       "      <td>0.313085</td>\n",
       "      <td>0.102646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365784</td>\n",
       "      <td>0.069271</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>0.034706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365784</td>\n",
       "      <td>0.069271</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>0.034706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.369206</td>\n",
       "      <td>0.069517</td>\n",
       "      <td>0.257175</td>\n",
       "      <td>0.030030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.372100</td>\n",
       "      <td>0.086788</td>\n",
       "      <td>0.346706</td>\n",
       "      <td>0.106813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.372807</td>\n",
       "      <td>0.089863</td>\n",
       "      <td>0.311254</td>\n",
       "      <td>0.128923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.375085</td>\n",
       "      <td>0.134705</td>\n",
       "      <td>0.324762</td>\n",
       "      <td>0.106288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.375085</td>\n",
       "      <td>0.134705</td>\n",
       "      <td>0.324762</td>\n",
       "      <td>0.106288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.375205</td>\n",
       "      <td>0.044761</td>\n",
       "      <td>0.268855</td>\n",
       "      <td>0.055948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392708</td>\n",
       "      <td>0.096556</td>\n",
       "      <td>0.306686</td>\n",
       "      <td>0.113867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.399836</td>\n",
       "      <td>0.112039</td>\n",
       "      <td>0.334243</td>\n",
       "      <td>0.105579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.399836</td>\n",
       "      <td>0.112039</td>\n",
       "      <td>0.334243</td>\n",
       "      <td>0.105579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.928769</td>\n",
       "      <td>0.119806</td>\n",
       "      <td>0.119806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.473140</td>\n",
       "      <td>0.035217</td>\n",
       "      <td>0.035217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.345819</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0.021886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.264702</td>\n",
       "      <td>0.015998</td>\n",
       "      <td>0.015998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.095529</td>\n",
       "      <td>0.003286</td>\n",
       "      <td>0.003286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.131946</td>\n",
       "      <td>0.002874</td>\n",
       "      <td>0.002874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.082713</td>\n",
       "      <td>0.002065</td>\n",
       "      <td>0.002065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.093896</td>\n",
       "      <td>0.001946</td>\n",
       "      <td>0.001946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.050325</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.011322</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.020738</td>\n",
       "      <td>0.000059</td>\n",
       "      <td>0.000059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.929</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.141</td>\n",
       "      <td>0.236</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.346</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.265</td>\n",
       "      <td>0.021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.132</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.083</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.204</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.209</td>\n",
       "      <td>0.235</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.11997251572222778, -0.08538631345414638, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08904939548776289\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.009391</td>\n",
       "      <td>0.020589</td>\n",
       "      <td>0.035081</td>\n",
       "      <td>0.010865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.010320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.008570</td>\n",
       "      <td>0.019918</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.010320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.008146</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.054084</td>\n",
       "      <td>0.010220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.020655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.006587</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.011376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.015580</td>\n",
       "      <td>0.025167</td>\n",
       "      <td>0.009040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>0.005895</td>\n",
       "      <td>0.015580</td>\n",
       "      <td>0.025167</td>\n",
       "      <td>0.009040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.005837</td>\n",
       "      <td>0.015559</td>\n",
       "      <td>0.025126</td>\n",
       "      <td>0.009027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.005579</td>\n",
       "      <td>0.020375</td>\n",
       "      <td>0.028883</td>\n",
       "      <td>0.011483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.005493</td>\n",
       "      <td>0.019752</td>\n",
       "      <td>0.035876</td>\n",
       "      <td>0.010980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>0.009646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.021444</td>\n",
       "      <td>0.058721</td>\n",
       "      <td>0.012130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.003936</td>\n",
       "      <td>0.013439</td>\n",
       "      <td>0.023552</td>\n",
       "      <td>0.006503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.006861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.006861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.012416</td>\n",
       "      <td>0.018979</td>\n",
       "      <td>0.006861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.012237</td>\n",
       "      <td>0.018701</td>\n",
       "      <td>0.006816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002626</td>\n",
       "      <td>0.011210</td>\n",
       "      <td>0.018011</td>\n",
       "      <td>0.007267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002380</td>\n",
       "      <td>0.037849</td>\n",
       "      <td>0.047145</td>\n",
       "      <td>0.018613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001834</td>\n",
       "      <td>0.021752</td>\n",
       "      <td>0.061784</td>\n",
       "      <td>0.013221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001817</td>\n",
       "      <td>0.016143</td>\n",
       "      <td>0.029640</td>\n",
       "      <td>0.005445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.001793</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>0.020681</td>\n",
       "      <td>0.008288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.022042</td>\n",
       "      <td>0.063583</td>\n",
       "      <td>0.013948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.058667</td>\n",
       "      <td>0.019805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.058667</td>\n",
       "      <td>0.019805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.058667</td>\n",
       "      <td>0.019805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000132</td>\n",
       "      <td>0.012264</td>\n",
       "      <td>0.058667</td>\n",
       "      <td>0.019805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000583</td>\n",
       "      <td>0.019550</td>\n",
       "      <td>0.036865</td>\n",
       "      <td>0.005075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.000842</td>\n",
       "      <td>0.015115</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.005874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001823</td>\n",
       "      <td>0.034338</td>\n",
       "      <td>0.047689</td>\n",
       "      <td>0.019755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.001823</td>\n",
       "      <td>0.034338</td>\n",
       "      <td>0.047689</td>\n",
       "      <td>0.019755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.002172</td>\n",
       "      <td>0.022513</td>\n",
       "      <td>0.065616</td>\n",
       "      <td>0.014842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.005083</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.067960</td>\n",
       "      <td>0.015956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.006035</td>\n",
       "      <td>0.037299</td>\n",
       "      <td>0.046080</td>\n",
       "      <td>0.011760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.006924</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.006924</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.006924</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.006924</td>\n",
       "      <td>0.011394</td>\n",
       "      <td>0.010907</td>\n",
       "      <td>0.005602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.007427</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.011416</td>\n",
       "      <td>0.005388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008196</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008196</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008196</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008196</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>0.049783</td>\n",
       "      <td>0.019048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.009032</td>\n",
       "      <td>0.023345</td>\n",
       "      <td>0.068126</td>\n",
       "      <td>0.020585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.009932</td>\n",
       "      <td>0.014365</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.004920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.010671</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.018554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.010671</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.018554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.010671</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.018554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.010671</td>\n",
       "      <td>0.025412</td>\n",
       "      <td>0.068154</td>\n",
       "      <td>0.018554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.019093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.019093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.019093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.013662</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.061415</td>\n",
       "      <td>0.019093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016214</td>\n",
       "      <td>0.045220</td>\n",
       "      <td>0.047546</td>\n",
       "      <td>0.022025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.017983</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.017983</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.017983</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.017983</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.009573</td>\n",
       "      <td>0.008300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018263</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.009921</td>\n",
       "      <td>0.008033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018291</td>\n",
       "      <td>0.012967</td>\n",
       "      <td>0.009966</td>\n",
       "      <td>0.008271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019748</td>\n",
       "      <td>0.023117</td>\n",
       "      <td>0.057271</td>\n",
       "      <td>0.031717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020057</td>\n",
       "      <td>0.048671</td>\n",
       "      <td>0.048813</td>\n",
       "      <td>0.022976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020997</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>0.056015</td>\n",
       "      <td>0.037720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024956</td>\n",
       "      <td>0.049640</td>\n",
       "      <td>0.050480</td>\n",
       "      <td>0.022270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029881</td>\n",
       "      <td>0.030429</td>\n",
       "      <td>0.055335</td>\n",
       "      <td>0.026805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030995</td>\n",
       "      <td>0.032202</td>\n",
       "      <td>0.052794</td>\n",
       "      <td>0.029157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.031546</td>\n",
       "      <td>0.051058</td>\n",
       "      <td>0.052983</td>\n",
       "      <td>0.020855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035857</td>\n",
       "      <td>0.052062</td>\n",
       "      <td>0.054869</td>\n",
       "      <td>0.019647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.036548</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>0.075191</td>\n",
       "      <td>0.008396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.039204</td>\n",
       "      <td>0.030493</td>\n",
       "      <td>0.072277</td>\n",
       "      <td>0.006104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.039804</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.071766</td>\n",
       "      <td>0.008406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.039804</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>0.071766</td>\n",
       "      <td>0.008406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.040773</td>\n",
       "      <td>0.034204</td>\n",
       "      <td>0.056834</td>\n",
       "      <td>0.024928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041246</td>\n",
       "      <td>0.053414</td>\n",
       "      <td>0.057565</td>\n",
       "      <td>0.017922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.042460</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>0.073003</td>\n",
       "      <td>0.009522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.042460</td>\n",
       "      <td>0.028190</td>\n",
       "      <td>0.073003</td>\n",
       "      <td>0.009522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044478</td>\n",
       "      <td>0.038344</td>\n",
       "      <td>0.057536</td>\n",
       "      <td>0.028877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.048316</td>\n",
       "      <td>0.055386</td>\n",
       "      <td>0.061723</td>\n",
       "      <td>0.015756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.053287</td>\n",
       "      <td>0.032213</td>\n",
       "      <td>0.066449</td>\n",
       "      <td>0.017297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.053962</td>\n",
       "      <td>0.061257</td>\n",
       "      <td>0.062553</td>\n",
       "      <td>0.024939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.054554</td>\n",
       "      <td>0.030538</td>\n",
       "      <td>0.059609</td>\n",
       "      <td>0.025931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.056757</td>\n",
       "      <td>0.068948</td>\n",
       "      <td>0.063314</td>\n",
       "      <td>0.022485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.058460</td>\n",
       "      <td>0.030849</td>\n",
       "      <td>0.067453</td>\n",
       "      <td>0.018190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.061292</td>\n",
       "      <td>0.066102</td>\n",
       "      <td>0.063465</td>\n",
       "      <td>0.029697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.062087</td>\n",
       "      <td>0.073905</td>\n",
       "      <td>0.064510</td>\n",
       "      <td>0.026121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.065227</td>\n",
       "      <td>0.065089</td>\n",
       "      <td>0.063807</td>\n",
       "      <td>0.025967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.065227</td>\n",
       "      <td>0.065089</td>\n",
       "      <td>0.063807</td>\n",
       "      <td>0.025967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.066735</td>\n",
       "      <td>0.026776</td>\n",
       "      <td>0.051879</td>\n",
       "      <td>0.029488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.068758</td>\n",
       "      <td>0.074719</td>\n",
       "      <td>0.065951</td>\n",
       "      <td>0.028913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.070678</td>\n",
       "      <td>0.067822</td>\n",
       "      <td>0.064622</td>\n",
       "      <td>0.033631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.071454</td>\n",
       "      <td>0.031230</td>\n",
       "      <td>0.066047</td>\n",
       "      <td>0.010880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.071633</td>\n",
       "      <td>0.070189</td>\n",
       "      <td>0.064589</td>\n",
       "      <td>0.030031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.071633</td>\n",
       "      <td>0.070189</td>\n",
       "      <td>0.064589</td>\n",
       "      <td>0.030031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.077583</td>\n",
       "      <td>0.075560</td>\n",
       "      <td>0.067763</td>\n",
       "      <td>0.032551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.079952</td>\n",
       "      <td>0.071837</td>\n",
       "      <td>0.065766</td>\n",
       "      <td>0.033132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.079952</td>\n",
       "      <td>0.071837</td>\n",
       "      <td>0.065766</td>\n",
       "      <td>0.033132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.083327</td>\n",
       "      <td>0.075992</td>\n",
       "      <td>0.068930</td>\n",
       "      <td>0.034859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.083379</td>\n",
       "      <td>0.070567</td>\n",
       "      <td>0.066246</td>\n",
       "      <td>0.038609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.087503</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.075636</td>\n",
       "      <td>0.030522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.089416</td>\n",
       "      <td>0.029924</td>\n",
       "      <td>0.069229</td>\n",
       "      <td>0.017723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.090565</td>\n",
       "      <td>0.076453</td>\n",
       "      <td>0.070491</td>\n",
       "      <td>0.037615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.091464</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.067707</td>\n",
       "      <td>0.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.091464</td>\n",
       "      <td>0.074441</td>\n",
       "      <td>0.067707</td>\n",
       "      <td>0.037200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.091754</td>\n",
       "      <td>0.072586</td>\n",
       "      <td>0.067375</td>\n",
       "      <td>0.041750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.097400</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.075833</td>\n",
       "      <td>0.037041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.097400</td>\n",
       "      <td>0.038313</td>\n",
       "      <td>0.075833</td>\n",
       "      <td>0.037041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.099245</td>\n",
       "      <td>0.076430</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>0.039779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.099245</td>\n",
       "      <td>0.076430</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>0.039779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.100363</td>\n",
       "      <td>0.077037</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>0.040849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.102353</td>\n",
       "      <td>0.075308</td>\n",
       "      <td>0.068894</td>\n",
       "      <td>0.045623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.105962</td>\n",
       "      <td>0.026827</td>\n",
       "      <td>0.080013</td>\n",
       "      <td>0.027259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.109355</td>\n",
       "      <td>0.079293</td>\n",
       "      <td>0.071622</td>\n",
       "      <td>0.042851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.109355</td>\n",
       "      <td>0.079293</td>\n",
       "      <td>0.071622</td>\n",
       "      <td>0.042851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.116649</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.071248</td>\n",
       "      <td>0.050581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.117945</td>\n",
       "      <td>0.030957</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>0.044869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.117945</td>\n",
       "      <td>0.030957</td>\n",
       "      <td>0.079333</td>\n",
       "      <td>0.044869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.123612</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.075774</td>\n",
       "      <td>0.046473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.123612</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.075774</td>\n",
       "      <td>0.046473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.695431</td>\n",
       "      <td>0.076268</td>\n",
       "      <td>0.076268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.301818</td>\n",
       "      <td>0.020209</td>\n",
       "      <td>0.020209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.246027</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.015520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.160768</td>\n",
       "      <td>0.008107</td>\n",
       "      <td>0.008107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.026304</td>\n",
       "      <td>0.000639</td>\n",
       "      <td>0.000639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PCS*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.302</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.161</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.11997251572222778, -0.06003743599259326, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08397961999545227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255178</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.065261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.262595</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271499</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.084335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.275463</td>\n",
       "      <td>0.061394</td>\n",
       "      <td>0.319901</td>\n",
       "      <td>0.048468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.276075</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>0.300211</td>\n",
       "      <td>0.069192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277201</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>0.081428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277943</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>0.338283</td>\n",
       "      <td>0.051149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.278310</td>\n",
       "      <td>0.069960</td>\n",
       "      <td>0.333670</td>\n",
       "      <td>0.043135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.278310</td>\n",
       "      <td>0.069960</td>\n",
       "      <td>0.333670</td>\n",
       "      <td>0.043135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.278690</td>\n",
       "      <td>0.070323</td>\n",
       "      <td>0.333673</td>\n",
       "      <td>0.043088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.280277</td>\n",
       "      <td>0.064663</td>\n",
       "      <td>0.298993</td>\n",
       "      <td>0.061998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280728</td>\n",
       "      <td>0.079895</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280805</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281511</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.084321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.282129</td>\n",
       "      <td>0.077194</td>\n",
       "      <td>0.344139</td>\n",
       "      <td>0.044455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.283292</td>\n",
       "      <td>0.069279</td>\n",
       "      <td>0.297914</td>\n",
       "      <td>0.067429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.285261</td>\n",
       "      <td>0.077336</td>\n",
       "      <td>0.338665</td>\n",
       "      <td>0.043153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286057</td>\n",
       "      <td>0.078208</td>\n",
       "      <td>0.335517</td>\n",
       "      <td>0.058365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286894</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.287043</td>\n",
       "      <td>0.070180</td>\n",
       "      <td>0.296941</td>\n",
       "      <td>0.069449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287454</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.340642</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288602</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.353791</td>\n",
       "      <td>0.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.289907</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.333861</td>\n",
       "      <td>0.043680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290244</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.254771</td>\n",
       "      <td>0.039511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291442</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.078728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.291721</td>\n",
       "      <td>0.070757</td>\n",
       "      <td>0.295988</td>\n",
       "      <td>0.071932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292894</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293008</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294424</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.294663</td>\n",
       "      <td>0.070952</td>\n",
       "      <td>0.295443</td>\n",
       "      <td>0.073143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.295116</td>\n",
       "      <td>0.071345</td>\n",
       "      <td>0.329382</td>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.298068</td>\n",
       "      <td>0.071067</td>\n",
       "      <td>0.295009</td>\n",
       "      <td>0.074554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299060</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>0.041387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299701</td>\n",
       "      <td>0.081017</td>\n",
       "      <td>0.284739</td>\n",
       "      <td>0.073831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301298</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>0.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301333</td>\n",
       "      <td>0.072146</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.302154</td>\n",
       "      <td>0.071008</td>\n",
       "      <td>0.294797</td>\n",
       "      <td>0.076432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305948</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.282923</td>\n",
       "      <td>0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310575</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.333777</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310993</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312164</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313481</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.067084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.320542</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.257971</td>\n",
       "      <td>0.062015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327152</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.327378</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.259215</td>\n",
       "      <td>0.063780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.328056</td>\n",
       "      <td>0.126492</td>\n",
       "      <td>0.376758</td>\n",
       "      <td>0.078378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.328240</td>\n",
       "      <td>0.111983</td>\n",
       "      <td>0.369747</td>\n",
       "      <td>0.081434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.335929</td>\n",
       "      <td>0.057290</td>\n",
       "      <td>0.261040</td>\n",
       "      <td>0.061222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337594</td>\n",
       "      <td>0.068209</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.036713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.338616</td>\n",
       "      <td>0.069776</td>\n",
       "      <td>0.246064</td>\n",
       "      <td>0.035920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.338616</td>\n",
       "      <td>0.069776</td>\n",
       "      <td>0.246064</td>\n",
       "      <td>0.035920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343089</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>0.089983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.347177</td>\n",
       "      <td>0.057836</td>\n",
       "      <td>0.263728</td>\n",
       "      <td>0.058371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.347361</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>0.355234</td>\n",
       "      <td>0.106691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350813</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.034419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.354360</td>\n",
       "      <td>0.091572</td>\n",
       "      <td>0.360383</td>\n",
       "      <td>0.102959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.354655</td>\n",
       "      <td>0.057611</td>\n",
       "      <td>0.265920</td>\n",
       "      <td>0.056895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355006</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.311593</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.364376</td>\n",
       "      <td>0.056544</td>\n",
       "      <td>0.268553</td>\n",
       "      <td>0.054821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368240</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.258145</td>\n",
       "      <td>0.031309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.377270</td>\n",
       "      <td>0.055268</td>\n",
       "      <td>0.271159</td>\n",
       "      <td>0.053036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.379639</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.393186</td>\n",
       "      <td>0.109074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.383771</td>\n",
       "      <td>0.069268</td>\n",
       "      <td>0.359770</td>\n",
       "      <td>0.106847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389879</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.102402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.398388</td>\n",
       "      <td>0.126673</td>\n",
       "      <td>0.370259</td>\n",
       "      <td>0.136860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.406994</td>\n",
       "      <td>0.069157</td>\n",
       "      <td>0.359774</td>\n",
       "      <td>0.105869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411295</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.095744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.972764</td>\n",
       "      <td>0.126574</td>\n",
       "      <td>0.126574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>0.051583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.392702</td>\n",
       "      <td>0.021206</td>\n",
       "      <td>0.021206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.007577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.109025</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057500158838832416, 0.0935617227055966, -0.046821564784558234, -0.05804501344604618, -0.22385906041246062]\n",
      "overall_score:\n",
      "-0.035532751419727206\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.039031</td>\n",
       "      <td>0.020678</td>\n",
       "      <td>0.069515</td>\n",
       "      <td>0.021402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.037671</td>\n",
       "      <td>0.022059</td>\n",
       "      <td>0.072029</td>\n",
       "      <td>0.022814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.035753</td>\n",
       "      <td>0.022266</td>\n",
       "      <td>0.075005</td>\n",
       "      <td>0.022933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>0.078602</td>\n",
       "      <td>0.023110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.031051</td>\n",
       "      <td>0.023091</td>\n",
       "      <td>0.080704</td>\n",
       "      <td>0.023262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.042900</td>\n",
       "      <td>0.046264</td>\n",
       "      <td>0.025458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.029458</td>\n",
       "      <td>0.041304</td>\n",
       "      <td>0.051029</td>\n",
       "      <td>0.021506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.028613</td>\n",
       "      <td>0.023742</td>\n",
       "      <td>0.083063</td>\n",
       "      <td>0.023511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.028337</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>0.028337</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.049383</td>\n",
       "      <td>0.024893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.028129</td>\n",
       "      <td>0.031859</td>\n",
       "      <td>0.040941</td>\n",
       "      <td>0.018780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.026848</td>\n",
       "      <td>0.044559</td>\n",
       "      <td>0.053097</td>\n",
       "      <td>0.022657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.041425</td>\n",
       "      <td>0.014832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.041425</td>\n",
       "      <td>0.014832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.025375</td>\n",
       "      <td>0.024864</td>\n",
       "      <td>0.085737</td>\n",
       "      <td>0.023951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.024839</td>\n",
       "      <td>0.042586</td>\n",
       "      <td>0.046589</td>\n",
       "      <td>0.019647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.045489</td>\n",
       "      <td>0.055827</td>\n",
       "      <td>0.021789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.022722</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.042605</td>\n",
       "      <td>0.013442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.018322</td>\n",
       "      <td>0.046732</td>\n",
       "      <td>0.059696</td>\n",
       "      <td>0.019582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.018275</td>\n",
       "      <td>0.021119</td>\n",
       "      <td>0.038450</td>\n",
       "      <td>0.015388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>0.016962</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.012492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.016962</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.012492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.016205</td>\n",
       "      <td>0.018417</td>\n",
       "      <td>0.040787</td>\n",
       "      <td>0.013448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.015532</td>\n",
       "      <td>0.016640</td>\n",
       "      <td>0.029988</td>\n",
       "      <td>0.012349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.014897</td>\n",
       "      <td>0.047568</td>\n",
       "      <td>0.062370</td>\n",
       "      <td>0.017595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.016172</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.011884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.013343</td>\n",
       "      <td>0.020783</td>\n",
       "      <td>0.033754</td>\n",
       "      <td>0.013655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.010488</td>\n",
       "      <td>0.048676</td>\n",
       "      <td>0.065885</td>\n",
       "      <td>0.014663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.010403</td>\n",
       "      <td>0.016228</td>\n",
       "      <td>0.027527</td>\n",
       "      <td>0.009352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.018318</td>\n",
       "      <td>0.034778</td>\n",
       "      <td>0.010059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.009047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.009047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.009056</td>\n",
       "      <td>0.014936</td>\n",
       "      <td>0.020914</td>\n",
       "      <td>0.009047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.008251</td>\n",
       "      <td>0.014939</td>\n",
       "      <td>0.020938</td>\n",
       "      <td>0.007753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.007512</td>\n",
       "      <td>0.014072</td>\n",
       "      <td>0.020165</td>\n",
       "      <td>0.009300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.016517</td>\n",
       "      <td>0.024613</td>\n",
       "      <td>0.009560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.004538</td>\n",
       "      <td>0.050313</td>\n",
       "      <td>0.070808</td>\n",
       "      <td>0.010649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.056682</td>\n",
       "      <td>0.066571</td>\n",
       "      <td>0.029138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.059996</td>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.059996</td>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.059996</td>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002228</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.059996</td>\n",
       "      <td>0.021138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.016075</td>\n",
       "      <td>0.018476</td>\n",
       "      <td>0.007033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.001307</td>\n",
       "      <td>0.023109</td>\n",
       "      <td>0.071787</td>\n",
       "      <td>0.025989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.005424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.005424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.005424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001581</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.012377</td>\n",
       "      <td>0.005424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.002241</td>\n",
       "      <td>0.059912</td>\n",
       "      <td>0.067640</td>\n",
       "      <td>0.032932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.002442</td>\n",
       "      <td>0.057008</td>\n",
       "      <td>0.060901</td>\n",
       "      <td>0.027662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.002790</td>\n",
       "      <td>0.011203</td>\n",
       "      <td>0.012947</td>\n",
       "      <td>0.005044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003065</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.052477</td>\n",
       "      <td>0.021767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003065</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.052477</td>\n",
       "      <td>0.021767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003065</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.052477</td>\n",
       "      <td>0.021767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003065</td>\n",
       "      <td>0.020155</td>\n",
       "      <td>0.052477</td>\n",
       "      <td>0.021767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.006900</td>\n",
       "      <td>0.013436</td>\n",
       "      <td>0.012113</td>\n",
       "      <td>0.005381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.007984</td>\n",
       "      <td>0.059580</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.035435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.067295</td>\n",
       "      <td>0.021696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.067295</td>\n",
       "      <td>0.021696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.067295</td>\n",
       "      <td>0.021696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008507</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.067295</td>\n",
       "      <td>0.021696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.008668</td>\n",
       "      <td>0.061452</td>\n",
       "      <td>0.062720</td>\n",
       "      <td>0.032079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.009734</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.069359</td>\n",
       "      <td>0.022491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.013820</td>\n",
       "      <td>0.065396</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.030297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.013820</td>\n",
       "      <td>0.065396</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.030297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014450</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014450</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014450</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.014450</td>\n",
       "      <td>0.009671</td>\n",
       "      <td>0.010645</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014764</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>0.011544</td>\n",
       "      <td>0.007089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014943</td>\n",
       "      <td>0.027447</td>\n",
       "      <td>0.062772</td>\n",
       "      <td>0.029735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.015813</td>\n",
       "      <td>0.059034</td>\n",
       "      <td>0.070515</td>\n",
       "      <td>0.038716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.016155</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.061824</td>\n",
       "      <td>0.028896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.016155</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.061824</td>\n",
       "      <td>0.028896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016360</td>\n",
       "      <td>0.011003</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.007918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016731</td>\n",
       "      <td>0.062902</td>\n",
       "      <td>0.065068</td>\n",
       "      <td>0.035290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016838</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.065793</td>\n",
       "      <td>0.026364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.017215</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.065349</td>\n",
       "      <td>0.026229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.017215</td>\n",
       "      <td>0.025391</td>\n",
       "      <td>0.065349</td>\n",
       "      <td>0.026229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.019753</td>\n",
       "      <td>0.070394</td>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.034231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019753</td>\n",
       "      <td>0.070394</td>\n",
       "      <td>0.066811</td>\n",
       "      <td>0.034231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020399</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>0.010740</td>\n",
       "      <td>0.009335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020431</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>0.010799</td>\n",
       "      <td>0.009271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020531</td>\n",
       "      <td>0.031234</td>\n",
       "      <td>0.059609</td>\n",
       "      <td>0.014848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021035</td>\n",
       "      <td>0.058633</td>\n",
       "      <td>0.071569</td>\n",
       "      <td>0.040788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021571</td>\n",
       "      <td>0.031698</td>\n",
       "      <td>0.059063</td>\n",
       "      <td>0.017864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.027516</td>\n",
       "      <td>0.071882</td>\n",
       "      <td>0.068187</td>\n",
       "      <td>0.036941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.027516</td>\n",
       "      <td>0.071882</td>\n",
       "      <td>0.068187</td>\n",
       "      <td>0.036941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.027747</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.073066</td>\n",
       "      <td>0.043187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.027804</td>\n",
       "      <td>0.065196</td>\n",
       "      <td>0.068158</td>\n",
       "      <td>0.039415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.029634</td>\n",
       "      <td>0.035575</td>\n",
       "      <td>0.073062</td>\n",
       "      <td>0.022123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.030695</td>\n",
       "      <td>0.033742</td>\n",
       "      <td>0.075209</td>\n",
       "      <td>0.022421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035216</td>\n",
       "      <td>0.066923</td>\n",
       "      <td>0.070084</td>\n",
       "      <td>0.042149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.036776</td>\n",
       "      <td>0.036473</td>\n",
       "      <td>0.063812</td>\n",
       "      <td>0.029177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.037033</td>\n",
       "      <td>0.057516</td>\n",
       "      <td>0.075805</td>\n",
       "      <td>0.045675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.038218</td>\n",
       "      <td>0.039074</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.029651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.038331</td>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.040729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.038331</td>\n",
       "      <td>0.074257</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.040729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.044737</td>\n",
       "      <td>0.069365</td>\n",
       "      <td>0.072393</td>\n",
       "      <td>0.045677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.045671</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.071551</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.045671</td>\n",
       "      <td>0.076084</td>\n",
       "      <td>0.071551</td>\n",
       "      <td>0.043268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.055235</td>\n",
       "      <td>0.078726</td>\n",
       "      <td>0.073539</td>\n",
       "      <td>0.046403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.055235</td>\n",
       "      <td>0.078726</td>\n",
       "      <td>0.073539</td>\n",
       "      <td>0.046403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.057464</td>\n",
       "      <td>0.045229</td>\n",
       "      <td>0.092914</td>\n",
       "      <td>0.030203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.057849</td>\n",
       "      <td>0.073130</td>\n",
       "      <td>0.075424</td>\n",
       "      <td>0.050392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.058278</td>\n",
       "      <td>0.040594</td>\n",
       "      <td>0.083925</td>\n",
       "      <td>0.017142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.060629</td>\n",
       "      <td>0.043366</td>\n",
       "      <td>0.067235</td>\n",
       "      <td>0.015650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.061735</td>\n",
       "      <td>0.046063</td>\n",
       "      <td>0.090934</td>\n",
       "      <td>0.033361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.061735</td>\n",
       "      <td>0.046063</td>\n",
       "      <td>0.090934</td>\n",
       "      <td>0.033361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.068769</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.076937</td>\n",
       "      <td>0.050167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.068769</td>\n",
       "      <td>0.082927</td>\n",
       "      <td>0.076937</td>\n",
       "      <td>0.050167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.069252</td>\n",
       "      <td>0.043657</td>\n",
       "      <td>0.066805</td>\n",
       "      <td>0.022511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.070314</td>\n",
       "      <td>0.047606</td>\n",
       "      <td>0.082838</td>\n",
       "      <td>0.035705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.073495</td>\n",
       "      <td>0.038775</td>\n",
       "      <td>0.079660</td>\n",
       "      <td>0.018847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.081370</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>0.035917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.081370</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.087338</td>\n",
       "      <td>0.035917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.089458</td>\n",
       "      <td>0.025161</td>\n",
       "      <td>0.109092</td>\n",
       "      <td>0.023685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.093884</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.088587</td>\n",
       "      <td>0.020082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.255017</td>\n",
       "      <td>1.213726e+00</td>\n",
       "      <td>1.213726e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.478866</td>\n",
       "      <td>7.106648e-01</td>\n",
       "      <td>7.106648e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.502351</td>\n",
       "      <td>2.548956e-01</td>\n",
       "      <td>2.548956e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.215197</td>\n",
       "      <td>1.770851e-01</td>\n",
       "      <td>1.770851e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.995290</td>\n",
       "      <td>1.114887e-01</td>\n",
       "      <td>1.114887e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.384072</td>\n",
       "      <td>1.726315e-02</td>\n",
       "      <td>1.726315e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.279677</td>\n",
       "      <td>7.600461e-03</td>\n",
       "      <td>7.600461e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PCS*ni</td>\n",
       "      <td>-0.118738</td>\n",
       "      <td>1.662091e-03</td>\n",
       "      <td>1.662091e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>-1.844985e-05</td>\n",
       "      <td>1.844985e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RS*ni</td>\n",
       "      <td>-0.071713</td>\n",
       "      <td>-4.080377e-07</td>\n",
       "      <td>4.080377e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>0.003</td>\n",
       "      <td>-3.255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>1.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.255</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057500158838832416, 0.0652425453399087, -0.03244363267364525, -0.10007857858537106, -0.233033673622135]\n",
      "overall_score:\n",
      "-0.04856263614048204\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280536</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.066271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282740</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.068620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285976</td>\n",
       "      <td>0.075457</td>\n",
       "      <td>0.303230</td>\n",
       "      <td>0.066774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291359</td>\n",
       "      <td>0.075054</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.064125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293160</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.257528</td>\n",
       "      <td>0.035962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294270</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.313554</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.295468</td>\n",
       "      <td>0.074691</td>\n",
       "      <td>0.302547</td>\n",
       "      <td>0.062963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300421</td>\n",
       "      <td>0.074639</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.062179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300582</td>\n",
       "      <td>0.060656</td>\n",
       "      <td>0.258034</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.306252</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>0.062085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.309809</td>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.308167</td>\n",
       "      <td>0.058285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310130</td>\n",
       "      <td>0.062629</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.038809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.313456</td>\n",
       "      <td>0.063423</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.061218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.315653</td>\n",
       "      <td>0.067707</td>\n",
       "      <td>0.296633</td>\n",
       "      <td>0.066865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.318322</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.265462</td>\n",
       "      <td>0.071001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.318920</td>\n",
       "      <td>0.068388</td>\n",
       "      <td>0.294937</td>\n",
       "      <td>0.069629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.319607</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.077290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.323328</td>\n",
       "      <td>0.068874</td>\n",
       "      <td>0.293437</td>\n",
       "      <td>0.073048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324294</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.258747</td>\n",
       "      <td>0.038023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324805</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>0.267112</td>\n",
       "      <td>0.073673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326063</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.341145</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.326254</td>\n",
       "      <td>0.068934</td>\n",
       "      <td>0.292858</td>\n",
       "      <td>0.074990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.329746</td>\n",
       "      <td>0.068973</td>\n",
       "      <td>0.292444</td>\n",
       "      <td>0.077035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.333064</td>\n",
       "      <td>0.070044</td>\n",
       "      <td>0.269195</td>\n",
       "      <td>0.071443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333661</td>\n",
       "      <td>0.066372</td>\n",
       "      <td>0.259026</td>\n",
       "      <td>0.036894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.334341</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.292365</td>\n",
       "      <td>0.078994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.339150</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>0.035994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.339150</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>0.035994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.339692</td>\n",
       "      <td>0.066463</td>\n",
       "      <td>0.328883</td>\n",
       "      <td>0.039991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.344913</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>0.272081</td>\n",
       "      <td>0.069695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.345042</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.344765</td>\n",
       "      <td>0.035074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.345042</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.344765</td>\n",
       "      <td>0.035074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345193</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.035140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.348200</td>\n",
       "      <td>0.078463</td>\n",
       "      <td>0.344799</td>\n",
       "      <td>0.033290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349217</td>\n",
       "      <td>0.077211</td>\n",
       "      <td>0.354956</td>\n",
       "      <td>0.049818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352848</td>\n",
       "      <td>0.084820</td>\n",
       "      <td>0.348796</td>\n",
       "      <td>0.071307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.352877</td>\n",
       "      <td>0.071304</td>\n",
       "      <td>0.273455</td>\n",
       "      <td>0.068449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.357259</td>\n",
       "      <td>0.075501</td>\n",
       "      <td>0.339890</td>\n",
       "      <td>0.045998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358048</td>\n",
       "      <td>0.078793</td>\n",
       "      <td>0.361033</td>\n",
       "      <td>0.046373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.360595</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.259809</td>\n",
       "      <td>0.033047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361595</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.354704</td>\n",
       "      <td>0.035836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361774</td>\n",
       "      <td>0.081672</td>\n",
       "      <td>0.349012</td>\n",
       "      <td>0.034196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.363190</td>\n",
       "      <td>0.070539</td>\n",
       "      <td>0.274821</td>\n",
       "      <td>0.066681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363338</td>\n",
       "      <td>0.080531</td>\n",
       "      <td>0.350533</td>\n",
       "      <td>0.056860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365256</td>\n",
       "      <td>0.082006</td>\n",
       "      <td>0.342261</td>\n",
       "      <td>0.035913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.364699</td>\n",
       "      <td>0.041511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367144</td>\n",
       "      <td>0.134187</td>\n",
       "      <td>0.370470</td>\n",
       "      <td>0.090199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368761</td>\n",
       "      <td>0.078618</td>\n",
       "      <td>0.352578</td>\n",
       "      <td>0.051769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.372953</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.359609</td>\n",
       "      <td>0.043287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373126</td>\n",
       "      <td>0.122264</td>\n",
       "      <td>0.378094</td>\n",
       "      <td>0.082357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.376700</td>\n",
       "      <td>0.068904</td>\n",
       "      <td>0.276507</td>\n",
       "      <td>0.064899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.380331</td>\n",
       "      <td>0.075514</td>\n",
       "      <td>0.362062</td>\n",
       "      <td>0.040357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383812</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390169</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.357324</td>\n",
       "      <td>0.035748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390392</td>\n",
       "      <td>0.073656</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.035560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390402</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.349142</td>\n",
       "      <td>0.105288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390518</td>\n",
       "      <td>0.080193</td>\n",
       "      <td>0.348067</td>\n",
       "      <td>0.107437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.401774</td>\n",
       "      <td>0.145669</td>\n",
       "      <td>0.387647</td>\n",
       "      <td>0.065251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.406119</td>\n",
       "      <td>0.138176</td>\n",
       "      <td>0.397882</td>\n",
       "      <td>0.059342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418096</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.338926</td>\n",
       "      <td>0.107341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.421770</td>\n",
       "      <td>0.097651</td>\n",
       "      <td>0.359664</td>\n",
       "      <td>0.109374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.425092</td>\n",
       "      <td>0.085598</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>0.099936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451667</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>0.313566</td>\n",
       "      <td>0.124625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.453425</td>\n",
       "      <td>0.093819</td>\n",
       "      <td>0.357815</td>\n",
       "      <td>0.126289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.456979</td>\n",
       "      <td>0.082932</td>\n",
       "      <td>0.314455</td>\n",
       "      <td>0.113557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.463417</td>\n",
       "      <td>0.127703</td>\n",
       "      <td>0.335019</td>\n",
       "      <td>0.122756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.473608</td>\n",
       "      <td>0.158563</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>0.082078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.474836</td>\n",
       "      <td>0.084723</td>\n",
       "      <td>0.364816</td>\n",
       "      <td>0.110905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.501541</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>0.106978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.813027</td>\n",
       "      <td>1.657010</td>\n",
       "      <td>1.657010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>3.054898</td>\n",
       "      <td>1.097093</td>\n",
       "      <td>1.097093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.033321</td>\n",
       "      <td>1.044694</td>\n",
       "      <td>1.044694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.389706</td>\n",
       "      <td>0.678421</td>\n",
       "      <td>0.678421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.935767</td>\n",
       "      <td>0.461544</td>\n",
       "      <td>0.461544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.514676</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.425740</td>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.241843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.158152</td>\n",
       "      <td>0.164594</td>\n",
       "      <td>0.164594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-1.102637</td>\n",
       "      <td>0.135514</td>\n",
       "      <td>0.135514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>0.080227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>1.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>1.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.774</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-1.103</td>\n",
       "      <td>1.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.07\n",
      "1          EDM                0.07\n",
      "2       BIS_11               -0.07\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.07\n",
      "5                       TRSQ                0.07\n",
      "6  ACES_neglectful_parenting               -0.07\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.0024193505586995734, -0.0005974098928871463, -0.046514101180944234, -0.041414821097769394, -0.1413840444521477]\n",
      "overall_score:\n",
      "-0.045498205213009776\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.031179</td>\n",
       "      <td>0.030021</td>\n",
       "      <td>0.010457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.021517</td>\n",
       "      <td>0.022576</td>\n",
       "      <td>0.007996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.002646</td>\n",
       "      <td>0.016279</td>\n",
       "      <td>0.017814</td>\n",
       "      <td>0.006975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.002766</td>\n",
       "      <td>0.011374</td>\n",
       "      <td>0.029041</td>\n",
       "      <td>0.012002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.002799</td>\n",
       "      <td>0.011454</td>\n",
       "      <td>0.022630</td>\n",
       "      <td>0.008260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.004696</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>0.014453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.004696</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.029735</td>\n",
       "      <td>0.014453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.004724</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.022594</td>\n",
       "      <td>0.009253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.004724</td>\n",
       "      <td>0.014229</td>\n",
       "      <td>0.022594</td>\n",
       "      <td>0.009253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.004737</td>\n",
       "      <td>0.014236</td>\n",
       "      <td>0.022613</td>\n",
       "      <td>0.009228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.005720</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.035513</td>\n",
       "      <td>0.016224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.005873</td>\n",
       "      <td>0.022590</td>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.014673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.007083</td>\n",
       "      <td>0.048215</td>\n",
       "      <td>0.032064</td>\n",
       "      <td>0.018809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.035318</td>\n",
       "      <td>0.016735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.007203</td>\n",
       "      <td>0.037241</td>\n",
       "      <td>0.035318</td>\n",
       "      <td>0.016735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.010525</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.010525</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.010525</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.010525</td>\n",
       "      <td>0.011378</td>\n",
       "      <td>0.012098</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.011727</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.020881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.011772</td>\n",
       "      <td>0.014357</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.005489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014441</td>\n",
       "      <td>0.033571</td>\n",
       "      <td>0.035183</td>\n",
       "      <td>0.019019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017715</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017715</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017715</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017715</td>\n",
       "      <td>0.024155</td>\n",
       "      <td>0.057065</td>\n",
       "      <td>0.026942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018990</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.009718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019466</td>\n",
       "      <td>0.013756</td>\n",
       "      <td>0.009567</td>\n",
       "      <td>0.008452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019538</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019538</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.019538</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.019538</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.008354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019943</td>\n",
       "      <td>0.015450</td>\n",
       "      <td>0.020685</td>\n",
       "      <td>0.010701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020269</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.010669</td>\n",
       "      <td>0.009209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021227</td>\n",
       "      <td>0.013567</td>\n",
       "      <td>0.009672</td>\n",
       "      <td>0.009146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.012776</td>\n",
       "      <td>0.009677</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.023388</td>\n",
       "      <td>0.017115</td>\n",
       "      <td>0.027343</td>\n",
       "      <td>0.014169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.023820</td>\n",
       "      <td>0.013873</td>\n",
       "      <td>0.055433</td>\n",
       "      <td>0.020886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.024080</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>0.037540</td>\n",
       "      <td>0.022127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.024080</td>\n",
       "      <td>0.058925</td>\n",
       "      <td>0.037540</td>\n",
       "      <td>0.022127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.026033</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.057396</td>\n",
       "      <td>0.021950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.028829</td>\n",
       "      <td>0.016228</td>\n",
       "      <td>0.059769</td>\n",
       "      <td>0.021781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029708</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029708</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029708</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029708</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.035272</td>\n",
       "      <td>0.012469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.031500</td>\n",
       "      <td>0.049638</td>\n",
       "      <td>0.038523</td>\n",
       "      <td>0.023366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.032493</td>\n",
       "      <td>0.017224</td>\n",
       "      <td>0.062715</td>\n",
       "      <td>0.021716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.034047</td>\n",
       "      <td>0.026224</td>\n",
       "      <td>0.040946</td>\n",
       "      <td>0.018760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.034805</td>\n",
       "      <td>0.017804</td>\n",
       "      <td>0.064485</td>\n",
       "      <td>0.021778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.036786</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.026625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.036786</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.026625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.036786</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.026625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.036786</td>\n",
       "      <td>0.024789</td>\n",
       "      <td>0.045944</td>\n",
       "      <td>0.026625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.037580</td>\n",
       "      <td>0.018450</td>\n",
       "      <td>0.066522</td>\n",
       "      <td>0.021975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.039932</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>0.044791</td>\n",
       "      <td>0.025349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.041008</td>\n",
       "      <td>0.019169</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>0.022426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044429</td>\n",
       "      <td>0.037822</td>\n",
       "      <td>0.048405</td>\n",
       "      <td>0.021031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.046400</td>\n",
       "      <td>0.061141</td>\n",
       "      <td>0.057841</td>\n",
       "      <td>0.022240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.048606</td>\n",
       "      <td>0.072475</td>\n",
       "      <td>0.053340</td>\n",
       "      <td>0.024541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.052094</td>\n",
       "      <td>0.015784</td>\n",
       "      <td>0.052239</td>\n",
       "      <td>0.024314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.057801</td>\n",
       "      <td>0.040666</td>\n",
       "      <td>0.045470</td>\n",
       "      <td>0.021823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.058847</td>\n",
       "      <td>0.039784</td>\n",
       "      <td>0.046891</td>\n",
       "      <td>0.020598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.062394</td>\n",
       "      <td>0.038260</td>\n",
       "      <td>0.054450</td>\n",
       "      <td>0.012834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063092</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063092</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063092</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063092</td>\n",
       "      <td>0.033697</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>0.012683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.063174</td>\n",
       "      <td>0.043926</td>\n",
       "      <td>0.060681</td>\n",
       "      <td>0.016346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.063840</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>0.060569</td>\n",
       "      <td>0.017241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.064678</td>\n",
       "      <td>0.046278</td>\n",
       "      <td>0.060285</td>\n",
       "      <td>0.017094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.065813</td>\n",
       "      <td>0.046033</td>\n",
       "      <td>0.059704</td>\n",
       "      <td>0.016918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.066570</td>\n",
       "      <td>0.045893</td>\n",
       "      <td>0.059235</td>\n",
       "      <td>0.016856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.067538</td>\n",
       "      <td>0.045758</td>\n",
       "      <td>0.058591</td>\n",
       "      <td>0.016874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.068849</td>\n",
       "      <td>0.045673</td>\n",
       "      <td>0.057724</td>\n",
       "      <td>0.017080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.071208</td>\n",
       "      <td>0.074511</td>\n",
       "      <td>0.078832</td>\n",
       "      <td>0.044627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.074144</td>\n",
       "      <td>0.045995</td>\n",
       "      <td>0.062633</td>\n",
       "      <td>0.013134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.075307</td>\n",
       "      <td>0.040056</td>\n",
       "      <td>0.077317</td>\n",
       "      <td>0.027838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.075307</td>\n",
       "      <td>0.040056</td>\n",
       "      <td>0.077317</td>\n",
       "      <td>0.027838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.075352</td>\n",
       "      <td>0.046571</td>\n",
       "      <td>0.075778</td>\n",
       "      <td>0.018695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.076573</td>\n",
       "      <td>0.046425</td>\n",
       "      <td>0.076628</td>\n",
       "      <td>0.016430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.078157</td>\n",
       "      <td>0.080890</td>\n",
       "      <td>0.082194</td>\n",
       "      <td>0.051151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.079787</td>\n",
       "      <td>0.053294</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.023435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.079787</td>\n",
       "      <td>0.053294</td>\n",
       "      <td>0.071281</td>\n",
       "      <td>0.023435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.082734</td>\n",
       "      <td>0.074720</td>\n",
       "      <td>0.098046</td>\n",
       "      <td>0.034194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.083203</td>\n",
       "      <td>0.040448</td>\n",
       "      <td>0.060284</td>\n",
       "      <td>0.022218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.086860</td>\n",
       "      <td>0.083184</td>\n",
       "      <td>0.086090</td>\n",
       "      <td>0.055856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.087024</td>\n",
       "      <td>0.080164</td>\n",
       "      <td>0.101049</td>\n",
       "      <td>0.038355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.089409</td>\n",
       "      <td>0.046918</td>\n",
       "      <td>0.069593</td>\n",
       "      <td>0.037290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.092301</td>\n",
       "      <td>0.081472</td>\n",
       "      <td>0.104475</td>\n",
       "      <td>0.041008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.098279</td>\n",
       "      <td>0.086076</td>\n",
       "      <td>0.090686</td>\n",
       "      <td>0.061845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.099185</td>\n",
       "      <td>0.083505</td>\n",
       "      <td>0.108409</td>\n",
       "      <td>0.044653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.099435</td>\n",
       "      <td>0.056753</td>\n",
       "      <td>0.087162</td>\n",
       "      <td>0.042853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.103648</td>\n",
       "      <td>0.085020</td>\n",
       "      <td>0.110577</td>\n",
       "      <td>0.047140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.105569</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.093347</td>\n",
       "      <td>0.065509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.109329</td>\n",
       "      <td>0.087141</td>\n",
       "      <td>0.112852</td>\n",
       "      <td>0.050423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.114495</td>\n",
       "      <td>0.089878</td>\n",
       "      <td>0.096399</td>\n",
       "      <td>0.069726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.115501</td>\n",
       "      <td>0.063875</td>\n",
       "      <td>0.093484</td>\n",
       "      <td>0.036139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.117322</td>\n",
       "      <td>0.090375</td>\n",
       "      <td>0.115176</td>\n",
       "      <td>0.055097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.125943</td>\n",
       "      <td>0.092372</td>\n",
       "      <td>0.100348</td>\n",
       "      <td>0.074258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.127576</td>\n",
       "      <td>0.054743</td>\n",
       "      <td>0.076154</td>\n",
       "      <td>0.036056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.145610</td>\n",
       "      <td>0.095088</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.037678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.145610</td>\n",
       "      <td>0.095088</td>\n",
       "      <td>0.111618</td>\n",
       "      <td>0.037678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.146772</td>\n",
       "      <td>0.054570</td>\n",
       "      <td>0.086126</td>\n",
       "      <td>0.038309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.151918</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>0.077829</td>\n",
       "      <td>0.028607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.151918</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>0.077829</td>\n",
       "      <td>0.028607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.156485</td>\n",
       "      <td>0.100881</td>\n",
       "      <td>0.118699</td>\n",
       "      <td>0.041324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.156485</td>\n",
       "      <td>0.100881</td>\n",
       "      <td>0.118699</td>\n",
       "      <td>0.041324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.170196</td>\n",
       "      <td>0.100823</td>\n",
       "      <td>0.127211</td>\n",
       "      <td>0.043732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.170196</td>\n",
       "      <td>0.100823</td>\n",
       "      <td>0.127211</td>\n",
       "      <td>0.043732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.172532</td>\n",
       "      <td>0.065775</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.035466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.172532</td>\n",
       "      <td>0.065775</td>\n",
       "      <td>0.074886</td>\n",
       "      <td>0.035466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.188592</td>\n",
       "      <td>0.100757</td>\n",
       "      <td>0.137724</td>\n",
       "      <td>0.047808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.188592</td>\n",
       "      <td>0.100757</td>\n",
       "      <td>0.137724</td>\n",
       "      <td>0.047808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.200800</td>\n",
       "      <td>0.100824</td>\n",
       "      <td>0.144051</td>\n",
       "      <td>0.050739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.200800</td>\n",
       "      <td>0.100824</td>\n",
       "      <td>0.144051</td>\n",
       "      <td>0.050739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.216600</td>\n",
       "      <td>0.101146</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.054423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.216600</td>\n",
       "      <td>0.101146</td>\n",
       "      <td>0.151458</td>\n",
       "      <td>0.054423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.239171</td>\n",
       "      <td>0.102164</td>\n",
       "      <td>0.160707</td>\n",
       "      <td>0.058895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.239171</td>\n",
       "      <td>0.102164</td>\n",
       "      <td>0.160707</td>\n",
       "      <td>0.058895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.723630</td>\n",
       "      <td>0.083572</td>\n",
       "      <td>0.083572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.361068</td>\n",
       "      <td>0.027074</td>\n",
       "      <td>0.027074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.128862</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>0.006185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.060662</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>0.002807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.361</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.061</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.07\n",
      "1          EDM                0.07\n",
      "2       BIS_11               -0.07\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.07\n",
      "5                       TRSQ                0.07\n",
      "6  ACES_neglectful_parenting               -0.07\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.004195589714443226, -0.0005974098928871463, -0.11681410997963648, -0.05154953220963354, -0.3585614799468666]\n",
      "overall_score:\n",
      "-0.1046653884629161\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.224635</td>\n",
       "      <td>0.048179</td>\n",
       "      <td>0.301346</td>\n",
       "      <td>0.081608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.231677</td>\n",
       "      <td>0.063116</td>\n",
       "      <td>0.326475</td>\n",
       "      <td>0.066780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.237246</td>\n",
       "      <td>0.048236</td>\n",
       "      <td>0.284585</td>\n",
       "      <td>0.037944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.237246</td>\n",
       "      <td>0.048236</td>\n",
       "      <td>0.284585</td>\n",
       "      <td>0.037944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.239973</td>\n",
       "      <td>0.051970</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.045354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.239973</td>\n",
       "      <td>0.051970</td>\n",
       "      <td>0.325400</td>\n",
       "      <td>0.045354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.246000</td>\n",
       "      <td>0.066979</td>\n",
       "      <td>0.335249</td>\n",
       "      <td>0.051610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.248196</td>\n",
       "      <td>0.063834</td>\n",
       "      <td>0.336150</td>\n",
       "      <td>0.045475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.248196</td>\n",
       "      <td>0.063834</td>\n",
       "      <td>0.336150</td>\n",
       "      <td>0.045475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.250409</td>\n",
       "      <td>0.072297</td>\n",
       "      <td>0.339317</td>\n",
       "      <td>0.049423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.251113</td>\n",
       "      <td>0.064687</td>\n",
       "      <td>0.334650</td>\n",
       "      <td>0.049220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.251535</td>\n",
       "      <td>0.078708</td>\n",
       "      <td>0.343516</td>\n",
       "      <td>0.041300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.253015</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.341533</td>\n",
       "      <td>0.044158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.253015</td>\n",
       "      <td>0.073994</td>\n",
       "      <td>0.341533</td>\n",
       "      <td>0.044158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.253073</td>\n",
       "      <td>0.074010</td>\n",
       "      <td>0.341525</td>\n",
       "      <td>0.044159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.253473</td>\n",
       "      <td>0.082271</td>\n",
       "      <td>0.343775</td>\n",
       "      <td>0.044119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.258415</td>\n",
       "      <td>0.076807</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.040559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.258415</td>\n",
       "      <td>0.076807</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.040559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.258415</td>\n",
       "      <td>0.076807</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.040559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.258415</td>\n",
       "      <td>0.076807</td>\n",
       "      <td>0.348373</td>\n",
       "      <td>0.040559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.259215</td>\n",
       "      <td>0.076374</td>\n",
       "      <td>0.343600</td>\n",
       "      <td>0.055204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.259351</td>\n",
       "      <td>0.075119</td>\n",
       "      <td>0.348401</td>\n",
       "      <td>0.042993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.260232</td>\n",
       "      <td>0.085571</td>\n",
       "      <td>0.343698</td>\n",
       "      <td>0.045512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.260270</td>\n",
       "      <td>0.075280</td>\n",
       "      <td>0.343098</td>\n",
       "      <td>0.049230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.261092</td>\n",
       "      <td>0.052708</td>\n",
       "      <td>0.321512</td>\n",
       "      <td>0.054717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.264435</td>\n",
       "      <td>0.064231</td>\n",
       "      <td>0.348387</td>\n",
       "      <td>0.034541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.265916</td>\n",
       "      <td>0.062198</td>\n",
       "      <td>0.345827</td>\n",
       "      <td>0.032040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.266406</td>\n",
       "      <td>0.070308</td>\n",
       "      <td>0.349253</td>\n",
       "      <td>0.038436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268279</td>\n",
       "      <td>0.071508</td>\n",
       "      <td>0.345202</td>\n",
       "      <td>0.039265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268490</td>\n",
       "      <td>0.071520</td>\n",
       "      <td>0.345519</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268490</td>\n",
       "      <td>0.071520</td>\n",
       "      <td>0.345519</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.268490</td>\n",
       "      <td>0.071520</td>\n",
       "      <td>0.345519</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.268490</td>\n",
       "      <td>0.071520</td>\n",
       "      <td>0.345519</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269494</td>\n",
       "      <td>0.071032</td>\n",
       "      <td>0.346091</td>\n",
       "      <td>0.038523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269824</td>\n",
       "      <td>0.067369</td>\n",
       "      <td>0.345751</td>\n",
       "      <td>0.035996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.270676</td>\n",
       "      <td>0.060077</td>\n",
       "      <td>0.340759</td>\n",
       "      <td>0.032559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.270976</td>\n",
       "      <td>0.088692</td>\n",
       "      <td>0.342927</td>\n",
       "      <td>0.047052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.273280</td>\n",
       "      <td>0.038306</td>\n",
       "      <td>0.293300</td>\n",
       "      <td>0.058711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.273718</td>\n",
       "      <td>0.080262</td>\n",
       "      <td>0.261685</td>\n",
       "      <td>0.095702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274131</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>0.333023</td>\n",
       "      <td>0.060464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274131</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>0.333023</td>\n",
       "      <td>0.060464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274131</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>0.333023</td>\n",
       "      <td>0.060464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274131</td>\n",
       "      <td>0.098383</td>\n",
       "      <td>0.333023</td>\n",
       "      <td>0.060464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280397</td>\n",
       "      <td>0.048391</td>\n",
       "      <td>0.328795</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282432</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>0.261622</td>\n",
       "      <td>0.099575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288441</td>\n",
       "      <td>0.072403</td>\n",
       "      <td>0.308261</td>\n",
       "      <td>0.077949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.289845</td>\n",
       "      <td>0.082703</td>\n",
       "      <td>0.356140</td>\n",
       "      <td>0.146546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.290246</td>\n",
       "      <td>0.069730</td>\n",
       "      <td>0.331720</td>\n",
       "      <td>0.043997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290914</td>\n",
       "      <td>0.089370</td>\n",
       "      <td>0.346366</td>\n",
       "      <td>0.070032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290914</td>\n",
       "      <td>0.089370</td>\n",
       "      <td>0.346366</td>\n",
       "      <td>0.070032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290914</td>\n",
       "      <td>0.089370</td>\n",
       "      <td>0.346366</td>\n",
       "      <td>0.070032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290914</td>\n",
       "      <td>0.089370</td>\n",
       "      <td>0.346366</td>\n",
       "      <td>0.070032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.291186</td>\n",
       "      <td>0.074808</td>\n",
       "      <td>0.357969</td>\n",
       "      <td>0.145421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.291953</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.119754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.291953</td>\n",
       "      <td>0.074729</td>\n",
       "      <td>0.371545</td>\n",
       "      <td>0.119754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292388</td>\n",
       "      <td>0.070530</td>\n",
       "      <td>0.302484</td>\n",
       "      <td>0.076469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293163</td>\n",
       "      <td>0.093164</td>\n",
       "      <td>0.261740</td>\n",
       "      <td>0.097114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.293705</td>\n",
       "      <td>0.073612</td>\n",
       "      <td>0.330362</td>\n",
       "      <td>0.049391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.297435</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>0.366946</td>\n",
       "      <td>0.115933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.297435</td>\n",
       "      <td>0.060742</td>\n",
       "      <td>0.366946</td>\n",
       "      <td>0.115933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.298032</td>\n",
       "      <td>0.073145</td>\n",
       "      <td>0.328550</td>\n",
       "      <td>0.053093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299079</td>\n",
       "      <td>0.082821</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.060034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299079</td>\n",
       "      <td>0.082821</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.060034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299079</td>\n",
       "      <td>0.082821</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.060034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299079</td>\n",
       "      <td>0.082821</td>\n",
       "      <td>0.352168</td>\n",
       "      <td>0.060034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.299631</td>\n",
       "      <td>0.087650</td>\n",
       "      <td>0.304387</td>\n",
       "      <td>0.050419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.301671</td>\n",
       "      <td>0.087691</td>\n",
       "      <td>0.359566</td>\n",
       "      <td>0.080268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.303497</td>\n",
       "      <td>0.072824</td>\n",
       "      <td>0.326330</td>\n",
       "      <td>0.058001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.307246</td>\n",
       "      <td>0.072037</td>\n",
       "      <td>0.325176</td>\n",
       "      <td>0.060807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307993</td>\n",
       "      <td>0.096172</td>\n",
       "      <td>0.262286</td>\n",
       "      <td>0.094120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.310743</td>\n",
       "      <td>0.042660</td>\n",
       "      <td>0.247681</td>\n",
       "      <td>0.086302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.311637</td>\n",
       "      <td>0.071275</td>\n",
       "      <td>0.323845</td>\n",
       "      <td>0.064091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.312419</td>\n",
       "      <td>0.097062</td>\n",
       "      <td>0.308364</td>\n",
       "      <td>0.050289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313168</td>\n",
       "      <td>0.034171</td>\n",
       "      <td>0.303220</td>\n",
       "      <td>0.040090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314371</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.302778</td>\n",
       "      <td>0.042460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.315642</td>\n",
       "      <td>0.047051</td>\n",
       "      <td>0.247281</td>\n",
       "      <td>0.092722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.315808</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.302157</td>\n",
       "      <td>0.042451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.316830</td>\n",
       "      <td>0.070653</td>\n",
       "      <td>0.322370</td>\n",
       "      <td>0.068188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.317071</td>\n",
       "      <td>0.097539</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.092485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.317633</td>\n",
       "      <td>0.038611</td>\n",
       "      <td>0.301216</td>\n",
       "      <td>0.042589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.318785</td>\n",
       "      <td>0.039420</td>\n",
       "      <td>0.300544</td>\n",
       "      <td>0.042784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.320222</td>\n",
       "      <td>0.040489</td>\n",
       "      <td>0.299625</td>\n",
       "      <td>0.043179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.322139</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.298323</td>\n",
       "      <td>0.043945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.322257</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.247679</td>\n",
       "      <td>0.093746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.323665</td>\n",
       "      <td>0.113537</td>\n",
       "      <td>0.365402</td>\n",
       "      <td>0.068859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324278</td>\n",
       "      <td>0.058986</td>\n",
       "      <td>0.340444</td>\n",
       "      <td>0.066173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324278</td>\n",
       "      <td>0.058986</td>\n",
       "      <td>0.340444</td>\n",
       "      <td>0.066173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324278</td>\n",
       "      <td>0.058986</td>\n",
       "      <td>0.340444</td>\n",
       "      <td>0.066173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324278</td>\n",
       "      <td>0.058986</td>\n",
       "      <td>0.340444</td>\n",
       "      <td>0.066173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325611</td>\n",
       "      <td>0.114164</td>\n",
       "      <td>0.367993</td>\n",
       "      <td>0.072548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.328419</td>\n",
       "      <td>0.098628</td>\n",
       "      <td>0.263689</td>\n",
       "      <td>0.090347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.331547</td>\n",
       "      <td>0.053404</td>\n",
       "      <td>0.248464</td>\n",
       "      <td>0.093588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.337914</td>\n",
       "      <td>0.056821</td>\n",
       "      <td>0.248830</td>\n",
       "      <td>0.092372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.340290</td>\n",
       "      <td>0.065455</td>\n",
       "      <td>0.310192</td>\n",
       "      <td>0.155315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342945</td>\n",
       "      <td>0.099383</td>\n",
       "      <td>0.264325</td>\n",
       "      <td>0.087647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.345760</td>\n",
       "      <td>0.061351</td>\n",
       "      <td>0.249360</td>\n",
       "      <td>0.090560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.356085</td>\n",
       "      <td>0.067732</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.088291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362223</td>\n",
       "      <td>0.114877</td>\n",
       "      <td>0.348076</td>\n",
       "      <td>0.067949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363037</td>\n",
       "      <td>0.132731</td>\n",
       "      <td>0.288759</td>\n",
       "      <td>0.121448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.363045</td>\n",
       "      <td>0.077878</td>\n",
       "      <td>0.213607</td>\n",
       "      <td>0.046797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.363045</td>\n",
       "      <td>0.077878</td>\n",
       "      <td>0.213607</td>\n",
       "      <td>0.046797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.369912</td>\n",
       "      <td>0.110879</td>\n",
       "      <td>0.345485</td>\n",
       "      <td>0.068548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.370696</td>\n",
       "      <td>0.068945</td>\n",
       "      <td>0.298070</td>\n",
       "      <td>0.157643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.376929</td>\n",
       "      <td>0.083588</td>\n",
       "      <td>0.214610</td>\n",
       "      <td>0.047738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.376929</td>\n",
       "      <td>0.083588</td>\n",
       "      <td>0.214610</td>\n",
       "      <td>0.047738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381394</td>\n",
       "      <td>0.114885</td>\n",
       "      <td>0.275828</td>\n",
       "      <td>0.130494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.392419</td>\n",
       "      <td>0.082615</td>\n",
       "      <td>0.296949</td>\n",
       "      <td>0.103382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.392419</td>\n",
       "      <td>0.082615</td>\n",
       "      <td>0.296949</td>\n",
       "      <td>0.103382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.394695</td>\n",
       "      <td>0.084903</td>\n",
       "      <td>0.216963</td>\n",
       "      <td>0.045685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.394695</td>\n",
       "      <td>0.084903</td>\n",
       "      <td>0.216963</td>\n",
       "      <td>0.045685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.417736</td>\n",
       "      <td>0.086245</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.045554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.417736</td>\n",
       "      <td>0.086245</td>\n",
       "      <td>0.221874</td>\n",
       "      <td>0.045554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.432859</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>0.098164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.432859</td>\n",
       "      <td>0.053289</td>\n",
       "      <td>0.298715</td>\n",
       "      <td>0.098164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433104</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>0.225130</td>\n",
       "      <td>0.046744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433104</td>\n",
       "      <td>0.085568</td>\n",
       "      <td>0.225130</td>\n",
       "      <td>0.046744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452767</td>\n",
       "      <td>0.084188</td>\n",
       "      <td>0.230718</td>\n",
       "      <td>0.049304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.452767</td>\n",
       "      <td>0.084188</td>\n",
       "      <td>0.230718</td>\n",
       "      <td>0.049304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479904</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.239081</td>\n",
       "      <td>0.053582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.479904</td>\n",
       "      <td>0.082330</td>\n",
       "      <td>0.239081</td>\n",
       "      <td>0.053582</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.411874</td>\n",
       "      <td>0.266299</td>\n",
       "      <td>0.266299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.755465</td>\n",
       "      <td>0.087090</td>\n",
       "      <td>0.087090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.285412</td>\n",
       "      <td>0.015221</td>\n",
       "      <td>0.015221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.360233</td>\n",
       "      <td>0.013868</td>\n",
       "      <td>0.013868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.233940</td>\n",
       "      <td>0.010450</td>\n",
       "      <td>0.010450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.139699</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.006760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.151651</td>\n",
       "      <td>0.001818</td>\n",
       "      <td>0.001818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.146504</td>\n",
       "      <td>0.001780</td>\n",
       "      <td>0.001780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.036962</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.010128</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>0.000031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACES_divorced_separated</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.412</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.266</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>-0.049</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.360</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.194</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.00611321062267034, -0.018534990667956164, -0.019150372008972294, -0.05675115891629945, -0.14274278152201814]\n",
      "overall_score:\n",
      "-0.04621321849851514\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.032892</td>\n",
       "      <td>0.031421</td>\n",
       "      <td>0.011019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.021996</td>\n",
       "      <td>0.024038</td>\n",
       "      <td>0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.049908</td>\n",
       "      <td>0.034108</td>\n",
       "      <td>0.015704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.012269</td>\n",
       "      <td>0.030287</td>\n",
       "      <td>0.012934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.015103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000193</td>\n",
       "      <td>0.022343</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.015103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000214</td>\n",
       "      <td>0.012012</td>\n",
       "      <td>0.023477</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.000710</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.015521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000710</td>\n",
       "      <td>0.037421</td>\n",
       "      <td>0.035905</td>\n",
       "      <td>0.015521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.001413</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>0.018366</td>\n",
       "      <td>0.007379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001520</td>\n",
       "      <td>0.012387</td>\n",
       "      <td>0.037250</td>\n",
       "      <td>0.017069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001694</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>0.010084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.001694</td>\n",
       "      <td>0.014156</td>\n",
       "      <td>0.022937</td>\n",
       "      <td>0.010084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.001737</td>\n",
       "      <td>0.014164</td>\n",
       "      <td>0.022979</td>\n",
       "      <td>0.010031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.002051</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.031658</td>\n",
       "      <td>0.015397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.005217</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.042824</td>\n",
       "      <td>0.022450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008421</td>\n",
       "      <td>0.010484</td>\n",
       "      <td>0.012295</td>\n",
       "      <td>0.004539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.008425</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.004540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008425</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.004540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008425</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.012292</td>\n",
       "      <td>0.004540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.008699</td>\n",
       "      <td>0.032308</td>\n",
       "      <td>0.038047</td>\n",
       "      <td>0.019462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.010541</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.011172</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.012183</td>\n",
       "      <td>0.060531</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>0.019514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012183</td>\n",
       "      <td>0.060531</td>\n",
       "      <td>0.037810</td>\n",
       "      <td>0.019514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.012758</td>\n",
       "      <td>0.014967</td>\n",
       "      <td>0.058320</td>\n",
       "      <td>0.020190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>0.028421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>0.028421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>0.028421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013939</td>\n",
       "      <td>0.018353</td>\n",
       "      <td>0.059122</td>\n",
       "      <td>0.028421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014884</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.060245</td>\n",
       "      <td>0.021256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.017589</td>\n",
       "      <td>0.016973</td>\n",
       "      <td>0.062572</td>\n",
       "      <td>0.021091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.018046</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.008293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.018046</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.008293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.018046</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.008293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.018046</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>0.008293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018562</td>\n",
       "      <td>0.012972</td>\n",
       "      <td>0.009815</td>\n",
       "      <td>0.008392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018871</td>\n",
       "      <td>0.013010</td>\n",
       "      <td>0.017879</td>\n",
       "      <td>0.008008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019621</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.008740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019854</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>0.011510</td>\n",
       "      <td>0.008756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020989</td>\n",
       "      <td>0.012722</td>\n",
       "      <td>0.009859</td>\n",
       "      <td>0.009505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.021104</td>\n",
       "      <td>0.011980</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.008861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.021160</td>\n",
       "      <td>0.017729</td>\n",
       "      <td>0.065454</td>\n",
       "      <td>0.020963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.022379</td>\n",
       "      <td>0.015252</td>\n",
       "      <td>0.028759</td>\n",
       "      <td>0.013453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.022984</td>\n",
       "      <td>0.048555</td>\n",
       "      <td>0.044026</td>\n",
       "      <td>0.022290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.023427</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>0.067177</td>\n",
       "      <td>0.020954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.025958</td>\n",
       "      <td>0.045595</td>\n",
       "      <td>0.065817</td>\n",
       "      <td>0.036796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.026162</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.069150</td>\n",
       "      <td>0.021042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.026889</td>\n",
       "      <td>0.057214</td>\n",
       "      <td>0.060308</td>\n",
       "      <td>0.030083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029119</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029119</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029119</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.029119</td>\n",
       "      <td>0.020728</td>\n",
       "      <td>0.033479</td>\n",
       "      <td>0.008957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.029561</td>\n",
       "      <td>0.019243</td>\n",
       "      <td>0.071442</td>\n",
       "      <td>0.021342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.030850</td>\n",
       "      <td>0.023052</td>\n",
       "      <td>0.042187</td>\n",
       "      <td>0.020702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.032185</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>0.053702</td>\n",
       "      <td>0.028789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.034791</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.034791</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.034791</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.034791</td>\n",
       "      <td>0.026479</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.027855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.037330</td>\n",
       "      <td>0.035531</td>\n",
       "      <td>0.055955</td>\n",
       "      <td>0.026171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.041013</td>\n",
       "      <td>0.043195</td>\n",
       "      <td>0.052329</td>\n",
       "      <td>0.024203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.042074</td>\n",
       "      <td>0.042517</td>\n",
       "      <td>0.054112</td>\n",
       "      <td>0.022317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050086</td>\n",
       "      <td>0.017380</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.025906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.055581</td>\n",
       "      <td>0.074624</td>\n",
       "      <td>0.077602</td>\n",
       "      <td>0.046777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.060395</td>\n",
       "      <td>0.025732</td>\n",
       "      <td>0.059734</td>\n",
       "      <td>0.016058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.061343</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>0.059443</td>\n",
       "      <td>0.016530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.062443</td>\n",
       "      <td>0.081241</td>\n",
       "      <td>0.080910</td>\n",
       "      <td>0.053640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.062590</td>\n",
       "      <td>0.047620</td>\n",
       "      <td>0.059000</td>\n",
       "      <td>0.016558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063479</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063479</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063479</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.063479</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>0.045497</td>\n",
       "      <td>0.013764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.064136</td>\n",
       "      <td>0.048833</td>\n",
       "      <td>0.058351</td>\n",
       "      <td>0.015318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.066139</td>\n",
       "      <td>0.050316</td>\n",
       "      <td>0.057386</td>\n",
       "      <td>0.013716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.067408</td>\n",
       "      <td>0.051189</td>\n",
       "      <td>0.056726</td>\n",
       "      <td>0.012760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.067614</td>\n",
       "      <td>0.042935</td>\n",
       "      <td>0.060848</td>\n",
       "      <td>0.023279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.068682</td>\n",
       "      <td>0.037637</td>\n",
       "      <td>0.064805</td>\n",
       "      <td>0.014931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.068951</td>\n",
       "      <td>0.052175</td>\n",
       "      <td>0.055892</td>\n",
       "      <td>0.011742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.069929</td>\n",
       "      <td>0.040716</td>\n",
       "      <td>0.065988</td>\n",
       "      <td>0.031268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.070005</td>\n",
       "      <td>0.068037</td>\n",
       "      <td>0.096741</td>\n",
       "      <td>0.029396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.070768</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.077867</td>\n",
       "      <td>0.031434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.070768</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>0.077867</td>\n",
       "      <td>0.031434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.070914</td>\n",
       "      <td>0.053312</td>\n",
       "      <td>0.054823</td>\n",
       "      <td>0.010844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.071087</td>\n",
       "      <td>0.083845</td>\n",
       "      <td>0.084731</td>\n",
       "      <td>0.058616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.071745</td>\n",
       "      <td>0.049458</td>\n",
       "      <td>0.076229</td>\n",
       "      <td>0.029750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.074152</td>\n",
       "      <td>0.072926</td>\n",
       "      <td>0.099363</td>\n",
       "      <td>0.033313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.074345</td>\n",
       "      <td>0.050357</td>\n",
       "      <td>0.077827</td>\n",
       "      <td>0.021864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.045453</td>\n",
       "      <td>0.076272</td>\n",
       "      <td>0.023170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.076475</td>\n",
       "      <td>0.045453</td>\n",
       "      <td>0.076272</td>\n",
       "      <td>0.023170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.078677</td>\n",
       "      <td>0.042478</td>\n",
       "      <td>0.078637</td>\n",
       "      <td>0.036587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.079256</td>\n",
       "      <td>0.074093</td>\n",
       "      <td>0.102418</td>\n",
       "      <td>0.035967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.082495</td>\n",
       "      <td>0.087162</td>\n",
       "      <td>0.089206</td>\n",
       "      <td>0.064987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.085926</td>\n",
       "      <td>0.076002</td>\n",
       "      <td>0.105998</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.089813</td>\n",
       "      <td>0.089193</td>\n",
       "      <td>0.091769</td>\n",
       "      <td>0.068918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.090263</td>\n",
       "      <td>0.077462</td>\n",
       "      <td>0.107991</td>\n",
       "      <td>0.041925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.093342</td>\n",
       "      <td>0.054231</td>\n",
       "      <td>0.089314</td>\n",
       "      <td>0.038661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.095797</td>\n",
       "      <td>0.079543</td>\n",
       "      <td>0.110077</td>\n",
       "      <td>0.045043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.098802</td>\n",
       "      <td>0.091572</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>0.073433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.103602</td>\n",
       "      <td>0.082781</td>\n",
       "      <td>0.112151</td>\n",
       "      <td>0.049404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.110365</td>\n",
       "      <td>0.094463</td>\n",
       "      <td>0.099438</td>\n",
       "      <td>0.076903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.110691</td>\n",
       "      <td>0.060924</td>\n",
       "      <td>0.062856</td>\n",
       "      <td>0.033243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.121395</td>\n",
       "      <td>0.095632</td>\n",
       "      <td>0.110443</td>\n",
       "      <td>0.037948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.121395</td>\n",
       "      <td>0.095632</td>\n",
       "      <td>0.110443</td>\n",
       "      <td>0.037948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.130450</td>\n",
       "      <td>0.060032</td>\n",
       "      <td>0.084429</td>\n",
       "      <td>0.030736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.131933</td>\n",
       "      <td>0.101376</td>\n",
       "      <td>0.117507</td>\n",
       "      <td>0.041659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.131933</td>\n",
       "      <td>0.101376</td>\n",
       "      <td>0.117507</td>\n",
       "      <td>0.041659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.145241</td>\n",
       "      <td>0.101223</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>0.044153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.145241</td>\n",
       "      <td>0.101223</td>\n",
       "      <td>0.125992</td>\n",
       "      <td>0.044153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.147307</td>\n",
       "      <td>0.049306</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.033779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.147307</td>\n",
       "      <td>0.049306</td>\n",
       "      <td>0.073420</td>\n",
       "      <td>0.033779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.163133</td>\n",
       "      <td>0.101044</td>\n",
       "      <td>0.136459</td>\n",
       "      <td>0.048377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.163133</td>\n",
       "      <td>0.101044</td>\n",
       "      <td>0.136459</td>\n",
       "      <td>0.048377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.169132</td>\n",
       "      <td>0.069152</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.032946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.169132</td>\n",
       "      <td>0.069152</td>\n",
       "      <td>0.067387</td>\n",
       "      <td>0.032946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.175032</td>\n",
       "      <td>0.101044</td>\n",
       "      <td>0.142747</td>\n",
       "      <td>0.051430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.175032</td>\n",
       "      <td>0.101044</td>\n",
       "      <td>0.142747</td>\n",
       "      <td>0.051430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.190463</td>\n",
       "      <td>0.101290</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>0.055307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.190463</td>\n",
       "      <td>0.101290</td>\n",
       "      <td>0.150092</td>\n",
       "      <td>0.055307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.212568</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>0.060124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.212568</td>\n",
       "      <td>0.102224</td>\n",
       "      <td>0.159226</td>\n",
       "      <td>0.060124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.086381</td>\n",
       "      <td>0.086381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.031686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.194826</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.010759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.059079</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.002682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.011029072644280769, 0.05103383687350138, -0.10485951827373197, 0.037046924382313384, -0.38575629856163185]\n",
      "overall_score:\n",
      "-0.07830119658705366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.250385</td>\n",
       "      <td>0.053035</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.081511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.253106</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.289953</td>\n",
       "      <td>0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.253106</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.289953</td>\n",
       "      <td>0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.264384</td>\n",
       "      <td>0.061781</td>\n",
       "      <td>0.327677</td>\n",
       "      <td>0.069726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.267684</td>\n",
       "      <td>0.049697</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267684</td>\n",
       "      <td>0.049697</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.279107</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>0.339821</td>\n",
       "      <td>0.050708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.279376</td>\n",
       "      <td>0.066624</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.043856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.279376</td>\n",
       "      <td>0.066624</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.043856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281872</td>\n",
       "      <td>0.081962</td>\n",
       "      <td>0.257870</td>\n",
       "      <td>0.092071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.283315</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>0.357960</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.284202</td>\n",
       "      <td>0.067280</td>\n",
       "      <td>0.341063</td>\n",
       "      <td>0.046535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285404</td>\n",
       "      <td>0.072023</td>\n",
       "      <td>0.343528</td>\n",
       "      <td>0.049963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.286469</td>\n",
       "      <td>0.083171</td>\n",
       "      <td>0.350206</td>\n",
       "      <td>0.042443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.286801</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.348245</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.286801</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.348245</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.287008</td>\n",
       "      <td>0.078122</td>\n",
       "      <td>0.348216</td>\n",
       "      <td>0.043031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.288373</td>\n",
       "      <td>0.086073</td>\n",
       "      <td>0.348183</td>\n",
       "      <td>0.041424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.289511</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>0.322922</td>\n",
       "      <td>0.086736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290555</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.341598</td>\n",
       "      <td>0.087181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290663</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>0.095559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.291705</td>\n",
       "      <td>0.052861</td>\n",
       "      <td>0.326872</td>\n",
       "      <td>0.056337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.291741</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.353814</td>\n",
       "      <td>0.046674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.292240</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>0.352827</td>\n",
       "      <td>0.039541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.293070</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>0.346690</td>\n",
       "      <td>0.040574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293392</td>\n",
       "      <td>0.073605</td>\n",
       "      <td>0.352856</td>\n",
       "      <td>0.043913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.298844</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>0.345626</td>\n",
       "      <td>0.039949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299437</td>\n",
       "      <td>0.066993</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.036018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300071</td>\n",
       "      <td>0.070655</td>\n",
       "      <td>0.353187</td>\n",
       "      <td>0.037746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301186</td>\n",
       "      <td>0.094844</td>\n",
       "      <td>0.258220</td>\n",
       "      <td>0.092990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301434</td>\n",
       "      <td>0.071783</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.038996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301640</td>\n",
       "      <td>0.065566</td>\n",
       "      <td>0.350558</td>\n",
       "      <td>0.034295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.301688</td>\n",
       "      <td>0.034013</td>\n",
       "      <td>0.295086</td>\n",
       "      <td>0.058242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303563</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305983</td>\n",
       "      <td>0.067095</td>\n",
       "      <td>0.349222</td>\n",
       "      <td>0.035289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.311036</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>0.336489</td>\n",
       "      <td>0.038642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312155</td>\n",
       "      <td>0.058151</td>\n",
       "      <td>0.342988</td>\n",
       "      <td>0.043755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.314560</td>\n",
       "      <td>0.073926</td>\n",
       "      <td>0.334561</td>\n",
       "      <td>0.044023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.315396</td>\n",
       "      <td>0.098410</td>\n",
       "      <td>0.258818</td>\n",
       "      <td>0.089979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.318666</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.332368</td>\n",
       "      <td>0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324171</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.329467</td>\n",
       "      <td>0.052956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324518</td>\n",
       "      <td>0.099955</td>\n",
       "      <td>0.259418</td>\n",
       "      <td>0.088546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.325360</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.325360</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.326397</td>\n",
       "      <td>0.081598</td>\n",
       "      <td>0.375988</td>\n",
       "      <td>0.113371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.327817</td>\n",
       "      <td>0.072968</td>\n",
       "      <td>0.327884</td>\n",
       "      <td>0.055946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.330718</td>\n",
       "      <td>0.069918</td>\n",
       "      <td>0.328412</td>\n",
       "      <td>0.056157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.332245</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>0.326097</td>\n",
       "      <td>0.059363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.333225</td>\n",
       "      <td>0.074841</td>\n",
       "      <td>0.375473</td>\n",
       "      <td>0.112484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.335583</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>0.109870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.335583</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>0.109870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335657</td>\n",
       "      <td>0.101631</td>\n",
       "      <td>0.260564</td>\n",
       "      <td>0.087354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337336</td>\n",
       "      <td>0.130104</td>\n",
       "      <td>0.390732</td>\n",
       "      <td>0.043883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.337488</td>\n",
       "      <td>0.071748</td>\n",
       "      <td>0.324063</td>\n",
       "      <td>0.063663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.339295</td>\n",
       "      <td>0.130873</td>\n",
       "      <td>0.393410</td>\n",
       "      <td>0.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.342433</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>0.255656</td>\n",
       "      <td>0.073663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.344328</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>0.316097</td>\n",
       "      <td>0.060761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.347025</td>\n",
       "      <td>0.033794</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.079528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348129</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.305526</td>\n",
       "      <td>0.034893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350150</td>\n",
       "      <td>0.102973</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.085574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350708</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.302595</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.352324</td>\n",
       "      <td>0.035266</td>\n",
       "      <td>0.255594</td>\n",
       "      <td>0.081496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353707</td>\n",
       "      <td>0.039670</td>\n",
       "      <td>0.299160</td>\n",
       "      <td>0.028737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357318</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.295012</td>\n",
       "      <td>0.023589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.359366</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.083043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359466</td>\n",
       "      <td>0.039734</td>\n",
       "      <td>0.292563</td>\n",
       "      <td>0.020651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362008</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.289711</td>\n",
       "      <td>0.017463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.363831</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.216066</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.363831</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.216066</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.364414</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>0.255698</td>\n",
       "      <td>0.082776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365126</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.286342</td>\n",
       "      <td>0.014032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.371146</td>\n",
       "      <td>0.044645</td>\n",
       "      <td>0.256015</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374608</td>\n",
       "      <td>0.067666</td>\n",
       "      <td>0.337801</td>\n",
       "      <td>0.125979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.375624</td>\n",
       "      <td>0.123566</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>0.059611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376963</td>\n",
       "      <td>0.109118</td>\n",
       "      <td>0.300138</td>\n",
       "      <td>0.125292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.377514</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.377514</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378659</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>0.373034</td>\n",
       "      <td>0.062625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380412</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.256345</td>\n",
       "      <td>0.082113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390867</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.277128</td>\n",
       "      <td>0.148082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.394970</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.218784</td>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.394970</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.218784</td>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.406245</td>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.328546</td>\n",
       "      <td>0.131979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.417910</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.417910</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433097</td>\n",
       "      <td>0.085431</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.046248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433097</td>\n",
       "      <td>0.085431</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.046248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.443822</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.111131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.443822</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.111131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.452620</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452620</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.479704</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.053432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479704</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.053432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.490854</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.490854</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.382029</td>\n",
       "      <td>0.382029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.096467</td>\n",
       "      <td>0.096467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.050630</td>\n",
       "      <td>0.050630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.028504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.009089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.004410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.03840873739877326, 0.025163581636640342, 0.019087738607952764, -0.08514665604555738, -0.36320442525420504]\n",
      "overall_score:\n",
      "-0.07313820473127922\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.026209</td>\n",
       "      <td>0.047035</td>\n",
       "      <td>0.039634</td>\n",
       "      <td>0.017749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.019224</td>\n",
       "      <td>0.026598</td>\n",
       "      <td>0.036908</td>\n",
       "      <td>0.011509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.017992</td>\n",
       "      <td>0.064622</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>0.012993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>0.017992</td>\n",
       "      <td>0.064622</td>\n",
       "      <td>0.041173</td>\n",
       "      <td>0.012993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.014662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.016848</td>\n",
       "      <td>0.035819</td>\n",
       "      <td>0.037053</td>\n",
       "      <td>0.014662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.013008</td>\n",
       "      <td>0.023629</td>\n",
       "      <td>0.057356</td>\n",
       "      <td>0.018085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.011970</td>\n",
       "      <td>0.025777</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>0.018578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.014964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>0.010951</td>\n",
       "      <td>0.021868</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.014964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.010563</td>\n",
       "      <td>0.018074</td>\n",
       "      <td>0.027679</td>\n",
       "      <td>0.009081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.010452</td>\n",
       "      <td>0.026622</td>\n",
       "      <td>0.060753</td>\n",
       "      <td>0.017693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.008165</td>\n",
       "      <td>0.027630</td>\n",
       "      <td>0.063243</td>\n",
       "      <td>0.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.028206</td>\n",
       "      <td>0.064802</td>\n",
       "      <td>0.015768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.017017</td>\n",
       "      <td>0.030686</td>\n",
       "      <td>0.012003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.022145</td>\n",
       "      <td>0.035147</td>\n",
       "      <td>0.014424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.005760</td>\n",
       "      <td>0.015369</td>\n",
       "      <td>0.024392</td>\n",
       "      <td>0.009763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.025936</td>\n",
       "      <td>0.011708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.005730</td>\n",
       "      <td>0.015183</td>\n",
       "      <td>0.025936</td>\n",
       "      <td>0.011708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.005354</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.026123</td>\n",
       "      <td>0.011607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.004533</td>\n",
       "      <td>0.028833</td>\n",
       "      <td>0.066648</td>\n",
       "      <td>0.015047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.003722</td>\n",
       "      <td>0.019133</td>\n",
       "      <td>0.037031</td>\n",
       "      <td>0.014552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.042907</td>\n",
       "      <td>0.016059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.014206</td>\n",
       "      <td>0.020779</td>\n",
       "      <td>0.006459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001864</td>\n",
       "      <td>0.053897</td>\n",
       "      <td>0.046732</td>\n",
       "      <td>0.022767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>0.001844</td>\n",
       "      <td>0.029509</td>\n",
       "      <td>0.068866</td>\n",
       "      <td>0.014482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.000383</td>\n",
       "      <td>0.033226</td>\n",
       "      <td>0.041332</td>\n",
       "      <td>0.016481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003243</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003243</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.003243</td>\n",
       "      <td>0.011776</td>\n",
       "      <td>0.013896</td>\n",
       "      <td>0.005037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.003266</td>\n",
       "      <td>0.011775</td>\n",
       "      <td>0.013984</td>\n",
       "      <td>0.005032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.037056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.037056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.037056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.004251</td>\n",
       "      <td>0.015566</td>\n",
       "      <td>0.066705</td>\n",
       "      <td>0.037056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.006532</td>\n",
       "      <td>0.012533</td>\n",
       "      <td>0.012531</td>\n",
       "      <td>0.004500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.008241</td>\n",
       "      <td>0.073605</td>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.053231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.009299</td>\n",
       "      <td>0.032204</td>\n",
       "      <td>0.054977</td>\n",
       "      <td>0.024766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.009572</td>\n",
       "      <td>0.026485</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.020345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014225</td>\n",
       "      <td>0.080573</td>\n",
       "      <td>0.078421</td>\n",
       "      <td>0.060245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.014485</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.007694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014485</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.007694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014485</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.007694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014485</td>\n",
       "      <td>0.009624</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.007694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.014608</td>\n",
       "      <td>0.046410</td>\n",
       "      <td>0.057691</td>\n",
       "      <td>0.030406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016448</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>0.010542</td>\n",
       "      <td>0.008205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.018724</td>\n",
       "      <td>0.051364</td>\n",
       "      <td>0.063670</td>\n",
       "      <td>0.029417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018946</td>\n",
       "      <td>0.012286</td>\n",
       "      <td>0.012353</td>\n",
       "      <td>0.007926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019097</td>\n",
       "      <td>0.016909</td>\n",
       "      <td>0.018135</td>\n",
       "      <td>0.007590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019402</td>\n",
       "      <td>0.019602</td>\n",
       "      <td>0.022342</td>\n",
       "      <td>0.008830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.020359</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010693</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020395</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.009333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020534</td>\n",
       "      <td>0.011245</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.010047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020618</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>0.010687</td>\n",
       "      <td>0.009306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.021893</td>\n",
       "      <td>0.083607</td>\n",
       "      <td>0.082650</td>\n",
       "      <td>0.064601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.022735</td>\n",
       "      <td>0.023536</td>\n",
       "      <td>0.027605</td>\n",
       "      <td>0.012073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.031741</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.030856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.031741</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.030856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.031741</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.030856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.030238</td>\n",
       "      <td>0.031741</td>\n",
       "      <td>0.047731</td>\n",
       "      <td>0.030856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.032191</td>\n",
       "      <td>0.087384</td>\n",
       "      <td>0.087953</td>\n",
       "      <td>0.069706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.034296</td>\n",
       "      <td>0.031945</td>\n",
       "      <td>0.039071</td>\n",
       "      <td>0.013535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.035034</td>\n",
       "      <td>0.072467</td>\n",
       "      <td>0.096520</td>\n",
       "      <td>0.015013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035318</td>\n",
       "      <td>0.018175</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035318</td>\n",
       "      <td>0.018175</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035318</td>\n",
       "      <td>0.018175</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.035318</td>\n",
       "      <td>0.018175</td>\n",
       "      <td>0.041280</td>\n",
       "      <td>0.015801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.038628</td>\n",
       "      <td>0.077633</td>\n",
       "      <td>0.099013</td>\n",
       "      <td>0.016550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.038878</td>\n",
       "      <td>0.089668</td>\n",
       "      <td>0.091152</td>\n",
       "      <td>0.072627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.042272</td>\n",
       "      <td>0.034748</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.030867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.043103</td>\n",
       "      <td>0.078762</td>\n",
       "      <td>0.101910</td>\n",
       "      <td>0.017301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.043489</td>\n",
       "      <td>0.037325</td>\n",
       "      <td>0.063512</td>\n",
       "      <td>0.028416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.043489</td>\n",
       "      <td>0.037325</td>\n",
       "      <td>0.063512</td>\n",
       "      <td>0.028416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.044954</td>\n",
       "      <td>0.025325</td>\n",
       "      <td>0.051999</td>\n",
       "      <td>0.025206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.045148</td>\n",
       "      <td>0.040683</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>0.022624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.045148</td>\n",
       "      <td>0.040683</td>\n",
       "      <td>0.068510</td>\n",
       "      <td>0.022624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.047160</td>\n",
       "      <td>0.092344</td>\n",
       "      <td>0.094861</td>\n",
       "      <td>0.075833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.048748</td>\n",
       "      <td>0.039966</td>\n",
       "      <td>0.060459</td>\n",
       "      <td>0.028329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.049032</td>\n",
       "      <td>0.080543</td>\n",
       "      <td>0.105297</td>\n",
       "      <td>0.018360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.049833</td>\n",
       "      <td>0.038424</td>\n",
       "      <td>0.062102</td>\n",
       "      <td>0.025853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.018485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.018485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.018485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.050438</td>\n",
       "      <td>0.022850</td>\n",
       "      <td>0.050157</td>\n",
       "      <td>0.018485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.051339</td>\n",
       "      <td>0.047286</td>\n",
       "      <td>0.073428</td>\n",
       "      <td>0.021225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.052932</td>\n",
       "      <td>0.081880</td>\n",
       "      <td>0.107169</td>\n",
       "      <td>0.019166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.057893</td>\n",
       "      <td>0.095647</td>\n",
       "      <td>0.099382</td>\n",
       "      <td>0.079222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.057952</td>\n",
       "      <td>0.083770</td>\n",
       "      <td>0.109082</td>\n",
       "      <td>0.020397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.058191</td>\n",
       "      <td>0.057293</td>\n",
       "      <td>0.063704</td>\n",
       "      <td>0.019245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.058504</td>\n",
       "      <td>0.061202</td>\n",
       "      <td>0.064239</td>\n",
       "      <td>0.020864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.058884</td>\n",
       "      <td>0.061596</td>\n",
       "      <td>0.064749</td>\n",
       "      <td>0.021208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.059362</td>\n",
       "      <td>0.061914</td>\n",
       "      <td>0.065198</td>\n",
       "      <td>0.021365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.059651</td>\n",
       "      <td>0.062026</td>\n",
       "      <td>0.065383</td>\n",
       "      <td>0.021336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.059983</td>\n",
       "      <td>0.062094</td>\n",
       "      <td>0.065524</td>\n",
       "      <td>0.021209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.060220</td>\n",
       "      <td>0.035394</td>\n",
       "      <td>0.082473</td>\n",
       "      <td>0.022523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.060361</td>\n",
       "      <td>0.062097</td>\n",
       "      <td>0.065595</td>\n",
       "      <td>0.020959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.061879</td>\n",
       "      <td>0.041103</td>\n",
       "      <td>0.082061</td>\n",
       "      <td>0.021390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.065085</td>\n",
       "      <td>0.086717</td>\n",
       "      <td>0.110772</td>\n",
       "      <td>0.022587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.067579</td>\n",
       "      <td>0.095349</td>\n",
       "      <td>0.107255</td>\n",
       "      <td>0.038940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.067579</td>\n",
       "      <td>0.095349</td>\n",
       "      <td>0.107255</td>\n",
       "      <td>0.038940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.069389</td>\n",
       "      <td>0.036042</td>\n",
       "      <td>0.069496</td>\n",
       "      <td>0.043971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.074364</td>\n",
       "      <td>0.041989</td>\n",
       "      <td>0.073474</td>\n",
       "      <td>0.032051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.074517</td>\n",
       "      <td>0.036863</td>\n",
       "      <td>0.069633</td>\n",
       "      <td>0.047217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.077352</td>\n",
       "      <td>0.100913</td>\n",
       "      <td>0.114172</td>\n",
       "      <td>0.042691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.077352</td>\n",
       "      <td>0.100913</td>\n",
       "      <td>0.114172</td>\n",
       "      <td>0.042691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.079577</td>\n",
       "      <td>0.047468</td>\n",
       "      <td>0.075621</td>\n",
       "      <td>0.038445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.089744</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>0.122480</td>\n",
       "      <td>0.045170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.089744</td>\n",
       "      <td>0.100574</td>\n",
       "      <td>0.122480</td>\n",
       "      <td>0.045170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.106494</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.132718</td>\n",
       "      <td>0.049430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.106494</td>\n",
       "      <td>0.100175</td>\n",
       "      <td>0.132718</td>\n",
       "      <td>0.049430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.109091</td>\n",
       "      <td>0.037807</td>\n",
       "      <td>0.083928</td>\n",
       "      <td>0.034910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-0.110544</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>0.069971</td>\n",
       "      <td>0.036528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.110544</td>\n",
       "      <td>0.062465</td>\n",
       "      <td>0.069971</td>\n",
       "      <td>0.036528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.117690</td>\n",
       "      <td>0.100047</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0.052564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-0.117690</td>\n",
       "      <td>0.100047</td>\n",
       "      <td>0.138852</td>\n",
       "      <td>0.052564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.123660</td>\n",
       "      <td>0.069247</td>\n",
       "      <td>0.065601</td>\n",
       "      <td>0.037777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.123660</td>\n",
       "      <td>0.069247</td>\n",
       "      <td>0.065601</td>\n",
       "      <td>0.037777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.129213</td>\n",
       "      <td>0.035404</td>\n",
       "      <td>0.077727</td>\n",
       "      <td>0.031105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.132279</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.145987</td>\n",
       "      <td>0.056636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.132279</td>\n",
       "      <td>0.100149</td>\n",
       "      <td>0.145987</td>\n",
       "      <td>0.056636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.153306</td>\n",
       "      <td>0.100926</td>\n",
       "      <td>0.154786</td>\n",
       "      <td>0.061923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-0.153306</td>\n",
       "      <td>0.100926</td>\n",
       "      <td>0.154786</td>\n",
       "      <td>0.061923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.341333</td>\n",
       "      <td>0.670922</td>\n",
       "      <td>0.670922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.260258</td>\n",
       "      <td>0.208286</td>\n",
       "      <td>0.208286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>0.102452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.544510</td>\n",
       "      <td>0.031210</td>\n",
       "      <td>0.031210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.232784</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.009447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.005210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.182961</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.085507</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.341</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x1822efeb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.02522862129908343, 0.025163581636640342, -0.07364967084625151, -0.21854703231558892, -0.36320442525420504]\n",
      "overall_score:\n",
      "-0.12100178509606434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.285414</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.298713</td>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.285414</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.298713</td>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300585</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.319323</td>\n",
       "      <td>0.067024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304495</td>\n",
       "      <td>0.120749</td>\n",
       "      <td>0.276454</td>\n",
       "      <td>0.067585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.311944</td>\n",
       "      <td>0.131912</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.070760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321352</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0.276253</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.324230</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.324230</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327913</td>\n",
       "      <td>0.067239</td>\n",
       "      <td>0.341078</td>\n",
       "      <td>0.061043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334452</td>\n",
       "      <td>0.140091</td>\n",
       "      <td>0.276935</td>\n",
       "      <td>0.070247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.337538</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.368947</td>\n",
       "      <td>0.077641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.342223</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.368398</td>\n",
       "      <td>0.076590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343175</td>\n",
       "      <td>0.142158</td>\n",
       "      <td>0.278188</td>\n",
       "      <td>0.070289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.344851</td>\n",
       "      <td>0.061754</td>\n",
       "      <td>0.337880</td>\n",
       "      <td>0.033026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.345440</td>\n",
       "      <td>0.064166</td>\n",
       "      <td>0.334902</td>\n",
       "      <td>0.036291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.347131</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>0.331073</td>\n",
       "      <td>0.037787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.348110</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.355173</td>\n",
       "      <td>0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.348110</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.355173</td>\n",
       "      <td>0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.349669</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.326368</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350318</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.349656</td>\n",
       "      <td>0.046702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.351702</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.323294</td>\n",
       "      <td>0.041930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353826</td>\n",
       "      <td>0.144244</td>\n",
       "      <td>0.280347</td>\n",
       "      <td>0.070758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.354124</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.312422</td>\n",
       "      <td>0.057298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.354698</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.319875</td>\n",
       "      <td>0.043896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355962</td>\n",
       "      <td>0.119837</td>\n",
       "      <td>0.348240</td>\n",
       "      <td>0.090726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.358862</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.315860</td>\n",
       "      <td>0.047020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359631</td>\n",
       "      <td>0.113483</td>\n",
       "      <td>0.344839</td>\n",
       "      <td>0.073175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.359868</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.354737</td>\n",
       "      <td>0.043573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.363585</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.363585</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.364220</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.364533</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.037108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.365554</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.365554</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.366133</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.359814</td>\n",
       "      <td>0.038225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367200</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>0.284069</td>\n",
       "      <td>0.071861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.368016</td>\n",
       "      <td>0.092195</td>\n",
       "      <td>0.359188</td>\n",
       "      <td>0.035592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.368472</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.336913</td>\n",
       "      <td>0.056795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370383</td>\n",
       "      <td>0.078174</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>0.045049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.370514</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.363814</td>\n",
       "      <td>0.041289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.372614</td>\n",
       "      <td>0.092474</td>\n",
       "      <td>0.358390</td>\n",
       "      <td>0.036465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.372665</td>\n",
       "      <td>0.086650</td>\n",
       "      <td>0.358909</td>\n",
       "      <td>0.029829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374045</td>\n",
       "      <td>0.070226</td>\n",
       "      <td>0.333590</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374292</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.388962</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.374292</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.388962</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.376441</td>\n",
       "      <td>0.043951</td>\n",
       "      <td>0.256594</td>\n",
       "      <td>0.071256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.378945</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>0.221267</td>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.378945</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>0.221267</td>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.379681</td>\n",
       "      <td>0.097342</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.148586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.379681</td>\n",
       "      <td>0.097342</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.148586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380595</td>\n",
       "      <td>0.047816</td>\n",
       "      <td>0.255355</td>\n",
       "      <td>0.079440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383012</td>\n",
       "      <td>0.075569</td>\n",
       "      <td>0.359680</td>\n",
       "      <td>0.041392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385123</td>\n",
       "      <td>0.072903</td>\n",
       "      <td>0.359459</td>\n",
       "      <td>0.039081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.385716</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.254623</td>\n",
       "      <td>0.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.386045</td>\n",
       "      <td>0.070844</td>\n",
       "      <td>0.354320</td>\n",
       "      <td>0.037626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.387811</td>\n",
       "      <td>0.068986</td>\n",
       "      <td>0.350749</td>\n",
       "      <td>0.038258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.388910</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.318575</td>\n",
       "      <td>0.074520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389411</td>\n",
       "      <td>0.076709</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.038957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390217</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.357353</td>\n",
       "      <td>0.035709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.392408</td>\n",
       "      <td>0.051154</td>\n",
       "      <td>0.253489</td>\n",
       "      <td>0.088712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393555</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.346417</td>\n",
       "      <td>0.040194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.395240</td>\n",
       "      <td>0.083594</td>\n",
       "      <td>0.401948</td>\n",
       "      <td>0.154185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.395730</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>0.044928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.395730</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>0.044928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.397175</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.251956</td>\n",
       "      <td>0.090524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.400629</td>\n",
       "      <td>0.076749</td>\n",
       "      <td>0.399760</td>\n",
       "      <td>0.154282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.403833</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>0.250554</td>\n",
       "      <td>0.092793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.405266</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.037445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.413535</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.095563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.418534</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.418534</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424915</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>0.300880</td>\n",
       "      <td>0.027111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.425065</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>0.028502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.425614</td>\n",
       "      <td>0.050878</td>\n",
       "      <td>0.300536</td>\n",
       "      <td>0.028191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.427059</td>\n",
       "      <td>0.051088</td>\n",
       "      <td>0.300229</td>\n",
       "      <td>0.028005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.428107</td>\n",
       "      <td>0.051122</td>\n",
       "      <td>0.300102</td>\n",
       "      <td>0.027869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429290</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>0.299920</td>\n",
       "      <td>0.027793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.430592</td>\n",
       "      <td>0.050967</td>\n",
       "      <td>0.299757</td>\n",
       "      <td>0.027724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433229</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.228778</td>\n",
       "      <td>0.045213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433229</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.228778</td>\n",
       "      <td>0.045213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.435098</td>\n",
       "      <td>0.093692</td>\n",
       "      <td>0.363372</td>\n",
       "      <td>0.072388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.436364</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.073816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.450775</td>\n",
       "      <td>0.098792</td>\n",
       "      <td>0.375888</td>\n",
       "      <td>0.155372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.462844</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.368592</td>\n",
       "      <td>0.074591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466339</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>0.284734</td>\n",
       "      <td>0.118238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.469952</td>\n",
       "      <td>0.089226</td>\n",
       "      <td>0.372521</td>\n",
       "      <td>0.075975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.470453</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.470453</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.471184</td>\n",
       "      <td>0.110872</td>\n",
       "      <td>0.266708</td>\n",
       "      <td>0.127714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.479305</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.053128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479305</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.053128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.484671</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>0.356781</td>\n",
       "      <td>0.151985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.493742</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.366265</td>\n",
       "      <td>0.163585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x1822efeb0&gt;}</th>\n",
       "      <td>-3.493742</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.366265</td>\n",
       "      <td>0.163585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.520835</td>\n",
       "      <td>0.280856</td>\n",
       "      <td>0.280856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.053674</td>\n",
       "      <td>0.053674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>0.521283</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.037669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.454181</td>\n",
       "      <td>0.030541</td>\n",
       "      <td>0.030541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.443326</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.030219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.452073</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.028686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.448212</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>0.331615</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.022058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.301765</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.017198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>-0.325563</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.262815</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.010228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.190043</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.005946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RS</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.003983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.118715</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.111035</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.138684</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.072272</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.036881</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.521</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.443</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.119</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.448</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_56060/3502319901.py:20: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    }
   ],
   "source": [
    "overall_scores = pd.DataFrame(columns=['n_features','effect_size', 'overall_score'])\n",
    "        \n",
    "        \n",
    "hypers = {\n",
    "    'r2':do_hyperparameter_selection_loop_r2,\n",
    "    'mae':do_hyperparameter_selection_loop\n",
    "}\n",
    "for pcount in [10,15]:\n",
    "    for effect_size in [0.07,0.08,0.10]:\n",
    "        for ho in ['r2','mae']:\n",
    "            overall_score = run_full_limited_predictor_analysis(\n",
    "                pcount,\n",
    "                outcome_measures,\n",
    "                analysis_data_imputed,\n",
    "                effect_size= effect_size,\n",
    "                hyperparameter_optimizer = hypers[ho]\n",
    "                )\n",
    "\n",
    "            #run the analysis with a limited number of predictors\n",
    "            overall_scores = overall_scores.append(\n",
    "                {'n_features':pcount,\n",
    "                'effect_size':effect_size,\n",
    "                'overall_score':overall_score,\n",
    "                'hyper_target':ho},\n",
    "                ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>overall_score</th>\n",
       "      <th>hyper_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.048384</td>\n",
       "      <td>r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.046887</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.089049</td>\n",
       "      <td>r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.083980</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.035533</td>\n",
       "      <td>r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.048563</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.045498</td>\n",
       "      <td>r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.104665</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.046213</td>\n",
       "      <td>r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.078301</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.073138</td>\n",
       "      <td>r2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.121002</td>\n",
       "      <td>mae</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  effect_size  overall_score hyper_target\n",
       "0          10         0.07      -0.048384           r2\n",
       "1          10         0.07      -0.046887          mae\n",
       "2          10         0.08      -0.089049           r2\n",
       "3          10         0.08      -0.083980          mae\n",
       "4          10         0.10      -0.035533           r2\n",
       "5          10         0.10      -0.048563          mae\n",
       "6          15         0.07      -0.045498           r2\n",
       "7          15         0.07      -0.104665          mae\n",
       "8          15         0.08      -0.046213           r2\n",
       "9          15         0.08      -0.078301          mae\n",
       "10         15         0.10      -0.073138           r2\n",
       "11         15         0.10      -0.121002          mae"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014247d405695287815678bf9349a8dffb2674e9fe9a5bd4bb9820af018d638d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
