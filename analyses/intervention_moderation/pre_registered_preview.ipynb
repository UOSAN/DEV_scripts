{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-2.local\n",
      "{'dropbox_data_dir': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/'}\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from socket import gethostname\n",
    "import numpy as np\n",
    "from dev_interaction_util import generate_synthetic_dev_outcomes, generate_synthetic_dev_data\n",
    "from ml_util import *\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "with open('config.yml') as f:\n",
    "    all_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "    if gethostname() in all_yaml.keys():\n",
    "        config = all_yaml[gethostname()]\n",
    "    else:\n",
    "        config = all_yaml['default']\n",
    "        \n",
    "print(config)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This is a pre-registered analysis for measuring moderations of the intervention.\n",
    "\n",
    "We'll cross-validate the intervention moderations.\n",
    "\n",
    "For this analysis, we'll try to make predictions based on some synthetic data. we'll take wave 1 data and randomly mix in changes based on our predictors, then try to model how we would predict those things. Finally, we'll make the predictions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_by_ppt_path = dropbox_data_dir + '/data_by_ppt.csv'\n",
    "data_codebook_path = dropbox_data_dir + 'data_codebook.csv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_by_ppt = pd.read_csv(data_by_ppt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_codebook = pd.read_csv(data_codebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find out which columns in data_by_ppt are missing from the codebook\n",
    "data_by_ppt.columns.difference(data_codebook['VarName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#copy our outcome measures, bf_1 and FFQ_1, into a new dataframe\n",
    "data_by_ppt['bf_2'] = data_by_ppt.bf_1\n",
    "#need to decide what sort of FFQ we want to use\n",
    "data_by_ppt['cancer_promoting_minus_preventing_FFQ_1'] = data_by_ppt.cancer_promoting_minus_preventing_FFQ\n",
    "data_by_ppt['cancer_promoting_minus_preventing_FFQ_2'] = data_by_ppt.cancer_promoting_minus_preventing_FFQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data  = data_by_ppt.loc[:,data_codebook.loc[data_codebook.IsSelectedPredictor,\"VarName\"]].copy()\n",
    "outcome_measures = data_by_ppt.loc[:,data_codebook.loc[data_codebook.IsSelectedOutcomeMeasure,\"VarName\"]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_values = pd.DataFrame(data_by_ppt.isna().sum())\n",
    "na_values.columns = ['NA_Count']\n",
    "na_values['prop_NA'] = na_values.NA_Count / data_by_ppt.shape[0]\n",
    "data_codebook = data_codebook.merge(na_values, left_on='VarName', right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_codebook.to_csv(dropbox_data_dir + 'data_metadata.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to count the number of valid and missing entries in each of our data predictors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting data to numeric format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_vals = pd.get_dummies(analysis_data.birthsex_factor)\n",
    "#there's only two variables here so we can convert this into a dummy variable\n",
    "analysis_data.drop(columns=['birthsex_factor'], inplace=True)\n",
    "one_hot_vals.columns = ['birthsex_factor_' + str(col) for col in one_hot_vals.columns]\n",
    "analysis_data = analysis_data.join(one_hot_vals.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSCS</th>\n",
       "      <th>EDM</th>\n",
       "      <th>BIS_11</th>\n",
       "      <th>PCS</th>\n",
       "      <th>RS</th>\n",
       "      <th>TRSQ</th>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <th>ACES_abuse</th>\n",
       "      <th>ACES_sum</th>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_median_income_acs</th>\n",
       "      <th>household_income_per_person</th>\n",
       "      <th>SST_prop_successful_stops</th>\n",
       "      <th>SST_GRTmean</th>\n",
       "      <th>SST_SSD</th>\n",
       "      <th>SST_PostErrorSlowW1_mean</th>\n",
       "      <th>SST_mean_ssrt_0</th>\n",
       "      <th>ROC_Crave_Regulate_Minus_Look</th>\n",
       "      <th>WTP_unhealthy_minus_healthy</th>\n",
       "      <th>birthsex_factor_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.538462</td>\n",
       "      <td>3.250</td>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5125</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.384615</td>\n",
       "      <td>1.750</td>\n",
       "      <td>89</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.384615</td>\n",
       "      <td>2.500</td>\n",
       "      <td>63</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>533.315052</td>\n",
       "      <td>284.375</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.247061</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.076923</td>\n",
       "      <td>2.800</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>498.167248</td>\n",
       "      <td>103.125</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>0.446583</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>0.170363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.307692</td>\n",
       "      <td>2.750</td>\n",
       "      <td>64</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>626.507764</td>\n",
       "      <td>250.000</td>\n",
       "      <td>0.105660</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>-1.5500</td>\n",
       "      <td>-0.494624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>3.461538</td>\n",
       "      <td>4.000</td>\n",
       "      <td>58</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690347</td>\n",
       "      <td>1.768485</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357362</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-1.008152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>3.692308</td>\n",
       "      <td>3.875</td>\n",
       "      <td>54</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511475</td>\n",
       "      <td>-0.234851</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335849</td>\n",
       "      <td>-0.1500</td>\n",
       "      <td>-1.889247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.125</td>\n",
       "      <td>69</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335248</td>\n",
       "      <td>0.099038</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.273736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.000</td>\n",
       "      <td>62</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855379</td>\n",
       "      <td>-0.234851</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401098</td>\n",
       "      <td>-0.9875</td>\n",
       "      <td>-0.151210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>3.230769</td>\n",
       "      <td>2.500</td>\n",
       "      <td>52</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834004</td>\n",
       "      <td>1.768485</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481932</td>\n",
       "      <td>-0.5500</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BSCS    EDM  BIS_11   PCS    RS  TRSQ  ACES_neglectful_parenting  \\\n",
       "0    2.538462  3.250      72   7.0  20.0  63.0                        NaN   \n",
       "1    2.384615  1.750      89   9.0  22.0  63.0                        NaN   \n",
       "2    3.384615  2.500      63   9.0  18.0  57.0                        NaN   \n",
       "3    3.076923  2.800      75   NaN   NaN  64.0                        NaN   \n",
       "4    3.307692  2.750      64  12.0  21.0  55.0                        NaN   \n",
       "..        ...    ...     ...   ...   ...   ...                        ...   \n",
       "270  3.461538  4.000      58  18.0  17.0  54.0                        0.0   \n",
       "271  3.692308  3.875      54  17.0  13.0  55.0                        2.0   \n",
       "272  3.461538  3.125      69  11.0  13.0  53.0                        1.0   \n",
       "273  2.846154  3.000      62  15.0  22.0  84.0                        0.0   \n",
       "274  3.230769  2.500      52   9.0  15.0  59.0                        0.0   \n",
       "\n",
       "     ACES_abuse  ACES_sum  ACES_divorced_separated  ...  \\\n",
       "0           NaN       NaN                      NaN  ...   \n",
       "1           NaN       NaN                      NaN  ...   \n",
       "2           NaN       NaN                      NaN  ...   \n",
       "3           NaN       NaN                      NaN  ...   \n",
       "4           NaN       NaN                      NaN  ...   \n",
       "..          ...       ...                      ...  ...   \n",
       "270         1.0       3.0                      1.0  ...   \n",
       "271         2.0       5.0                      0.0  ...   \n",
       "272         1.0       6.0                      1.0  ...   \n",
       "273         1.0       4.0                      1.0  ...   \n",
       "274         0.0       3.0                      1.0  ...   \n",
       "\n",
       "     zipcode_median_income_acs  household_income_per_person  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "..                         ...                          ...   \n",
       "270                  -0.690347                     1.768485   \n",
       "271                  -0.511475                    -0.234851   \n",
       "272                   1.335248                     0.099038   \n",
       "273                   0.855379                    -0.234851   \n",
       "274                   0.834004                     1.768485   \n",
       "\n",
       "     SST_prop_successful_stops  SST_GRTmean  SST_SSD  \\\n",
       "0                          NaN          NaN      NaN   \n",
       "1                          NaN          NaN      NaN   \n",
       "2                     0.500000   533.315052  284.375   \n",
       "3                     0.312500   498.167248  103.125   \n",
       "4                     0.562500   626.507764  250.000   \n",
       "..                         ...          ...      ...   \n",
       "270                   0.523438          NaN      NaN   \n",
       "271                   0.492188          NaN      NaN   \n",
       "272                   0.507812          NaN      NaN   \n",
       "273                   0.479167          NaN      NaN   \n",
       "274                   0.476562          NaN      NaN   \n",
       "\n",
       "     SST_PostErrorSlowW1_mean  SST_mean_ssrt_0  ROC_Crave_Regulate_Minus_Look  \\\n",
       "0                         NaN              NaN                        -0.5125   \n",
       "1                         NaN              NaN                            NaN   \n",
       "2                    0.058297         0.247061                        -0.8000   \n",
       "3                    0.027730         0.446583                        -0.8000   \n",
       "4                    0.105660         0.369308                        -1.5500   \n",
       "..                        ...              ...                            ...   \n",
       "270                       NaN         0.357362                        -0.0125   \n",
       "271                       NaN         0.335849                        -0.1500   \n",
       "272                       NaN         0.273736                            NaN   \n",
       "273                       NaN         0.401098                        -0.9875   \n",
       "274                       NaN         0.481932                        -0.5500   \n",
       "\n",
       "     WTP_unhealthy_minus_healthy  birthsex_factor_Male  \n",
       "0                      -0.312500                     1  \n",
       "1                       0.440524                     0  \n",
       "2                      -0.190476                     0  \n",
       "3                       0.170363                     0  \n",
       "4                      -0.494624                     0  \n",
       "..                           ...                   ...  \n",
       "270                    -1.008152                     1  \n",
       "271                    -1.889247                     1  \n",
       "272                     0.516129                     1  \n",
       "273                    -0.151210                     0  \n",
       "274                     0.343750                     1  \n",
       "\n",
       "[275 rows x 76 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data \n",
    "\n",
    "Apply missing data imputation to columns including cSES, ACES_sum, ses_aggregate, zipcode_median_income_acs, IMI, mcarthur social standing, based on demographic and self-report predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing with MICE\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn import linear_model\n",
    "\n",
    "#which columns do we want to exclude? \n",
    "# \n",
    "# Probably we can include all the columns in the codebook which aren't predictors.\n",
    "# I checked, and ACES, cSES, RTFS are the only columns over 20% missing, and I'm comfortable imputing those from other values.\n",
    "# Sitautions we might wnat to avoid imputing are where missingness is correlated with the predictor itself\n",
    "# that's the case for IPAQ probably, but we're avoiding IPAQ altogether for now.\n",
    "\n",
    "#analysis_data_imputed = analysis_data.loc[:,['ACES_sum','cSES']].copy()\n",
    "def get_data_for_imputation(analysis_data):\n",
    "    analysis_data_imputed = analysis_data.copy()\n",
    "    return(analysis_data_imputed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try a few methods of imputation and compare them.\n",
    "#I tried a few. the default is BayesianRidge, but i found this didn't pick up on the linear relationship between ACES and cSES\n",
    "#Ridge found the linear relationship, but also does some regularization which is probably useful for accuracy\n",
    "\n",
    "imputation_methods = {\n",
    "    \n",
    "    'knn_3':KNNImputer(n_neighbors=3),\n",
    "    'ridge_10':IterativeImputer(estimator=linear_model.Ridge(),n_nearest_features=10,max_iter=100),\n",
    "    'knn_4':KNNImputer(n_neighbors=4),\n",
    "    \n",
    "    'knn_6':KNNImputer(n_neighbors=6),\n",
    "    'ridge':IterativeImputer(estimator=linear_model.Ridge(),max_iter=100),\n",
    "    'ridge_5':IterativeImputer(estimator=linear_model.Ridge(),n_nearest_features=5,max_iter=100),\n",
    "    \n",
    "    'bayesianridge_3':IterativeImputer(estimator=linear_model.BayesianRidge(),max_iter=100,n_nearest_features=3)\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for imp_label in imputation_methods.keys():\n",
    "#     analysis_data_imputed = get_data_for_imputation(analysis_data)\n",
    "#     print(imp_label)\n",
    "#     imp = imputation_methods[imp_label]\n",
    "#     #this dataset is already filtered for columns so we don't need to filter those further.\n",
    "#     analysis_data_imputed = pd.DataFrame(imp.fit_transform(analysis_data_imputed), columns=analysis_data_imputed.columns)\n",
    "#     imputed_datapoint = analysis_data.isna()\n",
    "#     do_aces_cses_imputation_diagnostic(analysis_data_imputed, imputed_datapoint,imp_label)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this experiment, I'm going for Ridge regression with 10 nearest features. The values it imputes are a compromise between simply using the nearest mean, which is conservative when using these values for prediction because it doesn't introduce erroneous variance, but isn't very informative, and then using all available information, which Ridge regression with an unlimited number of features would do. It's a tough choice between this and KNN, which doesn't assume normality. Overall I'm going with KNN, because it picks up on relationships between the two variables while not generating extreme values like KNN seems to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSCS</th>\n",
       "      <th>EDM</th>\n",
       "      <th>BIS_11</th>\n",
       "      <th>PCS</th>\n",
       "      <th>RS</th>\n",
       "      <th>TRSQ</th>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <th>ACES_abuse</th>\n",
       "      <th>ACES_sum</th>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_median_income_acs</th>\n",
       "      <th>household_income_per_person</th>\n",
       "      <th>SST_prop_successful_stops</th>\n",
       "      <th>SST_GRTmean</th>\n",
       "      <th>SST_SSD</th>\n",
       "      <th>SST_PostErrorSlowW1_mean</th>\n",
       "      <th>SST_mean_ssrt_0</th>\n",
       "      <th>ROC_Crave_Regulate_Minus_Look</th>\n",
       "      <th>WTP_unhealthy_minus_healthy</th>\n",
       "      <th>birthsex_factor_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.538462</td>\n",
       "      <td>3.250</td>\n",
       "      <td>72</td>\n",
       "      <td>7.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.5125</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.384615</td>\n",
       "      <td>1.750</td>\n",
       "      <td>89</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.440524</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.384615</td>\n",
       "      <td>2.500</td>\n",
       "      <td>63</td>\n",
       "      <td>9.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>533.315052</td>\n",
       "      <td>284.375</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.247061</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.076923</td>\n",
       "      <td>2.800</td>\n",
       "      <td>75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>498.167248</td>\n",
       "      <td>103.125</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>0.446583</td>\n",
       "      <td>-0.8000</td>\n",
       "      <td>0.170363</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.307692</td>\n",
       "      <td>2.750</td>\n",
       "      <td>64</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>626.507764</td>\n",
       "      <td>250.000</td>\n",
       "      <td>0.105660</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>-1.5500</td>\n",
       "      <td>-0.494624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>3.461538</td>\n",
       "      <td>4.000</td>\n",
       "      <td>58</td>\n",
       "      <td>18.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690347</td>\n",
       "      <td>1.768485</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.357362</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-1.008152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>3.692308</td>\n",
       "      <td>3.875</td>\n",
       "      <td>54</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511475</td>\n",
       "      <td>-0.234851</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335849</td>\n",
       "      <td>-0.1500</td>\n",
       "      <td>-1.889247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.125</td>\n",
       "      <td>69</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335248</td>\n",
       "      <td>0.099038</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.273736</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.000</td>\n",
       "      <td>62</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855379</td>\n",
       "      <td>-0.234851</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.401098</td>\n",
       "      <td>-0.9875</td>\n",
       "      <td>-0.151210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>3.230769</td>\n",
       "      <td>2.500</td>\n",
       "      <td>52</td>\n",
       "      <td>9.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834004</td>\n",
       "      <td>1.768485</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.481932</td>\n",
       "      <td>-0.5500</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BSCS    EDM  BIS_11   PCS    RS  TRSQ  ACES_neglectful_parenting  \\\n",
       "0    2.538462  3.250      72   7.0  20.0  63.0                        NaN   \n",
       "1    2.384615  1.750      89   9.0  22.0  63.0                        NaN   \n",
       "2    3.384615  2.500      63   9.0  18.0  57.0                        NaN   \n",
       "3    3.076923  2.800      75   NaN   NaN  64.0                        NaN   \n",
       "4    3.307692  2.750      64  12.0  21.0  55.0                        NaN   \n",
       "..        ...    ...     ...   ...   ...   ...                        ...   \n",
       "270  3.461538  4.000      58  18.0  17.0  54.0                        0.0   \n",
       "271  3.692308  3.875      54  17.0  13.0  55.0                        2.0   \n",
       "272  3.461538  3.125      69  11.0  13.0  53.0                        1.0   \n",
       "273  2.846154  3.000      62  15.0  22.0  84.0                        0.0   \n",
       "274  3.230769  2.500      52   9.0  15.0  59.0                        0.0   \n",
       "\n",
       "     ACES_abuse  ACES_sum  ACES_divorced_separated  ...  \\\n",
       "0           NaN       NaN                      NaN  ...   \n",
       "1           NaN       NaN                      NaN  ...   \n",
       "2           NaN       NaN                      NaN  ...   \n",
       "3           NaN       NaN                      NaN  ...   \n",
       "4           NaN       NaN                      NaN  ...   \n",
       "..          ...       ...                      ...  ...   \n",
       "270         1.0       3.0                      1.0  ...   \n",
       "271         2.0       5.0                      0.0  ...   \n",
       "272         1.0       6.0                      1.0  ...   \n",
       "273         1.0       4.0                      1.0  ...   \n",
       "274         0.0       3.0                      1.0  ...   \n",
       "\n",
       "     zipcode_median_income_acs  household_income_per_person  \\\n",
       "0                          NaN                          NaN   \n",
       "1                          NaN                          NaN   \n",
       "2                          NaN                          NaN   \n",
       "3                          NaN                          NaN   \n",
       "4                          NaN                          NaN   \n",
       "..                         ...                          ...   \n",
       "270                  -0.690347                     1.768485   \n",
       "271                  -0.511475                    -0.234851   \n",
       "272                   1.335248                     0.099038   \n",
       "273                   0.855379                    -0.234851   \n",
       "274                   0.834004                     1.768485   \n",
       "\n",
       "     SST_prop_successful_stops  SST_GRTmean  SST_SSD  \\\n",
       "0                          NaN          NaN      NaN   \n",
       "1                          NaN          NaN      NaN   \n",
       "2                     0.500000   533.315052  284.375   \n",
       "3                     0.312500   498.167248  103.125   \n",
       "4                     0.562500   626.507764  250.000   \n",
       "..                         ...          ...      ...   \n",
       "270                   0.523438          NaN      NaN   \n",
       "271                   0.492188          NaN      NaN   \n",
       "272                   0.507812          NaN      NaN   \n",
       "273                   0.479167          NaN      NaN   \n",
       "274                   0.476562          NaN      NaN   \n",
       "\n",
       "     SST_PostErrorSlowW1_mean  SST_mean_ssrt_0  ROC_Crave_Regulate_Minus_Look  \\\n",
       "0                         NaN              NaN                        -0.5125   \n",
       "1                         NaN              NaN                            NaN   \n",
       "2                    0.058297         0.247061                        -0.8000   \n",
       "3                    0.027730         0.446583                        -0.8000   \n",
       "4                    0.105660         0.369308                        -1.5500   \n",
       "..                        ...              ...                            ...   \n",
       "270                       NaN         0.357362                        -0.0125   \n",
       "271                       NaN         0.335849                        -0.1500   \n",
       "272                       NaN         0.273736                            NaN   \n",
       "273                       NaN         0.401098                        -0.9875   \n",
       "274                       NaN         0.481932                        -0.5500   \n",
       "\n",
       "     WTP_unhealthy_minus_healthy  birthsex_factor_Male  \n",
       "0                      -0.312500                     1  \n",
       "1                       0.440524                     0  \n",
       "2                      -0.190476                     0  \n",
       "3                       0.170363                     0  \n",
       "4                      -0.494624                     0  \n",
       "..                           ...                   ...  \n",
       "270                    -1.008152                     1  \n",
       "271                    -1.889247                     1  \n",
       "272                     0.516129                     1  \n",
       "273                    -0.151210                     0  \n",
       "274                     0.343750                     1  \n",
       "\n",
       "[275 rows x 76 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/impute/_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "imputer = IterativeImputer(estimator=linear_model.Ridge(),n_nearest_features=10,max_iter=100,random_state=0)\n",
    "analysis_data_imputed = get_data_for_imputation(analysis_data)\n",
    "\n",
    "#this dataset is already filtered for columns so we don't need to filter those further.\n",
    "analysis_data_imputed = pd.DataFrame(imputer.fit_transform(analysis_data_imputed), columns=analysis_data_imputed.columns)\n",
    "imputed_datapoint = analysis_data.isna()\n",
    "# do_aces_cses_imputation_diagnostic(analysis_data_imputed, imputed_datapoint,'ridge_10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BSCS</th>\n",
       "      <th>EDM</th>\n",
       "      <th>BIS_11</th>\n",
       "      <th>PCS</th>\n",
       "      <th>RS</th>\n",
       "      <th>TRSQ</th>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <th>ACES_abuse</th>\n",
       "      <th>ACES_sum</th>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <th>...</th>\n",
       "      <th>zipcode_median_income_acs</th>\n",
       "      <th>household_income_per_person</th>\n",
       "      <th>SST_prop_successful_stops</th>\n",
       "      <th>SST_GRTmean</th>\n",
       "      <th>SST_SSD</th>\n",
       "      <th>SST_PostErrorSlowW1_mean</th>\n",
       "      <th>SST_mean_ssrt_0</th>\n",
       "      <th>ROC_Crave_Regulate_Minus_Look</th>\n",
       "      <th>WTP_unhealthy_minus_healthy</th>\n",
       "      <th>birthsex_factor_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.538462</td>\n",
       "      <td>3.250</td>\n",
       "      <td>72.0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.317872</td>\n",
       "      <td>0.661088</td>\n",
       "      <td>2.377413</td>\n",
       "      <td>0.524304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404760</td>\n",
       "      <td>-0.191422</td>\n",
       "      <td>0.484371</td>\n",
       "      <td>562.923974</td>\n",
       "      <td>248.939281</td>\n",
       "      <td>0.045181</td>\n",
       "      <td>0.342462</td>\n",
       "      <td>-0.512500</td>\n",
       "      <td>-0.312500</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.384615</td>\n",
       "      <td>1.750</td>\n",
       "      <td>89.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.410249</td>\n",
       "      <td>0.519489</td>\n",
       "      <td>2.033396</td>\n",
       "      <td>0.503125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304016</td>\n",
       "      <td>0.480210</td>\n",
       "      <td>0.553755</td>\n",
       "      <td>694.937485</td>\n",
       "      <td>381.484974</td>\n",
       "      <td>0.058525</td>\n",
       "      <td>0.263203</td>\n",
       "      <td>-0.796734</td>\n",
       "      <td>0.440524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.384615</td>\n",
       "      <td>2.500</td>\n",
       "      <td>63.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.594894</td>\n",
       "      <td>1.085837</td>\n",
       "      <td>3.163201</td>\n",
       "      <td>0.577384</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578832</td>\n",
       "      <td>-0.365323</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>533.315052</td>\n",
       "      <td>284.375000</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>0.247061</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>-0.190476</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.076923</td>\n",
       "      <td>2.800</td>\n",
       "      <td>75.0</td>\n",
       "      <td>11.344625</td>\n",
       "      <td>17.617698</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.262608</td>\n",
       "      <td>0.646088</td>\n",
       "      <td>1.793320</td>\n",
       "      <td>0.563715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.327618</td>\n",
       "      <td>-0.068923</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>498.167248</td>\n",
       "      <td>103.125000</td>\n",
       "      <td>0.027730</td>\n",
       "      <td>0.446583</td>\n",
       "      <td>-0.800000</td>\n",
       "      <td>0.170363</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.307692</td>\n",
       "      <td>2.750</td>\n",
       "      <td>64.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.443790</td>\n",
       "      <td>0.714933</td>\n",
       "      <td>2.528502</td>\n",
       "      <td>0.631102</td>\n",
       "      <td>...</td>\n",
       "      <td>0.230123</td>\n",
       "      <td>-0.050786</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>626.507764</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.105660</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>-1.550000</td>\n",
       "      <td>-0.494624</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>3.461538</td>\n",
       "      <td>4.000</td>\n",
       "      <td>58.0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.690347</td>\n",
       "      <td>1.768485</td>\n",
       "      <td>0.523438</td>\n",
       "      <td>564.326545</td>\n",
       "      <td>247.685788</td>\n",
       "      <td>0.074503</td>\n",
       "      <td>0.357362</td>\n",
       "      <td>-0.012500</td>\n",
       "      <td>-1.008152</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>3.692308</td>\n",
       "      <td>3.875</td>\n",
       "      <td>54.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.511475</td>\n",
       "      <td>-0.234851</td>\n",
       "      <td>0.492188</td>\n",
       "      <td>570.356523</td>\n",
       "      <td>242.446242</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>0.335849</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>-1.889247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>3.461538</td>\n",
       "      <td>3.125</td>\n",
       "      <td>69.0</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.335248</td>\n",
       "      <td>0.099038</td>\n",
       "      <td>0.507812</td>\n",
       "      <td>627.534668</td>\n",
       "      <td>330.803985</td>\n",
       "      <td>0.074095</td>\n",
       "      <td>0.273736</td>\n",
       "      <td>-0.877697</td>\n",
       "      <td>0.516129</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>2.846154</td>\n",
       "      <td>3.000</td>\n",
       "      <td>62.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.855379</td>\n",
       "      <td>-0.234851</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>498.265901</td>\n",
       "      <td>160.923504</td>\n",
       "      <td>0.056039</td>\n",
       "      <td>0.401098</td>\n",
       "      <td>-0.987500</td>\n",
       "      <td>-0.151210</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>3.230769</td>\n",
       "      <td>2.500</td>\n",
       "      <td>52.0</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.834004</td>\n",
       "      <td>1.768485</td>\n",
       "      <td>0.476562</td>\n",
       "      <td>508.781817</td>\n",
       "      <td>147.817897</td>\n",
       "      <td>0.053503</td>\n",
       "      <td>0.481932</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>0.343750</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         BSCS    EDM  BIS_11        PCS         RS  TRSQ  \\\n",
       "0    2.538462  3.250    72.0   7.000000  20.000000  63.0   \n",
       "1    2.384615  1.750    89.0   9.000000  22.000000  63.0   \n",
       "2    3.384615  2.500    63.0   9.000000  18.000000  57.0   \n",
       "3    3.076923  2.800    75.0  11.344625  17.617698  64.0   \n",
       "4    3.307692  2.750    64.0  12.000000  21.000000  55.0   \n",
       "..        ...    ...     ...        ...        ...   ...   \n",
       "270  3.461538  4.000    58.0  18.000000  17.000000  54.0   \n",
       "271  3.692308  3.875    54.0  17.000000  13.000000  55.0   \n",
       "272  3.461538  3.125    69.0  11.000000  13.000000  53.0   \n",
       "273  2.846154  3.000    62.0  15.000000  22.000000  84.0   \n",
       "274  3.230769  2.500    52.0   9.000000  15.000000  59.0   \n",
       "\n",
       "     ACES_neglectful_parenting  ACES_abuse  ACES_sum  ACES_divorced_separated  \\\n",
       "0                     0.317872    0.661088  2.377413                 0.524304   \n",
       "1                     0.410249    0.519489  2.033396                 0.503125   \n",
       "2                     0.594894    1.085837  3.163201                 0.577384   \n",
       "3                     0.262608    0.646088  1.793320                 0.563715   \n",
       "4                     0.443790    0.714933  2.528502                 0.631102   \n",
       "..                         ...         ...       ...                      ...   \n",
       "270                   0.000000    1.000000  3.000000                 1.000000   \n",
       "271                   2.000000    2.000000  5.000000                 0.000000   \n",
       "272                   1.000000    1.000000  6.000000                 1.000000   \n",
       "273                   0.000000    1.000000  4.000000                 1.000000   \n",
       "274                   0.000000    0.000000  3.000000                 1.000000   \n",
       "\n",
       "     ...  zipcode_median_income_acs  household_income_per_person  \\\n",
       "0    ...                   0.404760                    -0.191422   \n",
       "1    ...                   0.304016                     0.480210   \n",
       "2    ...                   0.578832                    -0.365323   \n",
       "3    ...                   0.327618                    -0.068923   \n",
       "4    ...                   0.230123                    -0.050786   \n",
       "..   ...                        ...                          ...   \n",
       "270  ...                  -0.690347                     1.768485   \n",
       "271  ...                  -0.511475                    -0.234851   \n",
       "272  ...                   1.335248                     0.099038   \n",
       "273  ...                   0.855379                    -0.234851   \n",
       "274  ...                   0.834004                     1.768485   \n",
       "\n",
       "     SST_prop_successful_stops  SST_GRTmean     SST_SSD  \\\n",
       "0                     0.484371   562.923974  248.939281   \n",
       "1                     0.553755   694.937485  381.484974   \n",
       "2                     0.500000   533.315052  284.375000   \n",
       "3                     0.312500   498.167248  103.125000   \n",
       "4                     0.562500   626.507764  250.000000   \n",
       "..                         ...          ...         ...   \n",
       "270                   0.523438   564.326545  247.685788   \n",
       "271                   0.492188   570.356523  242.446242   \n",
       "272                   0.507812   627.534668  330.803985   \n",
       "273                   0.479167   498.265901  160.923504   \n",
       "274                   0.476562   508.781817  147.817897   \n",
       "\n",
       "     SST_PostErrorSlowW1_mean  SST_mean_ssrt_0  ROC_Crave_Regulate_Minus_Look  \\\n",
       "0                    0.045181         0.342462                      -0.512500   \n",
       "1                    0.058525         0.263203                      -0.796734   \n",
       "2                    0.058297         0.247061                      -0.800000   \n",
       "3                    0.027730         0.446583                      -0.800000   \n",
       "4                    0.105660         0.369308                      -1.550000   \n",
       "..                        ...              ...                            ...   \n",
       "270                  0.074503         0.357362                      -0.012500   \n",
       "271                  0.062163         0.335849                      -0.150000   \n",
       "272                  0.074095         0.273736                      -0.877697   \n",
       "273                  0.056039         0.401098                      -0.987500   \n",
       "274                  0.053503         0.481932                      -0.550000   \n",
       "\n",
       "     WTP_unhealthy_minus_healthy  birthsex_factor_Male  \n",
       "0                      -0.312500                   1.0  \n",
       "1                       0.440524                   0.0  \n",
       "2                      -0.190476                   0.0  \n",
       "3                       0.170363                   0.0  \n",
       "4                      -0.494624                   0.0  \n",
       "..                           ...                   ...  \n",
       "270                    -1.008152                   1.0  \n",
       "271                    -1.889247                   1.0  \n",
       "272                     0.516129                   1.0  \n",
       "273                    -0.151210                   0.0  \n",
       "274                     0.343750                   1.0  \n",
       "\n",
       "[275 rows x 76 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data_imputed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add synthetic data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## synthetic condition mediator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set np random seed\n",
    "np.random.seed(3161527)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['ichi','ni','san']\n",
    "#assign each row randomly to a group\n",
    "group_assignments = np.random.choice(group_names,analysis_data_imputed.shape[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## synthetic outcome variables\n",
    "\n",
    "Which variables will we test to predict? We need to select variables from the following groups:\n",
    "\n",
    " - self-report variables\n",
    " - demographic variables we'll test\n",
    " - summaries of neural activities from each of WTP, SST, and ROC\n",
    " - summaries of behavioral data from each of WTP, SST, and ROC\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_measures = generate_synthetic_dev_outcomes(outcome_measures)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add synthetic primary and interaction effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                                    feature_name  interaction_effect\n",
      "64                                        age365            1.208606\n",
      "2                                         BIS_11           -0.990043\n",
      "17                         IMI_effort_importance           -0.958636\n",
      "15                                  BFI_openness            0.949431\n",
      "40              NCS_satisfaction_in_deliberating            0.930933\n",
      "23                         NCS_intellectual_task           -0.930569\n",
      "31                            NCS_prefer_complex           -0.888134\n",
      "65                                 education_own           -0.874354\n",
      "20                          IMI_perceived_choice            0.799869\n",
      "60                              RTFS_f1_minus_f2            0.790402\n",
      "59                  SRHI_healthy_minus_unhealthy            0.626453\n",
      "57                                    TESQ_E_sum           -0.612132\n",
      "72                               SST_mean_ssrt_0            0.606104\n",
      "32                     NCS_prefer_little_thought           -0.605050\n",
      "1                                            EDM           -0.589600\n",
      "49                                  SRHI_healthy            0.584133\n",
      "61  cancer_promoting_minus_preventing_craved_FCI            0.555034\n",
      "47                                 RTFS_factor_1            0.547233\n",
      "36                         NCS_abstract_thinking            0.546582\n",
      "67                   household_income_per_person           -0.525581\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                        feature_name  interaction_effect\n",
      "21          IMI_perceived_competence           -1.634156\n",
      "12             BFI_conscientiousness           -1.135730\n",
      "70                           SST_SSD           -1.115029\n",
      "33       NCS_relief_not_satisfaction            0.886930\n",
      "45                    RMQ_assessment           -0.877257\n",
      "30               NCS_think_minimally            0.869242\n",
      "44                           RMQ_lie            0.866752\n",
      "40  NCS_satisfaction_in_deliberating           -0.824564\n",
      "66         zipcode_median_income_acs            0.784310\n",
      "20              IMI_perceived_choice            0.743981\n",
      "48                     RTFS_factor_2           -0.723901\n",
      "55      TESQ_E_goal_and_rule_setting            0.713090\n",
      "52    TESQ_E_controlling_temptations           -0.710659\n",
      "0                               BSCS           -0.676796\n",
      "39                 NCS_solve_puzzles           -0.675358\n",
      "11                 BFI_agreeableness            0.674328\n",
      "47                     RTFS_factor_1           -0.636170\n",
      "9            ACES_divorced_separated           -0.623386\n",
      "29             NCS_thought_appealing            0.622036\n",
      "67       household_income_per_person            0.612929\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "synthetic_data = generate_synthetic_dev_data(analysis_data_imputed, group_assignments,outcome_measures)\n",
    "interaction_effect_df = synthetic_data['X_weights']\n",
    "outcome_measures = synthetic_data['y']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further preprocessing\n",
    "\n",
    "These steps are performed on the data regardless of whether we are using synthetic data or real data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up outcome measures and group assignment one-hot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_measures = calculate_outcome_changes(outcome_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_assignment_onehots = pd.get_dummies(group_assignments).loc[:,['ni','san']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bf_1</th>\n",
       "      <th>bf_2</th>\n",
       "      <th>d_bf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33.0</td>\n",
       "      <td>121.373628</td>\n",
       "      <td>88.373628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>39.8</td>\n",
       "      <td>58.983743</td>\n",
       "      <td>19.183743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40.8</td>\n",
       "      <td>40.022751</td>\n",
       "      <td>-0.777249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>47.6</td>\n",
       "      <td>-33.046255</td>\n",
       "      <td>-80.646255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>29.9</td>\n",
       "      <td>31.240484</td>\n",
       "      <td>1.340484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>33.1</td>\n",
       "      <td>28.992403</td>\n",
       "      <td>-4.107597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>27.4</td>\n",
       "      <td>51.350718</td>\n",
       "      <td>23.950718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>42.1</td>\n",
       "      <td>64.553479</td>\n",
       "      <td>22.453479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>33.3</td>\n",
       "      <td>57.106888</td>\n",
       "      <td>23.806888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     bf_1        bf_2       d_bf\n",
       "0    33.0  121.373628  88.373628\n",
       "1     NaN         NaN        NaN\n",
       "2    39.8   58.983743  19.183743\n",
       "3    40.8   40.022751  -0.777249\n",
       "4    47.6  -33.046255 -80.646255\n",
       "..    ...         ...        ...\n",
       "270  29.9   31.240484   1.340484\n",
       "271  33.1   28.992403  -4.107597\n",
       "272  27.4   51.350718  23.950718\n",
       "273  42.1   64.553479  22.453479\n",
       "274  33.3   57.106888  23.806888\n",
       "\n",
       "[275 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_measures.loc[:,['bf_1','bf_2','d_bf']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 76)\n",
      "(275, 76)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictor_data = analysis_data_imputed\n",
    "predictor_data_columns = predictor_data.columns\n",
    "predictor_data_array = np.array(predictor_data)\n",
    "predictor_data = pd.concat([predictor_data,group_assignment_onehots],axis=1)\n",
    "for group_name in group_assignment_onehots.columns:\n",
    "\n",
    "    #do a matrix multiplication of the group assignment onehot with the analysis data\n",
    "    #repeat the group assignment onehot for each column in the analysis data\n",
    "    \n",
    "    interaction_array = predictor_data_array*np.array(group_assignment_onehots[group_name],ndmin=2).T\n",
    "    interaction_df = pd.DataFrame(interaction_array, columns= [(c + '*'+group_name) for c in predictor_data_columns])\n",
    "    print(interaction_df.shape)\n",
    "    #then add the result to the analysis data\n",
    "    predictor_data = pd.concat([predictor_data,interaction_df],axis=1)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove any NA values for this outcome measure in both the predictor data and the outcome data\n",
    "outcome_nas = outcome_measures['d_bf'].isna()\n",
    "\n",
    "outcome_measures_nona = outcome_measures.loc[~outcome_nas,:]\n",
    "predictor_data_nona = predictor_data.loc[~outcome_nas,:]\n",
    "group_assignment_onehots_nonan = group_assignment_onehots.loc[~outcome_nas,:]\n",
    "group_assignments_nona = group_assignments[~outcome_nas]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      88.373628\n",
       "2      19.183743\n",
       "3      -0.777249\n",
       "4     -80.646255\n",
       "6       0.827321\n",
       "         ...    \n",
       "270     1.340484\n",
       "271    -4.107597\n",
       "272    23.950718\n",
       "273    22.453479\n",
       "274    23.806888\n",
       "Name: d_bf, Length: 270, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcome_measures_nona['d_bf']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run a basic regression with interactions to ensure we can detect effects"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we want to know: which variables are correlated with the outcome measures? A naive way is to use ridge regression to predict the outcome measures from the predictors, with every predictor crossed with a one-hot of the group assignment. \n",
    "\n",
    "To do this, unlike in R where we'd write out an equation and let the system take care of it, here, I'll build the interactions manually."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do ridge regression to hopefully identify any predictors of outcome measures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>d_bf</td>       <th>  R-squared:         </th> <td>   0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   3.326</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Apr 2023</td> <th>  Prob (F-statistic):</th>  <td>0.00122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:26:32</td>     <th>  Log-Likelihood:    </th> <td> -1433.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   270</td>      <th>  AIC:               </th> <td>   2885.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   261</td>      <th>  BIC:               </th> <td>   2917.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>        <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>    <td>    1.7621</td> <td>   33.215</td> <td>    0.053</td> <td> 0.958</td> <td>  -63.641</td> <td>   67.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ni</th>       <td> -100.3524</td> <td>   47.064</td> <td>   -2.132</td> <td> 0.034</td> <td> -193.025</td> <td>   -7.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>san</th>      <td>  -20.2126</td> <td>   48.266</td> <td>   -0.419</td> <td> 0.676</td> <td> -115.252</td> <td>   74.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BSCS</th>     <td>   -1.3075</td> <td>    9.939</td> <td>   -0.132</td> <td> 0.895</td> <td>  -20.879</td> <td>   18.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDM</th>      <td>    0.6650</td> <td>    7.509</td> <td>    0.089</td> <td> 0.930</td> <td>  -14.122</td> <td>   15.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BSCS*ni</th>  <td>   22.3347</td> <td>   14.746</td> <td>    1.515</td> <td> 0.131</td> <td>   -6.702</td> <td>   51.371</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BSCS*san</th> <td>  -24.5239</td> <td>   15.266</td> <td>   -1.606</td> <td> 0.109</td> <td>  -54.583</td> <td>    5.536</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDM*ni</th>   <td>    8.6681</td> <td>   10.806</td> <td>    0.802</td> <td> 0.423</td> <td>  -12.609</td> <td>   29.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDM*san</th>  <td>   28.2973</td> <td>   10.734</td> <td>    2.636</td> <td> 0.009</td> <td>    7.162</td> <td>   49.433</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>31.657</td> <th>  Durbin-Watson:     </th> <td>   1.964</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td> 142.734</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.284</td> <th>  Prob(JB):          </th> <td>1.01e-31</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.516</td> <th>  Cond. No.          </th> <td>    115.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   d_bf   R-squared:                       0.093\n",
       "Model:                            OLS   Adj. R-squared:                  0.065\n",
       "Method:                 Least Squares   F-statistic:                     3.326\n",
       "Date:                Tue, 04 Apr 2023   Prob (F-statistic):            0.00122\n",
       "Time:                        15:26:32   Log-Likelihood:                -1433.3\n",
       "No. Observations:                 270   AIC:                             2885.\n",
       "Df Residuals:                     261   BIC:                             2917.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          1.7621     33.215      0.053      0.958     -63.641      67.165\n",
       "ni          -100.3524     47.064     -2.132      0.034    -193.025      -7.680\n",
       "san          -20.2126     48.266     -0.419      0.676    -115.252      74.827\n",
       "BSCS          -1.3075      9.939     -0.132      0.895     -20.879      18.263\n",
       "EDM            0.6650      7.509      0.089      0.930     -14.122      15.452\n",
       "BSCS*ni       22.3347     14.746      1.515      0.131      -6.702      51.371\n",
       "BSCS*san     -24.5239     15.266     -1.606      0.109     -54.583       5.536\n",
       "EDM*ni         8.6681     10.806      0.802      0.423     -12.609      29.945\n",
       "EDM*san       28.2973     10.734      2.636      0.009       7.162      49.433\n",
       "==============================================================================\n",
       "Omnibus:                       31.657   Durbin-Watson:                   1.964\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              142.734\n",
       "Skew:                          -0.284   Prob(JB):                     1.01e-31\n",
       "Kurtosis:                       6.516   Cond. No.                         115.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "predictor_data_nona = sm.add_constant(predictor_data_nona)\n",
    "model = sm.OLS(outcome_measures_nona['d_bf'], predictor_data_nona.loc[:,['const','ni','san','BSCS','EDM','BSCS*ni','BSCS*san','EDM*ni','EDM*san']]).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>d_bf</td>       <th>  R-squared:         </th> <td>   0.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.994</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   208.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 04 Apr 2023</td> <th>  Prob (F-statistic):</th> <td>6.38e-38</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:47:10</td>     <th>  Log-Likelihood:    </th> <td> -485.90</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   270</td>      <th>  AIC:               </th> <td>   1434.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    39</td>      <th>  BIC:               </th> <td>   2265.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   230</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                          <td></td>                            <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                            <td>  -30.0280</td> <td>   25.767</td> <td>   -1.165</td> <td> 0.251</td> <td>  -82.146</td> <td>   22.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BSCS</th>                                             <td>   -2.3243</td> <td>    3.470</td> <td>   -0.670</td> <td> 0.507</td> <td>   -9.344</td> <td>    4.695</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDM</th>                                              <td>   -2.3868</td> <td>    2.461</td> <td>   -0.970</td> <td> 0.338</td> <td>   -7.364</td> <td>    2.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIS_11</th>                                           <td>    0.1871</td> <td>    0.182</td> <td>    1.026</td> <td> 0.311</td> <td>   -0.182</td> <td>    0.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCS</th>                                              <td>   -0.3929</td> <td>    0.413</td> <td>   -0.952</td> <td> 0.347</td> <td>   -1.228</td> <td>    0.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RS</th>                                               <td>   -0.1684</td> <td>    0.242</td> <td>   -0.697</td> <td> 0.490</td> <td>   -0.657</td> <td>    0.320</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TRSQ</th>                                             <td>    0.0532</td> <td>    0.130</td> <td>    0.407</td> <td> 0.686</td> <td>   -0.211</td> <td>    0.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_neglectful_parenting</th>                        <td>  -79.5500</td> <td>  197.870</td> <td>   -0.402</td> <td> 0.690</td> <td> -479.781</td> <td>  320.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_abuse</th>                                       <td>  -76.1594</td> <td>  198.014</td> <td>   -0.385</td> <td> 0.703</td> <td> -476.680</td> <td>  324.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_sum</th>                                         <td>   76.7746</td> <td>  198.057</td> <td>    0.388</td> <td> 0.700</td> <td> -323.835</td> <td>  477.384</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_divorced_separated</th>                          <td>  -74.3117</td> <td>  198.077</td> <td>   -0.375</td> <td> 0.710</td> <td> -474.959</td> <td>  326.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_household_dysfunction</th>                       <td>  -76.1972</td> <td>  198.459</td> <td>   -0.384</td> <td> 0.703</td> <td> -477.618</td> <td>  325.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_agreeableness</th>                                <td>    0.1145</td> <td>    0.248</td> <td>    0.461</td> <td> 0.647</td> <td>   -0.388</td> <td>    0.617</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_conscientiousness</th>                            <td>    0.6372</td> <td>    0.329</td> <td>    1.937</td> <td> 0.060</td> <td>   -0.028</td> <td>    1.303</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_extraversion</th>                                 <td>   -0.4868</td> <td>    0.224</td> <td>   -2.171</td> <td> 0.036</td> <td>   -0.940</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_neuroticism</th>                                  <td>    0.2702</td> <td>    0.256</td> <td>    1.056</td> <td> 0.298</td> <td>   -0.248</td> <td>    0.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_openness</th>                                     <td>   -0.0380</td> <td>    0.223</td> <td>   -0.171</td> <td> 0.865</td> <td>   -0.488</td> <td>    0.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_mcarthur_social_standing</th>                    <td>    0.0132</td> <td>    0.455</td> <td>    0.029</td> <td> 0.977</td> <td>   -0.907</td> <td>    0.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_effort_importance</th>                            <td>    2.0814</td> <td>    1.759</td> <td>    1.183</td> <td> 0.244</td> <td>   -1.476</td> <td>    5.639</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_value_usefulness</th>                             <td>   -1.3005</td> <td>    2.167</td> <td>   -0.600</td> <td> 0.552</td> <td>   -5.683</td> <td>    3.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_interest_enjoyment</th>                           <td>    1.9611</td> <td>    1.225</td> <td>    1.600</td> <td> 0.118</td> <td>   -0.517</td> <td>    4.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_perceived_choice</th>                             <td>    0.4931</td> <td>    1.248</td> <td>    0.395</td> <td> 0.695</td> <td>   -2.031</td> <td>    3.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_perceived_competence</th>                         <td>    0.9202</td> <td>    2.008</td> <td>    0.458</td> <td> 0.649</td> <td>   -3.142</td> <td>    4.982</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_get_job_done</th>                                 <td>    7.1141</td> <td>    2.582</td> <td>    2.755</td> <td> 0.009</td> <td>    1.891</td> <td>   12.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_intellectual_task</th>                            <td>    5.9770</td> <td>    2.240</td> <td>    2.668</td> <td> 0.011</td> <td>    1.446</td> <td>   10.508</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_deliberating_issues</th>                          <td>    8.9683</td> <td>    2.724</td> <td>    3.293</td> <td> 0.002</td> <td>    3.459</td> <td>   14.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_like_responsibility</th>                          <td>    6.6917</td> <td>    2.864</td> <td>    2.336</td> <td> 0.025</td> <td>    0.898</td> <td>   12.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thinking_not_exciting</th>                        <td>    9.8211</td> <td>    3.303</td> <td>    2.973</td> <td> 0.005</td> <td>    3.139</td> <td>   16.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_avoid_depth</th>                                  <td>    8.3105</td> <td>    2.293</td> <td>    3.625</td> <td> 0.001</td> <td>    3.673</td> <td>   12.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thinking_not_fun</th>                             <td>    6.6814</td> <td>    3.117</td> <td>    2.144</td> <td> 0.038</td> <td>    0.377</td> <td>   12.986</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thought_appealing</th>                            <td>    9.6564</td> <td>    4.445</td> <td>    2.172</td> <td> 0.036</td> <td>    0.665</td> <td>   18.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_think_minimally</th>                              <td>    6.6270</td> <td>    2.864</td> <td>    2.314</td> <td> 0.026</td> <td>    0.834</td> <td>   12.420</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_prefer_complex</th>                               <td>    7.9779</td> <td>    2.455</td> <td>    3.250</td> <td> 0.002</td> <td>    3.013</td> <td>   12.943</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_prefer_little_thought</th>                        <td>    6.2843</td> <td>    2.678</td> <td>    2.347</td> <td> 0.024</td> <td>    0.868</td> <td>   11.701</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_relief_not_satisfaction</th>                      <td>    8.0960</td> <td>    2.798</td> <td>    2.894</td> <td> 0.006</td> <td>    2.437</td> <td>   13.755</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_tasks_little_thought</th>                         <td>    8.4785</td> <td>    2.618</td> <td>    3.239</td> <td> 0.002</td> <td>    3.184</td> <td>   13.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_new_solutions_to_problems</th>                    <td>    2.7369</td> <td>    2.699</td> <td>    1.014</td> <td> 0.317</td> <td>   -2.723</td> <td>    8.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_abstract_thinking</th>                            <td>    7.6080</td> <td>    3.326</td> <td>    2.288</td> <td> 0.028</td> <td>    0.881</td> <td>   14.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_total</th>                                        <td> -131.3666</td> <td>   42.513</td> <td>   -3.090</td> <td> 0.004</td> <td> -217.358</td> <td>  -45.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_small_daily_projects</th>                         <td>    5.9828</td> <td>    2.404</td> <td>    2.489</td> <td> 0.017</td> <td>    1.120</td> <td>   10.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_solve_puzzles</th>                                <td>    7.4277</td> <td>    2.480</td> <td>    2.995</td> <td> 0.005</td> <td>    2.411</td> <td>   12.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_satisfaction_in_deliberating</th>                 <td>    6.0261</td> <td>    2.572</td> <td>    2.343</td> <td> 0.024</td> <td>    0.824</td> <td>   11.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_cognitive_strategies</th>                        <td>    7.0961</td> <td>    4.538</td> <td>    1.564</td> <td> 0.126</td> <td>   -2.083</td> <td>   16.275</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_mental_forecasting</th>                          <td>   -2.9035</td> <td>    3.116</td> <td>   -0.932</td> <td> 0.357</td> <td>   -9.205</td> <td>    3.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_temporal_orientation</th>                        <td>   -1.7105</td> <td>    3.675</td> <td>   -0.465</td> <td> 0.644</td> <td>   -9.143</td> <td>    5.722</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_lie</th>                                          <td>   -0.5419</td> <td>    1.922</td> <td>   -0.282</td> <td> 0.780</td> <td>   -4.430</td> <td>    3.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_assessment</th>                                   <td>   -2.4054</td> <td>    1.620</td> <td>   -1.485</td> <td> 0.146</td> <td>   -5.682</td> <td>    0.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_locomotion</th>                                   <td>    3.6178</td> <td>    2.619</td> <td>    1.381</td> <td> 0.175</td> <td>   -1.680</td> <td>    8.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_factor_1</th>                                    <td>    0.6123</td> <td>    3.912</td> <td>    0.157</td> <td> 0.876</td> <td>   -7.300</td> <td>    8.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_factor_2</th>                                    <td>   -1.1424</td> <td>    3.731</td> <td>   -0.306</td> <td> 0.761</td> <td>   -8.688</td> <td>    6.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_healthy</th>                                     <td>   -3.1812</td> <td>    2.506</td> <td>   -1.269</td> <td> 0.212</td> <td>   -8.251</td> <td>    1.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_unhealthy</th>                                   <td>   -0.6132</td> <td>    0.555</td> <td>   -1.105</td> <td> 0.276</td> <td>   -1.735</td> <td>    0.509</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_sum</th>                                         <td>    1.9195</td> <td>    1.482</td> <td>    1.295</td> <td> 0.203</td> <td>   -1.077</td> <td>    4.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_controlling_temptations</th>                   <td>   -0.5627</td> <td>    1.680</td> <td>   -0.335</td> <td> 0.739</td> <td>   -3.961</td> <td>    2.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_avoidance_of_temptations</th>                  <td>   -0.0040</td> <td>    2.018</td> <td>   -0.002</td> <td> 0.998</td> <td>   -4.086</td> <td>    4.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_distraction</th>                               <td>    0.3359</td> <td>    1.874</td> <td>    0.179</td> <td> 0.859</td> <td>   -3.455</td> <td>    4.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_goal_and_rule_setting</th>                     <td>    0.4739</td> <td>    1.898</td> <td>    0.250</td> <td> 0.804</td> <td>   -3.365</td> <td>    4.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_goal_deliberation</th>                         <td>    0.7923</td> <td>    1.957</td> <td>    0.405</td> <td> 0.688</td> <td>   -3.167</td> <td>    4.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_sum</th>                                       <td>   -0.3488</td> <td>    1.807</td> <td>   -0.193</td> <td> 0.848</td> <td>   -4.004</td> <td>    3.306</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_suppression</th>                               <td>    0.2393</td> <td>    1.845</td> <td>    0.130</td> <td> 0.897</td> <td>   -3.492</td> <td>    3.970</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_healthy_minus_unhealthy</th>                     <td>    1.2184</td> <td>    1.026</td> <td>    1.188</td> <td> 0.242</td> <td>   -0.857</td> <td>    3.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_f1_minus_f2</th>                                 <td>   -1.6658</td> <td>    3.993</td> <td>   -0.417</td> <td> 0.679</td> <td>   -9.742</td> <td>    6.410</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancer_promoting_minus_preventing_craved_FCI</th>     <td>    0.6215</td> <td>    3.942</td> <td>    0.158</td> <td> 0.876</td> <td>   -7.353</td> <td>    8.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancer_promoting_minus_preventing_liked_FCI</th>      <td>   -5.1758</td> <td>    4.996</td> <td>   -1.036</td> <td> 0.307</td> <td>  -15.282</td> <td>    4.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cSES</th>                                             <td>   -0.1331</td> <td>    0.677</td> <td>   -0.197</td> <td> 0.845</td> <td>   -1.502</td> <td>    1.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age365</th>                                           <td>   -0.0251</td> <td>    0.125</td> <td>   -0.201</td> <td> 0.842</td> <td>   -0.278</td> <td>    0.228</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_own</th>                                    <td>   -1.2670</td> <td>    1.409</td> <td>   -0.899</td> <td> 0.374</td> <td>   -4.117</td> <td>    1.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_median_income_acs</th>                        <td>    0.0703</td> <td>    1.000</td> <td>    0.070</td> <td> 0.944</td> <td>   -1.952</td> <td>    2.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>household_income_per_person</th>                      <td>    0.4565</td> <td>    1.244</td> <td>    0.367</td> <td> 0.716</td> <td>   -2.060</td> <td>    2.973</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_prop_successful_stops</th>                        <td>   18.7191</td> <td>   19.645</td> <td>    0.953</td> <td> 0.347</td> <td>  -21.017</td> <td>   58.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_GRTmean</th>                                      <td>   -0.0797</td> <td>    0.031</td> <td>   -2.554</td> <td> 0.015</td> <td>   -0.143</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_SSD</th>                                          <td>    0.0664</td> <td>    0.037</td> <td>    1.804</td> <td> 0.079</td> <td>   -0.008</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_PostErrorSlowW1_mean</th>                         <td>   13.1562</td> <td>   14.406</td> <td>    0.913</td> <td> 0.367</td> <td>  -15.984</td> <td>   42.296</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_mean_ssrt_0</th>                                  <td>   30.7458</td> <td>   29.887</td> <td>    1.029</td> <td> 0.310</td> <td>  -29.707</td> <td>   91.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROC_Crave_Regulate_Minus_Look</th>                    <td>    0.4530</td> <td>    2.348</td> <td>    0.193</td> <td> 0.848</td> <td>   -4.297</td> <td>    5.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WTP_unhealthy_minus_healthy</th>                      <td>   -3.5882</td> <td>    2.837</td> <td>   -1.265</td> <td> 0.213</td> <td>   -9.327</td> <td>    2.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>birthsex_factor_Male</th>                             <td>    3.0308</td> <td>    3.455</td> <td>    0.877</td> <td> 0.386</td> <td>   -3.958</td> <td>   10.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ni</th>                                               <td>  -57.9873</td> <td>   49.224</td> <td>   -1.178</td> <td> 0.246</td> <td> -157.553</td> <td>   41.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>san</th>                                              <td>  287.8658</td> <td>   41.419</td> <td>    6.950</td> <td> 0.000</td> <td>  204.089</td> <td>  371.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BSCS*ni</th>                                          <td>   -0.5585</td> <td>    5.209</td> <td>   -0.107</td> <td> 0.915</td> <td>  -11.094</td> <td>    9.977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDM*ni</th>                                           <td>   -2.1473</td> <td>    2.881</td> <td>   -0.745</td> <td> 0.461</td> <td>   -7.975</td> <td>    3.681</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIS_11*ni</th>                                        <td>   -1.3391</td> <td>    0.263</td> <td>   -5.091</td> <td> 0.000</td> <td>   -1.871</td> <td>   -0.807</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCS*ni</th>                                           <td>    0.7279</td> <td>    0.485</td> <td>    1.500</td> <td> 0.142</td> <td>   -0.253</td> <td>    1.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RS*ni</th>                                            <td>   -0.3919</td> <td>    0.332</td> <td>   -1.182</td> <td> 0.245</td> <td>   -1.063</td> <td>    0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TRSQ*ni</th>                                          <td>   -0.0146</td> <td>    0.170</td> <td>   -0.085</td> <td> 0.932</td> <td>   -0.359</td> <td>    0.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_neglectful_parenting*ni</th>                     <td>    7.1667</td> <td>  290.461</td> <td>    0.025</td> <td> 0.980</td> <td> -580.347</td> <td>  594.680</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_abuse*ni</th>                                    <td>   -1.2167</td> <td>  291.039</td> <td>   -0.004</td> <td> 0.997</td> <td> -589.898</td> <td>  587.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_sum*ni</th>                                      <td>   -0.3006</td> <td>  290.698</td> <td>   -0.001</td> <td> 0.999</td> <td> -588.293</td> <td>  587.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_divorced_separated*ni</th>                       <td>   -3.6302</td> <td>  290.635</td> <td>   -0.012</td> <td> 0.990</td> <td> -591.495</td> <td>  584.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_household_dysfunction*ni</th>                    <td>    3.7157</td> <td>  291.005</td> <td>    0.013</td> <td> 0.990</td> <td> -584.898</td> <td>  592.330</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_agreeableness*ni</th>                             <td>    0.6190</td> <td>    0.331</td> <td>    1.870</td> <td> 0.069</td> <td>   -0.051</td> <td>    1.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_conscientiousness*ni</th>                         <td>    0.1375</td> <td>    0.394</td> <td>    0.349</td> <td> 0.729</td> <td>   -0.659</td> <td>    0.934</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_extraversion*ni</th>                              <td>    0.5361</td> <td>    0.270</td> <td>    1.985</td> <td> 0.054</td> <td>   -0.010</td> <td>    1.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_neuroticism*ni</th>                               <td>    0.1101</td> <td>    0.336</td> <td>    0.328</td> <td> 0.745</td> <td>   -0.569</td> <td>    0.789</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_openness*ni</th>                                  <td>    1.8531</td> <td>    0.365</td> <td>    5.081</td> <td> 0.000</td> <td>    1.115</td> <td>    2.591</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_mcarthur_social_standing*ni</th>                 <td>   -0.2524</td> <td>    0.601</td> <td>   -0.420</td> <td> 0.677</td> <td>   -1.468</td> <td>    0.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_effort_importance*ni</th>                         <td>   -9.9373</td> <td>    2.318</td> <td>   -4.286</td> <td> 0.000</td> <td>  -14.627</td> <td>   -5.248</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_value_usefulness*ni</th>                          <td>    0.1018</td> <td>    2.578</td> <td>    0.039</td> <td> 0.969</td> <td>   -5.113</td> <td>    5.317</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_interest_enjoyment*ni</th>                        <td>   -3.8097</td> <td>    1.986</td> <td>   -1.918</td> <td> 0.062</td> <td>   -7.827</td> <td>    0.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_perceived_choice*ni</th>                          <td>    5.0693</td> <td>    1.479</td> <td>    3.427</td> <td> 0.001</td> <td>    2.077</td> <td>    8.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_perceived_competence*ni</th>                      <td>   -5.1612</td> <td>    2.738</td> <td>   -1.885</td> <td> 0.067</td> <td>  -10.699</td> <td>    0.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_get_job_done*ni</th>                              <td>   -2.0307</td> <td>    3.669</td> <td>   -0.554</td> <td> 0.583</td> <td>   -9.451</td> <td>    5.390</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_intellectual_task*ni</th>                         <td>   -9.8014</td> <td>    3.344</td> <td>   -2.931</td> <td> 0.006</td> <td>  -16.566</td> <td>   -3.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_deliberating_issues*ni</th>                       <td>   -1.1473</td> <td>    3.561</td> <td>   -0.322</td> <td> 0.749</td> <td>   -8.351</td> <td>    6.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_like_responsibility*ni</th>                       <td>    3.8552</td> <td>    4.000</td> <td>    0.964</td> <td> 0.341</td> <td>   -4.237</td> <td>   11.947</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thinking_not_exciting*ni</th>                     <td>   -2.8065</td> <td>    4.246</td> <td>   -0.661</td> <td> 0.513</td> <td>  -11.395</td> <td>    5.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_avoid_depth*ni</th>                               <td>   -5.2505</td> <td>    3.209</td> <td>   -1.636</td> <td> 0.110</td> <td>  -11.742</td> <td>    1.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thinking_not_fun*ni</th>                          <td>   -5.2401</td> <td>    4.072</td> <td>   -1.287</td> <td> 0.206</td> <td>  -13.477</td> <td>    2.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thought_appealing*ni</th>                         <td>   -5.5047</td> <td>    5.270</td> <td>   -1.044</td> <td> 0.303</td> <td>  -16.165</td> <td>    5.155</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_think_minimally*ni</th>                           <td>   -1.2245</td> <td>    4.076</td> <td>   -0.300</td> <td> 0.765</td> <td>   -9.470</td> <td>    7.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_prefer_complex*ni</th>                            <td>   -9.6546</td> <td>    3.679</td> <td>   -2.625</td> <td> 0.012</td> <td>  -17.095</td> <td>   -2.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_prefer_little_thought*ni</th>                     <td>   -5.6976</td> <td>    3.827</td> <td>   -1.489</td> <td> 0.145</td> <td>  -13.438</td> <td>    2.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_relief_not_satisfaction*ni</th>                   <td>   -1.8123</td> <td>    3.406</td> <td>   -0.532</td> <td> 0.598</td> <td>   -8.702</td> <td>    5.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_tasks_little_thought*ni</th>                      <td>   -3.5469</td> <td>    3.643</td> <td>   -0.974</td> <td> 0.336</td> <td>  -10.915</td> <td>    3.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_new_solutions_to_problems*ni</th>                 <td>    1.7359</td> <td>    4.177</td> <td>    0.416</td> <td> 0.680</td> <td>   -6.712</td> <td>   10.184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_abstract_thinking*ni</th>                         <td>    3.1841</td> <td>    4.236</td> <td>    0.752</td> <td> 0.457</td> <td>   -5.383</td> <td>   11.752</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_total*ni</th>                                     <td>   42.3955</td> <td>   57.813</td> <td>    0.733</td> <td> 0.468</td> <td>  -74.542</td> <td>  159.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_small_daily_projects*ni</th>                      <td>   -0.7852</td> <td>    3.949</td> <td>   -0.199</td> <td> 0.843</td> <td>   -8.773</td> <td>    7.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_solve_puzzles*ni</th>                             <td>   -1.6530</td> <td>    3.185</td> <td>   -0.519</td> <td> 0.607</td> <td>   -8.096</td> <td>    4.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_satisfaction_in_deliberating*ni</th>              <td>    6.2020</td> <td>    3.667</td> <td>    1.691</td> <td> 0.099</td> <td>   -1.216</td> <td>   13.620</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_cognitive_strategies*ni</th>                     <td>   -5.8873</td> <td>    5.240</td> <td>   -1.123</td> <td> 0.268</td> <td>  -16.487</td> <td>    4.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_mental_forecasting*ni</th>                       <td>    3.2811</td> <td>    4.066</td> <td>    0.807</td> <td> 0.425</td> <td>   -4.944</td> <td>   11.506</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_temporal_orientation*ni</th>                     <td>   12.5884</td> <td>    5.376</td> <td>    2.342</td> <td> 0.024</td> <td>    1.714</td> <td>   23.463</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_lie*ni</th>                                       <td>   -3.6871</td> <td>    2.696</td> <td>   -1.367</td> <td> 0.179</td> <td>   -9.141</td> <td>    1.767</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_assessment*ni</th>                                <td>    0.6521</td> <td>    2.447</td> <td>    0.266</td> <td> 0.791</td> <td>   -4.298</td> <td>    5.602</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_locomotion*ni</th>                                <td>    1.5083</td> <td>    3.429</td> <td>    0.440</td> <td> 0.662</td> <td>   -5.427</td> <td>    8.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_factor_1*ni</th>                                 <td>    4.4823</td> <td>    6.052</td> <td>    0.741</td> <td> 0.463</td> <td>   -7.760</td> <td>   16.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_factor_2*ni</th>                                 <td>   -2.8243</td> <td>    5.664</td> <td>   -0.499</td> <td> 0.621</td> <td>  -14.280</td> <td>    8.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_healthy*ni</th>                                  <td>   -0.8389</td> <td>    3.475</td> <td>   -0.241</td> <td> 0.811</td> <td>   -7.868</td> <td>    6.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_unhealthy*ni</th>                                <td>    1.1515</td> <td>    0.769</td> <td>    1.497</td> <td> 0.142</td> <td>   -0.404</td> <td>    2.707</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_sum*ni</th>                                      <td>   -0.2918</td> <td>    1.928</td> <td>   -0.151</td> <td> 0.881</td> <td>   -4.192</td> <td>    3.609</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_controlling_temptations*ni</th>                <td>   -3.4792</td> <td>    3.185</td> <td>   -1.092</td> <td> 0.281</td> <td>   -9.921</td> <td>    2.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_avoidance_of_temptations*ni</th>               <td>   -4.4853</td> <td>    3.227</td> <td>   -1.390</td> <td> 0.172</td> <td>  -11.012</td> <td>    2.041</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_distraction*ni</th>                            <td>   -3.7476</td> <td>    3.112</td> <td>   -1.204</td> <td> 0.236</td> <td>  -10.043</td> <td>    2.548</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_goal_and_rule_setting*ni</th>                  <td>   -5.1475</td> <td>    3.290</td> <td>   -1.565</td> <td> 0.126</td> <td>  -11.802</td> <td>    1.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_goal_deliberation*ni</th>                      <td>   -5.2274</td> <td>    3.409</td> <td>   -1.534</td> <td> 0.133</td> <td>  -12.122</td> <td>    1.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_sum*ni</th>                                    <td>    4.6630</td> <td>    3.189</td> <td>    1.462</td> <td> 0.152</td> <td>   -1.787</td> <td>   11.113</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_suppression*ni</th>                            <td>   -4.0258</td> <td>    3.158</td> <td>   -1.275</td> <td> 0.210</td> <td>  -10.414</td> <td>    2.362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_healthy_minus_unhealthy*ni</th>                  <td>    1.8130</td> <td>    1.610</td> <td>    1.126</td> <td> 0.267</td> <td>   -1.444</td> <td>    5.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_f1_minus_f2*ni</th>                              <td>    4.8834</td> <td>    5.974</td> <td>    0.817</td> <td> 0.419</td> <td>   -7.200</td> <td>   16.967</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancer_promoting_minus_preventing_craved_FCI*ni</th>  <td>    3.7762</td> <td>    4.850</td> <td>    0.779</td> <td> 0.441</td> <td>   -6.034</td> <td>   13.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancer_promoting_minus_preventing_liked_FCI*ni</th>   <td>    4.0400</td> <td>    6.173</td> <td>    0.654</td> <td> 0.517</td> <td>   -8.447</td> <td>   16.527</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cSES*ni</th>                                          <td>   -2.8019</td> <td>    1.095</td> <td>   -2.559</td> <td> 0.014</td> <td>   -5.017</td> <td>   -0.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age365*ni</th>                                        <td>    0.8004</td> <td>    0.173</td> <td>    4.615</td> <td> 0.000</td> <td>    0.450</td> <td>    1.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_own*ni</th>                                 <td>   -7.2353</td> <td>    1.688</td> <td>   -4.286</td> <td> 0.000</td> <td>  -10.649</td> <td>   -3.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_median_income_acs*ni</th>                     <td>    1.6993</td> <td>    1.365</td> <td>    1.245</td> <td> 0.221</td> <td>   -1.061</td> <td>    4.460</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>household_income_per_person*ni</th>                   <td>   -4.4646</td> <td>    1.605</td> <td>   -2.781</td> <td> 0.008</td> <td>   -7.711</td> <td>   -1.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_prop_successful_stops*ni</th>                     <td>  -48.7942</td> <td>   22.834</td> <td>   -2.137</td> <td> 0.039</td> <td>  -94.980</td> <td>   -2.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_GRTmean*ni</th>                                   <td>    0.1137</td> <td>    0.040</td> <td>    2.870</td> <td> 0.007</td> <td>    0.034</td> <td>    0.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_SSD*ni</th>                                       <td>   -0.0425</td> <td>    0.049</td> <td>   -0.872</td> <td> 0.389</td> <td>   -0.141</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_PostErrorSlowW1_mean*ni</th>                      <td>  -34.2883</td> <td>   21.332</td> <td>   -1.607</td> <td> 0.116</td> <td>  -77.436</td> <td>    8.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_mean_ssrt_0*ni</th>                               <td>   60.7059</td> <td>   37.166</td> <td>    1.633</td> <td> 0.110</td> <td>  -14.470</td> <td>  135.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROC_Crave_Regulate_Minus_Look*ni</th>                 <td>    2.3056</td> <td>    3.032</td> <td>    0.760</td> <td> 0.452</td> <td>   -3.827</td> <td>    8.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WTP_unhealthy_minus_healthy*ni</th>                   <td>   12.1178</td> <td>    3.803</td> <td>    3.187</td> <td> 0.003</td> <td>    4.426</td> <td>   19.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>birthsex_factor_Male*ni</th>                          <td>    9.9927</td> <td>    4.584</td> <td>    2.180</td> <td> 0.035</td> <td>    0.721</td> <td>   19.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BSCS*san</th>                                         <td>  -28.1544</td> <td>    5.570</td> <td>   -5.054</td> <td> 0.000</td> <td>  -39.421</td> <td>  -16.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>EDM*san</th>                                          <td>    9.6604</td> <td>    2.997</td> <td>    3.223</td> <td> 0.003</td> <td>    3.598</td> <td>   15.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BIS_11*san</th>                                       <td>    0.9531</td> <td>    0.263</td> <td>    3.622</td> <td> 0.001</td> <td>    0.421</td> <td>    1.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCS*san</th>                                          <td>    2.1795</td> <td>    0.576</td> <td>    3.785</td> <td> 0.001</td> <td>    1.015</td> <td>    3.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RS*san</th>                                           <td>   -2.1702</td> <td>    0.438</td> <td>   -4.957</td> <td> 0.000</td> <td>   -3.056</td> <td>   -1.285</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TRSQ*san</th>                                         <td>   -0.5528</td> <td>    0.244</td> <td>   -2.267</td> <td> 0.029</td> <td>   -1.046</td> <td>   -0.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_neglectful_parenting*san</th>                    <td>  164.1143</td> <td>  321.822</td> <td>    0.510</td> <td> 0.613</td> <td> -486.832</td> <td>  815.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_abuse*san</th>                                   <td>  166.5503</td> <td>  321.771</td> <td>    0.518</td> <td> 0.608</td> <td> -484.293</td> <td>  817.393</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_sum*san</th>                                     <td> -148.2082</td> <td>  321.694</td> <td>   -0.461</td> <td> 0.648</td> <td> -798.896</td> <td>  502.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_divorced_separated*san</th>                      <td>  118.4542</td> <td>  321.331</td> <td>    0.369</td> <td> 0.714</td> <td> -531.498</td> <td>  768.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ACES_household_dysfunction*san</th>                   <td>  152.5896</td> <td>  322.138</td> <td>    0.474</td> <td> 0.638</td> <td> -498.997</td> <td>  804.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_agreeableness*san</th>                            <td>    3.2211</td> <td>    0.388</td> <td>    8.309</td> <td> 0.000</td> <td>    2.437</td> <td>    4.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_conscientiousness*san</th>                        <td>   -5.4891</td> <td>    0.484</td> <td>  -11.345</td> <td> 0.000</td> <td>   -6.468</td> <td>   -4.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_extraversion*san</th>                             <td>    1.4155</td> <td>    0.331</td> <td>    4.283</td> <td> 0.000</td> <td>    0.747</td> <td>    2.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_neuroticism*san</th>                              <td>   -0.5262</td> <td>    0.367</td> <td>   -1.433</td> <td> 0.160</td> <td>   -1.269</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>BFI_openness*san</th>                                 <td>   -1.2556</td> <td>    0.389</td> <td>   -3.225</td> <td> 0.003</td> <td>   -2.043</td> <td>   -0.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DEMO_mcarthur_social_standing*san</th>                <td>    0.0795</td> <td>    0.696</td> <td>    0.114</td> <td> 0.910</td> <td>   -1.329</td> <td>    1.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_effort_importance*san</th>                        <td>   -6.6259</td> <td>    2.598</td> <td>   -2.550</td> <td> 0.015</td> <td>  -11.881</td> <td>   -1.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_value_usefulness*san</th>                         <td>   -4.3275</td> <td>    2.535</td> <td>   -1.707</td> <td> 0.096</td> <td>   -9.454</td> <td>    0.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_interest_enjoyment*san</th>                       <td>   10.5791</td> <td>    2.089</td> <td>    5.063</td> <td> 0.000</td> <td>    6.353</td> <td>   14.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_perceived_choice*san</th>                         <td>   11.7566</td> <td>    1.599</td> <td>    7.352</td> <td> 0.000</td> <td>    8.522</td> <td>   14.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IMI_perceived_competence*san</th>                     <td>  -49.8396</td> <td>    2.703</td> <td>  -18.437</td> <td> 0.000</td> <td>  -55.307</td> <td>  -44.372</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_get_job_done*san</th>                             <td>  -12.5273</td> <td>    4.281</td> <td>   -2.926</td> <td> 0.006</td> <td>  -21.187</td> <td>   -3.867</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_intellectual_task*san</th>                        <td>   -6.2877</td> <td>    5.456</td> <td>   -1.152</td> <td> 0.256</td> <td>  -17.324</td> <td>    4.748</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_deliberating_issues*san</th>                      <td>    3.2164</td> <td>    4.808</td> <td>    0.669</td> <td> 0.507</td> <td>   -6.508</td> <td>   12.941</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_like_responsibility*san</th>                      <td>   -3.8472</td> <td>    5.385</td> <td>   -0.714</td> <td> 0.479</td> <td>  -14.739</td> <td>    7.044</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thinking_not_exciting*san</th>                    <td>   -6.2617</td> <td>    5.689</td> <td>   -1.101</td> <td> 0.278</td> <td>  -17.768</td> <td>    5.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_avoid_depth*san</th>                              <td>    6.9651</td> <td>    5.225</td> <td>    1.333</td> <td> 0.190</td> <td>   -3.603</td> <td>   17.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thinking_not_fun*san</th>                         <td>   -2.8525</td> <td>    4.745</td> <td>   -0.601</td> <td> 0.551</td> <td>  -12.450</td> <td>    6.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_thought_appealing*san</th>                        <td>   13.5778</td> <td>    5.431</td> <td>    2.500</td> <td> 0.017</td> <td>    2.593</td> <td>   24.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_think_minimally*san</th>                          <td>   13.2428</td> <td>    4.789</td> <td>    2.765</td> <td> 0.009</td> <td>    3.556</td> <td>   22.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_prefer_complex*san</th>                           <td>   -0.8799</td> <td>    5.271</td> <td>   -0.167</td> <td> 0.868</td> <td>  -11.542</td> <td>    9.782</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_prefer_little_thought*san</th>                    <td>   -5.9112</td> <td>    4.974</td> <td>   -1.188</td> <td> 0.242</td> <td>  -15.973</td> <td>    4.150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_relief_not_satisfaction*san</th>                  <td>   14.7172</td> <td>    5.095</td> <td>    2.889</td> <td> 0.006</td> <td>    4.412</td> <td>   25.022</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_tasks_little_thought*san</th>                     <td>   -7.4151</td> <td>    4.854</td> <td>   -1.528</td> <td> 0.135</td> <td>  -17.233</td> <td>    2.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_new_solutions_to_problems*san</th>                <td>  -10.6502</td> <td>    4.655</td> <td>   -2.288</td> <td> 0.028</td> <td>  -20.065</td> <td>   -1.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_abstract_thinking*san</th>                        <td>  -17.3261</td> <td>    5.145</td> <td>   -3.368</td> <td> 0.002</td> <td>  -27.732</td> <td>   -6.920</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_total*san</th>                                    <td>   56.3853</td> <td>   80.359</td> <td>    0.702</td> <td> 0.487</td> <td> -106.157</td> <td>  218.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_small_daily_projects*san</th>                     <td>   -2.7248</td> <td>    4.278</td> <td>   -0.637</td> <td> 0.528</td> <td>  -11.377</td> <td>    5.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_solve_puzzles*san</th>                            <td>  -17.5264</td> <td>    4.881</td> <td>   -3.591</td> <td> 0.001</td> <td>  -27.398</td> <td>   -7.654</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NCS_satisfaction_in_deliberating*san</th>             <td>  -16.7182</td> <td>    4.924</td> <td>   -3.395</td> <td> 0.002</td> <td>  -26.679</td> <td>   -6.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_cognitive_strategies*san</th>                    <td>   11.3233</td> <td>    5.409</td> <td>    2.094</td> <td> 0.043</td> <td>    0.384</td> <td>   22.263</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_mental_forecasting*san</th>                      <td>   13.9748</td> <td>    4.335</td> <td>    3.224</td> <td> 0.003</td> <td>    5.207</td> <td>   22.743</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PLAN_temporal_orientation*san</th>                    <td>    7.3800</td> <td>    4.910</td> <td>    1.503</td> <td> 0.141</td> <td>   -2.551</td> <td>   17.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_lie*san</th>                                      <td>   34.9325</td> <td>    3.563</td> <td>    9.803</td> <td> 0.000</td> <td>   27.725</td> <td>   42.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_assessment*san</th>                               <td>  -25.5602</td> <td>    2.990</td> <td>   -8.550</td> <td> 0.000</td> <td>  -31.607</td> <td>  -19.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RMQ_locomotion*san</th>                               <td>   13.8772</td> <td>    3.509</td> <td>    3.955</td> <td> 0.000</td> <td>    6.780</td> <td>   20.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_factor_1*san</th>                                <td>  -14.4880</td> <td>    6.811</td> <td>   -2.127</td> <td> 0.040</td> <td>  -28.264</td> <td>   -0.712</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_factor_2*san</th>                                <td>   -8.8112</td> <td>    6.646</td> <td>   -1.326</td> <td> 0.193</td> <td>  -22.254</td> <td>    4.632</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_healthy*san</th>                                 <td>    7.7812</td> <td>    4.466</td> <td>    1.742</td> <td> 0.089</td> <td>   -1.251</td> <td>   16.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_unhealthy*san</th>                               <td>    1.5723</td> <td>    1.432</td> <td>    1.098</td> <td> 0.279</td> <td>   -1.324</td> <td>    4.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_sum*san</th>                                     <td>   -3.8964</td> <td>    2.824</td> <td>   -1.380</td> <td> 0.176</td> <td>   -9.609</td> <td>    1.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_controlling_temptations*san</th>               <td>   -5.8899</td> <td>    3.694</td> <td>   -1.594</td> <td> 0.119</td> <td>  -13.362</td> <td>    1.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_avoidance_of_temptations*san</th>              <td>   -5.4007</td> <td>    3.872</td> <td>   -1.395</td> <td> 0.171</td> <td>  -13.233</td> <td>    2.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_distraction*san</th>                           <td>   -2.6928</td> <td>    3.876</td> <td>   -0.695</td> <td> 0.491</td> <td>  -10.533</td> <td>    5.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_goal_and_rule_setting*san</th>                 <td>    4.4056</td> <td>    3.791</td> <td>    1.162</td> <td> 0.252</td> <td>   -3.262</td> <td>   12.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_goal_deliberation*san</th>                     <td>   -1.1310</td> <td>    3.910</td> <td>   -0.289</td> <td> 0.774</td> <td>   -9.040</td> <td>    6.778</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_sum*san</th>                                   <td>    1.5712</td> <td>    3.771</td> <td>    0.417</td> <td> 0.679</td> <td>   -6.057</td> <td>    9.199</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TESQ_E_suppression*san</th>                           <td>   -4.2248</td> <td>    3.796</td> <td>   -1.113</td> <td> 0.273</td> <td>  -11.903</td> <td>    3.453</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SRHI_healthy_minus_unhealthy*san</th>                 <td>   -2.5341</td> <td>    1.705</td> <td>   -1.486</td> <td> 0.145</td> <td>   -5.984</td> <td>    0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RTFS_f1_minus_f2*san</th>                             <td>    9.8235</td> <td>    6.752</td> <td>    1.455</td> <td> 0.154</td> <td>   -3.834</td> <td>   23.481</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancer_promoting_minus_preventing_craved_FCI*san</th> <td>   -4.0945</td> <td>    5.362</td> <td>   -0.764</td> <td> 0.450</td> <td>  -14.940</td> <td>    6.751</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cancer_promoting_minus_preventing_liked_FCI*san</th>  <td>    0.6009</td> <td>    6.783</td> <td>    0.089</td> <td> 0.930</td> <td>  -13.119</td> <td>   14.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cSES*san</th>                                         <td>    1.9333</td> <td>    1.278</td> <td>    1.513</td> <td> 0.138</td> <td>   -0.652</td> <td>    4.518</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age365*san</th>                                       <td>   -0.7111</td> <td>    0.191</td> <td>   -3.725</td> <td> 0.001</td> <td>   -1.097</td> <td>   -0.325</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>education_own*san</th>                                <td>    3.9820</td> <td>    2.111</td> <td>    1.886</td> <td> 0.067</td> <td>   -0.288</td> <td>    8.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>zipcode_median_income_acs*san</th>                    <td>   18.3424</td> <td>    1.883</td> <td>    9.741</td> <td> 0.000</td> <td>   14.534</td> <td>   22.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>household_income_per_person*san</th>                  <td>   14.6318</td> <td>    2.099</td> <td>    6.971</td> <td> 0.000</td> <td>   10.386</td> <td>   18.877</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_prop_successful_stops*san</th>                    <td>  -11.2390</td> <td>   31.755</td> <td>   -0.354</td> <td> 0.725</td> <td>  -75.469</td> <td>   52.991</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_GRTmean*san</th>                                  <td>    0.1231</td> <td>    0.041</td> <td>    2.999</td> <td> 0.005</td> <td>    0.040</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_SSD*san</th>                                      <td>   -0.2750</td> <td>    0.053</td> <td>   -5.170</td> <td> 0.000</td> <td>   -0.383</td> <td>   -0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_PostErrorSlowW1_mean*san</th>                     <td>  113.7675</td> <td>   31.313</td> <td>    3.633</td> <td> 0.001</td> <td>   50.432</td> <td>  177.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SST_mean_ssrt_0*san</th>                              <td>   25.1530</td> <td>   41.268</td> <td>    0.609</td> <td> 0.546</td> <td>  -58.320</td> <td>  108.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ROC_Crave_Regulate_Minus_Look*san</th>                <td>    3.1391</td> <td>    3.418</td> <td>    0.918</td> <td> 0.364</td> <td>   -3.775</td> <td>   10.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WTP_unhealthy_minus_healthy*san</th>                  <td>    4.7186</td> <td>    4.565</td> <td>    1.034</td> <td> 0.308</td> <td>   -4.515</td> <td>   13.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>birthsex_factor_Male*san</th>                         <td>    2.1080</td> <td>    5.313</td> <td>    0.397</td> <td> 0.694</td> <td>   -8.639</td> <td>   12.855</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>27.045</td> <th>  Durbin-Watson:     </th> <td>   1.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td> <th>  Jarque-Bera (JB):  </th> <td>  57.670</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.504</td> <th>  Prob(JB):          </th> <td>3.00e-13</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.028</td> <th>  Cond. No.          </th> <td>2.85e+06</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.85e+06. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                   d_bf   R-squared:                       0.999\n",
       "Model:                            OLS   Adj. R-squared:                  0.994\n",
       "Method:                 Least Squares   F-statistic:                     208.4\n",
       "Date:                Tue, 04 Apr 2023   Prob (F-statistic):           6.38e-38\n",
       "Time:                        14:47:10   Log-Likelihood:                -485.90\n",
       "No. Observations:                 270   AIC:                             1434.\n",
       "Df Residuals:                      39   BIC:                             2265.\n",
       "Df Model:                         230                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================\n",
       "                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------------------------\n",
       "const                                              -30.0280     25.767     -1.165      0.251     -82.146      22.090\n",
       "BSCS                                                -2.3243      3.470     -0.670      0.507      -9.344       4.695\n",
       "EDM                                                 -2.3868      2.461     -0.970      0.338      -7.364       2.591\n",
       "BIS_11                                               0.1871      0.182      1.026      0.311      -0.182       0.556\n",
       "PCS                                                 -0.3929      0.413     -0.952      0.347      -1.228       0.442\n",
       "RS                                                  -0.1684      0.242     -0.697      0.490      -0.657       0.320\n",
       "TRSQ                                                 0.0532      0.130      0.407      0.686      -0.211       0.317\n",
       "ACES_neglectful_parenting                          -79.5500    197.870     -0.402      0.690    -479.781     320.681\n",
       "ACES_abuse                                         -76.1594    198.014     -0.385      0.703    -476.680     324.361\n",
       "ACES_sum                                            76.7746    198.057      0.388      0.700    -323.835     477.384\n",
       "ACES_divorced_separated                            -74.3117    198.077     -0.375      0.710    -474.959     326.336\n",
       "ACES_household_dysfunction                         -76.1972    198.459     -0.384      0.703    -477.618     325.224\n",
       "BFI_agreeableness                                    0.1145      0.248      0.461      0.647      -0.388       0.617\n",
       "BFI_conscientiousness                                0.6372      0.329      1.937      0.060      -0.028       1.303\n",
       "BFI_extraversion                                    -0.4868      0.224     -2.171      0.036      -0.940      -0.033\n",
       "BFI_neuroticism                                      0.2702      0.256      1.056      0.298      -0.248       0.788\n",
       "BFI_openness                                        -0.0380      0.223     -0.171      0.865      -0.488       0.412\n",
       "DEMO_mcarthur_social_standing                        0.0132      0.455      0.029      0.977      -0.907       0.934\n",
       "IMI_effort_importance                                2.0814      1.759      1.183      0.244      -1.476       5.639\n",
       "IMI_value_usefulness                                -1.3005      2.167     -0.600      0.552      -5.683       3.082\n",
       "IMI_interest_enjoyment                               1.9611      1.225      1.600      0.118      -0.517       4.440\n",
       "IMI_perceived_choice                                 0.4931      1.248      0.395      0.695      -2.031       3.017\n",
       "IMI_perceived_competence                             0.9202      2.008      0.458      0.649      -3.142       4.982\n",
       "NCS_get_job_done                                     7.1141      2.582      2.755      0.009       1.891      12.337\n",
       "NCS_intellectual_task                                5.9770      2.240      2.668      0.011       1.446      10.508\n",
       "NCS_deliberating_issues                              8.9683      2.724      3.293      0.002       3.459      14.478\n",
       "NCS_like_responsibility                              6.6917      2.864      2.336      0.025       0.898      12.485\n",
       "NCS_thinking_not_exciting                            9.8211      3.303      2.973      0.005       3.139      16.503\n",
       "NCS_avoid_depth                                      8.3105      2.293      3.625      0.001       3.673      12.948\n",
       "NCS_thinking_not_fun                                 6.6814      3.117      2.144      0.038       0.377      12.986\n",
       "NCS_thought_appealing                                9.6564      4.445      2.172      0.036       0.665      18.648\n",
       "NCS_think_minimally                                  6.6270      2.864      2.314      0.026       0.834      12.420\n",
       "NCS_prefer_complex                                   7.9779      2.455      3.250      0.002       3.013      12.943\n",
       "NCS_prefer_little_thought                            6.2843      2.678      2.347      0.024       0.868      11.701\n",
       "NCS_relief_not_satisfaction                          8.0960      2.798      2.894      0.006       2.437      13.755\n",
       "NCS_tasks_little_thought                             8.4785      2.618      3.239      0.002       3.184      13.773\n",
       "NCS_new_solutions_to_problems                        2.7369      2.699      1.014      0.317      -2.723       8.196\n",
       "NCS_abstract_thinking                                7.6080      3.326      2.288      0.028       0.881      14.335\n",
       "NCS_total                                         -131.3666     42.513     -3.090      0.004    -217.358     -45.375\n",
       "NCS_small_daily_projects                             5.9828      2.404      2.489      0.017       1.120      10.845\n",
       "NCS_solve_puzzles                                    7.4277      2.480      2.995      0.005       2.411      12.445\n",
       "NCS_satisfaction_in_deliberating                     6.0261      2.572      2.343      0.024       0.824      11.228\n",
       "PLAN_cognitive_strategies                            7.0961      4.538      1.564      0.126      -2.083      16.275\n",
       "PLAN_mental_forecasting                             -2.9035      3.116     -0.932      0.357      -9.205       3.398\n",
       "PLAN_temporal_orientation                           -1.7105      3.675     -0.465      0.644      -9.143       5.722\n",
       "RMQ_lie                                             -0.5419      1.922     -0.282      0.780      -4.430       3.346\n",
       "RMQ_assessment                                      -2.4054      1.620     -1.485      0.146      -5.682       0.871\n",
       "RMQ_locomotion                                       3.6178      2.619      1.381      0.175      -1.680       8.916\n",
       "RTFS_factor_1                                        0.6123      3.912      0.157      0.876      -7.300       8.524\n",
       "RTFS_factor_2                                       -1.1424      3.731     -0.306      0.761      -8.688       6.403\n",
       "SRHI_healthy                                        -3.1812      2.506     -1.269      0.212      -8.251       1.888\n",
       "SRHI_unhealthy                                      -0.6132      0.555     -1.105      0.276      -1.735       0.509\n",
       "SRHI_sum                                             1.9195      1.482      1.295      0.203      -1.077       4.916\n",
       "TESQ_E_controlling_temptations                      -0.5627      1.680     -0.335      0.739      -3.961       2.835\n",
       "TESQ_E_avoidance_of_temptations                     -0.0040      2.018     -0.002      0.998      -4.086       4.078\n",
       "TESQ_E_distraction                                   0.3359      1.874      0.179      0.859      -3.455       4.126\n",
       "TESQ_E_goal_and_rule_setting                         0.4739      1.898      0.250      0.804      -3.365       4.313\n",
       "TESQ_E_goal_deliberation                             0.7923      1.957      0.405      0.688      -3.167       4.752\n",
       "TESQ_E_sum                                          -0.3488      1.807     -0.193      0.848      -4.004       3.306\n",
       "TESQ_E_suppression                                   0.2393      1.845      0.130      0.897      -3.492       3.970\n",
       "SRHI_healthy_minus_unhealthy                         1.2184      1.026      1.188      0.242      -0.857       3.293\n",
       "RTFS_f1_minus_f2                                    -1.6658      3.993     -0.417      0.679      -9.742       6.410\n",
       "cancer_promoting_minus_preventing_craved_FCI         0.6215      3.942      0.158      0.876      -7.353       8.596\n",
       "cancer_promoting_minus_preventing_liked_FCI         -5.1758      4.996     -1.036      0.307     -15.282       4.930\n",
       "cSES                                                -0.1331      0.677     -0.197      0.845      -1.502       1.235\n",
       "age365                                              -0.0251      0.125     -0.201      0.842      -0.278       0.228\n",
       "education_own                                       -1.2670      1.409     -0.899      0.374      -4.117       1.583\n",
       "zipcode_median_income_acs                            0.0703      1.000      0.070      0.944      -1.952       2.092\n",
       "household_income_per_person                          0.4565      1.244      0.367      0.716      -2.060       2.973\n",
       "SST_prop_successful_stops                           18.7191     19.645      0.953      0.347     -21.017      58.455\n",
       "SST_GRTmean                                         -0.0797      0.031     -2.554      0.015      -0.143      -0.017\n",
       "SST_SSD                                              0.0664      0.037      1.804      0.079      -0.008       0.141\n",
       "SST_PostErrorSlowW1_mean                            13.1562     14.406      0.913      0.367     -15.984      42.296\n",
       "SST_mean_ssrt_0                                     30.7458     29.887      1.029      0.310     -29.707      91.198\n",
       "ROC_Crave_Regulate_Minus_Look                        0.4530      2.348      0.193      0.848      -4.297       5.203\n",
       "WTP_unhealthy_minus_healthy                         -3.5882      2.837     -1.265      0.213      -9.327       2.150\n",
       "birthsex_factor_Male                                 3.0308      3.455      0.877      0.386      -3.958      10.020\n",
       "ni                                                 -57.9873     49.224     -1.178      0.246    -157.553      41.579\n",
       "san                                                287.8658     41.419      6.950      0.000     204.089     371.643\n",
       "BSCS*ni                                             -0.5585      5.209     -0.107      0.915     -11.094       9.977\n",
       "EDM*ni                                              -2.1473      2.881     -0.745      0.461      -7.975       3.681\n",
       "BIS_11*ni                                           -1.3391      0.263     -5.091      0.000      -1.871      -0.807\n",
       "PCS*ni                                               0.7279      0.485      1.500      0.142      -0.253       1.709\n",
       "RS*ni                                               -0.3919      0.332     -1.182      0.245      -1.063       0.279\n",
       "TRSQ*ni                                             -0.0146      0.170     -0.085      0.932      -0.359       0.330\n",
       "ACES_neglectful_parenting*ni                         7.1667    290.461      0.025      0.980    -580.347     594.680\n",
       "ACES_abuse*ni                                       -1.2167    291.039     -0.004      0.997    -589.898     587.464\n",
       "ACES_sum*ni                                         -0.3006    290.698     -0.001      0.999    -588.293     587.692\n",
       "ACES_divorced_separated*ni                          -3.6302    290.635     -0.012      0.990    -591.495     584.235\n",
       "ACES_household_dysfunction*ni                        3.7157    291.005      0.013      0.990    -584.898     592.330\n",
       "BFI_agreeableness*ni                                 0.6190      0.331      1.870      0.069      -0.051       1.289\n",
       "BFI_conscientiousness*ni                             0.1375      0.394      0.349      0.729      -0.659       0.934\n",
       "BFI_extraversion*ni                                  0.5361      0.270      1.985      0.054      -0.010       1.082\n",
       "BFI_neuroticism*ni                                   0.1101      0.336      0.328      0.745      -0.569       0.789\n",
       "BFI_openness*ni                                      1.8531      0.365      5.081      0.000       1.115       2.591\n",
       "DEMO_mcarthur_social_standing*ni                    -0.2524      0.601     -0.420      0.677      -1.468       0.963\n",
       "IMI_effort_importance*ni                            -9.9373      2.318     -4.286      0.000     -14.627      -5.248\n",
       "IMI_value_usefulness*ni                              0.1018      2.578      0.039      0.969      -5.113       5.317\n",
       "IMI_interest_enjoyment*ni                           -3.8097      1.986     -1.918      0.062      -7.827       0.207\n",
       "IMI_perceived_choice*ni                              5.0693      1.479      3.427      0.001       2.077       8.061\n",
       "IMI_perceived_competence*ni                         -5.1612      2.738     -1.885      0.067     -10.699       0.377\n",
       "NCS_get_job_done*ni                                 -2.0307      3.669     -0.554      0.583      -9.451       5.390\n",
       "NCS_intellectual_task*ni                            -9.8014      3.344     -2.931      0.006     -16.566      -3.037\n",
       "NCS_deliberating_issues*ni                          -1.1473      3.561     -0.322      0.749      -8.351       6.056\n",
       "NCS_like_responsibility*ni                           3.8552      4.000      0.964      0.341      -4.237      11.947\n",
       "NCS_thinking_not_exciting*ni                        -2.8065      4.246     -0.661      0.513     -11.395       5.782\n",
       "NCS_avoid_depth*ni                                  -5.2505      3.209     -1.636      0.110     -11.742       1.241\n",
       "NCS_thinking_not_fun*ni                             -5.2401      4.072     -1.287      0.206     -13.477       2.996\n",
       "NCS_thought_appealing*ni                            -5.5047      5.270     -1.044      0.303     -16.165       5.155\n",
       "NCS_think_minimally*ni                              -1.2245      4.076     -0.300      0.765      -9.470       7.021\n",
       "NCS_prefer_complex*ni                               -9.6546      3.679     -2.625      0.012     -17.095      -2.214\n",
       "NCS_prefer_little_thought*ni                        -5.6976      3.827     -1.489      0.145     -13.438       2.043\n",
       "NCS_relief_not_satisfaction*ni                      -1.8123      3.406     -0.532      0.598      -8.702       5.078\n",
       "NCS_tasks_little_thought*ni                         -3.5469      3.643     -0.974      0.336     -10.915       3.821\n",
       "NCS_new_solutions_to_problems*ni                     1.7359      4.177      0.416      0.680      -6.712      10.184\n",
       "NCS_abstract_thinking*ni                             3.1841      4.236      0.752      0.457      -5.383      11.752\n",
       "NCS_total*ni                                        42.3955     57.813      0.733      0.468     -74.542     159.333\n",
       "NCS_small_daily_projects*ni                         -0.7852      3.949     -0.199      0.843      -8.773       7.203\n",
       "NCS_solve_puzzles*ni                                -1.6530      3.185     -0.519      0.607      -8.096       4.790\n",
       "NCS_satisfaction_in_deliberating*ni                  6.2020      3.667      1.691      0.099      -1.216      13.620\n",
       "PLAN_cognitive_strategies*ni                        -5.8873      5.240     -1.123      0.268     -16.487       4.712\n",
       "PLAN_mental_forecasting*ni                           3.2811      4.066      0.807      0.425      -4.944      11.506\n",
       "PLAN_temporal_orientation*ni                        12.5884      5.376      2.342      0.024       1.714      23.463\n",
       "RMQ_lie*ni                                          -3.6871      2.696     -1.367      0.179      -9.141       1.767\n",
       "RMQ_assessment*ni                                    0.6521      2.447      0.266      0.791      -4.298       5.602\n",
       "RMQ_locomotion*ni                                    1.5083      3.429      0.440      0.662      -5.427       8.443\n",
       "RTFS_factor_1*ni                                     4.4823      6.052      0.741      0.463      -7.760      16.724\n",
       "RTFS_factor_2*ni                                    -2.8243      5.664     -0.499      0.621     -14.280       8.632\n",
       "SRHI_healthy*ni                                     -0.8389      3.475     -0.241      0.811      -7.868       6.191\n",
       "SRHI_unhealthy*ni                                    1.1515      0.769      1.497      0.142      -0.404       2.707\n",
       "SRHI_sum*ni                                         -0.2918      1.928     -0.151      0.881      -4.192       3.609\n",
       "TESQ_E_controlling_temptations*ni                   -3.4792      3.185     -1.092      0.281      -9.921       2.963\n",
       "TESQ_E_avoidance_of_temptations*ni                  -4.4853      3.227     -1.390      0.172     -11.012       2.041\n",
       "TESQ_E_distraction*ni                               -3.7476      3.112     -1.204      0.236     -10.043       2.548\n",
       "TESQ_E_goal_and_rule_setting*ni                     -5.1475      3.290     -1.565      0.126     -11.802       1.507\n",
       "TESQ_E_goal_deliberation*ni                         -5.2274      3.409     -1.534      0.133     -12.122       1.667\n",
       "TESQ_E_sum*ni                                        4.6630      3.189      1.462      0.152      -1.787      11.113\n",
       "TESQ_E_suppression*ni                               -4.0258      3.158     -1.275      0.210     -10.414       2.362\n",
       "SRHI_healthy_minus_unhealthy*ni                      1.8130      1.610      1.126      0.267      -1.444       5.070\n",
       "RTFS_f1_minus_f2*ni                                  4.8834      5.974      0.817      0.419      -7.200      16.967\n",
       "cancer_promoting_minus_preventing_craved_FCI*ni      3.7762      4.850      0.779      0.441      -6.034      13.586\n",
       "cancer_promoting_minus_preventing_liked_FCI*ni       4.0400      6.173      0.654      0.517      -8.447      16.527\n",
       "cSES*ni                                             -2.8019      1.095     -2.559      0.014      -5.017      -0.587\n",
       "age365*ni                                            0.8004      0.173      4.615      0.000       0.450       1.151\n",
       "education_own*ni                                    -7.2353      1.688     -4.286      0.000     -10.649      -3.821\n",
       "zipcode_median_income_acs*ni                         1.6993      1.365      1.245      0.221      -1.061       4.460\n",
       "household_income_per_person*ni                      -4.4646      1.605     -2.781      0.008      -7.711      -1.218\n",
       "SST_prop_successful_stops*ni                       -48.7942     22.834     -2.137      0.039     -94.980      -2.608\n",
       "SST_GRTmean*ni                                       0.1137      0.040      2.870      0.007       0.034       0.194\n",
       "SST_SSD*ni                                          -0.0425      0.049     -0.872      0.389      -0.141       0.056\n",
       "SST_PostErrorSlowW1_mean*ni                        -34.2883     21.332     -1.607      0.116     -77.436       8.859\n",
       "SST_mean_ssrt_0*ni                                  60.7059     37.166      1.633      0.110     -14.470     135.881\n",
       "ROC_Crave_Regulate_Minus_Look*ni                     2.3056      3.032      0.760      0.452      -3.827       8.438\n",
       "WTP_unhealthy_minus_healthy*ni                      12.1178      3.803      3.187      0.003       4.426      19.810\n",
       "birthsex_factor_Male*ni                              9.9927      4.584      2.180      0.035       0.721      19.264\n",
       "BSCS*san                                           -28.1544      5.570     -5.054      0.000     -39.421     -16.888\n",
       "EDM*san                                              9.6604      2.997      3.223      0.003       3.598      15.723\n",
       "BIS_11*san                                           0.9531      0.263      3.622      0.001       0.421       1.485\n",
       "PCS*san                                              2.1795      0.576      3.785      0.001       1.015       3.344\n",
       "RS*san                                              -2.1702      0.438     -4.957      0.000      -3.056      -1.285\n",
       "TRSQ*san                                            -0.5528      0.244     -2.267      0.029      -1.046      -0.060\n",
       "ACES_neglectful_parenting*san                      164.1143    321.822      0.510      0.613    -486.832     815.061\n",
       "ACES_abuse*san                                     166.5503    321.771      0.518      0.608    -484.293     817.393\n",
       "ACES_sum*san                                      -148.2082    321.694     -0.461      0.648    -798.896     502.480\n",
       "ACES_divorced_separated*san                        118.4542    321.331      0.369      0.714    -531.498     768.407\n",
       "ACES_household_dysfunction*san                     152.5896    322.138      0.474      0.638    -498.997     804.176\n",
       "BFI_agreeableness*san                                3.2211      0.388      8.309      0.000       2.437       4.005\n",
       "BFI_conscientiousness*san                           -5.4891      0.484    -11.345      0.000      -6.468      -4.510\n",
       "BFI_extraversion*san                                 1.4155      0.331      4.283      0.000       0.747       2.084\n",
       "BFI_neuroticism*san                                 -0.5262      0.367     -1.433      0.160      -1.269       0.217\n",
       "BFI_openness*san                                    -1.2556      0.389     -3.225      0.003      -2.043      -0.468\n",
       "DEMO_mcarthur_social_standing*san                    0.0795      0.696      0.114      0.910      -1.329       1.488\n",
       "IMI_effort_importance*san                           -6.6259      2.598     -2.550      0.015     -11.881      -1.370\n",
       "IMI_value_usefulness*san                            -4.3275      2.535     -1.707      0.096      -9.454       0.799\n",
       "IMI_interest_enjoyment*san                          10.5791      2.089      5.063      0.000       6.353      14.806\n",
       "IMI_perceived_choice*san                            11.7566      1.599      7.352      0.000       8.522      14.991\n",
       "IMI_perceived_competence*san                       -49.8396      2.703    -18.437      0.000     -55.307     -44.372\n",
       "NCS_get_job_done*san                               -12.5273      4.281     -2.926      0.006     -21.187      -3.867\n",
       "NCS_intellectual_task*san                           -6.2877      5.456     -1.152      0.256     -17.324       4.748\n",
       "NCS_deliberating_issues*san                          3.2164      4.808      0.669      0.507      -6.508      12.941\n",
       "NCS_like_responsibility*san                         -3.8472      5.385     -0.714      0.479     -14.739       7.044\n",
       "NCS_thinking_not_exciting*san                       -6.2617      5.689     -1.101      0.278     -17.768       5.245\n",
       "NCS_avoid_depth*san                                  6.9651      5.225      1.333      0.190      -3.603      17.534\n",
       "NCS_thinking_not_fun*san                            -2.8525      4.745     -0.601      0.551     -12.450       6.745\n",
       "NCS_thought_appealing*san                           13.5778      5.431      2.500      0.017       2.593      24.563\n",
       "NCS_think_minimally*san                             13.2428      4.789      2.765      0.009       3.556      22.929\n",
       "NCS_prefer_complex*san                              -0.8799      5.271     -0.167      0.868     -11.542       9.782\n",
       "NCS_prefer_little_thought*san                       -5.9112      4.974     -1.188      0.242     -15.973       4.150\n",
       "NCS_relief_not_satisfaction*san                     14.7172      5.095      2.889      0.006       4.412      25.022\n",
       "NCS_tasks_little_thought*san                        -7.4151      4.854     -1.528      0.135     -17.233       2.403\n",
       "NCS_new_solutions_to_problems*san                  -10.6502      4.655     -2.288      0.028     -20.065      -1.235\n",
       "NCS_abstract_thinking*san                          -17.3261      5.145     -3.368      0.002     -27.732      -6.920\n",
       "NCS_total*san                                       56.3853     80.359      0.702      0.487    -106.157     218.928\n",
       "NCS_small_daily_projects*san                        -2.7248      4.278     -0.637      0.528     -11.377       5.928\n",
       "NCS_solve_puzzles*san                              -17.5264      4.881     -3.591      0.001     -27.398      -7.654\n",
       "NCS_satisfaction_in_deliberating*san               -16.7182      4.924     -3.395      0.002     -26.679      -6.758\n",
       "PLAN_cognitive_strategies*san                       11.3233      5.409      2.094      0.043       0.384      22.263\n",
       "PLAN_mental_forecasting*san                         13.9748      4.335      3.224      0.003       5.207      22.743\n",
       "PLAN_temporal_orientation*san                        7.3800      4.910      1.503      0.141      -2.551      17.311\n",
       "RMQ_lie*san                                         34.9325      3.563      9.803      0.000      27.725      42.140\n",
       "RMQ_assessment*san                                 -25.5602      2.990     -8.550      0.000     -31.607     -19.513\n",
       "RMQ_locomotion*san                                  13.8772      3.509      3.955      0.000       6.780      20.975\n",
       "RTFS_factor_1*san                                  -14.4880      6.811     -2.127      0.040     -28.264      -0.712\n",
       "RTFS_factor_2*san                                   -8.8112      6.646     -1.326      0.193     -22.254       4.632\n",
       "SRHI_healthy*san                                     7.7812      4.466      1.742      0.089      -1.251      16.814\n",
       "SRHI_unhealthy*san                                   1.5723      1.432      1.098      0.279      -1.324       4.469\n",
       "SRHI_sum*san                                        -3.8964      2.824     -1.380      0.176      -9.609       1.816\n",
       "TESQ_E_controlling_temptations*san                  -5.8899      3.694     -1.594      0.119     -13.362       1.582\n",
       "TESQ_E_avoidance_of_temptations*san                 -5.4007      3.872     -1.395      0.171     -13.233       2.432\n",
       "TESQ_E_distraction*san                              -2.6928      3.876     -0.695      0.491     -10.533       5.148\n",
       "TESQ_E_goal_and_rule_setting*san                     4.4056      3.791      1.162      0.252      -3.262      12.073\n",
       "TESQ_E_goal_deliberation*san                        -1.1310      3.910     -0.289      0.774      -9.040       6.778\n",
       "TESQ_E_sum*san                                       1.5712      3.771      0.417      0.679      -6.057       9.199\n",
       "TESQ_E_suppression*san                              -4.2248      3.796     -1.113      0.273     -11.903       3.453\n",
       "SRHI_healthy_minus_unhealthy*san                    -2.5341      1.705     -1.486      0.145      -5.984       0.916\n",
       "RTFS_f1_minus_f2*san                                 9.8235      6.752      1.455      0.154      -3.834      23.481\n",
       "cancer_promoting_minus_preventing_craved_FCI*san    -4.0945      5.362     -0.764      0.450     -14.940       6.751\n",
       "cancer_promoting_minus_preventing_liked_FCI*san      0.6009      6.783      0.089      0.930     -13.119      14.321\n",
       "cSES*san                                             1.9333      1.278      1.513      0.138      -0.652       4.518\n",
       "age365*san                                          -0.7111      0.191     -3.725      0.001      -1.097      -0.325\n",
       "education_own*san                                    3.9820      2.111      1.886      0.067      -0.288       8.252\n",
       "zipcode_median_income_acs*san                       18.3424      1.883      9.741      0.000      14.534      22.151\n",
       "household_income_per_person*san                     14.6318      2.099      6.971      0.000      10.386      18.877\n",
       "SST_prop_successful_stops*san                      -11.2390     31.755     -0.354      0.725     -75.469      52.991\n",
       "SST_GRTmean*san                                      0.1231      0.041      2.999      0.005       0.040       0.206\n",
       "SST_SSD*san                                         -0.2750      0.053     -5.170      0.000      -0.383      -0.167\n",
       "SST_PostErrorSlowW1_mean*san                       113.7675     31.313      3.633      0.001      50.432     177.103\n",
       "SST_mean_ssrt_0*san                                 25.1530     41.268      0.609      0.546     -58.320     108.626\n",
       "ROC_Crave_Regulate_Minus_Look*san                    3.1391      3.418      0.918      0.364      -3.775      10.053\n",
       "WTP_unhealthy_minus_healthy*san                      4.7186      4.565      1.034      0.308      -4.515      13.952\n",
       "birthsex_factor_Male*san                             2.1080      5.313      0.397      0.694      -8.639      12.855\n",
       "==============================================================================\n",
       "Omnibus:                       27.045   Durbin-Watson:                   1.968\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               57.670\n",
       "Skew:                           0.504   Prob(JB):                     3.00e-13\n",
       "Kurtosis:                       5.028   Cond. No.                     2.85e+06\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.85e+06. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "predictor_data_nona = sm.add_constant(predictor_data_nona)\n",
    "model = sm.OLS(outcome_measures_nona['d_bf'], predictor_data_nona).fit()\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a ridge regression\n",
    "primary_regression = linear_model.Ridge(fit_intercept=True, alpha=1.0)\n",
    "\n",
    "#fit the model\n",
    "model_fit = primary_regression.fit(predictor_data_nona,outcome_measures_nona['d_bf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the coefficients\n",
    "ridge_results = pd.DataFrame({\n",
    "    'predictor': predictor_data_nona.columns,\n",
    "    'coef': model_fit.coef_\n",
    "    #'std_err': np.sqrt(np.diag(model_fit.coef_cov_)),\n",
    "    #'pval': 2*(1-stats.t.cdf(np.abs(model_fit.coef_/np.sqrt(np.diag(model_fit.coef_cov_))),df=predictor_data_nona.shape[0]-predictor_data_nona.shape[1]))\n",
    "})\n",
    "\n",
    "ridge_results['coef_abs'] = np.abs(ridge_results.coef)\n",
    "ridge_results = ridge_results.sort_values('coef_abs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>coef_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>IMI_perceived_competence*san</td>\n",
       "      <td>-38.319246</td>\n",
       "      <td>38.319246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>RMQ_lie*san</td>\n",
       "      <td>32.328790</td>\n",
       "      <td>32.328790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>zipcode_median_income_acs*san</td>\n",
       "      <td>21.519625</td>\n",
       "      <td>21.519625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-20.561807</td>\n",
       "      <td>20.561807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>RMQ_assessment*san</td>\n",
       "      <td>-17.940740</td>\n",
       "      <td>17.940740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>SST_SSD</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>0.026923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>SST_GRTmean*san</td>\n",
       "      <td>-0.024063</td>\n",
       "      <td>0.024063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BFI_openness</td>\n",
       "      <td>0.022933</td>\n",
       "      <td>0.022933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*san</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0.013583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>const</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>231 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            predictor       coef   coef_abs\n",
       "176      IMI_perceived_competence*san -38.319246  38.319246\n",
       "199                       RMQ_lie*san  32.328790  32.328790\n",
       "221     zipcode_median_income_acs*san  21.519625  21.519625\n",
       "164       ACES_divorced_separated*san -20.561807  20.561807\n",
       "200                RMQ_assessment*san -17.940740  17.940740\n",
       "..                                ...        ...        ...\n",
       "71                            SST_SSD   0.026923   0.026923\n",
       "224                   SST_GRTmean*san  -0.024063   0.024063\n",
       "16                       BFI_openness   0.022933   0.022933\n",
       "214  SRHI_healthy_minus_unhealthy*san   0.013583   0.013583\n",
       "0                               const   0.000000   0.000000\n",
       "\n",
       "[231 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running models with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_10pow_lower = 6\n",
    "alpha_10pow_upper = -1\n",
    "alpha_increments=1\n",
    "alpha_range = np.power(10,np.linspace(-alpha_10pow_lower,alpha_10pow_upper,(alpha_10pow_lower+alpha_10pow_upper)*alpha_increments+1))\n",
    "# elasticnet_parameters = {\n",
    "#     'alpha':alpha_range,\n",
    "#     'l1_ratio': [0.1,0.3,0.5,0.9,0.99],#np.linspace(0.1,0.9,4+1),\n",
    "#     'max_iter': [10000]\n",
    "#     }\n",
    "# print(elasticnet_parameters)\n",
    "# elasticnet_model = linear_model.ElasticNet()\n",
    "\n",
    "\n",
    "\n",
    "# elasticnet_grid_search_cv = GridSearchCV(estimator=get_estimator_with_preprocessing(elasticnet_model), param_grid = get_param_grid_with_preprocessing(elasticnet_parameters), cv=10,scoring='neg_mean_absolute_error')\n",
    "# elasticnet_grid_search_cv.fit(predictor_data_nona,outcome_measures_nona['d_bf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_estimator__alpha',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'split5_test_score',\n",
       " 'split6_test_score',\n",
       " 'split7_test_score',\n",
       " 'split8_test_score',\n",
       " 'split9_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "ridge_parameters = {'alpha':alpha_range}\n",
    "ridge_model = linear_model.Ridge()\n",
    "print(ridge_parameters)\n",
    "ridge_grid_search_cv = GridSearchCV(estimator=get_estimator_with_preprocessing(ridge_model), param_grid = get_param_grid_with_preprocessing(ridge_parameters), cv=10,scoring='neg_mean_absolute_error')\n",
    "ridge_grid_search_cv.fit(predictor_data_nona,outcome_measures_nona['d_bf'])\n",
    "sorted(ridge_grid_search_cv.cv_results_.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('scaler', StandardScaler()), ('estimator', Ridge(alpha=0.01))],\n",
       " 'verbose': False,\n",
       " 'scaler': StandardScaler(),\n",
       " 'estimator': Ridge(alpha=0.01),\n",
       " 'scaler__copy': True,\n",
       " 'scaler__with_mean': True,\n",
       " 'scaler__with_std': True,\n",
       " 'estimator__alpha': 0.01,\n",
       " 'estimator__copy_X': True,\n",
       " 'estimator__fit_intercept': True,\n",
       " 'estimator__max_iter': None,\n",
       " 'estimator__normalize': 'deprecated',\n",
       " 'estimator__positive': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__solver': 'auto',\n",
       " 'estimator__tol': 0.001}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_grid_search_cv.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.227e+03, tolerance: 6.382e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.208e+03, tolerance: 6.598e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.578e+02, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.002e+03, tolerance: 6.415e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.124e+03, tolerance: 6.885e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.520e+02, tolerance: 6.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.862e+02, tolerance: 6.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.452e+02, tolerance: 6.524e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.634e+02, tolerance: 6.666e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.165e+03, tolerance: 6.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.230e+03, tolerance: 6.382e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+03, tolerance: 6.598e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.615e+02, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+03, tolerance: 6.415e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.127e+03, tolerance: 6.885e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.556e+02, tolerance: 6.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.905e+02, tolerance: 6.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.494e+02, tolerance: 6.524e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.675e+02, tolerance: 6.666e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+03, tolerance: 6.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.268e+03, tolerance: 6.382e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.250e+03, tolerance: 6.598e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.988e+02, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.045e+03, tolerance: 6.415e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+03, tolerance: 6.885e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.918e+02, tolerance: 6.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.327e+02, tolerance: 6.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.909e+02, tolerance: 6.524e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.082e+02, tolerance: 6.666e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.207e+03, tolerance: 6.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.628e+03, tolerance: 6.382e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.622e+03, tolerance: 6.598e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.256e+03, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.422e+03, tolerance: 6.415e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.514e+03, tolerance: 6.885e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+03, tolerance: 6.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.339e+03, tolerance: 6.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.290e+03, tolerance: 6.524e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+03, tolerance: 6.666e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.573e+03, tolerance: 6.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.515e+03, tolerance: 6.382e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.260e+03, tolerance: 6.598e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.729e+03, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.212e+03, tolerance: 6.415e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.048e+03, tolerance: 6.885e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.762e+03, tolerance: 6.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.435e+03, tolerance: 6.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.154e+03, tolerance: 6.524e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.161e+03, tolerance: 6.666e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.236e+03, tolerance: 6.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.647e+03, tolerance: 6.382e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.489e+03, tolerance: 6.598e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.472e+03, tolerance: 5.997e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.552e+03, tolerance: 6.415e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.508e+03, tolerance: 6.885e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.481e+03, tolerance: 6.148e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.709e+03, tolerance: 6.142e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.149e+04, tolerance: 6.524e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.005e+04, tolerance: 6.666e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+04, tolerance: 6.231e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:648: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.878e+03, tolerance: 7.112e+01\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, Lasso())]),\n",
       "             param_grid={&#x27;estimator__alpha&#x27;: array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, Lasso())]),\n",
       "             param_grid={&#x27;estimator__alpha&#x27;: array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()), (&#x27;estimator&#x27;, Lasso())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('estimator', Lasso())]),\n",
       "             param_grid={'estimator__alpha': array([1.e-06, 1.e-05, 1.e-04, 1.e-03, 1.e-02, 1.e-01])},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_parameters = {'alpha':alpha_range}\n",
    "lasso_model = linear_model.Lasso()\n",
    "print(lasso_parameters)\n",
    "lasso_grid_search_cv = GridSearchCV(estimator=get_estimator_with_preprocessing(lasso_model), param_grid = get_param_grid_with_preprocessing(lasso_parameters), cv=10,scoring='neg_mean_absolute_error')\n",
    "lasso_grid_search_cv.fit(predictor_data_nona,outcome_measures_nona['d_bf'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': array([  1,   2,   3,   4,   6,  10,  16,  25,  40,  63, 100])}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, KNeighborsRegressor())]),\n",
       "             param_grid={&#x27;estimator__n_neighbors&#x27;: array([  1,   2,   3,   4,   6,  10,  16,  25,  40,  63, 100])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                                       (&#x27;estimator&#x27;, KNeighborsRegressor())]),\n",
       "             param_grid={&#x27;estimator__n_neighbors&#x27;: array([  1,   2,   3,   4,   6,  10,  16,  25,  40,  63, 100])},\n",
       "             scoring=&#x27;neg_mean_absolute_error&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;estimator&#x27;, KNeighborsRegressor())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsRegressor</label><div class=\"sk-toggleable__content\"><pre>KNeighborsRegressor()</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=10,\n",
       "             estimator=Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                                       ('estimator', KNeighborsRegressor())]),\n",
       "             param_grid={'estimator__n_neighbors': array([  1,   2,   3,   4,   6,  10,  16,  25,  40,  63, 100])},\n",
       "             scoring='neg_mean_absolute_error')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#KNeighborsRegressor\n",
    "knn_parameters = {'n_neighbors':np.unique(np.round(np.power(10,np.linspace(0,2,2*5+1)))).astype(int)}\n",
    "knn_model = KNeighborsRegressor()\n",
    "print(knn_parameters)\n",
    "knn_grid_search_cv = GridSearchCV(estimator=get_estimator_with_preprocessing(knn_model), param_grid = get_param_grid_with_preprocessing(knn_parameters), cv=10,scoring='neg_mean_absolute_error')\n",
    "knn_grid_search_cv.fit(predictor_data_nona,outcome_measures_nona['d_bf'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_estimator_params_from_gridsearch(param_dict):\n",
    "    dict_list = [{k.replace(pipeline_estimator_name + \"__\",\"\"):param_dict[k]} for k in param_dict.keys() if k.startswith(pipeline_estimator_name)]\n",
    "    #convert the dict_list into a dict\n",
    "    return({k:v for d in dict_list for k,v in d.items()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot a heatmap of cv_results_ for the param alpha and l1_ratio using matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#convert the cv_results_ to a dataframe\n",
    "# elasticnet_cv_results_df = pd.DataFrame(elasticnet_grid_search_cv.cv_results_)\n",
    "# estimator_params = elasticnet_cv_results_df.params.apply(lambda x: extract_estimator_params_from_gridsearch(x))\n",
    "# elasticnet_cv_results_df['alpha'] = estimator_params.apply(lambda x: x['alpha'])\n",
    "# elasticnet_cv_results_df['l1_ratio'] = estimator_params.apply(lambda x: x['l1_ratio'])\n",
    "# elasticnet_cv_results_df['mean_test_score'] = elasticnet_cv_results_df.mean_test_score*-1\n",
    "\n",
    "# #plot the heatmap\n",
    "# plt.figure(figsize=(10,10))\n",
    "# sns.heatmap(elasticnet_cv_results_df.pivot(index='alpha',columns='l1_ratio',values='mean_test_score'),annot=True,fmt='.2f')\n",
    "# plt.title('ElasticNet Mean Absolute Error')\n",
    "# plt.xlabel('l1_ratio')\n",
    "# plt.ylabel('alpha')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'KNN Mean Absolute Error')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph alpha and mean_test_score\n",
    "#use the log10 of alpha but label the x-axis with alpha\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot([extract_estimator_params_from_gridsearch(p)['n_neighbors'] for p in knn_grid_search_cv.cv_results_['params']],knn_grid_search_cv.cv_results_['mean_test_score'])\n",
    "plt.ylabel('mean_test_score')\n",
    "plt.title('KNN Mean Absolute Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lasso Mean Absolute Error')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#graph alpha and mean_test_score\n",
    "#use the log10 of alpha but label the x-axis with alpha\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(np.log10([extract_estimator_params_from_gridsearch(p)['alpha'] for p in lasso_grid_search_cv.cv_results_['params']]),lasso_grid_search_cv.cv_results_['mean_test_score'])\n",
    "plt.xlabel('log10(alpha)')\n",
    "plt.ylabel('mean_test_score')\n",
    "plt.title('Lasso Mean Absolute Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ridge Mean Absolute Error')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph alpha and mean_test_score\n",
    "#use the log10 of alpha but label the x-axis with alpha\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(np.log10([p['estimator__alpha'] for p in ridge_grid_search_cv.cv_results_['params']]),ridge_grid_search_cv.cv_results_['mean_test_score'])\n",
    "plt.xlabel('log10(alpha)')\n",
    "plt.ylabel('mean_test_score')\n",
    "plt.title('Ridge Mean Absolute Error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Ridge Mean Absolute Error')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graph alpha and mean_test_score\n",
    "#use the log10 of alpha but label the x-axis with alpha\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(np.log10([extract_estimator_params_from_gridsearch(p)['alpha'] for p in ridge_grid_search_cv.cv_results_['params']]),ridge_grid_search_cv.cv_results_['mean_test_score'])\n",
    "plt.xlabel('log10(alpha)')\n",
    "plt.ylabel('mean_test_score')\n",
    "plt.title('Ridge Mean Absolute Error')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pick the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cv_results = [ridge_grid_search_cv, lasso_grid_search_cv, elasticnet_grid_search_cv, knn_grid_search_cv]\n",
    "\n",
    "#create a dataframe with the best parameters, best mean_test_score, and name of the model\n",
    "\n",
    "best_params_df = pd.DataFrame({\n",
    "    'model': [cv_result.estimator for cv_result in all_cv_results],\n",
    "    'model_name': [cv_result.estimator.__class__.__name__ for cv_result in all_cv_results],\n",
    "    'best_params': [extract_estimator_params_from_gridsearch(cv_result.best_params_) for cv_result in all_cv_results],\n",
    "    'best_score': [cv_result.best_score_ for cv_result in all_cv_results],\n",
    "    'best_raw_params' : [cv_result.best_params_ for cv_result in all_cv_results]\n",
    "    })\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import clone\n",
    "\n",
    "best_params_df = best_params_df.sort_values('best_score',ascending=False).reset_index(drop=True)\n",
    "\n",
    "best_model = clone(best_params_df['model'][0])\n",
    "best_model_params = best_params_df['best_raw_params'][0]\n",
    "best_model.set_params(**best_model_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do next:\n",
    "\n",
    " - normalize the dataset, using a pipeline so that normalizing is only done on the training set, with the same transformation then done on the test set. \n",
    "   - DONE\n",
    " - after that, we'll have a reasonable pipeline for model selection, but we then need to embed that in a nested CV for estimating generalization.\n",
    " - Need to deal with the "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression seems to perform best so far, on this dataset. If the Ridge regression performs best on the actual dataset, we would potentially choose it. But we might want to rule it out from the start because it doesn't entirely eliminate variables that aren't predictive. Note that the actual, final dataset might be quite different and there's no real reason to think that it will respond in the same wya. In particular, it might choose an entirely different model. we should also ensure the grid-search has a range of params that is wider than the range we specialized on here."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# optimizing ridge regression using nested cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the sample into 10 folds using sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, KFold\n",
    "\n",
    "\n",
    "\n",
    "n_folds = 10\n",
    "#make sure there are an equal number of samples from each class in each fold\n",
    "kf = KFold(n_splits=n_folds, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "# for each fold, run a grid search to find the best parameters\n",
    "# then use hte best parameters to fit the model and predict the test set\n",
    "# then calculate the mean absolute error for the test set\n",
    "# repeat for each fold\n",
    "# then average the mean absolute error across all folds\n",
    "# then pick the best fitting parameter set to generate a final model\n",
    "# that final model will be somewhat overfit, but we can perhaps use a control to make sure it's not excessively overfit\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things I need to sort out here:\n",
    "\n",
    "1. Is the pattern of GridSearchCV followed by cross_val_score enough? See https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html\n",
    "2. How do we do the nested cross-validation, with the constraint that we use the same sets of groups for the inner and outer CV?\n",
    "\n",
    "It seems that whether we do GridSearchCV followed by cross_val_score, or follow the manual pattern I was planning, we need either a custom CV or a custom iterable. Perhaps we should try a custom CV class, wrapping StratifiedKFold, which stratifies on a third variable passed to the constructor.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IndependentVarStratifiedKFold function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.validation import column_or_1d\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils.multiclass import type_of_target\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "class IndependentVarStratifiedKFold(StratifiedKFold):\n",
    "    def __init__(self, independent_vars, n_splits=5, shuffle=False, random_state=None):\n",
    "        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n",
    "        self.independent_vars = independent_vars\n",
    "\n",
    "    # def _iter_test_masks(self, X, y=None, groups=None):\n",
    "    #     test_folds = self._make_test_folds(X, y)\n",
    "    #     for i in range(self.n_splits):\n",
    "    #         yield test_folds == i\n",
    "\n",
    "    def _iter_test_indices(self, X, y, groups):\n",
    "        unique_independent_vars, counts = np.unique(self.independent_vars, return_counts=True)\n",
    "        for test_index in super()._iter_test_indices(X, self.independent_vars, groups):\n",
    "            test_independent_vars = self.independent_vars[test_index]\n",
    "            _, test_counts = np.unique(test_independent_vars, return_counts=True)\n",
    "            if np.all(counts >= test_counts):\n",
    "                yield test_index\n",
    "\n",
    "    def _make_test_folds(self, X, y=None):\n",
    "        rng = check_random_state(self.random_state)\n",
    "        g = np.asarray(self.independent_vars)\n",
    "        type_of_target_g = type_of_target(g)\n",
    "        allowed_target_types = (\"binary\", \"multiclass\")\n",
    "        if type_of_target_g not in allowed_target_types:\n",
    "            warnings.warn(\n",
    "                \"Supported target types are: {}. Got {!r} instead.\".format(\n",
    "                    allowed_target_types, type_of_target_g\n",
    "                )\n",
    "            )\n",
    "\n",
    "        g = column_or_1d(g)\n",
    "\n",
    "        _, g_idx, g_inv = np.unique(g, return_index=True, return_inverse=True)\n",
    "        # y_inv encodes y according to lexicographic order. We invert y_idx to\n",
    "        # map the classes so that they are encoded by order of appearance:\n",
    "        # 0 represents the first label appearing in y, 1 the second, etc.\n",
    "        _, class_perm = np.unique(g_idx, return_inverse=True)\n",
    "        g_encoded = class_perm[g_inv]\n",
    "\n",
    "        n_classes = len(g_idx)\n",
    "        g_counts = np.bincount(g_encoded)\n",
    "        min_groups = np.min(g_counts)\n",
    "        if np.all(self.n_splits > g_counts):\n",
    "            raise ValueError(\n",
    "                \"n_splits=%d cannot be greater than the\"\n",
    "                \" number of members in each class.\" % (self.n_splits)\n",
    "            )\n",
    "        if self.n_splits > min_groups:\n",
    "            warnings.warn(\n",
    "                \"The least populated class in y has only %d\"\n",
    "                \" members, which is less than n_splits=%d.\"\n",
    "                % (min_groups, self.n_splits),\n",
    "                UserWarning,\n",
    "            )\n",
    "\n",
    "        # Determine the optimal number of samples from each class in each fold,\n",
    "        # using round robin over the sorted y. (This can be done direct from\n",
    "        # counts, but that code is unreadable.)\n",
    "        g_order = np.sort(g_encoded)\n",
    "        allocation = np.asarray(\n",
    "            [\n",
    "                np.bincount(g_order[i :: self.n_splits], minlength=n_classes)\n",
    "                for i in range(self.n_splits)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # To maintain the data order dependencies as best as possible within\n",
    "        # the stratification constraint, we assign samples from each class in\n",
    "        # blocks (and then mess that up when shuffle=True).\n",
    "        test_folds = np.empty(len(g), dtype=\"i\")\n",
    "        for k in range(n_classes):\n",
    "            # since the kth column of allocation stores the number of samples\n",
    "            # of class k in each test set, this generates blocks of fold\n",
    "            # indices corresponding to the allocation for class k.\n",
    "            folds_for_class = np.arange(self.n_splits).repeat(allocation[:, k])\n",
    "            if self.shuffle:\n",
    "                rng.shuffle(folds_for_class)\n",
    "            test_folds[g_encoded == k] = folds_for_class\n",
    "        return test_folds\n",
    "\n",
    "\n",
    "# create a stratified k-fold object\n",
    "# the independent variable is the 'group' column\n",
    "# this will ensure that each fold has an equal number of samples from each group\n",
    "# this is important because we want to make sure that each fold has an equal number of samples from each class\n",
    "\n",
    "cv = IndependentVarStratifiedKFold(independent_vars=group_assignments_nona, n_splits=3, shuffle=True, random_state=0)\n",
    "\n",
    "# now do cv.split and print the items in each fold\n",
    "for train_ik, test_i in cv.split(predictor_data_nona, group_assignments_nona):\n",
    "    print(\"TRAIN:\", np.array(train_ik), \"TEST:\", np.array(test_i))\n",
    "    #test to see if this works on the group assignments\n",
    "    print(\"train:\")\n",
    "    print(pd.Series(group_assignments_nona[train_ik]).value_counts())\n",
    "    print(\"test:\")\n",
    "    print(pd.Series(group_assignments_nona[test_i]).value_counts())\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design the splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# create a stratified k-fold object\n",
    "# the independent variable is the 'group' column\n",
    "# this will ensure that each fold has an equal number of samples from each group\n",
    "# this is important because we want to make sure that each fold has an equal number of samples from each class\n",
    "outer_splits = 10\n",
    "inner_splits = outer_splits - 1\n",
    "\n",
    "outer_cv = IndependentVarStratifiedKFold(independent_vars=group_assignments_nona, n_splits=outer_splits, shuffle=True, random_state=3211050)\n",
    "#hold up. how does cross_val_score manage with an outer and inner CV that are defined at the same time?\n",
    "#maybe it doesn't matter.\n",
    "\n",
    "\n",
    "# now do cv.split and print the items in each fold\n",
    "for i, (train_i, test_i) in enumerate(outer_cv.split(predictor_data_nona, outcome_measures_nona['d_bf'])):\n",
    "    print(\"outer split\" + str(i))\n",
    "    #print(str(train_ik) + \", \" + str(test_i))\n",
    "\n",
    "    #the problem with this design is we STILL, if we want to pass this to a nested CV, have to split *further* in order to hold out one component of data for validation\n",
    "    #if we use the GridSearchCV followed by cross_val_score pattern, it *might* work???\n",
    "\n",
    "\n",
    "\n",
    "    #print(\"TRAIN:\", np.array(train_i), \"TEST:\", np.array(test_i))\n",
    "    #test to see if this works on the group assignments\n",
    "    print(\"train:\"+ str(dict(pd.Series(group_assignments_nona[train_i]).value_counts())) + \", \" + \n",
    "          \"test:\" + \n",
    "        str(dict(pd.Series(group_assignments_nona[test_i]).value_counts()))\n",
    "    )\n",
    "\n",
    "    \n",
    "\n",
    "    train_i_X = predictor_data_nona.iloc[train_i]\n",
    "    train_i_y = outcome_measures_nona['d_bf'].iloc[train_i]\n",
    "    train_i_group_assignments = group_assignments_nona[train_i]\n",
    "\n",
    "    inner_cv = IndependentVarStratifiedKFold(independent_vars=train_i_group_assignments, n_splits=inner_splits, shuffle=True, random_state=3211050)\n",
    "    for j, (train_j, test_j) in enumerate(inner_cv.split(train_i_X, train_i_y)):\n",
    "        print(\"inner split \" + str(j))\n",
    "        #print(\"TRAIN:\", np.array(train_i[train_j]), \"TEST:\", np.array(train_i[test_j]))\n",
    "        print(\"train:\" + str(dict(pd.Series(train_i_group_assignments[train_j]).value_counts())) + \"; \"\n",
    "              \"test:\" + str(dict(pd.Series(train_i_group_assignments[test_j]).value_counts())))\n",
    "    \n",
    "    #gridsearch = GridSearchCV(estimator=Ridge(), param_grid={'alpha':[0.1,0.5,0.9]}, cv=inner_cv)\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try GridSearchCV with cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# inner_cv = IndependentVarStratifiedKFold(independent_vars=group_assignments_nona, n_splits=4, shuffle=True, random_state=0)\n",
    "# outer_cv = IndependentVarStratifiedKFold(independent_vars=group_assignments_nona, n_splits=4, shuffle=True, random_state=0)\n",
    "inner_cv = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=0)\n",
    "\n",
    "\n",
    "gridsearch = GridSearchCV(estimator=Ridge(), param_grid={'alpha':[0.1,0.5,0.9]}, cv=inner_cv)\n",
    "nested_score = cross_val_score(gridsearch, X=predictor_data_nona, y=outcome_measures_nona['d_bf'], cv=outer_cv)\n",
    "nested_scores = nested_score.mean()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a function to do CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import clone\n",
    "from sklearn.base import clone\n",
    "\n",
    "def do_hyperparameter_selection_on_fold(X, y,cv):\n",
    "    alpha_10pow_lower = 6\n",
    "    alpha_10pow_upper = -1\n",
    "    alpha_increments=1\n",
    "    alpha_range = np.power(10,np.linspace(-alpha_10pow_lower,alpha_10pow_upper,(alpha_10pow_lower+alpha_10pow_upper)*alpha_increments+1))\n",
    "\n",
    "    ############\n",
    "    #RIDGE\n",
    "    ridge_parameters = {'alpha':alpha_range}\n",
    "    ridge_model = linear_model.Ridge()\n",
    "    print(ridge_parameters)\n",
    "    #do a gridsearch, using the same folds as the outer loop\n",
    "    ridge_grid_search_cv = GridSearchCV(estimator=get_estimator_with_preprocessing(ridge_model), param_grid = get_param_grid_with_preprocessing(ridge_parameters), cv=cv,scoring='neg_mean_absolute_error')\n",
    "    ridge_grid_search_cv.fit(X,y)\n",
    "\n",
    "    ############\n",
    "    #LASSO\n",
    "    lasso_parameters = {'alpha':alpha_range}\n",
    "    lasso_model = linear_model.Lasso()\n",
    "    print(lasso_parameters)\n",
    "    lasso_grid_search_cv = GridSearchCV(estimator=get_estimator_with_preprocessing(lasso_model), param_grid = get_param_grid_with_preprocessing(lasso_parameters), cv=cv,scoring='neg_mean_absolute_error')\n",
    "    lasso_grid_search_cv.fit(X,y)\n",
    "\n",
    "\n",
    "\n",
    "    all_cv_results = [ridge_grid_search_cv, lasso_grid_search_cv]\n",
    "\n",
    "    #create a dataframe with the best parameters, best mean_test_score, and name of the model\n",
    "\n",
    "    best_params_df = pd.DataFrame({\n",
    "        'model': [cv_result.estimator for cv_result in all_cv_results],\n",
    "        'model_name': [cv_result.estimator.__class__.__name__ for cv_result in all_cv_results],\n",
    "        'best_params': [extract_estimator_params_from_gridsearch(cv_result.best_params_) for cv_result in all_cv_results],\n",
    "        'best_score': [cv_result.best_score_ for cv_result in all_cv_results],\n",
    "        'best_raw_params' : [cv_result.best_params_ for cv_result in all_cv_results]\n",
    "        })\n",
    "    \n",
    "    best_params_df = best_params_df.sort_values('best_score',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    best_model = clone(best_params_df['model'][0])\n",
    "    best_model_params = best_params_df['best_raw_params'][0]\n",
    "    best_model.set_params(**best_model_params)\n",
    "\n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_params_df':best_params_df,\n",
    "        'raw_cv_results':all_cv_results\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try out CV with simple gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "outer_splits = 4\n",
    "inner_splits = outer_splits - 1\n",
    "\n",
    "outer_cv = IndependentVarStratifiedKFold(independent_vars=group_assignments_nona, n_splits=outer_splits, shuffle=True, random_state=3211050)\n",
    "#hold up. how does cross_val_score manage with an outer and inner CV that are defined at the same time?\n",
    "#maybe it doesn't matter.\n",
    "\n",
    "scores = []\n",
    "\n",
    "best_models = []\n",
    "best_params_df_list = []\n",
    "raw_cv_results_list = []\n",
    "\n",
    "# now do cv.split and print the items in each fold\n",
    "for i, (train_i, test_i) in enumerate(outer_cv.split(predictor_data_nona, outcome_measures_nona['d_bf'])):\n",
    "    print(\"outer split\" + str(i))\n",
    "\n",
    "    #test to see if this works on the group assignments\n",
    "    print(\"train:\"+ str(dict(pd.Series(group_assignments_nona[train_i]).value_counts())) + \", \" + \n",
    "          \"test:\" + \n",
    "        str(dict(pd.Series(group_assignments_nona[test_i]).value_counts()))\n",
    "    )\n",
    "\n",
    "    train_i_X = predictor_data_nona.iloc[train_i]\n",
    "    train_i_y = outcome_measures_nona['d_bf'].iloc[train_i]\n",
    "    train_i_group_assignments = group_assignments_nona[train_i]\n",
    "    print(train_i_y)\n",
    "\n",
    "    test_i_X = predictor_data_nona.iloc[test_i]\n",
    "    test_i_y = outcome_measures_nona['d_bf'].iloc[test_i]\n",
    "    print(test_i_y)\n",
    "\n",
    "    inner_cv = IndependentVarStratifiedKFold(independent_vars=train_i_group_assignments, n_splits=inner_splits, shuffle=True, random_state=3211050)\n",
    "\n",
    "    selection_info = do_hyperparameter_selection_on_fold(train_i_X, train_i_y,cv = inner_cv)\n",
    "    best_model_i = selection_info['best_model']\n",
    "    best_params_i = selection_info['best_params_df']\n",
    "    best_models.append(best_model_i)\n",
    "    best_params_df_list.append(best_params_i)\n",
    "    raw_cv_results_list.append(selection_info['raw_cv_results'])\n",
    "\n",
    "    best_model_i.fit(train_i_X, train_i_y)\n",
    "    score_r2_i = best_model_i.score(test_i_X, test_i_y)\n",
    "\n",
    "    scores.append(score_r2_i)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    #now fit the model on the training data\n",
    "    #gridsearch.fit(train_i_X, train_i_y)\n",
    "\n",
    "    #model_with_hypers = gridsearch.cv_results_.keys()\n",
    "    #print(model_with_hypers)\n",
    "\n",
    "    #score = model_with_hypers.score(test_i_X, test_i_y)\n",
    "    #scores.append(score)\n",
    "\n",
    "\n",
    "    #best_score = gridsearch.score(train_i_X.iloc[test_j], train_i_y.iloc[test_j])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scores)\n",
    "overall_score = np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.warn(\"Need to test how this runs with different numbers of variables because I'm getting wildly varying performance scores.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_score"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to pick the best model, including model parameters. Two ways to do it; one is to follow the way its done in CV; the otehr is to do it like this:\n",
    "\n",
    " - We use each fold to 'vote' for a model, including the particular parameters used.\n",
    " - Possibly it will be a tie in that there will be two or more models with specific parameters that are chosen as best; possibly every single fold will have selected a slightly different set of parameters. In that case, if two or more models are 'first equal', eliminate the others, then select the model that got the highest test performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we followed how it's one in CV, perhaps we just run GridSearchCV one more time, across the entire dataset, to select model parameters. hmm. That is _definitely_ going to over-fit, but I'm not sure it will be biased to choose excessive precision, because we'll still be doing train/test analysis.\n",
    "\n",
    "\n",
    "Alternatively we could just use the data that GridSearchCV has _already generated_ to select the best model, by (I assume) adding up the performance for each model over the whole GridSearch and picking the best one. That would involve extracting performance for _every single model_ across ALL GridSearches and then combining them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_list = []\n",
    "for i, raw_result_fold_i in enumerate(raw_cv_results_list):\n",
    "    for gsm in raw_cv_results_list[i]:\n",
    "        gsm_j_cv_results_df = pd.DataFrame(gsm.cv_results_)\n",
    "        gsm_j_cv_results_df['fold'] = i\n",
    "        gsm_j_cv_results_df['model_description'] = str(gsm.estimator.named_steps.values())\n",
    "        gsm_j_cv_results_df['model'] = gsm.estimator\n",
    "        \n",
    "        cv_results_list.append(gsm_j_cv_results_df)\n",
    "\n",
    "cv_results_df = pd.concat(cv_results_list)\n",
    "cv_results_df['params_str'] = cv_results_df['params'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#group by model_description and params across folds and get the mean and std of the mean and std test scores\n",
    "\n",
    "list_model_performance = (cv_results_df\n",
    " .groupby(['model_description','params_str'])\n",
    " .agg({'mean_test_score':['mean','std'],'std_test_score':['mean','std']})\n",
    " .sort_values(('mean_test_score','mean'),ascending=False)\n",
    ")\n",
    "\n",
    "list_model_performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's one way to do it! I am still concerned about overfitting.\n",
    "\n",
    "At least we won't be picking hyper-parameters that do excessive overfitting, but we might still be over-optimizing hyper-parameters on this specific dataset. That would lead to an inflated performance estimate, but we are not using this for peformance. It would also lead to an inflated fit of the parameters to the data, but  (1) it's not clear any of the _other_ fits would be better; (2) because the hyper-parameters are taken from the cross-validation process, \n",
    "\n",
    "Perhaps it's better to re-run the GridSearchCV one more time on the full dataset; that would be less optimization, I think."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_fits =  (cv_results_df\n",
    " .groupby(['model_description','params_str'])\n",
    " .agg({'mean_test_score':['mean','std'],'std_test_score':['mean','std']})\n",
    ").reset_index()\n",
    "\n",
    "#identify the index of best fit\n",
    "best_fit_description = overall_fits[overall_fits[('mean_test_score','mean')]==overall_fits[('mean_test_score','mean')].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_fit_characteristics =  cv_results_df.loc[((cv_results_df['model_description']==best_fit_description['model_description'].values[0]) & \n",
    "                   (cv_results_df['params_str']==best_fit_description['params_str'].values[0])),:].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = clone(best_fit_characteristics.model)\n",
    "best_model_params = best_fit_characteristics.params\n",
    "best_model.set_params(**best_model_params)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, estimate based on ALL the data to get a set of regressors we can report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_fit = best_model.fit(predictor_data_nona, outcome_measures_nona['d_bf'])\n",
    "final_estimator = final_fit.named_steps['estimator']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#view the coefficients\n",
    "final_results = pd.DataFrame({\n",
    "    'predictor': predictor_data_nona.columns,\n",
    "    'coef': final_estimator.coef_\n",
    "    #'std_err': np.sqrt(np.diag(model_fit.coef_cov_)),\n",
    "    #'pval': 2*(1-stats.t.cdf(np.abs(model_fit.coef_/np.sqrt(np.diag(model_fit.coef_cov_))),df=predictor_data_nona.shape[0]-predictor_data_nona.shape[1]))\n",
    "})\n",
    "\n",
    "final_results['coef_abs'] = np.abs(final_results.coef)\n",
    "final_results = final_results.sort_values('coef_abs',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_count = np.sum(final_estimator.coef_!=0)\n",
    "print(f\"Number of selected features: {selected_features_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014247d405695287815678bf9349a8dffb2674e9fe9a5bd4bb9820af018d638d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
