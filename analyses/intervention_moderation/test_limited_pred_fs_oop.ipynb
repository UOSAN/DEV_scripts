{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "x\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from dev_interaction_util import generate_synthetic_dev_outcomes, generate_synthetic_dev_data, set_up_interactions\n",
    "from dev_interaction_util import do_scoring_loop, get_best_model, summarize_overall_df_results, do_final_fit, present_model_results, present_results_vs_ground_truth_cors\n",
    "from dev_interaction_util import load_and_preprocess_data, impute_data\n",
    "from ml_util import *\n",
    "\n",
    "# Imputing with MICE\n",
    "from devcvanalysis import DevAim3NestedCVManager, optimize_hypers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-2.local\n",
      "{'dropbox_data_dir': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "with open('config.yml') as f:\n",
    "    all_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "    if gethostname() in all_yaml.keys():\n",
    "        config = all_yaml[gethostname()]\n",
    "    else:\n",
    "        config = all_yaml['default']\n",
    "        \n",
    "print(config)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is derived from `test_feature_selection.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aim_3_analysis = DevAim3NestedCV()\n",
    "aim_3_analysis.load_and_preprocess_data(dropbox_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/impute/_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "aim_3_analysis.load_and_preprocess_data(analysis_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving fit with manual theory-driven feature\n",
    "\n",
    "My past analysis showed that by manually removing some features before the analysis starts, we can improve performance beyond the chance performance otherwise seen.\n",
    "\n",
    "So, it might be useful to understand how much we can improve our performance by manual feature selection before the automatic feature selection applies.\n",
    "\n",
    "This was previously done in `test_limited_predictors.ipynb`. We tested as few as 2 distractor features. In that test, predictor features generally had correlations in the range of |r|=0.06 to 0.53, with most around 0.4 (we should confirm that because it seems fishy that PCS was detegted as an effect, but didn't model as a large predictor). With most `|r|=0.4`, this seems unrealistically high to expect, and we should aim to build a pipeline capable of detecting more subtle effects than that. An approximate `|r|=0.3` can be achieved by mixing in a predictor scaled to 8% of normal scale.\n",
    "\n",
    "I can imagine it is plausible to cut down to as few as two self-report, one behavioral, and one neural measure per intervention, plus sex and age. That would yield 10 different variables. At the other end, we might want 10 self-report, two behavioral, and five neural measures per intervention tested, plus 6 different demographic variables--a total of 40 variables. Let's see how these would perform, as well as mid-range of 20 predictor variables. In each case we'll restrict to three valid predictors per intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty data frame with numeric two columns, n_features and overall_score\n",
    "overall_scores = pd.DataFrame(columns=['n_features','overall_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['BSCS', 'EDM', 'BIS_11', 'PCS', 'RS', 'TRSQ',\n",
       "       'ACES_neglectful_parenting', 'ACES_abuse', 'ACES_sum',\n",
       "       'ACES_divorced_separated', 'ACES_household_dysfunction',\n",
       "       'BFI_agreeableness', 'BFI_conscientiousness', 'BFI_extraversion',\n",
       "       'BFI_neuroticism', 'BFI_openness', 'DEMO_mcarthur_social_standing',\n",
       "       'IMI_effort_importance', 'IMI_value_usefulness',\n",
       "       'IMI_interest_enjoyment', 'IMI_perceived_choice',\n",
       "       'IMI_perceived_competence', 'NCS_get_job_done', 'NCS_intellectual_task',\n",
       "       'NCS_deliberating_issues', 'NCS_like_responsibility',\n",
       "       'NCS_thinking_not_exciting', 'NCS_avoid_depth', 'NCS_thinking_not_fun',\n",
       "       'NCS_thought_appealing', 'NCS_think_minimally', 'NCS_prefer_complex',\n",
       "       'NCS_prefer_little_thought', 'NCS_relief_not_satisfaction',\n",
       "       'NCS_tasks_little_thought', 'NCS_new_solutions_to_problems',\n",
       "       'NCS_abstract_thinking', 'NCS_total', 'NCS_small_daily_projects',\n",
       "       'NCS_solve_puzzles', 'NCS_satisfaction_in_deliberating',\n",
       "       'PLAN_cognitive_strategies', 'PLAN_mental_forecasting',\n",
       "       'PLAN_temporal_orientation', 'RMQ_lie', 'RMQ_assessment',\n",
       "       'RMQ_locomotion', 'RTFS_factor_1', 'RTFS_factor_2', 'SRHI_healthy',\n",
       "       'SRHI_unhealthy', 'SRHI_sum', 'TESQ_E_controlling_temptations',\n",
       "       'TESQ_E_avoidance_of_temptations', 'TESQ_E_distraction',\n",
       "       'TESQ_E_goal_and_rule_setting', 'TESQ_E_goal_deliberation',\n",
       "       'TESQ_E_sum', 'TESQ_E_suppression', 'SRHI_healthy_minus_unhealthy',\n",
       "       'RTFS_f1_minus_f2', 'cancer_promoting_minus_preventing_craved_FCI',\n",
       "       'cancer_promoting_minus_preventing_liked_FCI', 'cSES', 'age365',\n",
       "       'education_own', 'zipcode_median_income_acs',\n",
       "       'household_income_per_person', 'SST_prop_successful_stops',\n",
       "       'SST_GRTmean', 'SST_SSD', 'SST_PostErrorSlowW1_mean', 'SST_mean_ssrt_0',\n",
       "       'ROC_Crave_Regulate_Minus_Look', 'WTP_unhealthy_minus_healthy',\n",
       "       'birthsex_factor_Male'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_data_imputed.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.08\n",
      "1                        EDM                0.08\n",
      "2                     BIS_11               -0.08\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.10891340562308183, -0.06003743599259326, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08176779797562309\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255178</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.065261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.262595</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271499</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.084335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277201</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>0.081428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280728</td>\n",
       "      <td>0.079895</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280805</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281511</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.084321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.281915</td>\n",
       "      <td>0.075993</td>\n",
       "      <td>0.344097</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.285971</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.315441</td>\n",
       "      <td>0.048176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286894</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287454</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.340642</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.288578</td>\n",
       "      <td>0.041586</td>\n",
       "      <td>0.286704</td>\n",
       "      <td>0.072516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288602</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.353791</td>\n",
       "      <td>0.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290244</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.254771</td>\n",
       "      <td>0.039511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291442</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.078728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.292087</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>0.070562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292894</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293008</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294424</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.295521</td>\n",
       "      <td>0.065191</td>\n",
       "      <td>0.229453</td>\n",
       "      <td>0.074495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299060</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>0.041387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299651</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.228557</td>\n",
       "      <td>0.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301298</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>0.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301333</td>\n",
       "      <td>0.072146</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.305082</td>\n",
       "      <td>0.067009</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305948</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.282923</td>\n",
       "      <td>0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310575</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.333777</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310993</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312164</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313481</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.067084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.313667</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.228303</td>\n",
       "      <td>0.072135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.320649</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>0.228520</td>\n",
       "      <td>0.071249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327152</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343089</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>0.089983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.343326</td>\n",
       "      <td>0.137883</td>\n",
       "      <td>0.346256</td>\n",
       "      <td>0.098924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.343510</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.340076</td>\n",
       "      <td>0.102899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350813</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.034419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355006</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.311593</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368240</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.258145</td>\n",
       "      <td>0.031309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389879</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.102402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.394979</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.337829</td>\n",
       "      <td>0.123855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411295</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.095744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.422509</td>\n",
       "      <td>0.130699</td>\n",
       "      <td>0.321198</td>\n",
       "      <td>0.129938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.972764</td>\n",
       "      <td>0.119505</td>\n",
       "      <td>0.119505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.049022</td>\n",
       "      <td>0.049022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.392702</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.023960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.015961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.109025</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.003041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#run the analysis with a limited number of predictors\n",
    "\n",
    "overall_score = aim_3_analysis.run_full_limited_predictor_analysis(10, hyperparameter_optimizer = devcvanalysis.optimize_hypers)\n",
    "\n",
    "#overall_scores = overall_scores.append({'n_features':10,'overall_score':overall_score},ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterate through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.06\n",
      "1                        EDM                0.06\n",
      "2                     BIS_11               -0.06\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.06\n",
      "5                       TRSQ                0.06\n",
      "6  ACES_neglectful_parenting               -0.06\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.005471128834225514, -0.00421356791571359, -0.12942270885179386, -0.06211947536426354, -0.2961826357491628]\n",
      "overall_score:\n",
      "-0.09729345180934165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.204010</td>\n",
       "      <td>0.067043</td>\n",
       "      <td>0.327886</td>\n",
       "      <td>0.047794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.204673</td>\n",
       "      <td>0.072056</td>\n",
       "      <td>0.316297</td>\n",
       "      <td>0.049561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.211396</td>\n",
       "      <td>0.052455</td>\n",
       "      <td>0.317377</td>\n",
       "      <td>0.055353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.215128</td>\n",
       "      <td>0.069680</td>\n",
       "      <td>0.338412</td>\n",
       "      <td>0.045345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.216555</td>\n",
       "      <td>0.068767</td>\n",
       "      <td>0.335766</td>\n",
       "      <td>0.047779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.217758</td>\n",
       "      <td>0.069311</td>\n",
       "      <td>0.335563</td>\n",
       "      <td>0.047444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.217758</td>\n",
       "      <td>0.069311</td>\n",
       "      <td>0.335563</td>\n",
       "      <td>0.047444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.217758</td>\n",
       "      <td>0.069311</td>\n",
       "      <td>0.335563</td>\n",
       "      <td>0.047444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.218200</td>\n",
       "      <td>0.038423</td>\n",
       "      <td>0.287580</td>\n",
       "      <td>0.061849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.218688</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>0.310557</td>\n",
       "      <td>0.048016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.218688</td>\n",
       "      <td>0.054669</td>\n",
       "      <td>0.310557</td>\n",
       "      <td>0.048016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.227086</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.342413</td>\n",
       "      <td>0.044369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.227605</td>\n",
       "      <td>0.070940</td>\n",
       "      <td>0.343442</td>\n",
       "      <td>0.042166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.227762</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.343463</td>\n",
       "      <td>0.042026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.227762</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.343463</td>\n",
       "      <td>0.042026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.227762</td>\n",
       "      <td>0.070955</td>\n",
       "      <td>0.343463</td>\n",
       "      <td>0.042026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.227950</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.309744</td>\n",
       "      <td>0.052697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.228085</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.046168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.228085</td>\n",
       "      <td>0.036555</td>\n",
       "      <td>0.271611</td>\n",
       "      <td>0.046168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.233441</td>\n",
       "      <td>0.076916</td>\n",
       "      <td>0.313392</td>\n",
       "      <td>0.075334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.233441</td>\n",
       "      <td>0.076916</td>\n",
       "      <td>0.313392</td>\n",
       "      <td>0.075334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.233441</td>\n",
       "      <td>0.076916</td>\n",
       "      <td>0.313392</td>\n",
       "      <td>0.075334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.233441</td>\n",
       "      <td>0.076916</td>\n",
       "      <td>0.313392</td>\n",
       "      <td>0.075334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.237218</td>\n",
       "      <td>0.068304</td>\n",
       "      <td>0.340661</td>\n",
       "      <td>0.039982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.238490</td>\n",
       "      <td>0.069306</td>\n",
       "      <td>0.340210</td>\n",
       "      <td>0.039750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.238490</td>\n",
       "      <td>0.069306</td>\n",
       "      <td>0.340210</td>\n",
       "      <td>0.039750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.238490</td>\n",
       "      <td>0.069306</td>\n",
       "      <td>0.340210</td>\n",
       "      <td>0.039750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238503</td>\n",
       "      <td>0.069309</td>\n",
       "      <td>0.340215</td>\n",
       "      <td>0.039757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238557</td>\n",
       "      <td>0.080539</td>\n",
       "      <td>0.316811</td>\n",
       "      <td>0.069400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239615</td>\n",
       "      <td>0.072195</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.070973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.242160</td>\n",
       "      <td>0.041131</td>\n",
       "      <td>0.284209</td>\n",
       "      <td>0.067863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.244892</td>\n",
       "      <td>0.077823</td>\n",
       "      <td>0.273319</td>\n",
       "      <td>0.044806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.249991</td>\n",
       "      <td>0.082262</td>\n",
       "      <td>0.272051</td>\n",
       "      <td>0.045580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.251324</td>\n",
       "      <td>0.075186</td>\n",
       "      <td>0.337536</td>\n",
       "      <td>0.059781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.251324</td>\n",
       "      <td>0.075186</td>\n",
       "      <td>0.337536</td>\n",
       "      <td>0.059781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.251324</td>\n",
       "      <td>0.075186</td>\n",
       "      <td>0.337536</td>\n",
       "      <td>0.059781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.251324</td>\n",
       "      <td>0.075186</td>\n",
       "      <td>0.337536</td>\n",
       "      <td>0.059781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.252068</td>\n",
       "      <td>0.083197</td>\n",
       "      <td>0.341654</td>\n",
       "      <td>0.061062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.256231</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.324642</td>\n",
       "      <td>0.067822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.256799</td>\n",
       "      <td>0.081756</td>\n",
       "      <td>0.270739</td>\n",
       "      <td>0.043863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.258183</td>\n",
       "      <td>0.057543</td>\n",
       "      <td>0.326508</td>\n",
       "      <td>0.068890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.265158</td>\n",
       "      <td>0.083598</td>\n",
       "      <td>0.335244</td>\n",
       "      <td>0.074650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.265158</td>\n",
       "      <td>0.083598</td>\n",
       "      <td>0.335244</td>\n",
       "      <td>0.074650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.265158</td>\n",
       "      <td>0.083598</td>\n",
       "      <td>0.335244</td>\n",
       "      <td>0.074650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.265158</td>\n",
       "      <td>0.083598</td>\n",
       "      <td>0.335244</td>\n",
       "      <td>0.074650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.266317</td>\n",
       "      <td>0.081864</td>\n",
       "      <td>0.268917</td>\n",
       "      <td>0.042206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.270785</td>\n",
       "      <td>0.080148</td>\n",
       "      <td>0.310552</td>\n",
       "      <td>0.057020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.276409</td>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.343119</td>\n",
       "      <td>0.100641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.276409</td>\n",
       "      <td>0.100877</td>\n",
       "      <td>0.343119</td>\n",
       "      <td>0.100641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.279079</td>\n",
       "      <td>0.076263</td>\n",
       "      <td>0.302529</td>\n",
       "      <td>0.066472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.279612</td>\n",
       "      <td>0.082719</td>\n",
       "      <td>0.266247</td>\n",
       "      <td>0.040376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.280682</td>\n",
       "      <td>0.048567</td>\n",
       "      <td>0.231611</td>\n",
       "      <td>0.071208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.283463</td>\n",
       "      <td>0.081248</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.098862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.283463</td>\n",
       "      <td>0.081248</td>\n",
       "      <td>0.338890</td>\n",
       "      <td>0.098862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.284627</td>\n",
       "      <td>0.052170</td>\n",
       "      <td>0.230483</td>\n",
       "      <td>0.074828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288974</td>\n",
       "      <td>0.082766</td>\n",
       "      <td>0.264655</td>\n",
       "      <td>0.039948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.289502</td>\n",
       "      <td>0.052728</td>\n",
       "      <td>0.229387</td>\n",
       "      <td>0.073701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.289700</td>\n",
       "      <td>0.076019</td>\n",
       "      <td>0.321713</td>\n",
       "      <td>0.098752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292167</td>\n",
       "      <td>0.060146</td>\n",
       "      <td>0.248853</td>\n",
       "      <td>0.039781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.292299</td>\n",
       "      <td>0.064895</td>\n",
       "      <td>0.323139</td>\n",
       "      <td>0.098289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.296061</td>\n",
       "      <td>0.053093</td>\n",
       "      <td>0.228829</td>\n",
       "      <td>0.072142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.298680</td>\n",
       "      <td>0.064493</td>\n",
       "      <td>0.239997</td>\n",
       "      <td>0.037259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.298680</td>\n",
       "      <td>0.064493</td>\n",
       "      <td>0.239997</td>\n",
       "      <td>0.037259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301709</td>\n",
       "      <td>0.064904</td>\n",
       "      <td>0.249057</td>\n",
       "      <td>0.041879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.305601</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.241085</td>\n",
       "      <td>0.039420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.305601</td>\n",
       "      <td>0.068802</td>\n",
       "      <td>0.241085</td>\n",
       "      <td>0.039420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.305738</td>\n",
       "      <td>0.052745</td>\n",
       "      <td>0.229094</td>\n",
       "      <td>0.070030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.313507</td>\n",
       "      <td>0.051755</td>\n",
       "      <td>0.229341</td>\n",
       "      <td>0.068327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314446</td>\n",
       "      <td>0.066192</td>\n",
       "      <td>0.249478</td>\n",
       "      <td>0.040519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.315167</td>\n",
       "      <td>0.069431</td>\n",
       "      <td>0.242387</td>\n",
       "      <td>0.038540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.315167</td>\n",
       "      <td>0.069431</td>\n",
       "      <td>0.242387</td>\n",
       "      <td>0.038540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.328637</td>\n",
       "      <td>0.093687</td>\n",
       "      <td>0.289775</td>\n",
       "      <td>0.097290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.329035</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>0.243418</td>\n",
       "      <td>0.036821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329035</td>\n",
       "      <td>0.070088</td>\n",
       "      <td>0.243418</td>\n",
       "      <td>0.036821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.331299</td>\n",
       "      <td>0.067552</td>\n",
       "      <td>0.250615</td>\n",
       "      <td>0.037802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.332522</td>\n",
       "      <td>0.126564</td>\n",
       "      <td>0.309728</td>\n",
       "      <td>0.099912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340098</td>\n",
       "      <td>0.121633</td>\n",
       "      <td>0.314574</td>\n",
       "      <td>0.106744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349426</td>\n",
       "      <td>0.093261</td>\n",
       "      <td>0.272775</td>\n",
       "      <td>0.099721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.349782</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.246644</td>\n",
       "      <td>0.035021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.349782</td>\n",
       "      <td>0.070031</td>\n",
       "      <td>0.246644</td>\n",
       "      <td>0.035021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.354192</td>\n",
       "      <td>0.115542</td>\n",
       "      <td>0.295991</td>\n",
       "      <td>0.090259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.354192</td>\n",
       "      <td>0.115542</td>\n",
       "      <td>0.295991</td>\n",
       "      <td>0.090259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356072</td>\n",
       "      <td>0.068332</td>\n",
       "      <td>0.252922</td>\n",
       "      <td>0.033950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.365759</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>0.249303</td>\n",
       "      <td>0.034804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365759</td>\n",
       "      <td>0.069328</td>\n",
       "      <td>0.249303</td>\n",
       "      <td>0.034804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.370452</td>\n",
       "      <td>0.076050</td>\n",
       "      <td>0.293433</td>\n",
       "      <td>0.089745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.370452</td>\n",
       "      <td>0.076050</td>\n",
       "      <td>0.293433</td>\n",
       "      <td>0.089745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373946</td>\n",
       "      <td>0.068270</td>\n",
       "      <td>0.254250</td>\n",
       "      <td>0.031415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.647131</td>\n",
       "      <td>0.065302</td>\n",
       "      <td>0.065302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.170430</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.010150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.095414</td>\n",
       "      <td>0.003308</td>\n",
       "      <td>0.003308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.128</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.095</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.08\n",
      "1                        EDM                0.08\n",
      "2                     BIS_11               -0.08\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.10891340562308183, -0.06003743599259326, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08176779797562309\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255178</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.065261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.262595</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271499</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.084335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277201</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>0.081428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280728</td>\n",
       "      <td>0.079895</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280805</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281511</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.084321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.281915</td>\n",
       "      <td>0.075993</td>\n",
       "      <td>0.344097</td>\n",
       "      <td>0.044567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.285971</td>\n",
       "      <td>0.061448</td>\n",
       "      <td>0.315441</td>\n",
       "      <td>0.048176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286894</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287454</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.340642</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.288578</td>\n",
       "      <td>0.041586</td>\n",
       "      <td>0.286704</td>\n",
       "      <td>0.072516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288602</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.353791</td>\n",
       "      <td>0.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290244</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.254771</td>\n",
       "      <td>0.039511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291442</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.078728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.292087</td>\n",
       "      <td>0.060558</td>\n",
       "      <td>0.230580</td>\n",
       "      <td>0.070562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292894</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293008</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294424</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.295521</td>\n",
       "      <td>0.065191</td>\n",
       "      <td>0.229453</td>\n",
       "      <td>0.074495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299060</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>0.041387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.299651</td>\n",
       "      <td>0.066162</td>\n",
       "      <td>0.228557</td>\n",
       "      <td>0.073968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301298</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>0.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301333</td>\n",
       "      <td>0.072146</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.305082</td>\n",
       "      <td>0.067009</td>\n",
       "      <td>0.228113</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305948</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.282923</td>\n",
       "      <td>0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310575</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.333777</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310993</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312164</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313481</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.067084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.313667</td>\n",
       "      <td>0.067138</td>\n",
       "      <td>0.228303</td>\n",
       "      <td>0.072135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.320649</td>\n",
       "      <td>0.066578</td>\n",
       "      <td>0.228520</td>\n",
       "      <td>0.071249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324882</td>\n",
       "      <td>0.086807</td>\n",
       "      <td>0.349159</td>\n",
       "      <td>0.071484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327152</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343089</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>0.089983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.343326</td>\n",
       "      <td>0.137883</td>\n",
       "      <td>0.346256</td>\n",
       "      <td>0.098924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.343510</td>\n",
       "      <td>0.119893</td>\n",
       "      <td>0.340076</td>\n",
       "      <td>0.102899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350813</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.034419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355006</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.311593</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368240</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.258145</td>\n",
       "      <td>0.031309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389879</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.102402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.394979</td>\n",
       "      <td>0.138945</td>\n",
       "      <td>0.337829</td>\n",
       "      <td>0.123855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411295</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.095744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.422509</td>\n",
       "      <td>0.130699</td>\n",
       "      <td>0.321198</td>\n",
       "      <td>0.129938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.972764</td>\n",
       "      <td>0.119505</td>\n",
       "      <td>0.119505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.049022</td>\n",
       "      <td>0.049022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.392702</td>\n",
       "      <td>0.023960</td>\n",
       "      <td>0.023960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.015961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>0.005204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.109025</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.003821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.003787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.003041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.000429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.000175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.018</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                 0.1\n",
      "1                        EDM                 0.1\n",
      "2                     BIS_11                -0.1\n",
      "3                        PCS                 0.0\n",
      "4                         RS                 0.0\n",
      "5                       TRSQ                 0.0\n",
      "6  ACES_neglectful_parenting                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "1                        EDM                 0.0\n",
      "2                     BIS_11                 0.0\n",
      "3                        PCS                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057500158838832416, 0.0652425453399087, -0.06340593024759178, -0.10007857858537106, -0.233033673622135]\n",
      "overall_score:\n",
      "-0.05475509565527135\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280536</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.066271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282740</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.068620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285976</td>\n",
       "      <td>0.075457</td>\n",
       "      <td>0.303230</td>\n",
       "      <td>0.066774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291359</td>\n",
       "      <td>0.075054</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.064125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293160</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.257528</td>\n",
       "      <td>0.035962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294270</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.313554</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300421</td>\n",
       "      <td>0.074639</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.062179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300582</td>\n",
       "      <td>0.060656</td>\n",
       "      <td>0.258034</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.306252</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>0.062085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310130</td>\n",
       "      <td>0.062629</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.038809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.319607</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.077290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.319716</td>\n",
       "      <td>0.056735</td>\n",
       "      <td>0.236580</td>\n",
       "      <td>0.071679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.323386</td>\n",
       "      <td>0.061078</td>\n",
       "      <td>0.235028</td>\n",
       "      <td>0.075602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324294</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.258747</td>\n",
       "      <td>0.038023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326063</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.341145</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.327872</td>\n",
       "      <td>0.061889</td>\n",
       "      <td>0.233677</td>\n",
       "      <td>0.074882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.333311</td>\n",
       "      <td>0.046846</td>\n",
       "      <td>0.294311</td>\n",
       "      <td>0.068136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.333679</td>\n",
       "      <td>0.062573</td>\n",
       "      <td>0.232698</td>\n",
       "      <td>0.073931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.342525</td>\n",
       "      <td>0.062475</td>\n",
       "      <td>0.232313</td>\n",
       "      <td>0.072567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345193</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.035140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.349577</td>\n",
       "      <td>0.061872</td>\n",
       "      <td>0.231896</td>\n",
       "      <td>0.071387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352848</td>\n",
       "      <td>0.084820</td>\n",
       "      <td>0.348796</td>\n",
       "      <td>0.071307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.357044</td>\n",
       "      <td>0.066266</td>\n",
       "      <td>0.323026</td>\n",
       "      <td>0.044999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358048</td>\n",
       "      <td>0.078793</td>\n",
       "      <td>0.361033</td>\n",
       "      <td>0.046373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.359976</td>\n",
       "      <td>0.080182</td>\n",
       "      <td>0.354013</td>\n",
       "      <td>0.035563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.360595</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.259809</td>\n",
       "      <td>0.033047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.364699</td>\n",
       "      <td>0.041511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367144</td>\n",
       "      <td>0.134187</td>\n",
       "      <td>0.370470</td>\n",
       "      <td>0.090199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368761</td>\n",
       "      <td>0.078618</td>\n",
       "      <td>0.352578</td>\n",
       "      <td>0.051769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.372953</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.359609</td>\n",
       "      <td>0.043287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373126</td>\n",
       "      <td>0.122264</td>\n",
       "      <td>0.378094</td>\n",
       "      <td>0.082357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.380331</td>\n",
       "      <td>0.075514</td>\n",
       "      <td>0.362062</td>\n",
       "      <td>0.040357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383812</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390169</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.357324</td>\n",
       "      <td>0.035748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390392</td>\n",
       "      <td>0.073656</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.035560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390402</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.349142</td>\n",
       "      <td>0.105288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390518</td>\n",
       "      <td>0.080193</td>\n",
       "      <td>0.348067</td>\n",
       "      <td>0.107437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.391517</td>\n",
       "      <td>0.119728</td>\n",
       "      <td>0.361711</td>\n",
       "      <td>0.079734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418096</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.338926</td>\n",
       "      <td>0.107341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.420989</td>\n",
       "      <td>0.145629</td>\n",
       "      <td>0.347551</td>\n",
       "      <td>0.093513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.425335</td>\n",
       "      <td>0.138033</td>\n",
       "      <td>0.358507</td>\n",
       "      <td>0.088399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451667</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>0.313566</td>\n",
       "      <td>0.124625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.456979</td>\n",
       "      <td>0.082932</td>\n",
       "      <td>0.314455</td>\n",
       "      <td>0.113557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.463417</td>\n",
       "      <td>0.127703</td>\n",
       "      <td>0.335019</td>\n",
       "      <td>0.122756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.477298</td>\n",
       "      <td>0.163520</td>\n",
       "      <td>0.345219</td>\n",
       "      <td>0.120798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.499095</td>\n",
       "      <td>0.162325</td>\n",
       "      <td>0.346795</td>\n",
       "      <td>0.123544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.813027</td>\n",
       "      <td>1.682118</td>\n",
       "      <td>1.682118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.033321</td>\n",
       "      <td>1.066090</td>\n",
       "      <td>1.066090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>3.054898</td>\n",
       "      <td>1.049888</td>\n",
       "      <td>1.049888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.389706</td>\n",
       "      <td>0.668081</td>\n",
       "      <td>0.668081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.935767</td>\n",
       "      <td>0.445563</td>\n",
       "      <td>0.445563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.514676</td>\n",
       "      <td>0.272516</td>\n",
       "      <td>0.272516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.425740</td>\n",
       "      <td>0.227481</td>\n",
       "      <td>0.227481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.158152</td>\n",
       "      <td>0.150336</td>\n",
       "      <td>0.150336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-1.102637</td>\n",
       "      <td>0.142949</td>\n",
       "      <td>0.142949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.064189</td>\n",
       "      <td>0.064189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.066</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>1.066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>1.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.774</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-1.103</td>\n",
       "      <td>1.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.227</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                0.15\n",
      "1                        EDM                0.15\n",
      "2                     BIS_11               -0.15\n",
      "3                        PCS                0.00\n",
      "4                         RS                0.00\n",
      "5                       TRSQ                0.00\n",
      "6  ACES_neglectful_parenting                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.15\n",
      "5                       TRSQ                0.15\n",
      "6  ACES_neglectful_parenting               -0.15\n",
      "0                       BSCS                0.00\n",
      "1                        EDM                0.00\n",
      "2                     BIS_11                0.00\n",
      "3                        PCS                0.00\n",
      "7                 ACES_abuse                0.00\n",
      "8                   ACES_sum                0.00\n",
      "9    ACES_divorced_separated                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.16537611600226076, 0.22360590980202688, 0.10895360443227087, 0.03862980769093127, -0.20680131502929178]\n",
      "overall_score:\n",
      "0.06595282457963961\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313291</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.271523</td>\n",
       "      <td>0.038085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.314713</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.042587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.314713</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.042587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.318083</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.270421</td>\n",
       "      <td>0.040601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.318897</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.318897</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.324787</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.254367</td>\n",
       "      <td>0.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.324787</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.254367</td>\n",
       "      <td>0.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325055</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.041189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.334725</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.334725</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334893</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>0.328888</td>\n",
       "      <td>0.081433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334973</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.332893</td>\n",
       "      <td>0.078332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335664</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0.324804</td>\n",
       "      <td>0.079446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.336151</td>\n",
       "      <td>0.063554</td>\n",
       "      <td>0.266503</td>\n",
       "      <td>0.040563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.338583</td>\n",
       "      <td>0.113678</td>\n",
       "      <td>0.320940</td>\n",
       "      <td>0.077627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346590</td>\n",
       "      <td>0.112708</td>\n",
       "      <td>0.315752</td>\n",
       "      <td>0.077662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.348176</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.348176</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.351797</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.251206</td>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.351797</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.251206</td>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352976</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.313138</td>\n",
       "      <td>0.079296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354759</td>\n",
       "      <td>0.045979</td>\n",
       "      <td>0.329881</td>\n",
       "      <td>0.051990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355639</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.366802</td>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.033704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366802</td>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.033704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370572</td>\n",
       "      <td>0.065570</td>\n",
       "      <td>0.260941</td>\n",
       "      <td>0.036324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.392691</td>\n",
       "      <td>0.019855</td>\n",
       "      <td>0.266645</td>\n",
       "      <td>0.042307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.396044</td>\n",
       "      <td>0.022306</td>\n",
       "      <td>0.263786</td>\n",
       "      <td>0.046491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.401044</td>\n",
       "      <td>0.023031</td>\n",
       "      <td>0.260524</td>\n",
       "      <td>0.048475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.407883</td>\n",
       "      <td>0.024614</td>\n",
       "      <td>0.257376</td>\n",
       "      <td>0.050989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.417785</td>\n",
       "      <td>0.029084</td>\n",
       "      <td>0.255525</td>\n",
       "      <td>0.055044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.422222</td>\n",
       "      <td>0.039881</td>\n",
       "      <td>0.341340</td>\n",
       "      <td>0.055506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.425047</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>0.255666</td>\n",
       "      <td>0.058205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.433376</td>\n",
       "      <td>0.095087</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>0.091533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.471679</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.056303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.471679</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.056303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472749</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>0.371170</td>\n",
       "      <td>0.074490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.527282</td>\n",
       "      <td>0.084701</td>\n",
       "      <td>0.387274</td>\n",
       "      <td>0.102775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.538155</td>\n",
       "      <td>0.074540</td>\n",
       "      <td>0.367457</td>\n",
       "      <td>0.067556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.566573</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.388973</td>\n",
       "      <td>0.051971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.566573</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.388973</td>\n",
       "      <td>0.051971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.578664</td>\n",
       "      <td>0.088895</td>\n",
       "      <td>0.381797</td>\n",
       "      <td>0.054000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.583859</td>\n",
       "      <td>0.099309</td>\n",
       "      <td>0.396817</td>\n",
       "      <td>0.053920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.602994</td>\n",
       "      <td>0.143454</td>\n",
       "      <td>0.397971</td>\n",
       "      <td>0.125048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.603928</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.603928</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604194</td>\n",
       "      <td>0.142660</td>\n",
       "      <td>0.400596</td>\n",
       "      <td>0.123536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.608473</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>0.394455</td>\n",
       "      <td>0.129145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.609766</td>\n",
       "      <td>0.154966</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.128182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.609766</td>\n",
       "      <td>0.154966</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.128182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.610032</td>\n",
       "      <td>0.154868</td>\n",
       "      <td>0.395024</td>\n",
       "      <td>0.129202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613091</td>\n",
       "      <td>0.096461</td>\n",
       "      <td>0.379837</td>\n",
       "      <td>0.059097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616944</td>\n",
       "      <td>0.170896</td>\n",
       "      <td>0.363531</td>\n",
       "      <td>0.118143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.617682</td>\n",
       "      <td>0.090644</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>0.045920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.623825</td>\n",
       "      <td>0.182559</td>\n",
       "      <td>0.356952</td>\n",
       "      <td>0.129224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637249</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.379414</td>\n",
       "      <td>0.052483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637975</td>\n",
       "      <td>0.089121</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>0.042431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.646218</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.361509</td>\n",
       "      <td>0.071593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.646218</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.361509</td>\n",
       "      <td>0.071593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.649556</td>\n",
       "      <td>0.109065</td>\n",
       "      <td>0.380172</td>\n",
       "      <td>0.063740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650424</td>\n",
       "      <td>0.167471</td>\n",
       "      <td>0.333073</td>\n",
       "      <td>0.124623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.654022</td>\n",
       "      <td>0.094483</td>\n",
       "      <td>0.380363</td>\n",
       "      <td>0.047612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659164</td>\n",
       "      <td>0.084247</td>\n",
       "      <td>0.383653</td>\n",
       "      <td>0.044340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659532</td>\n",
       "      <td>0.147259</td>\n",
       "      <td>0.334754</td>\n",
       "      <td>0.102269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.665857</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.665857</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.667015</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>0.380291</td>\n",
       "      <td>0.043989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.691149</td>\n",
       "      <td>0.135288</td>\n",
       "      <td>0.372285</td>\n",
       "      <td>0.089277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.696987</td>\n",
       "      <td>0.148783</td>\n",
       "      <td>0.362455</td>\n",
       "      <td>0.094980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.719730</td>\n",
       "      <td>0.193939</td>\n",
       "      <td>0.334525</td>\n",
       "      <td>0.150313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.720082</td>\n",
       "      <td>0.169272</td>\n",
       "      <td>0.343955</td>\n",
       "      <td>0.151039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.680527</td>\n",
       "      <td>2.137507</td>\n",
       "      <td>2.137507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.788157</td>\n",
       "      <td>1.405222</td>\n",
       "      <td>1.405222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>3.137986</td>\n",
       "      <td>0.942479</td>\n",
       "      <td>0.942479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.020496</td>\n",
       "      <td>0.878203</td>\n",
       "      <td>0.878203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-2.427224</td>\n",
       "      <td>0.577184</td>\n",
       "      <td>0.577184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-2.250846</td>\n",
       "      <td>0.507167</td>\n",
       "      <td>0.507167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>2.177965</td>\n",
       "      <td>0.454127</td>\n",
       "      <td>0.454127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>1.802220</td>\n",
       "      <td>0.305329</td>\n",
       "      <td>0.305329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>1.597165</td>\n",
       "      <td>0.257525</td>\n",
       "      <td>0.257525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-1.214756</td>\n",
       "      <td>0.142431</td>\n",
       "      <td>0.142431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.151494</td>\n",
       "      <td>0.133708</td>\n",
       "      <td>0.133708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.037853</td>\n",
       "      <td>0.102181</td>\n",
       "      <td>0.102181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-1.056939</td>\n",
       "      <td>0.098368</td>\n",
       "      <td>0.098368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.809250</td>\n",
       "      <td>0.063450</td>\n",
       "      <td>0.063450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.722481</td>\n",
       "      <td>0.047984</td>\n",
       "      <td>0.047984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.479662</td>\n",
       "      <td>0.022814</td>\n",
       "      <td>0.022814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.441399</td>\n",
       "      <td>0.022532</td>\n",
       "      <td>0.022532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.400357</td>\n",
       "      <td>0.017881</td>\n",
       "      <td>0.017881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.374786</td>\n",
       "      <td>0.017299</td>\n",
       "      <td>0.017299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.424258</td>\n",
       "      <td>0.013982</td>\n",
       "      <td>0.013982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.375</td>\n",
       "      <td>4.681</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.017</td>\n",
       "      <td>2.138</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>2.203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.299</td>\n",
       "      <td>-3.788</td>\n",
       "      <td>-0.809</td>\n",
       "      <td>0.007</td>\n",
       "      <td>1.405</td>\n",
       "      <td>0.063</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>1.475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>1.597</td>\n",
       "      <td>-2.251</td>\n",
       "      <td>-1.215</td>\n",
       "      <td>0.258</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.142</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.441</td>\n",
       "      <td>-2.427</td>\n",
       "      <td>1.802</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.577</td>\n",
       "      <td>0.305</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.178</td>\n",
       "      <td>-0.480</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.454</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-1.057</td>\n",
       "      <td>1.151</td>\n",
       "      <td>-0.424</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.134</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                feature_name  interaction_effect\n",
      "0                       BSCS                 0.2\n",
      "1                        EDM                 0.2\n",
      "2                     BIS_11                -0.2\n",
      "3                        PCS                 0.0\n",
      "4                         RS                 0.0\n",
      "5                       TRSQ                 0.0\n",
      "6  ACES_neglectful_parenting                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.2\n",
      "5                       TRSQ                 0.2\n",
      "6  ACES_neglectful_parenting                -0.2\n",
      "0                       BSCS                 0.0\n",
      "1                        EDM                 0.0\n",
      "2                     BIS_11                 0.0\n",
      "3                        PCS                 0.0\n",
      "7                 ACES_abuse                 0.0\n",
      "8                   ACES_sum                 0.0\n",
      "9    ACES_divorced_separated                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.42479150955562195, 0.35168783658058655, 0.27644354337590515, 0.1918779999364676, -0.06388611239251407]\n",
      "overall_score:\n",
      "0.23618295541121342\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326964</td>\n",
       "      <td>0.060005</td>\n",
       "      <td>0.279462</td>\n",
       "      <td>0.053402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.329412</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.262711</td>\n",
       "      <td>0.047003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.329412</td>\n",
       "      <td>0.063789</td>\n",
       "      <td>0.262711</td>\n",
       "      <td>0.047003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330073</td>\n",
       "      <td>0.064848</td>\n",
       "      <td>0.277446</td>\n",
       "      <td>0.055342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330193</td>\n",
       "      <td>0.112270</td>\n",
       "      <td>0.291310</td>\n",
       "      <td>0.082583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.330309</td>\n",
       "      <td>0.068737</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>0.048639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.330309</td>\n",
       "      <td>0.068737</td>\n",
       "      <td>0.262526</td>\n",
       "      <td>0.048639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330407</td>\n",
       "      <td>0.114873</td>\n",
       "      <td>0.295051</td>\n",
       "      <td>0.089534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.332108</td>\n",
       "      <td>0.116356</td>\n",
       "      <td>0.298594</td>\n",
       "      <td>0.093863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.333903</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>0.045468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.333903</td>\n",
       "      <td>0.069214</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>0.045468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334478</td>\n",
       "      <td>0.110366</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.090925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335098</td>\n",
       "      <td>0.066143</td>\n",
       "      <td>0.275252</td>\n",
       "      <td>0.053542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335744</td>\n",
       "      <td>0.110128</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.074078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.341022</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>0.258635</td>\n",
       "      <td>0.041502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.341022</td>\n",
       "      <td>0.068821</td>\n",
       "      <td>0.258635</td>\n",
       "      <td>0.041502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342026</td>\n",
       "      <td>0.109787</td>\n",
       "      <td>0.282190</td>\n",
       "      <td>0.070875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342302</td>\n",
       "      <td>0.067336</td>\n",
       "      <td>0.272749</td>\n",
       "      <td>0.051150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.354809</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>0.254210</td>\n",
       "      <td>0.035973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.354809</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>0.254210</td>\n",
       "      <td>0.035973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357234</td>\n",
       "      <td>0.068175</td>\n",
       "      <td>0.268609</td>\n",
       "      <td>0.046585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.367763</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>0.252494</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.367763</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>0.252494</td>\n",
       "      <td>0.033561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370643</td>\n",
       "      <td>0.069662</td>\n",
       "      <td>0.266105</td>\n",
       "      <td>0.042640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.397921</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.313222</td>\n",
       "      <td>0.066544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.397921</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>0.313222</td>\n",
       "      <td>0.066544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406039</td>\n",
       "      <td>0.034661</td>\n",
       "      <td>0.341289</td>\n",
       "      <td>0.076134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.466504</td>\n",
       "      <td>0.044018</td>\n",
       "      <td>0.276529</td>\n",
       "      <td>0.085987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.466734</td>\n",
       "      <td>0.047232</td>\n",
       "      <td>0.271030</td>\n",
       "      <td>0.089951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.468089</td>\n",
       "      <td>0.047679</td>\n",
       "      <td>0.264568</td>\n",
       "      <td>0.087433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.472041</td>\n",
       "      <td>0.047095</td>\n",
       "      <td>0.257225</td>\n",
       "      <td>0.086747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472406</td>\n",
       "      <td>0.109389</td>\n",
       "      <td>0.347610</td>\n",
       "      <td>0.120226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.479350</td>\n",
       "      <td>0.048726</td>\n",
       "      <td>0.249566</td>\n",
       "      <td>0.085996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.485660</td>\n",
       "      <td>0.050158</td>\n",
       "      <td>0.247226</td>\n",
       "      <td>0.085528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.528894</td>\n",
       "      <td>0.058696</td>\n",
       "      <td>0.352878</td>\n",
       "      <td>0.064896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576085</td>\n",
       "      <td>0.046248</td>\n",
       "      <td>0.399176</td>\n",
       "      <td>0.086490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.581382</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.379091</td>\n",
       "      <td>0.074947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.581382</td>\n",
       "      <td>0.043571</td>\n",
       "      <td>0.379091</td>\n",
       "      <td>0.074947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.620905</td>\n",
       "      <td>0.103252</td>\n",
       "      <td>0.366041</td>\n",
       "      <td>0.117771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.699529</td>\n",
       "      <td>0.091481</td>\n",
       "      <td>0.371851</td>\n",
       "      <td>0.050194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.775611</td>\n",
       "      <td>0.105954</td>\n",
       "      <td>0.403251</td>\n",
       "      <td>0.066581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.775611</td>\n",
       "      <td>0.105954</td>\n",
       "      <td>0.403251</td>\n",
       "      <td>0.066581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.797673</td>\n",
       "      <td>0.107194</td>\n",
       "      <td>0.418345</td>\n",
       "      <td>0.073085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.829561</td>\n",
       "      <td>0.105097</td>\n",
       "      <td>0.394971</td>\n",
       "      <td>0.078443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.853314</td>\n",
       "      <td>0.147370</td>\n",
       "      <td>0.367019</td>\n",
       "      <td>0.123537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.854196</td>\n",
       "      <td>0.146843</td>\n",
       "      <td>0.364017</td>\n",
       "      <td>0.129082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.859053</td>\n",
       "      <td>0.112999</td>\n",
       "      <td>0.389540</td>\n",
       "      <td>0.065896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.880247</td>\n",
       "      <td>0.147479</td>\n",
       "      <td>0.359625</td>\n",
       "      <td>0.132714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.880247</td>\n",
       "      <td>0.147479</td>\n",
       "      <td>0.359625</td>\n",
       "      <td>0.132714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.881867</td>\n",
       "      <td>0.138261</td>\n",
       "      <td>0.332113</td>\n",
       "      <td>0.123108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.883455</td>\n",
       "      <td>0.160674</td>\n",
       "      <td>0.352620</td>\n",
       "      <td>0.116670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.884406</td>\n",
       "      <td>0.159898</td>\n",
       "      <td>0.349554</td>\n",
       "      <td>0.121390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.888058</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.888058</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.411636</td>\n",
       "      <td>0.073920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.891964</td>\n",
       "      <td>0.089509</td>\n",
       "      <td>0.411094</td>\n",
       "      <td>0.074683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.897182</td>\n",
       "      <td>0.175225</td>\n",
       "      <td>0.365002</td>\n",
       "      <td>0.116320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.897394</td>\n",
       "      <td>0.173510</td>\n",
       "      <td>0.369406</td>\n",
       "      <td>0.112216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.898965</td>\n",
       "      <td>0.176210</td>\n",
       "      <td>0.366449</td>\n",
       "      <td>0.114158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.898965</td>\n",
       "      <td>0.176210</td>\n",
       "      <td>0.366449</td>\n",
       "      <td>0.114158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.899176</td>\n",
       "      <td>0.174466</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>0.110281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.899176</td>\n",
       "      <td>0.174466</td>\n",
       "      <td>0.370777</td>\n",
       "      <td>0.110281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.908627</td>\n",
       "      <td>0.137222</td>\n",
       "      <td>0.322701</td>\n",
       "      <td>0.124140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.909885</td>\n",
       "      <td>0.102565</td>\n",
       "      <td>0.418601</td>\n",
       "      <td>0.067424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910287</td>\n",
       "      <td>0.147211</td>\n",
       "      <td>0.357729</td>\n",
       "      <td>0.094422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.916125</td>\n",
       "      <td>0.153012</td>\n",
       "      <td>0.347779</td>\n",
       "      <td>0.127476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.916125</td>\n",
       "      <td>0.153012</td>\n",
       "      <td>0.347779</td>\n",
       "      <td>0.127476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.932906</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.932906</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.932906</td>\n",
       "      <td>0.082776</td>\n",
       "      <td>0.410506</td>\n",
       "      <td>0.054758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.936044</td>\n",
       "      <td>0.112087</td>\n",
       "      <td>0.400938</td>\n",
       "      <td>0.068177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.946837</td>\n",
       "      <td>0.098889</td>\n",
       "      <td>0.413590</td>\n",
       "      <td>0.051376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.947473</td>\n",
       "      <td>0.142312</td>\n",
       "      <td>0.404690</td>\n",
       "      <td>0.106510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963130</td>\n",
       "      <td>0.106598</td>\n",
       "      <td>0.407527</td>\n",
       "      <td>0.072562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.966312</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.966312</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.966312</td>\n",
       "      <td>0.078661</td>\n",
       "      <td>0.411290</td>\n",
       "      <td>0.051092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.967226</td>\n",
       "      <td>0.118417</td>\n",
       "      <td>0.389922</td>\n",
       "      <td>0.091883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.973922</td>\n",
       "      <td>0.091090</td>\n",
       "      <td>0.409398</td>\n",
       "      <td>0.051676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.981268</td>\n",
       "      <td>0.152915</td>\n",
       "      <td>0.344353</td>\n",
       "      <td>0.071438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.981479</td>\n",
       "      <td>0.150581</td>\n",
       "      <td>0.348560</td>\n",
       "      <td>0.068686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.984806</td>\n",
       "      <td>0.098318</td>\n",
       "      <td>0.406965</td>\n",
       "      <td>0.067734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.989935</td>\n",
       "      <td>0.132474</td>\n",
       "      <td>0.396356</td>\n",
       "      <td>0.091357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.992398</td>\n",
       "      <td>0.143972</td>\n",
       "      <td>0.335512</td>\n",
       "      <td>0.101880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.993084</td>\n",
       "      <td>0.129924</td>\n",
       "      <td>0.335659</td>\n",
       "      <td>0.113346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>6.194726</td>\n",
       "      <td>3.180488</td>\n",
       "      <td>3.180488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.738392</td>\n",
       "      <td>1.890470</td>\n",
       "      <td>1.890470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>3.961708</td>\n",
       "      <td>1.316687</td>\n",
       "      <td>1.316687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.944021</td>\n",
       "      <td>1.259699</td>\n",
       "      <td>1.259699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.911378</td>\n",
       "      <td>0.719387</td>\n",
       "      <td>0.719387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>2.671417</td>\n",
       "      <td>0.603133</td>\n",
       "      <td>0.603133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-2.434931</td>\n",
       "      <td>0.494194</td>\n",
       "      <td>0.494194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.995138</td>\n",
       "      <td>0.328580</td>\n",
       "      <td>0.328580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>1.466134</td>\n",
       "      <td>0.183856</td>\n",
       "      <td>0.183856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-1.220320</td>\n",
       "      <td>0.111067</td>\n",
       "      <td>0.111067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.037504</td>\n",
       "      <td>0.085542</td>\n",
       "      <td>0.085542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.956758</td>\n",
       "      <td>0.072080</td>\n",
       "      <td>0.072080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.964943</td>\n",
       "      <td>0.071527</td>\n",
       "      <td>0.071527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.900777</td>\n",
       "      <td>0.059961</td>\n",
       "      <td>0.059961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.828148</td>\n",
       "      <td>0.050718</td>\n",
       "      <td>0.050718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.488216</td>\n",
       "      <td>0.023688</td>\n",
       "      <td>0.023688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.476118</td>\n",
       "      <td>0.019497</td>\n",
       "      <td>0.019497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.422425</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>0.016699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.337088</td>\n",
       "      <td>0.013883</td>\n",
       "      <td>0.013883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.426302</td>\n",
       "      <td>0.010604</td>\n",
       "      <td>0.010604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.426</td>\n",
       "      <td>6.195</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.011</td>\n",
       "      <td>3.180</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>3.215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.337</td>\n",
       "      <td>-4.738</td>\n",
       "      <td>-0.965</td>\n",
       "      <td>0.014</td>\n",
       "      <td>1.890</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.317</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1.317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.944</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.476</td>\n",
       "      <td>-2.435</td>\n",
       "      <td>2.911</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.218</td>\n",
       "      <td>2.671</td>\n",
       "      <td>-0.901</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>1.466</td>\n",
       "      <td>-1.995</td>\n",
       "      <td>-1.220</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.329</td>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.957</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-0.828</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.06\n",
      "2                          BIS_11               -0.06\n",
      "1                             EDM                0.06\n",
      "11              BFI_agreeableness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "6       ACES_neglectful_parenting                0.00\n",
      "5                            TRSQ                0.00\n",
      "4                              RS                0.00\n",
      "3                             PCS                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.06\n",
      "5                            TRSQ                0.06\n",
      "6       ACES_neglectful_parenting               -0.06\n",
      "0                            BSCS                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "11              BFI_agreeableness                0.00\n",
      "1                             EDM                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "3                             PCS                0.00\n",
      "2                          BIS_11                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.03790725257139016, 0.007614099576319311, -0.1334780867347567, 0.012927405740202347, -0.06409661221453966]\n",
      "overall_score:\n",
      "-0.04298808924083297\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.202030</td>\n",
       "      <td>0.069844</td>\n",
       "      <td>0.305311</td>\n",
       "      <td>0.092071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.208354</td>\n",
       "      <td>0.078154</td>\n",
       "      <td>0.326864</td>\n",
       "      <td>0.071641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.221322</td>\n",
       "      <td>0.075382</td>\n",
       "      <td>0.333762</td>\n",
       "      <td>0.047994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.224895</td>\n",
       "      <td>0.051132</td>\n",
       "      <td>0.328156</td>\n",
       "      <td>0.042945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.228983</td>\n",
       "      <td>0.051655</td>\n",
       "      <td>0.328536</td>\n",
       "      <td>0.036912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.230279</td>\n",
       "      <td>0.075144</td>\n",
       "      <td>0.341098</td>\n",
       "      <td>0.041310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.230890</td>\n",
       "      <td>0.074097</td>\n",
       "      <td>0.344558</td>\n",
       "      <td>0.037615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.230890</td>\n",
       "      <td>0.074097</td>\n",
       "      <td>0.344558</td>\n",
       "      <td>0.037615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.230890</td>\n",
       "      <td>0.074097</td>\n",
       "      <td>0.344558</td>\n",
       "      <td>0.037615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.231664</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.339783</td>\n",
       "      <td>0.025575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.231664</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.339783</td>\n",
       "      <td>0.025575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.233137</td>\n",
       "      <td>0.074836</td>\n",
       "      <td>0.338930</td>\n",
       "      <td>0.025825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238459</td>\n",
       "      <td>0.069927</td>\n",
       "      <td>0.339791</td>\n",
       "      <td>0.039034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.238708</td>\n",
       "      <td>0.069553</td>\n",
       "      <td>0.340237</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.238708</td>\n",
       "      <td>0.069553</td>\n",
       "      <td>0.340237</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.238708</td>\n",
       "      <td>0.069553</td>\n",
       "      <td>0.340237</td>\n",
       "      <td>0.039250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238818</td>\n",
       "      <td>0.069129</td>\n",
       "      <td>0.341258</td>\n",
       "      <td>0.038256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238976</td>\n",
       "      <td>0.059378</td>\n",
       "      <td>0.338551</td>\n",
       "      <td>0.036768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238979</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.330091</td>\n",
       "      <td>0.070798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238979</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.330091</td>\n",
       "      <td>0.070798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238979</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.330091</td>\n",
       "      <td>0.070798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238979</td>\n",
       "      <td>0.079157</td>\n",
       "      <td>0.330091</td>\n",
       "      <td>0.070798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.069861</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.038404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.241002</td>\n",
       "      <td>0.044845</td>\n",
       "      <td>0.331029</td>\n",
       "      <td>0.031106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.248802</td>\n",
       "      <td>0.028598</td>\n",
       "      <td>0.310847</td>\n",
       "      <td>0.036655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.251788</td>\n",
       "      <td>0.101195</td>\n",
       "      <td>0.314336</td>\n",
       "      <td>0.107965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.254837</td>\n",
       "      <td>0.091950</td>\n",
       "      <td>0.307576</td>\n",
       "      <td>0.100922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.259242</td>\n",
       "      <td>0.048404</td>\n",
       "      <td>0.279921</td>\n",
       "      <td>0.048965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.259928</td>\n",
       "      <td>0.077028</td>\n",
       "      <td>0.329368</td>\n",
       "      <td>0.028705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.267933</td>\n",
       "      <td>0.047204</td>\n",
       "      <td>0.290474</td>\n",
       "      <td>0.057333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.272279</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.346504</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.272279</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.346504</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.272279</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.346504</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.272279</td>\n",
       "      <td>0.078067</td>\n",
       "      <td>0.346504</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.275021</td>\n",
       "      <td>0.028486</td>\n",
       "      <td>0.271291</td>\n",
       "      <td>0.058149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.276064</td>\n",
       "      <td>0.031223</td>\n",
       "      <td>0.270693</td>\n",
       "      <td>0.061465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277221</td>\n",
       "      <td>0.032422</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.061230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.278649</td>\n",
       "      <td>0.079935</td>\n",
       "      <td>0.325920</td>\n",
       "      <td>0.077147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.278777</td>\n",
       "      <td>0.034107</td>\n",
       "      <td>0.268888</td>\n",
       "      <td>0.060866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280110</td>\n",
       "      <td>0.115227</td>\n",
       "      <td>0.361149</td>\n",
       "      <td>0.054828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280825</td>\n",
       "      <td>0.036365</td>\n",
       "      <td>0.267338</td>\n",
       "      <td>0.060495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.282014</td>\n",
       "      <td>0.075796</td>\n",
       "      <td>0.324195</td>\n",
       "      <td>0.029698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282153</td>\n",
       "      <td>0.037451</td>\n",
       "      <td>0.266387</td>\n",
       "      <td>0.060413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282272</td>\n",
       "      <td>0.116083</td>\n",
       "      <td>0.364163</td>\n",
       "      <td>0.059298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.284311</td>\n",
       "      <td>0.074918</td>\n",
       "      <td>0.342889</td>\n",
       "      <td>0.072506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.284311</td>\n",
       "      <td>0.074918</td>\n",
       "      <td>0.342889</td>\n",
       "      <td>0.072506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.284311</td>\n",
       "      <td>0.074918</td>\n",
       "      <td>0.342889</td>\n",
       "      <td>0.072506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.284311</td>\n",
       "      <td>0.074918</td>\n",
       "      <td>0.342889</td>\n",
       "      <td>0.072506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.284447</td>\n",
       "      <td>0.061439</td>\n",
       "      <td>0.343389</td>\n",
       "      <td>0.071251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.284447</td>\n",
       "      <td>0.061439</td>\n",
       "      <td>0.343389</td>\n",
       "      <td>0.071251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.284447</td>\n",
       "      <td>0.061439</td>\n",
       "      <td>0.343389</td>\n",
       "      <td>0.071251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.284447</td>\n",
       "      <td>0.061439</td>\n",
       "      <td>0.343389</td>\n",
       "      <td>0.071251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.285170</td>\n",
       "      <td>0.070475</td>\n",
       "      <td>0.316074</td>\n",
       "      <td>0.071860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.287362</td>\n",
       "      <td>0.078933</td>\n",
       "      <td>0.325145</td>\n",
       "      <td>0.077364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.289857</td>\n",
       "      <td>0.044045</td>\n",
       "      <td>0.338772</td>\n",
       "      <td>0.068558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.291364</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.338476</td>\n",
       "      <td>0.068385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.291364</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.338476</td>\n",
       "      <td>0.068385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.291364</td>\n",
       "      <td>0.043440</td>\n",
       "      <td>0.338476</td>\n",
       "      <td>0.068385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.293883</td>\n",
       "      <td>0.070334</td>\n",
       "      <td>0.314903</td>\n",
       "      <td>0.072174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.296048</td>\n",
       "      <td>0.095275</td>\n",
       "      <td>0.320751</td>\n",
       "      <td>0.066440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.297684</td>\n",
       "      <td>0.092775</td>\n",
       "      <td>0.317628</td>\n",
       "      <td>0.061717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305014</td>\n",
       "      <td>0.121591</td>\n",
       "      <td>0.229961</td>\n",
       "      <td>0.117932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.316037</td>\n",
       "      <td>0.133238</td>\n",
       "      <td>0.229117</td>\n",
       "      <td>0.126887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.323140</td>\n",
       "      <td>0.098797</td>\n",
       "      <td>0.290465</td>\n",
       "      <td>0.084513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.328780</td>\n",
       "      <td>0.137968</td>\n",
       "      <td>0.228443</td>\n",
       "      <td>0.129632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.332731</td>\n",
       "      <td>0.105786</td>\n",
       "      <td>0.321695</td>\n",
       "      <td>0.055032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337421</td>\n",
       "      <td>0.092369</td>\n",
       "      <td>0.327687</td>\n",
       "      <td>0.054747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346180</td>\n",
       "      <td>0.142345</td>\n",
       "      <td>0.227734</td>\n",
       "      <td>0.133159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349888</td>\n",
       "      <td>0.140378</td>\n",
       "      <td>0.250890</td>\n",
       "      <td>0.126212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.350273</td>\n",
       "      <td>0.087251</td>\n",
       "      <td>0.288961</td>\n",
       "      <td>0.078390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.357944</td>\n",
       "      <td>0.037504</td>\n",
       "      <td>0.275607</td>\n",
       "      <td>0.116081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.362624</td>\n",
       "      <td>0.104453</td>\n",
       "      <td>0.290231</td>\n",
       "      <td>0.048179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363969</td>\n",
       "      <td>0.134268</td>\n",
       "      <td>0.241368</td>\n",
       "      <td>0.129226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.371199</td>\n",
       "      <td>0.113376</td>\n",
       "      <td>0.288360</td>\n",
       "      <td>0.052905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373186</td>\n",
       "      <td>0.145066</td>\n",
       "      <td>0.226780</td>\n",
       "      <td>0.136859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.379066</td>\n",
       "      <td>0.059758</td>\n",
       "      <td>0.285189</td>\n",
       "      <td>0.074982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.381172</td>\n",
       "      <td>0.116601</td>\n",
       "      <td>0.286381</td>\n",
       "      <td>0.055077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.387625</td>\n",
       "      <td>0.034618</td>\n",
       "      <td>0.261127</td>\n",
       "      <td>0.112441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.391423</td>\n",
       "      <td>0.145489</td>\n",
       "      <td>0.226311</td>\n",
       "      <td>0.138922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.392889</td>\n",
       "      <td>0.120755</td>\n",
       "      <td>0.284126</td>\n",
       "      <td>0.057926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.407745</td>\n",
       "      <td>0.126565</td>\n",
       "      <td>0.281444</td>\n",
       "      <td>0.062503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.412012</td>\n",
       "      <td>0.074664</td>\n",
       "      <td>0.261547</td>\n",
       "      <td>0.062332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.419092</td>\n",
       "      <td>0.130486</td>\n",
       "      <td>0.279999</td>\n",
       "      <td>0.067895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.511746</td>\n",
       "      <td>0.053848</td>\n",
       "      <td>0.227192</td>\n",
       "      <td>0.059518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.532936</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.062439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.558846</td>\n",
       "      <td>0.062975</td>\n",
       "      <td>0.226509</td>\n",
       "      <td>0.062751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.592930</td>\n",
       "      <td>0.068502</td>\n",
       "      <td>0.228719</td>\n",
       "      <td>0.066813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.597857</td>\n",
       "      <td>0.139916</td>\n",
       "      <td>0.242899</td>\n",
       "      <td>0.045590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.624739</td>\n",
       "      <td>0.151732</td>\n",
       "      <td>0.244803</td>\n",
       "      <td>0.048008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.639038</td>\n",
       "      <td>0.077625</td>\n",
       "      <td>0.233985</td>\n",
       "      <td>0.074891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657770</td>\n",
       "      <td>0.154936</td>\n",
       "      <td>0.247311</td>\n",
       "      <td>0.049438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.670637</td>\n",
       "      <td>0.084591</td>\n",
       "      <td>0.239378</td>\n",
       "      <td>0.080795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.699976</td>\n",
       "      <td>0.159349</td>\n",
       "      <td>0.251448</td>\n",
       "      <td>0.054731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.758566</td>\n",
       "      <td>0.166232</td>\n",
       "      <td>0.259346</td>\n",
       "      <td>0.070973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.802555</td>\n",
       "      <td>0.175913</td>\n",
       "      <td>0.267701</td>\n",
       "      <td>0.086915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.133527</td>\n",
       "      <td>0.169783</td>\n",
       "      <td>0.169783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.716540</td>\n",
       "      <td>0.078902</td>\n",
       "      <td>0.078902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.293282</td>\n",
       "      <td>0.012499</td>\n",
       "      <td>0.012499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.230681</td>\n",
       "      <td>0.008880</td>\n",
       "      <td>0.008880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.162136</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.005160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.144958</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.004067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.141542</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.045777</td>\n",
       "      <td>0.001405</td>\n",
       "      <td>0.001405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.021932</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACES_divorced_separated</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.134</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.277</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.293</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.170</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.046</td>\n",
       "      <td>-0.231</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.145</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "11              BFI_agreeableness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "6       ACES_neglectful_parenting                0.00\n",
      "5                            TRSQ                0.00\n",
      "4                              RS                0.00\n",
      "3                             PCS                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.08\n",
      "5                            TRSQ                0.08\n",
      "6       ACES_neglectful_parenting               -0.08\n",
      "0                            BSCS                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "11              BFI_agreeableness                0.00\n",
      "1                             EDM                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "3                             PCS                0.00\n",
      "2                          BIS_11                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.019391378692160455, 0.05103383687350138, -0.12333443118999532, -0.04514095692852438, -0.3178977602412687]\n",
      "overall_score:\n",
      "-0.09094613803568949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268368</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.096481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269053</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.333186</td>\n",
       "      <td>0.078243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.280129</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.334510</td>\n",
       "      <td>0.041095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285580</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>0.341224</td>\n",
       "      <td>0.051844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.285924</td>\n",
       "      <td>0.054509</td>\n",
       "      <td>0.336622</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292086</td>\n",
       "      <td>0.054613</td>\n",
       "      <td>0.331360</td>\n",
       "      <td>0.084547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292451</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.352444</td>\n",
       "      <td>0.044752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.292899</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.288927</td>\n",
       "      <td>0.042831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292916</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.060843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294701</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.316998</td>\n",
       "      <td>0.098707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.296873</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.300339</td>\n",
       "      <td>0.052913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.297910</td>\n",
       "      <td>0.083830</td>\n",
       "      <td>0.349752</td>\n",
       "      <td>0.023424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298140</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.350294</td>\n",
       "      <td>0.034471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299520</td>\n",
       "      <td>0.070640</td>\n",
       "      <td>0.352882</td>\n",
       "      <td>0.037559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301337</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303547</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.037851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304050</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.335633</td>\n",
       "      <td>0.031791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313860</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.038524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.319412</td>\n",
       "      <td>0.086520</td>\n",
       "      <td>0.345630</td>\n",
       "      <td>0.026971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.334056</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.337450</td>\n",
       "      <td>0.095239</td>\n",
       "      <td>0.363220</td>\n",
       "      <td>0.077932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.337593</td>\n",
       "      <td>0.087906</td>\n",
       "      <td>0.339245</td>\n",
       "      <td>0.027032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340945</td>\n",
       "      <td>0.084623</td>\n",
       "      <td>0.361801</td>\n",
       "      <td>0.066980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343701</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.296362</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345577</td>\n",
       "      <td>0.029533</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.050156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.347661</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>0.291765</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350004</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>0.044666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352859</td>\n",
       "      <td>0.113390</td>\n",
       "      <td>0.262172</td>\n",
       "      <td>0.080464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353069</td>\n",
       "      <td>0.031679</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.040813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354948</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.284664</td>\n",
       "      <td>0.038697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356086</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.378191</td>\n",
       "      <td>0.069583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358045</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>0.072911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363721</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.083742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377219</td>\n",
       "      <td>0.122091</td>\n",
       "      <td>0.261163</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.377618</td>\n",
       "      <td>0.090508</td>\n",
       "      <td>0.346471</td>\n",
       "      <td>0.056866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.378890</td>\n",
       "      <td>0.083203</td>\n",
       "      <td>0.344019</td>\n",
       "      <td>0.051012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382975</td>\n",
       "      <td>0.105867</td>\n",
       "      <td>0.364802</td>\n",
       "      <td>0.059270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385794</td>\n",
       "      <td>0.096559</td>\n",
       "      <td>0.279813</td>\n",
       "      <td>0.096009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.386599</td>\n",
       "      <td>0.102026</td>\n",
       "      <td>0.316222</td>\n",
       "      <td>0.035314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393042</td>\n",
       "      <td>0.101054</td>\n",
       "      <td>0.362567</td>\n",
       "      <td>0.065183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.393614</td>\n",
       "      <td>0.109171</td>\n",
       "      <td>0.314859</td>\n",
       "      <td>0.040052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394098</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>0.260901</td>\n",
       "      <td>0.082618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.395871</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.264513</td>\n",
       "      <td>0.109018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.402055</td>\n",
       "      <td>0.110265</td>\n",
       "      <td>0.313004</td>\n",
       "      <td>0.043196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.412225</td>\n",
       "      <td>0.111472</td>\n",
       "      <td>0.310599</td>\n",
       "      <td>0.047198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418324</td>\n",
       "      <td>0.122146</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.418916</td>\n",
       "      <td>0.100508</td>\n",
       "      <td>0.330330</td>\n",
       "      <td>0.061356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.426821</td>\n",
       "      <td>0.112532</td>\n",
       "      <td>0.306588</td>\n",
       "      <td>0.053843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.434039</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.260568</td>\n",
       "      <td>0.081751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.438511</td>\n",
       "      <td>0.112760</td>\n",
       "      <td>0.304221</td>\n",
       "      <td>0.060014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.457834</td>\n",
       "      <td>0.086374</td>\n",
       "      <td>0.320605</td>\n",
       "      <td>0.050275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.477451</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.334278</td>\n",
       "      <td>0.102502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.500804</td>\n",
       "      <td>0.105517</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.071442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.505197</td>\n",
       "      <td>0.114893</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.095465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.519583</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.228225</td>\n",
       "      <td>0.064166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.538924</td>\n",
       "      <td>0.085158</td>\n",
       "      <td>0.227874</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.542032</td>\n",
       "      <td>0.120523</td>\n",
       "      <td>0.283429</td>\n",
       "      <td>0.055724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.563269</td>\n",
       "      <td>0.087077</td>\n",
       "      <td>0.226925</td>\n",
       "      <td>0.069061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.594981</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>0.069227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.598507</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.048030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.624750</td>\n",
       "      <td>0.152260</td>\n",
       "      <td>0.245901</td>\n",
       "      <td>0.049912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.639746</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.228980</td>\n",
       "      <td>0.067778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657535</td>\n",
       "      <td>0.155708</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>0.050784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.670994</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>0.232621</td>\n",
       "      <td>0.068573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.699242</td>\n",
       "      <td>0.159485</td>\n",
       "      <td>0.251567</td>\n",
       "      <td>0.055429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757841</td>\n",
       "      <td>0.166070</td>\n",
       "      <td>0.259378</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801947</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>0.267642</td>\n",
       "      <td>0.086866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.371292</td>\n",
       "      <td>0.371292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.097368</td>\n",
       "      <td>0.097368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.060679</td>\n",
       "      <td>0.060679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.025208</td>\n",
       "      <td>0.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.011571</td>\n",
       "      <td>0.011571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.005014</td>\n",
       "      <td>0.005014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.002590</td>\n",
       "      <td>0.002590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.1\n",
      "2                          BIS_11                -0.1\n",
      "1                             EDM                 0.1\n",
      "11              BFI_agreeableness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "6       ACES_neglectful_parenting                 0.0\n",
      "5                            TRSQ                 0.0\n",
      "4                              RS                 0.0\n",
      "3                             PCS                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.1\n",
      "5                            TRSQ                 0.1\n",
      "6       ACES_neglectful_parenting                -0.1\n",
      "0                            BSCS                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "11              BFI_agreeableness                 0.0\n",
      "1                             EDM                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "3                             PCS                 0.0\n",
      "2                          BIS_11                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.036906016757977333, 0.025163581636640342, 0.04604500169276293, -0.03671511219721468, -0.2969751146633599]\n",
      "overall_score:\n",
      "-0.045115125354638796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304918</td>\n",
       "      <td>0.063440</td>\n",
       "      <td>0.327492</td>\n",
       "      <td>0.108845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.327857</td>\n",
       "      <td>0.051110</td>\n",
       "      <td>0.296022</td>\n",
       "      <td>0.041828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334020</td>\n",
       "      <td>0.065040</td>\n",
       "      <td>0.340143</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.335768</td>\n",
       "      <td>0.053351</td>\n",
       "      <td>0.362784</td>\n",
       "      <td>0.084018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.337082</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.054855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.337902</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.341664</td>\n",
       "      <td>0.040095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.346496</td>\n",
       "      <td>0.056844</td>\n",
       "      <td>0.367956</td>\n",
       "      <td>0.079664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.347777</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.344863</td>\n",
       "      <td>0.033602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350320</td>\n",
       "      <td>0.117292</td>\n",
       "      <td>0.353507</td>\n",
       "      <td>0.102274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351489</td>\n",
       "      <td>0.111644</td>\n",
       "      <td>0.349906</td>\n",
       "      <td>0.099458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358653</td>\n",
       "      <td>0.106210</td>\n",
       "      <td>0.355172</td>\n",
       "      <td>0.088062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366980</td>\n",
       "      <td>0.122583</td>\n",
       "      <td>0.270095</td>\n",
       "      <td>0.111870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367200</td>\n",
       "      <td>0.114957</td>\n",
       "      <td>0.348451</td>\n",
       "      <td>0.071526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367622</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.353349</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.369659</td>\n",
       "      <td>0.116962</td>\n",
       "      <td>0.397206</td>\n",
       "      <td>0.148957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371729</td>\n",
       "      <td>0.077081</td>\n",
       "      <td>0.360293</td>\n",
       "      <td>0.045193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.375474</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.375474</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.377225</td>\n",
       "      <td>0.117343</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.154579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377600</td>\n",
       "      <td>0.131883</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.116884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.379671</td>\n",
       "      <td>0.090425</td>\n",
       "      <td>0.360816</td>\n",
       "      <td>0.014249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.380388</td>\n",
       "      <td>0.113346</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.148274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381142</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>0.356833</td>\n",
       "      <td>0.035260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382589</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>0.360971</td>\n",
       "      <td>0.037757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383239</td>\n",
       "      <td>0.075651</td>\n",
       "      <td>0.359666</td>\n",
       "      <td>0.041389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384915</td>\n",
       "      <td>0.049051</td>\n",
       "      <td>0.323918</td>\n",
       "      <td>0.060162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385893</td>\n",
       "      <td>0.063549</td>\n",
       "      <td>0.342065</td>\n",
       "      <td>0.039767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.387954</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.393366</td>\n",
       "      <td>0.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389257</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.358666</td>\n",
       "      <td>0.038876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390156</td>\n",
       "      <td>0.073377</td>\n",
       "      <td>0.357355</td>\n",
       "      <td>0.035709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390666</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.270984</td>\n",
       "      <td>0.116302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.395265</td>\n",
       "      <td>0.088710</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.042644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.398889</td>\n",
       "      <td>0.094104</td>\n",
       "      <td>0.353345</td>\n",
       "      <td>0.028711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406948</td>\n",
       "      <td>0.133007</td>\n",
       "      <td>0.272066</td>\n",
       "      <td>0.116533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.411962</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.375773</td>\n",
       "      <td>0.078904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.412851</td>\n",
       "      <td>0.088866</td>\n",
       "      <td>0.365440</td>\n",
       "      <td>0.058655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.413691</td>\n",
       "      <td>0.093085</td>\n",
       "      <td>0.328533</td>\n",
       "      <td>0.040238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.414383</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.288433</td>\n",
       "      <td>0.074842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415649</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.287326</td>\n",
       "      <td>0.079088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417229</td>\n",
       "      <td>0.045047</td>\n",
       "      <td>0.286014</td>\n",
       "      <td>0.078473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.419315</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.077652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.419564</td>\n",
       "      <td>0.099935</td>\n",
       "      <td>0.327006</td>\n",
       "      <td>0.044877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422146</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.076469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424069</td>\n",
       "      <td>0.051138</td>\n",
       "      <td>0.279994</td>\n",
       "      <td>0.075691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.426593</td>\n",
       "      <td>0.101443</td>\n",
       "      <td>0.325380</td>\n",
       "      <td>0.047330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.427004</td>\n",
       "      <td>0.048375</td>\n",
       "      <td>0.345488</td>\n",
       "      <td>0.061010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429332</td>\n",
       "      <td>0.133071</td>\n",
       "      <td>0.274467</td>\n",
       "      <td>0.117681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.435419</td>\n",
       "      <td>0.103101</td>\n",
       "      <td>0.323209</td>\n",
       "      <td>0.050025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.439828</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.300332</td>\n",
       "      <td>0.085673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.440957</td>\n",
       "      <td>0.105746</td>\n",
       "      <td>0.375967</td>\n",
       "      <td>0.070364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442223</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>0.377347</td>\n",
       "      <td>0.071956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.445347</td>\n",
       "      <td>0.132983</td>\n",
       "      <td>0.275069</td>\n",
       "      <td>0.118392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.449142</td>\n",
       "      <td>0.105225</td>\n",
       "      <td>0.318572</td>\n",
       "      <td>0.054309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451289</td>\n",
       "      <td>0.121726</td>\n",
       "      <td>0.277875</td>\n",
       "      <td>0.104293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454277</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.367305</td>\n",
       "      <td>0.082260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.457457</td>\n",
       "      <td>0.057614</td>\n",
       "      <td>0.343289</td>\n",
       "      <td>0.067609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.459055</td>\n",
       "      <td>0.106121</td>\n",
       "      <td>0.314673</td>\n",
       "      <td>0.058155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461667</td>\n",
       "      <td>0.095021</td>\n",
       "      <td>0.368599</td>\n",
       "      <td>0.082677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.493914</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.343536</td>\n",
       "      <td>0.191704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.509312</td>\n",
       "      <td>0.103322</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.512424</td>\n",
       "      <td>0.118686</td>\n",
       "      <td>0.312746</td>\n",
       "      <td>0.121671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.521362</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.354846</td>\n",
       "      <td>0.201077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.527624</td>\n",
       "      <td>0.111501</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.087882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.542496</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.322420</td>\n",
       "      <td>0.125426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.550410</td>\n",
       "      <td>0.114304</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.090646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.579715</td>\n",
       "      <td>0.117324</td>\n",
       "      <td>0.236668</td>\n",
       "      <td>0.093520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.599810</td>\n",
       "      <td>0.140503</td>\n",
       "      <td>0.244955</td>\n",
       "      <td>0.050022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.618827</td>\n",
       "      <td>0.120688</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.099021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.625576</td>\n",
       "      <td>0.152676</td>\n",
       "      <td>0.247007</td>\n",
       "      <td>0.052265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.647562</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.240094</td>\n",
       "      <td>0.105328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657793</td>\n",
       "      <td>0.156621</td>\n",
       "      <td>0.248994</td>\n",
       "      <td>0.052303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698816</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.251970</td>\n",
       "      <td>0.056410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757104</td>\n",
       "      <td>0.165911</td>\n",
       "      <td>0.259432</td>\n",
       "      <td>0.070998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801342</td>\n",
       "      <td>0.175274</td>\n",
       "      <td>0.267585</td>\n",
       "      <td>0.086837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.341333</td>\n",
       "      <td>0.648330</td>\n",
       "      <td>0.648330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.260258</td>\n",
       "      <td>0.215655</td>\n",
       "      <td>0.215655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.108059</td>\n",
       "      <td>0.108059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.544510</td>\n",
       "      <td>0.038063</td>\n",
       "      <td>0.038063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.232784</td>\n",
       "      <td>0.010994</td>\n",
       "      <td>0.010994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.182961</td>\n",
       "      <td>0.003156</td>\n",
       "      <td>0.003156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.085507</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.001820</td>\n",
       "      <td>0.001820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.341</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.648</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.038</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.15\n",
      "2                          BIS_11               -0.15\n",
      "1                             EDM                0.15\n",
      "11              BFI_agreeableness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "6       ACES_neglectful_parenting                0.00\n",
      "5                            TRSQ                0.00\n",
      "4                              RS                0.00\n",
      "3                             PCS                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.15\n",
      "5                            TRSQ                0.15\n",
      "6       ACES_neglectful_parenting               -0.15\n",
      "0                            BSCS                0.00\n",
      "12          BFI_conscientiousness                0.00\n",
      "18           IMI_value_usefulness                0.00\n",
      "17          IMI_effort_importance                0.00\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "15                   BFI_openness                0.00\n",
      "14                BFI_neuroticism                0.00\n",
      "13               BFI_extraversion                0.00\n",
      "10     ACES_household_dysfunction                0.00\n",
      "11              BFI_agreeableness                0.00\n",
      "1                             EDM                0.00\n",
      "9         ACES_divorced_separated                0.00\n",
      "8                        ACES_sum                0.00\n",
      "7                      ACES_abuse                0.00\n",
      "3                             PCS                0.00\n",
      "2                          BIS_11                0.00\n",
      "19         IMI_interest_enjoyment                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14229584469909184, 0.1879671778025348, 0.04247364456357472, 0.04741943460717779, -0.15101611362189882]\n",
      "overall_score:\n",
      "0.053827997610096066\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377097</td>\n",
       "      <td>0.124330</td>\n",
       "      <td>0.284815</td>\n",
       "      <td>0.087641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383615</td>\n",
       "      <td>0.133127</td>\n",
       "      <td>0.284997</td>\n",
       "      <td>0.090062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.391861</td>\n",
       "      <td>0.134964</td>\n",
       "      <td>0.285635</td>\n",
       "      <td>0.087538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.394726</td>\n",
       "      <td>0.061698</td>\n",
       "      <td>0.308553</td>\n",
       "      <td>0.048312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.404271</td>\n",
       "      <td>0.081683</td>\n",
       "      <td>0.346506</td>\n",
       "      <td>0.127971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.404940</td>\n",
       "      <td>0.135625</td>\n",
       "      <td>0.286143</td>\n",
       "      <td>0.089377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.417786</td>\n",
       "      <td>0.040339</td>\n",
       "      <td>0.326011</td>\n",
       "      <td>0.057091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424432</td>\n",
       "      <td>0.138098</td>\n",
       "      <td>0.286814</td>\n",
       "      <td>0.095462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.438921</td>\n",
       "      <td>0.139859</td>\n",
       "      <td>0.285378</td>\n",
       "      <td>0.099814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.496381</td>\n",
       "      <td>0.075096</td>\n",
       "      <td>0.361540</td>\n",
       "      <td>0.093659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.496963</td>\n",
       "      <td>0.052984</td>\n",
       "      <td>0.365331</td>\n",
       "      <td>0.040388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.520371</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.366708</td>\n",
       "      <td>0.038246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.544658</td>\n",
       "      <td>0.156017</td>\n",
       "      <td>0.229578</td>\n",
       "      <td>0.053051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.562335</td>\n",
       "      <td>0.170752</td>\n",
       "      <td>0.229039</td>\n",
       "      <td>0.061278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.568284</td>\n",
       "      <td>0.106801</td>\n",
       "      <td>0.333143</td>\n",
       "      <td>0.078437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.568359</td>\n",
       "      <td>0.094322</td>\n",
       "      <td>0.339527</td>\n",
       "      <td>0.072222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.568495</td>\n",
       "      <td>0.102862</td>\n",
       "      <td>0.336545</td>\n",
       "      <td>0.077472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.568849</td>\n",
       "      <td>0.110812</td>\n",
       "      <td>0.328276</td>\n",
       "      <td>0.079287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.569042</td>\n",
       "      <td>0.068080</td>\n",
       "      <td>0.388329</td>\n",
       "      <td>0.048557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.574695</td>\n",
       "      <td>0.111262</td>\n",
       "      <td>0.323367</td>\n",
       "      <td>0.077858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.580586</td>\n",
       "      <td>0.110869</td>\n",
       "      <td>0.321150</td>\n",
       "      <td>0.076471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.585505</td>\n",
       "      <td>0.175437</td>\n",
       "      <td>0.227299</td>\n",
       "      <td>0.069132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.591659</td>\n",
       "      <td>0.092798</td>\n",
       "      <td>0.387011</td>\n",
       "      <td>0.046857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.591889</td>\n",
       "      <td>0.092762</td>\n",
       "      <td>0.387352</td>\n",
       "      <td>0.173893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.593347</td>\n",
       "      <td>0.094577</td>\n",
       "      <td>0.386532</td>\n",
       "      <td>0.047247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.594498</td>\n",
       "      <td>0.089764</td>\n",
       "      <td>0.385613</td>\n",
       "      <td>0.182849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.606727</td>\n",
       "      <td>0.112672</td>\n",
       "      <td>0.389514</td>\n",
       "      <td>0.172909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.606771</td>\n",
       "      <td>0.141492</td>\n",
       "      <td>0.246404</td>\n",
       "      <td>0.053491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607490</td>\n",
       "      <td>0.150647</td>\n",
       "      <td>0.389213</td>\n",
       "      <td>0.084252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607631</td>\n",
       "      <td>0.096018</td>\n",
       "      <td>0.376481</td>\n",
       "      <td>0.051644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.609336</td>\n",
       "      <td>0.108535</td>\n",
       "      <td>0.388114</td>\n",
       "      <td>0.181784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.609457</td>\n",
       "      <td>0.078423</td>\n",
       "      <td>0.404079</td>\n",
       "      <td>0.130536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.610638</td>\n",
       "      <td>0.091259</td>\n",
       "      <td>0.388787</td>\n",
       "      <td>0.051168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.613089</td>\n",
       "      <td>0.084043</td>\n",
       "      <td>0.399064</td>\n",
       "      <td>0.138116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.615328</td>\n",
       "      <td>0.179682</td>\n",
       "      <td>0.225767</td>\n",
       "      <td>0.079044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.618304</td>\n",
       "      <td>0.086786</td>\n",
       "      <td>0.395546</td>\n",
       "      <td>0.044336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.618692</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.044483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.618692</td>\n",
       "      <td>0.087155</td>\n",
       "      <td>0.395509</td>\n",
       "      <td>0.044483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.624523</td>\n",
       "      <td>0.099318</td>\n",
       "      <td>0.380033</td>\n",
       "      <td>0.052112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.626198</td>\n",
       "      <td>0.086321</td>\n",
       "      <td>0.363050</td>\n",
       "      <td>0.065023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.627680</td>\n",
       "      <td>0.166536</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.114289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.630387</td>\n",
       "      <td>0.154036</td>\n",
       "      <td>0.248173</td>\n",
       "      <td>0.057058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.632062</td>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.338714</td>\n",
       "      <td>0.077206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.632285</td>\n",
       "      <td>0.088044</td>\n",
       "      <td>0.376887</td>\n",
       "      <td>0.052557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.633957</td>\n",
       "      <td>0.089411</td>\n",
       "      <td>0.384956</td>\n",
       "      <td>0.047891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.634760</td>\n",
       "      <td>0.044708</td>\n",
       "      <td>0.386109</td>\n",
       "      <td>0.237121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.636089</td>\n",
       "      <td>0.178021</td>\n",
       "      <td>0.397129</td>\n",
       "      <td>0.122598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.637621</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.390919</td>\n",
       "      <td>0.043028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.637621</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.390919</td>\n",
       "      <td>0.043028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.637621</td>\n",
       "      <td>0.087262</td>\n",
       "      <td>0.390919</td>\n",
       "      <td>0.043028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.641514</td>\n",
       "      <td>0.084159</td>\n",
       "      <td>0.383577</td>\n",
       "      <td>0.045970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646467</td>\n",
       "      <td>0.100677</td>\n",
       "      <td>0.285384</td>\n",
       "      <td>0.115490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646578</td>\n",
       "      <td>0.100550</td>\n",
       "      <td>0.286447</td>\n",
       "      <td>0.114001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646733</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.288402</td>\n",
       "      <td>0.111431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646965</td>\n",
       "      <td>0.099447</td>\n",
       "      <td>0.290084</td>\n",
       "      <td>0.109209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.647238</td>\n",
       "      <td>0.098768</td>\n",
       "      <td>0.291819</td>\n",
       "      <td>0.106835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.647438</td>\n",
       "      <td>0.092545</td>\n",
       "      <td>0.293415</td>\n",
       "      <td>0.098707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650162</td>\n",
       "      <td>0.089909</td>\n",
       "      <td>0.385273</td>\n",
       "      <td>0.046754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655424</td>\n",
       "      <td>0.087476</td>\n",
       "      <td>0.385911</td>\n",
       "      <td>0.045976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.658162</td>\n",
       "      <td>0.182891</td>\n",
       "      <td>0.227672</td>\n",
       "      <td>0.095573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.659292</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.659292</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.659292</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.384464</td>\n",
       "      <td>0.044566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.660392</td>\n",
       "      <td>0.158067</td>\n",
       "      <td>0.250678</td>\n",
       "      <td>0.057719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.664482</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.382967</td>\n",
       "      <td>0.044177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.665443</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.665443</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.665443</td>\n",
       "      <td>0.115440</td>\n",
       "      <td>0.385592</td>\n",
       "      <td>0.047379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.665889</td>\n",
       "      <td>0.085404</td>\n",
       "      <td>0.383137</td>\n",
       "      <td>0.044123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.666312</td>\n",
       "      <td>0.062768</td>\n",
       "      <td>0.385650</td>\n",
       "      <td>0.239106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.667279</td>\n",
       "      <td>0.116383</td>\n",
       "      <td>0.385552</td>\n",
       "      <td>0.047387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.669568</td>\n",
       "      <td>0.117112</td>\n",
       "      <td>0.384895</td>\n",
       "      <td>0.048454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.670944</td>\n",
       "      <td>0.117735</td>\n",
       "      <td>0.384419</td>\n",
       "      <td>0.048545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.671405</td>\n",
       "      <td>0.117961</td>\n",
       "      <td>0.384854</td>\n",
       "      <td>0.048460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672747</td>\n",
       "      <td>0.149263</td>\n",
       "      <td>0.381422</td>\n",
       "      <td>0.093929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.672780</td>\n",
       "      <td>0.118686</td>\n",
       "      <td>0.384345</td>\n",
       "      <td>0.048561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.675373</td>\n",
       "      <td>0.090584</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.053897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.677276</td>\n",
       "      <td>0.155764</td>\n",
       "      <td>0.373750</td>\n",
       "      <td>0.059426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.677276</td>\n",
       "      <td>0.155764</td>\n",
       "      <td>0.373750</td>\n",
       "      <td>0.059426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.689483</td>\n",
       "      <td>0.185062</td>\n",
       "      <td>0.231283</td>\n",
       "      <td>0.109117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.698244</td>\n",
       "      <td>0.095861</td>\n",
       "      <td>0.353675</td>\n",
       "      <td>0.100242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698934</td>\n",
       "      <td>0.161050</td>\n",
       "      <td>0.253547</td>\n",
       "      <td>0.060035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.703784</td>\n",
       "      <td>0.071535</td>\n",
       "      <td>0.384731</td>\n",
       "      <td>0.161808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.704904</td>\n",
       "      <td>0.147275</td>\n",
       "      <td>0.363608</td>\n",
       "      <td>0.083063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.706420</td>\n",
       "      <td>0.077552</td>\n",
       "      <td>0.371587</td>\n",
       "      <td>0.096416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.711573</td>\n",
       "      <td>0.189332</td>\n",
       "      <td>0.344245</td>\n",
       "      <td>0.061685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.713781</td>\n",
       "      <td>0.159172</td>\n",
       "      <td>0.357427</td>\n",
       "      <td>0.099566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.722597</td>\n",
       "      <td>0.211178</td>\n",
       "      <td>0.341019</td>\n",
       "      <td>0.077993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.724182</td>\n",
       "      <td>0.125699</td>\n",
       "      <td>0.372499</td>\n",
       "      <td>0.170920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.755764</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>0.259520</td>\n",
       "      <td>0.071658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.799835</td>\n",
       "      <td>0.174542</td>\n",
       "      <td>0.267441</td>\n",
       "      <td>0.086858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.536738</td>\n",
       "      <td>2.958784</td>\n",
       "      <td>2.958784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.951287</td>\n",
       "      <td>2.423926</td>\n",
       "      <td>2.423926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.551111</td>\n",
       "      <td>2.039284</td>\n",
       "      <td>2.039284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>3.115336</td>\n",
       "      <td>0.975236</td>\n",
       "      <td>0.975236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.647227</td>\n",
       "      <td>0.698057</td>\n",
       "      <td>0.698057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.114774</td>\n",
       "      <td>0.457119</td>\n",
       "      <td>0.457119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.795655</td>\n",
       "      <td>0.312005</td>\n",
       "      <td>0.312005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.776194</td>\n",
       "      <td>0.296678</td>\n",
       "      <td>0.296678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-1.084187</td>\n",
       "      <td>0.123009</td>\n",
       "      <td>0.123009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.961304</td>\n",
       "      <td>0.087602</td>\n",
       "      <td>0.087602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>-0.824600</td>\n",
       "      <td>0.070111</td>\n",
       "      <td>0.070111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.859372</td>\n",
       "      <td>0.069269</td>\n",
       "      <td>0.069269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.689644</td>\n",
       "      <td>0.050445</td>\n",
       "      <td>0.050445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.485440</td>\n",
       "      <td>0.027524</td>\n",
       "      <td>0.027524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.465924</td>\n",
       "      <td>0.020655</td>\n",
       "      <td>0.020655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.413256</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>0.017361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.408485</td>\n",
       "      <td>0.016604</td>\n",
       "      <td>0.016604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.392714</td>\n",
       "      <td>0.013255</td>\n",
       "      <td>0.013255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.312876</td>\n",
       "      <td>0.007965</td>\n",
       "      <td>0.007965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.212126</td>\n",
       "      <td>0.006439</td>\n",
       "      <td>0.006439</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.537</td>\n",
       "      <td>0.111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.959</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>2.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.951</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>2.424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.039</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.115</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.859</td>\n",
       "      <td>-1.084</td>\n",
       "      <td>-0.408</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.961</td>\n",
       "      <td>-0.413</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_conscientiousness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.175</td>\n",
       "      <td>-0.485</td>\n",
       "      <td>-0.466</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.021</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.313</td>\n",
       "      <td>-0.212</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.002</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.2\n",
      "2                          BIS_11                -0.2\n",
      "1                             EDM                 0.2\n",
      "11              BFI_agreeableness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "6       ACES_neglectful_parenting                 0.0\n",
      "5                            TRSQ                 0.0\n",
      "4                              RS                 0.0\n",
      "3                             PCS                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.2\n",
      "5                            TRSQ                 0.2\n",
      "6       ACES_neglectful_parenting                -0.2\n",
      "0                            BSCS                 0.0\n",
      "12          BFI_conscientiousness                 0.0\n",
      "18           IMI_value_usefulness                 0.0\n",
      "17          IMI_effort_importance                 0.0\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "15                   BFI_openness                 0.0\n",
      "14                BFI_neuroticism                 0.0\n",
      "13               BFI_extraversion                 0.0\n",
      "10     ACES_household_dysfunction                 0.0\n",
      "11              BFI_agreeableness                 0.0\n",
      "1                             EDM                 0.0\n",
      "9         ACES_divorced_separated                 0.0\n",
      "8                        ACES_sum                 0.0\n",
      "7                      ACES_abuse                 0.0\n",
      "3                             PCS                 0.0\n",
      "2                          BIS_11                 0.0\n",
      "19         IMI_interest_enjoyment                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.3761143969277374, 0.4025350263132723, 0.3692588258740668, 0.1812388781412888, -0.034314831395025225]\n",
      "overall_score:\n",
      "0.258966459172268\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393653</td>\n",
       "      <td>0.124741</td>\n",
       "      <td>0.322006</td>\n",
       "      <td>0.113549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.398527</td>\n",
       "      <td>0.134410</td>\n",
       "      <td>0.322792</td>\n",
       "      <td>0.118473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.408048</td>\n",
       "      <td>0.134234</td>\n",
       "      <td>0.323659</td>\n",
       "      <td>0.117048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422657</td>\n",
       "      <td>0.133549</td>\n",
       "      <td>0.324441</td>\n",
       "      <td>0.118868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.447358</td>\n",
       "      <td>0.134488</td>\n",
       "      <td>0.328178</td>\n",
       "      <td>0.128918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.449886</td>\n",
       "      <td>0.076178</td>\n",
       "      <td>0.316158</td>\n",
       "      <td>0.054329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466759</td>\n",
       "      <td>0.134699</td>\n",
       "      <td>0.332709</td>\n",
       "      <td>0.135271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.486821</td>\n",
       "      <td>0.105311</td>\n",
       "      <td>0.361609</td>\n",
       "      <td>0.143869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.491973</td>\n",
       "      <td>0.053313</td>\n",
       "      <td>0.353137</td>\n",
       "      <td>0.070937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.583748</td>\n",
       "      <td>0.148940</td>\n",
       "      <td>0.278037</td>\n",
       "      <td>0.092816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.594770</td>\n",
       "      <td>0.161438</td>\n",
       "      <td>0.274984</td>\n",
       "      <td>0.102435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.609619</td>\n",
       "      <td>0.166159</td>\n",
       "      <td>0.272069</td>\n",
       "      <td>0.106755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.612865</td>\n",
       "      <td>0.046255</td>\n",
       "      <td>0.392516</td>\n",
       "      <td>0.068385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.619262</td>\n",
       "      <td>0.143596</td>\n",
       "      <td>0.250157</td>\n",
       "      <td>0.056558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.632610</td>\n",
       "      <td>0.169002</td>\n",
       "      <td>0.267937</td>\n",
       "      <td>0.110547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.634287</td>\n",
       "      <td>0.101837</td>\n",
       "      <td>0.382237</td>\n",
       "      <td>0.156561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.639392</td>\n",
       "      <td>0.154495</td>\n",
       "      <td>0.249205</td>\n",
       "      <td>0.062056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.660261</td>\n",
       "      <td>0.056913</td>\n",
       "      <td>0.400342</td>\n",
       "      <td>0.068462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.666185</td>\n",
       "      <td>0.158433</td>\n",
       "      <td>0.250703</td>\n",
       "      <td>0.063318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.667758</td>\n",
       "      <td>0.173220</td>\n",
       "      <td>0.264264</td>\n",
       "      <td>0.114018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.695045</td>\n",
       "      <td>0.177956</td>\n",
       "      <td>0.262946</td>\n",
       "      <td>0.116197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.701254</td>\n",
       "      <td>0.162442</td>\n",
       "      <td>0.254381</td>\n",
       "      <td>0.065113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.709995</td>\n",
       "      <td>0.111616</td>\n",
       "      <td>0.335908</td>\n",
       "      <td>0.117353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.712927</td>\n",
       "      <td>0.110414</td>\n",
       "      <td>0.335778</td>\n",
       "      <td>0.123930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.720828</td>\n",
       "      <td>0.108504</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>0.129701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.730767</td>\n",
       "      <td>0.106025</td>\n",
       "      <td>0.344338</td>\n",
       "      <td>0.130765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.739327</td>\n",
       "      <td>0.104948</td>\n",
       "      <td>0.348945</td>\n",
       "      <td>0.130734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.747199</td>\n",
       "      <td>0.098576</td>\n",
       "      <td>0.351649</td>\n",
       "      <td>0.122402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.754900</td>\n",
       "      <td>0.165720</td>\n",
       "      <td>0.259852</td>\n",
       "      <td>0.073257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.792749</td>\n",
       "      <td>0.096801</td>\n",
       "      <td>0.408477</td>\n",
       "      <td>0.072217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.798451</td>\n",
       "      <td>0.173796</td>\n",
       "      <td>0.267428</td>\n",
       "      <td>0.087141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.812664</td>\n",
       "      <td>0.108256</td>\n",
       "      <td>0.395411</td>\n",
       "      <td>0.055158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.823370</td>\n",
       "      <td>0.113140</td>\n",
       "      <td>0.402821</td>\n",
       "      <td>0.049510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.855074</td>\n",
       "      <td>0.089665</td>\n",
       "      <td>0.391647</td>\n",
       "      <td>0.093496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.866604</td>\n",
       "      <td>0.126934</td>\n",
       "      <td>0.405630</td>\n",
       "      <td>0.084350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.871609</td>\n",
       "      <td>0.162496</td>\n",
       "      <td>0.323674</td>\n",
       "      <td>0.163528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.872997</td>\n",
       "      <td>0.165403</td>\n",
       "      <td>0.320963</td>\n",
       "      <td>0.163777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.877526</td>\n",
       "      <td>0.108248</td>\n",
       "      <td>0.407793</td>\n",
       "      <td>0.087141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.893969</td>\n",
       "      <td>0.103323</td>\n",
       "      <td>0.342129</td>\n",
       "      <td>0.175027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.896667</td>\n",
       "      <td>0.091022</td>\n",
       "      <td>0.367657</td>\n",
       "      <td>0.141774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.900690</td>\n",
       "      <td>0.134981</td>\n",
       "      <td>0.387937</td>\n",
       "      <td>0.139032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.901665</td>\n",
       "      <td>0.093577</td>\n",
       "      <td>0.414882</td>\n",
       "      <td>0.074958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.901665</td>\n",
       "      <td>0.093577</td>\n",
       "      <td>0.414882</td>\n",
       "      <td>0.074958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.904130</td>\n",
       "      <td>0.114609</td>\n",
       "      <td>0.369567</td>\n",
       "      <td>0.260630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.904407</td>\n",
       "      <td>0.092248</td>\n",
       "      <td>0.415216</td>\n",
       "      <td>0.075398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.905028</td>\n",
       "      <td>0.156071</td>\n",
       "      <td>0.360796</td>\n",
       "      <td>0.114549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.909672</td>\n",
       "      <td>0.151162</td>\n",
       "      <td>0.337931</td>\n",
       "      <td>0.158235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.909941</td>\n",
       "      <td>0.162754</td>\n",
       "      <td>0.338445</td>\n",
       "      <td>0.164687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.910571</td>\n",
       "      <td>0.165398</td>\n",
       "      <td>0.338617</td>\n",
       "      <td>0.160633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.911508</td>\n",
       "      <td>0.168209</td>\n",
       "      <td>0.338571</td>\n",
       "      <td>0.155737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.912567</td>\n",
       "      <td>0.137618</td>\n",
       "      <td>0.387671</td>\n",
       "      <td>0.137479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.913724</td>\n",
       "      <td>0.170166</td>\n",
       "      <td>0.337690</td>\n",
       "      <td>0.149701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.915390</td>\n",
       "      <td>0.170892</td>\n",
       "      <td>0.336918</td>\n",
       "      <td>0.145727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.918373</td>\n",
       "      <td>0.143871</td>\n",
       "      <td>0.314809</td>\n",
       "      <td>0.130354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.922373</td>\n",
       "      <td>0.133328</td>\n",
       "      <td>0.310533</td>\n",
       "      <td>0.125524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.926078</td>\n",
       "      <td>0.122810</td>\n",
       "      <td>0.408286</td>\n",
       "      <td>0.172636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.931998</td>\n",
       "      <td>0.095127</td>\n",
       "      <td>0.387818</td>\n",
       "      <td>0.086440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.933963</td>\n",
       "      <td>0.132403</td>\n",
       "      <td>0.374821</td>\n",
       "      <td>0.247143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.937087</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.416791</td>\n",
       "      <td>0.055421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.937087</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.416791</td>\n",
       "      <td>0.055421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.937087</td>\n",
       "      <td>0.085574</td>\n",
       "      <td>0.416791</td>\n",
       "      <td>0.055421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.937955</td>\n",
       "      <td>0.131168</td>\n",
       "      <td>0.411235</td>\n",
       "      <td>0.166236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.939467</td>\n",
       "      <td>0.103757</td>\n",
       "      <td>0.399936</td>\n",
       "      <td>0.070311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.950417</td>\n",
       "      <td>0.096240</td>\n",
       "      <td>0.399696</td>\n",
       "      <td>0.070326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.961556</td>\n",
       "      <td>0.145503</td>\n",
       "      <td>0.404765</td>\n",
       "      <td>0.276224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.965694</td>\n",
       "      <td>0.120151</td>\n",
       "      <td>0.390521</td>\n",
       "      <td>0.276509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.966138</td>\n",
       "      <td>0.100313</td>\n",
       "      <td>0.408107</td>\n",
       "      <td>0.061115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.967745</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.967745</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.967745</td>\n",
       "      <td>0.082788</td>\n",
       "      <td>0.413247</td>\n",
       "      <td>0.051697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.968548</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.360002</td>\n",
       "      <td>0.115834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.968548</td>\n",
       "      <td>0.128133</td>\n",
       "      <td>0.360002</td>\n",
       "      <td>0.115834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.970875</td>\n",
       "      <td>0.098995</td>\n",
       "      <td>0.406999</td>\n",
       "      <td>0.065718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985532</td>\n",
       "      <td>0.161483</td>\n",
       "      <td>0.388554</td>\n",
       "      <td>0.107321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.985781</td>\n",
       "      <td>0.095472</td>\n",
       "      <td>0.407443</td>\n",
       "      <td>0.058732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.989552</td>\n",
       "      <td>0.094855</td>\n",
       "      <td>0.407313</td>\n",
       "      <td>0.061059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.991967</td>\n",
       "      <td>0.154973</td>\n",
       "      <td>0.372108</td>\n",
       "      <td>0.145349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.995538</td>\n",
       "      <td>0.109482</td>\n",
       "      <td>0.350315</td>\n",
       "      <td>0.123265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.995749</td>\n",
       "      <td>0.107787</td>\n",
       "      <td>0.353359</td>\n",
       "      <td>0.120802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.998836</td>\n",
       "      <td>0.160676</td>\n",
       "      <td>0.377952</td>\n",
       "      <td>0.141450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.011751</td>\n",
       "      <td>0.128889</td>\n",
       "      <td>0.355385</td>\n",
       "      <td>0.137109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.020129</td>\n",
       "      <td>0.095501</td>\n",
       "      <td>0.400439</td>\n",
       "      <td>0.054484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.034906</td>\n",
       "      <td>0.114008</td>\n",
       "      <td>0.362078</td>\n",
       "      <td>0.148489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.037116</td>\n",
       "      <td>0.148448</td>\n",
       "      <td>0.424029</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.037613</td>\n",
       "      <td>0.148533</td>\n",
       "      <td>0.423517</td>\n",
       "      <td>0.095359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.037613</td>\n",
       "      <td>0.148533</td>\n",
       "      <td>0.423517</td>\n",
       "      <td>0.095359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.039157</td>\n",
       "      <td>0.148848</td>\n",
       "      <td>0.422577</td>\n",
       "      <td>0.095368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.039157</td>\n",
       "      <td>0.148848</td>\n",
       "      <td>0.422577</td>\n",
       "      <td>0.095368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-6.186751</td>\n",
       "      <td>3.100877</td>\n",
       "      <td>3.100877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-5.805162</td>\n",
       "      <td>2.692957</td>\n",
       "      <td>2.692957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.979813</td>\n",
       "      <td>2.009547</td>\n",
       "      <td>2.009547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>4.394904</td>\n",
       "      <td>1.502701</td>\n",
       "      <td>1.502701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>3.584174</td>\n",
       "      <td>1.014394</td>\n",
       "      <td>1.014394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>3.016197</td>\n",
       "      <td>0.727310</td>\n",
       "      <td>0.727310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.157135</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.364600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-2.019003</td>\n",
       "      <td>0.334696</td>\n",
       "      <td>0.334696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.980192</td>\n",
       "      <td>0.077247</td>\n",
       "      <td>0.077247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.872308</td>\n",
       "      <td>0.062605</td>\n",
       "      <td>0.062605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.857464</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0.060318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.783099</td>\n",
       "      <td>0.050905</td>\n",
       "      <td>0.050905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.761546</td>\n",
       "      <td>0.042671</td>\n",
       "      <td>0.042671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.701981</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.532389</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>0.023853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.487935</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>0.019748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.418512</td>\n",
       "      <td>0.017469</td>\n",
       "      <td>0.017469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.405992</td>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.015515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.459389</td>\n",
       "      <td>0.014920</td>\n",
       "      <td>0.014920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.309849</td>\n",
       "      <td>0.009194</td>\n",
       "      <td>0.009194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.187</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.011</td>\n",
       "      <td>3.101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-5.805</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.693</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.980</td>\n",
       "      <td>0.459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.010</td>\n",
       "      <td>0.015</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>2.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.395</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.503</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.319</td>\n",
       "      <td>0.515</td>\n",
       "      <td>1.503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.584</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.014</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.464</td>\n",
       "      <td>1.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.727</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.469</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>0.727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.157</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.019</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.857</td>\n",
       "      <td>-0.980</td>\n",
       "      <td>-0.406</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.077</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.702</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.762</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.043</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.06\n",
      "2                          BIS_11               -0.06\n",
      "1                             EDM                0.06\n",
      "38       NCS_small_daily_projects                0.00\n",
      "37                      NCS_total                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "23          NCS_intellectual_task                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "21       IMI_perceived_competence                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.06\n",
      "5                            TRSQ                0.06\n",
      "6       ACES_neglectful_parenting               -0.06\n",
      "0                            BSCS                0.00\n",
      "31             NCS_prefer_complex                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "37                      NCS_total                0.00\n",
      "38       NCS_small_daily_projects                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.017195151375846374, -0.026477851580208656, -0.018450847468570508, -0.004652170655963461, -0.3994523092697029]\n",
      "overall_score:\n",
      "-0.09324566607005838\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.206247</td>\n",
       "      <td>0.086781</td>\n",
       "      <td>0.321220</td>\n",
       "      <td>0.030632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.216625</td>\n",
       "      <td>0.083448</td>\n",
       "      <td>0.332963</td>\n",
       "      <td>0.061419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.224363</td>\n",
       "      <td>0.076203</td>\n",
       "      <td>0.336234</td>\n",
       "      <td>0.048438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.230559</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>0.345571</td>\n",
       "      <td>0.034949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.231566</td>\n",
       "      <td>0.073583</td>\n",
       "      <td>0.339044</td>\n",
       "      <td>0.033113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.231566</td>\n",
       "      <td>0.073583</td>\n",
       "      <td>0.339044</td>\n",
       "      <td>0.033113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.232045</td>\n",
       "      <td>0.073372</td>\n",
       "      <td>0.339749</td>\n",
       "      <td>0.041557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.232601</td>\n",
       "      <td>0.074993</td>\n",
       "      <td>0.338200</td>\n",
       "      <td>0.032162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.235685</td>\n",
       "      <td>0.069711</td>\n",
       "      <td>0.342990</td>\n",
       "      <td>0.038282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.236072</td>\n",
       "      <td>0.079565</td>\n",
       "      <td>0.343138</td>\n",
       "      <td>0.033259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.236477</td>\n",
       "      <td>0.070535</td>\n",
       "      <td>0.338506</td>\n",
       "      <td>0.032673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.236477</td>\n",
       "      <td>0.070535</td>\n",
       "      <td>0.338506</td>\n",
       "      <td>0.032673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.236477</td>\n",
       "      <td>0.070535</td>\n",
       "      <td>0.338506</td>\n",
       "      <td>0.032673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.236548</td>\n",
       "      <td>0.080486</td>\n",
       "      <td>0.332219</td>\n",
       "      <td>0.032421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.238563</td>\n",
       "      <td>0.070026</td>\n",
       "      <td>0.339739</td>\n",
       "      <td>0.038986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239311</td>\n",
       "      <td>0.069630</td>\n",
       "      <td>0.340485</td>\n",
       "      <td>0.038395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.239480</td>\n",
       "      <td>0.065866</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.036207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.239542</td>\n",
       "      <td>0.075872</td>\n",
       "      <td>0.337420</td>\n",
       "      <td>0.028247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.240360</td>\n",
       "      <td>0.066313</td>\n",
       "      <td>0.339607</td>\n",
       "      <td>0.031956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.240360</td>\n",
       "      <td>0.066313</td>\n",
       "      <td>0.339607</td>\n",
       "      <td>0.031956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.240360</td>\n",
       "      <td>0.066313</td>\n",
       "      <td>0.339607</td>\n",
       "      <td>0.031956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.241121</td>\n",
       "      <td>0.077068</td>\n",
       "      <td>0.336893</td>\n",
       "      <td>0.028360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.245781</td>\n",
       "      <td>0.113533</td>\n",
       "      <td>0.336008</td>\n",
       "      <td>0.071609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.245781</td>\n",
       "      <td>0.113533</td>\n",
       "      <td>0.336008</td>\n",
       "      <td>0.071609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.247288</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>0.335918</td>\n",
       "      <td>0.071689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.247288</td>\n",
       "      <td>0.113106</td>\n",
       "      <td>0.335918</td>\n",
       "      <td>0.071689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.253847</td>\n",
       "      <td>0.072904</td>\n",
       "      <td>0.332677</td>\n",
       "      <td>0.039199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.259694</td>\n",
       "      <td>0.086645</td>\n",
       "      <td>0.326971</td>\n",
       "      <td>0.031996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.265134</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.070080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.265134</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.070080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.265134</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.070080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.265134</td>\n",
       "      <td>0.117065</td>\n",
       "      <td>0.352626</td>\n",
       "      <td>0.070080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271535</td>\n",
       "      <td>0.145443</td>\n",
       "      <td>0.335060</td>\n",
       "      <td>0.104966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271760</td>\n",
       "      <td>0.148899</td>\n",
       "      <td>0.337632</td>\n",
       "      <td>0.096008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.276285</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>0.332148</td>\n",
       "      <td>0.026402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.276285</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>0.332148</td>\n",
       "      <td>0.026402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.276285</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>0.332148</td>\n",
       "      <td>0.026402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.276285</td>\n",
       "      <td>0.092527</td>\n",
       "      <td>0.332148</td>\n",
       "      <td>0.026402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.279253</td>\n",
       "      <td>0.089368</td>\n",
       "      <td>0.328490</td>\n",
       "      <td>0.035529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.279253</td>\n",
       "      <td>0.089368</td>\n",
       "      <td>0.328490</td>\n",
       "      <td>0.035529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.279253</td>\n",
       "      <td>0.089368</td>\n",
       "      <td>0.328490</td>\n",
       "      <td>0.035529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.279253</td>\n",
       "      <td>0.089368</td>\n",
       "      <td>0.328490</td>\n",
       "      <td>0.035529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.282039</td>\n",
       "      <td>0.093748</td>\n",
       "      <td>0.328759</td>\n",
       "      <td>0.039949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.286615</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.328851</td>\n",
       "      <td>0.040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.286615</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.328851</td>\n",
       "      <td>0.040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.286615</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.328851</td>\n",
       "      <td>0.040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.286615</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.328851</td>\n",
       "      <td>0.040423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.297986</td>\n",
       "      <td>0.079449</td>\n",
       "      <td>0.340372</td>\n",
       "      <td>0.021745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.302854</td>\n",
       "      <td>0.069948</td>\n",
       "      <td>0.325640</td>\n",
       "      <td>0.033124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307940</td>\n",
       "      <td>0.057056</td>\n",
       "      <td>0.316338</td>\n",
       "      <td>0.037930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310635</td>\n",
       "      <td>0.059897</td>\n",
       "      <td>0.315288</td>\n",
       "      <td>0.038360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.311486</td>\n",
       "      <td>0.117921</td>\n",
       "      <td>0.366183</td>\n",
       "      <td>0.039854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313711</td>\n",
       "      <td>0.059046</td>\n",
       "      <td>0.313902</td>\n",
       "      <td>0.035912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314193</td>\n",
       "      <td>0.120067</td>\n",
       "      <td>0.368320</td>\n",
       "      <td>0.045005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.317157</td>\n",
       "      <td>0.058103</td>\n",
       "      <td>0.312352</td>\n",
       "      <td>0.033246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321413</td>\n",
       "      <td>0.056641</td>\n",
       "      <td>0.310767</td>\n",
       "      <td>0.030344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.323755</td>\n",
       "      <td>0.138860</td>\n",
       "      <td>0.318703</td>\n",
       "      <td>0.082283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.323992</td>\n",
       "      <td>0.055656</td>\n",
       "      <td>0.309878</td>\n",
       "      <td>0.028937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.324934</td>\n",
       "      <td>0.083353</td>\n",
       "      <td>0.353188</td>\n",
       "      <td>0.113887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.330965</td>\n",
       "      <td>0.126884</td>\n",
       "      <td>0.328299</td>\n",
       "      <td>0.103602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.331118</td>\n",
       "      <td>0.125716</td>\n",
       "      <td>0.334263</td>\n",
       "      <td>0.057761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.345809</td>\n",
       "      <td>0.074920</td>\n",
       "      <td>0.354835</td>\n",
       "      <td>0.098672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.347698</td>\n",
       "      <td>0.121311</td>\n",
       "      <td>0.334753</td>\n",
       "      <td>0.091907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352378</td>\n",
       "      <td>0.121637</td>\n",
       "      <td>0.342689</td>\n",
       "      <td>0.062138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.355645</td>\n",
       "      <td>0.127547</td>\n",
       "      <td>0.316881</td>\n",
       "      <td>0.097013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357799</td>\n",
       "      <td>0.132565</td>\n",
       "      <td>0.340577</td>\n",
       "      <td>0.065904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.360893</td>\n",
       "      <td>0.165496</td>\n",
       "      <td>0.292121</td>\n",
       "      <td>0.098835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.367520</td>\n",
       "      <td>0.094685</td>\n",
       "      <td>0.346420</td>\n",
       "      <td>0.050123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.370729</td>\n",
       "      <td>0.109038</td>\n",
       "      <td>0.328659</td>\n",
       "      <td>0.070372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376685</td>\n",
       "      <td>0.211529</td>\n",
       "      <td>0.278933</td>\n",
       "      <td>0.109134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377657</td>\n",
       "      <td>0.181242</td>\n",
       "      <td>0.290977</td>\n",
       "      <td>0.111212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.377872</td>\n",
       "      <td>0.132237</td>\n",
       "      <td>0.298618</td>\n",
       "      <td>0.130097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.389819</td>\n",
       "      <td>0.102685</td>\n",
       "      <td>0.357066</td>\n",
       "      <td>0.051196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.395195</td>\n",
       "      <td>0.109281</td>\n",
       "      <td>0.356968</td>\n",
       "      <td>0.052712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.398747</td>\n",
       "      <td>0.211944</td>\n",
       "      <td>0.273215</td>\n",
       "      <td>0.122780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.400074</td>\n",
       "      <td>0.186469</td>\n",
       "      <td>0.288632</td>\n",
       "      <td>0.120480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.401817</td>\n",
       "      <td>0.110136</td>\n",
       "      <td>0.356128</td>\n",
       "      <td>0.051882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.408525</td>\n",
       "      <td>0.111674</td>\n",
       "      <td>0.283788</td>\n",
       "      <td>0.125236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.410233</td>\n",
       "      <td>0.110742</td>\n",
       "      <td>0.355155</td>\n",
       "      <td>0.051589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.421040</td>\n",
       "      <td>0.111592</td>\n",
       "      <td>0.354630</td>\n",
       "      <td>0.052157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.429346</td>\n",
       "      <td>0.109472</td>\n",
       "      <td>0.354810</td>\n",
       "      <td>0.053398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.430155</td>\n",
       "      <td>0.089617</td>\n",
       "      <td>0.332803</td>\n",
       "      <td>0.117603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.430660</td>\n",
       "      <td>0.189779</td>\n",
       "      <td>0.284925</td>\n",
       "      <td>0.133758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.461493</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>0.296683</td>\n",
       "      <td>0.070121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.471369</td>\n",
       "      <td>0.192719</td>\n",
       "      <td>0.284389</td>\n",
       "      <td>0.149067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.497736</td>\n",
       "      <td>0.193175</td>\n",
       "      <td>0.287740</td>\n",
       "      <td>0.154638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.501658</td>\n",
       "      <td>0.075009</td>\n",
       "      <td>0.308415</td>\n",
       "      <td>0.082156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.649096</td>\n",
       "      <td>0.076494</td>\n",
       "      <td>0.382782</td>\n",
       "      <td>0.068742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.665403</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.384908</td>\n",
       "      <td>0.076287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.686944</td>\n",
       "      <td>0.076196</td>\n",
       "      <td>0.387125</td>\n",
       "      <td>0.079601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.717627</td>\n",
       "      <td>0.076467</td>\n",
       "      <td>0.384937</td>\n",
       "      <td>0.076172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.763430</td>\n",
       "      <td>0.084224</td>\n",
       "      <td>0.378995</td>\n",
       "      <td>0.065438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.802956</td>\n",
       "      <td>0.094020</td>\n",
       "      <td>0.374455</td>\n",
       "      <td>0.052593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.312878</td>\n",
       "      <td>0.191324</td>\n",
       "      <td>0.343977</td>\n",
       "      <td>0.071395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.396508</td>\n",
       "      <td>0.227423</td>\n",
       "      <td>0.352300</td>\n",
       "      <td>0.079266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.509940</td>\n",
       "      <td>0.262221</td>\n",
       "      <td>0.363990</td>\n",
       "      <td>0.083357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.674667</td>\n",
       "      <td>0.306674</td>\n",
       "      <td>0.373513</td>\n",
       "      <td>0.091580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.957684</td>\n",
       "      <td>0.370838</td>\n",
       "      <td>0.381138</td>\n",
       "      <td>0.117978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.229833</td>\n",
       "      <td>0.395091</td>\n",
       "      <td>0.381551</td>\n",
       "      <td>0.143457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.849537</td>\n",
       "      <td>0.094969</td>\n",
       "      <td>0.094969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.637065</td>\n",
       "      <td>0.068661</td>\n",
       "      <td>0.068661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.245906</td>\n",
       "      <td>0.009770</td>\n",
       "      <td>0.009770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.115884</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>0.003954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.134868</td>\n",
       "      <td>0.001949</td>\n",
       "      <td>0.001949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.098676</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.001360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.062639</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.001136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.033687</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>0.000936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>IMI_perceived_choice*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>0.850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.063</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.099</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "38       NCS_small_daily_projects                0.00\n",
      "37                      NCS_total                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "23          NCS_intellectual_task                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "21       IMI_perceived_competence                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.08\n",
      "5                            TRSQ                0.08\n",
      "6       ACES_neglectful_parenting               -0.08\n",
      "0                            BSCS                0.00\n",
      "31             NCS_prefer_complex                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "37                      NCS_total                0.00\n",
      "38       NCS_small_daily_projects                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.0036091107931160993, 0.015382233580734317, -0.03508212446996439, 0.0045933750242519444, -0.33330574000360014]\n",
      "overall_score:\n",
      "-0.06896062901509244\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288410</td>\n",
       "      <td>0.053655</td>\n",
       "      <td>0.347298</td>\n",
       "      <td>0.035489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.293047</td>\n",
       "      <td>0.075910</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.293047</td>\n",
       "      <td>0.075910</td>\n",
       "      <td>0.350830</td>\n",
       "      <td>0.031284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.293667</td>\n",
       "      <td>0.076627</td>\n",
       "      <td>0.349722</td>\n",
       "      <td>0.030411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294777</td>\n",
       "      <td>0.066985</td>\n",
       "      <td>0.348409</td>\n",
       "      <td>0.039376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.297459</td>\n",
       "      <td>0.072774</td>\n",
       "      <td>0.348851</td>\n",
       "      <td>0.032227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298089</td>\n",
       "      <td>0.072020</td>\n",
       "      <td>0.352675</td>\n",
       "      <td>0.036457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299818</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.313285</td>\n",
       "      <td>0.021087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.300425</td>\n",
       "      <td>0.082337</td>\n",
       "      <td>0.342273</td>\n",
       "      <td>0.029175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300433</td>\n",
       "      <td>0.067204</td>\n",
       "      <td>0.350839</td>\n",
       "      <td>0.037694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301463</td>\n",
       "      <td>0.071130</td>\n",
       "      <td>0.351245</td>\n",
       "      <td>0.039034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.302016</td>\n",
       "      <td>0.071682</td>\n",
       "      <td>0.350127</td>\n",
       "      <td>0.037750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.302430</td>\n",
       "      <td>0.084377</td>\n",
       "      <td>0.348533</td>\n",
       "      <td>0.023347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.302510</td>\n",
       "      <td>0.068470</td>\n",
       "      <td>0.348318</td>\n",
       "      <td>0.031605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303563</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.303897</td>\n",
       "      <td>0.089003</td>\n",
       "      <td>0.348534</td>\n",
       "      <td>0.023626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307144</td>\n",
       "      <td>0.104330</td>\n",
       "      <td>0.328181</td>\n",
       "      <td>0.062543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308423</td>\n",
       "      <td>0.063950</td>\n",
       "      <td>0.347394</td>\n",
       "      <td>0.033606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308725</td>\n",
       "      <td>0.103753</td>\n",
       "      <td>0.328216</td>\n",
       "      <td>0.062523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325269</td>\n",
       "      <td>0.056862</td>\n",
       "      <td>0.334962</td>\n",
       "      <td>0.031944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.328481</td>\n",
       "      <td>0.087135</td>\n",
       "      <td>0.337360</td>\n",
       "      <td>0.030854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333055</td>\n",
       "      <td>0.108446</td>\n",
       "      <td>0.363827</td>\n",
       "      <td>0.064072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337441</td>\n",
       "      <td>0.103615</td>\n",
       "      <td>0.361082</td>\n",
       "      <td>0.031338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.340346</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>0.331027</td>\n",
       "      <td>0.044283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343193</td>\n",
       "      <td>0.095001</td>\n",
       "      <td>0.360162</td>\n",
       "      <td>0.043794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349665</td>\n",
       "      <td>0.118646</td>\n",
       "      <td>0.354225</td>\n",
       "      <td>0.066925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351895</td>\n",
       "      <td>0.117910</td>\n",
       "      <td>0.355717</td>\n",
       "      <td>0.056148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.352353</td>\n",
       "      <td>0.111412</td>\n",
       "      <td>0.355244</td>\n",
       "      <td>0.027131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.354081</td>\n",
       "      <td>0.090666</td>\n",
       "      <td>0.338806</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.355125</td>\n",
       "      <td>0.110097</td>\n",
       "      <td>0.335083</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.355832</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>0.330398</td>\n",
       "      <td>0.036763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.357460</td>\n",
       "      <td>0.121774</td>\n",
       "      <td>0.347151</td>\n",
       "      <td>0.050678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367551</td>\n",
       "      <td>0.036186</td>\n",
       "      <td>0.316098</td>\n",
       "      <td>0.032528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.369260</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.315976</td>\n",
       "      <td>0.032981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371135</td>\n",
       "      <td>0.037060</td>\n",
       "      <td>0.315886</td>\n",
       "      <td>0.031429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373678</td>\n",
       "      <td>0.035369</td>\n",
       "      <td>0.315083</td>\n",
       "      <td>0.028377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376697</td>\n",
       "      <td>0.033384</td>\n",
       "      <td>0.314036</td>\n",
       "      <td>0.025253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378476</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>0.313408</td>\n",
       "      <td>0.023845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392350</td>\n",
       "      <td>0.133143</td>\n",
       "      <td>0.359940</td>\n",
       "      <td>0.037180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.409784</td>\n",
       "      <td>0.167160</td>\n",
       "      <td>0.301032</td>\n",
       "      <td>0.111165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.411008</td>\n",
       "      <td>0.116619</td>\n",
       "      <td>0.371563</td>\n",
       "      <td>0.054809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415063</td>\n",
       "      <td>0.122209</td>\n",
       "      <td>0.360791</td>\n",
       "      <td>0.042429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.417805</td>\n",
       "      <td>0.071310</td>\n",
       "      <td>0.387993</td>\n",
       "      <td>0.107674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418336</td>\n",
       "      <td>0.150586</td>\n",
       "      <td>0.345614</td>\n",
       "      <td>0.062225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422506</td>\n",
       "      <td>0.185688</td>\n",
       "      <td>0.303132</td>\n",
       "      <td>0.123583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.427162</td>\n",
       "      <td>0.069461</td>\n",
       "      <td>0.398590</td>\n",
       "      <td>0.105313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.433742</td>\n",
       "      <td>0.125480</td>\n",
       "      <td>0.346453</td>\n",
       "      <td>0.120398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.435400</td>\n",
       "      <td>0.123250</td>\n",
       "      <td>0.335387</td>\n",
       "      <td>0.110144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.438559</td>\n",
       "      <td>0.195686</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.129856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.441517</td>\n",
       "      <td>0.108116</td>\n",
       "      <td>0.349139</td>\n",
       "      <td>0.085130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.443098</td>\n",
       "      <td>0.122632</td>\n",
       "      <td>0.359686</td>\n",
       "      <td>0.112010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.443733</td>\n",
       "      <td>0.151434</td>\n",
       "      <td>0.348433</td>\n",
       "      <td>0.071480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.454799</td>\n",
       "      <td>0.096457</td>\n",
       "      <td>0.368405</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.457660</td>\n",
       "      <td>0.101214</td>\n",
       "      <td>0.367982</td>\n",
       "      <td>0.072460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.460660</td>\n",
       "      <td>0.204279</td>\n",
       "      <td>0.309517</td>\n",
       "      <td>0.139231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.461852</td>\n",
       "      <td>0.099810</td>\n",
       "      <td>0.367065</td>\n",
       "      <td>0.069615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.468386</td>\n",
       "      <td>0.097949</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.065708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.475986</td>\n",
       "      <td>0.096245</td>\n",
       "      <td>0.363049</td>\n",
       "      <td>0.060105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.480336</td>\n",
       "      <td>0.136476</td>\n",
       "      <td>0.297415</td>\n",
       "      <td>0.101730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.482390</td>\n",
       "      <td>0.093313</td>\n",
       "      <td>0.361248</td>\n",
       "      <td>0.056452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.485786</td>\n",
       "      <td>0.137346</td>\n",
       "      <td>0.344748</td>\n",
       "      <td>0.116423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491286</td>\n",
       "      <td>0.211941</td>\n",
       "      <td>0.314959</td>\n",
       "      <td>0.154622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.499497</td>\n",
       "      <td>0.133567</td>\n",
       "      <td>0.307901</td>\n",
       "      <td>0.068284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.502722</td>\n",
       "      <td>0.064218</td>\n",
       "      <td>0.310633</td>\n",
       "      <td>0.074997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.512404</td>\n",
       "      <td>0.215938</td>\n",
       "      <td>0.319844</td>\n",
       "      <td>0.165234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.513499</td>\n",
       "      <td>0.103826</td>\n",
       "      <td>0.371735</td>\n",
       "      <td>0.067066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.518518</td>\n",
       "      <td>0.153531</td>\n",
       "      <td>0.326853</td>\n",
       "      <td>0.085935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.574988</td>\n",
       "      <td>0.117961</td>\n",
       "      <td>0.354894</td>\n",
       "      <td>0.042989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.685712</td>\n",
       "      <td>0.105841</td>\n",
       "      <td>0.382756</td>\n",
       "      <td>0.071584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.702860</td>\n",
       "      <td>0.111064</td>\n",
       "      <td>0.383765</td>\n",
       "      <td>0.078593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.723904</td>\n",
       "      <td>0.110667</td>\n",
       "      <td>0.384484</td>\n",
       "      <td>0.079806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.752958</td>\n",
       "      <td>0.110592</td>\n",
       "      <td>0.382805</td>\n",
       "      <td>0.076703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.794343</td>\n",
       "      <td>0.107459</td>\n",
       "      <td>0.383762</td>\n",
       "      <td>0.069937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.828454</td>\n",
       "      <td>0.106140</td>\n",
       "      <td>0.380285</td>\n",
       "      <td>0.056067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.322590</td>\n",
       "      <td>0.193137</td>\n",
       "      <td>0.346501</td>\n",
       "      <td>0.075421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.404271</td>\n",
       "      <td>0.228891</td>\n",
       "      <td>0.354093</td>\n",
       "      <td>0.082658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.517240</td>\n",
       "      <td>0.262708</td>\n",
       "      <td>0.366153</td>\n",
       "      <td>0.085429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.681205</td>\n",
       "      <td>0.306425</td>\n",
       "      <td>0.375756</td>\n",
       "      <td>0.093398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.960630</td>\n",
       "      <td>0.371456</td>\n",
       "      <td>0.383989</td>\n",
       "      <td>0.119859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.232267</td>\n",
       "      <td>0.394677</td>\n",
       "      <td>0.384232</td>\n",
       "      <td>0.145442</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.080712</td>\n",
       "      <td>0.080712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.403294</td>\n",
       "      <td>0.035082</td>\n",
       "      <td>0.035082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.194826</td>\n",
       "      <td>0.008660</td>\n",
       "      <td>0.008660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.059079</td>\n",
       "      <td>0.001749</td>\n",
       "      <td>0.001749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.1\n",
      "2                          BIS_11                -0.1\n",
      "1                             EDM                 0.1\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "23          NCS_intellectual_task                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "21       IMI_perceived_competence                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.1\n",
      "5                            TRSQ                 0.1\n",
      "6       ACES_neglectful_parenting                -0.1\n",
      "0                            BSCS                 0.0\n",
      "31             NCS_prefer_complex                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057337057875583186, 0.035141750540423455, -0.0501571896090387, -0.06248256167243871, -0.4292330285672843]\n",
      "overall_score:\n",
      "-0.08987879428655102\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.369094</td>\n",
       "      <td>0.078335</td>\n",
       "      <td>0.364914</td>\n",
       "      <td>0.031315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.369159</td>\n",
       "      <td>0.078495</td>\n",
       "      <td>0.365044</td>\n",
       "      <td>0.031475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.369159</td>\n",
       "      <td>0.078495</td>\n",
       "      <td>0.365044</td>\n",
       "      <td>0.031475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.374275</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.360296</td>\n",
       "      <td>0.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.374275</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.360296</td>\n",
       "      <td>0.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.374275</td>\n",
       "      <td>0.073978</td>\n",
       "      <td>0.360296</td>\n",
       "      <td>0.036466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376130</td>\n",
       "      <td>0.052604</td>\n",
       "      <td>0.300764</td>\n",
       "      <td>0.061430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.376968</td>\n",
       "      <td>0.087257</td>\n",
       "      <td>0.363764</td>\n",
       "      <td>0.030676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.377117</td>\n",
       "      <td>0.095347</td>\n",
       "      <td>0.366040</td>\n",
       "      <td>0.022136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381121</td>\n",
       "      <td>0.067086</td>\n",
       "      <td>0.364774</td>\n",
       "      <td>0.040478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.381361</td>\n",
       "      <td>0.099204</td>\n",
       "      <td>0.366837</td>\n",
       "      <td>0.023044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381954</td>\n",
       "      <td>0.070989</td>\n",
       "      <td>0.364618</td>\n",
       "      <td>0.042042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381989</td>\n",
       "      <td>0.077316</td>\n",
       "      <td>0.358906</td>\n",
       "      <td>0.033402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382317</td>\n",
       "      <td>0.082990</td>\n",
       "      <td>0.323042</td>\n",
       "      <td>0.037528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.384464</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.384464</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.384464</td>\n",
       "      <td>0.071758</td>\n",
       "      <td>0.355714</td>\n",
       "      <td>0.033165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384834</td>\n",
       "      <td>0.075437</td>\n",
       "      <td>0.358750</td>\n",
       "      <td>0.039400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385091</td>\n",
       "      <td>0.060684</td>\n",
       "      <td>0.364225</td>\n",
       "      <td>0.048840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.388233</td>\n",
       "      <td>0.075238</td>\n",
       "      <td>0.358933</td>\n",
       "      <td>0.038907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389895</td>\n",
       "      <td>0.073190</td>\n",
       "      <td>0.357872</td>\n",
       "      <td>0.036485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392552</td>\n",
       "      <td>0.082319</td>\n",
       "      <td>0.341998</td>\n",
       "      <td>0.020799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394927</td>\n",
       "      <td>0.083512</td>\n",
       "      <td>0.337620</td>\n",
       "      <td>0.082947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.395394</td>\n",
       "      <td>0.052350</td>\n",
       "      <td>0.355844</td>\n",
       "      <td>0.058322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.404783</td>\n",
       "      <td>0.095919</td>\n",
       "      <td>0.358851</td>\n",
       "      <td>0.036803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.408900</td>\n",
       "      <td>0.084471</td>\n",
       "      <td>0.343657</td>\n",
       "      <td>0.065066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.413660</td>\n",
       "      <td>0.082314</td>\n",
       "      <td>0.333171</td>\n",
       "      <td>0.041834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.414192</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.329940</td>\n",
       "      <td>0.055935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415023</td>\n",
       "      <td>0.051227</td>\n",
       "      <td>0.363064</td>\n",
       "      <td>0.047884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417076</td>\n",
       "      <td>0.053332</td>\n",
       "      <td>0.362848</td>\n",
       "      <td>0.048853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.420138</td>\n",
       "      <td>0.051498</td>\n",
       "      <td>0.361941</td>\n",
       "      <td>0.046571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422187</td>\n",
       "      <td>0.128012</td>\n",
       "      <td>0.319494</td>\n",
       "      <td>0.051178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.423888</td>\n",
       "      <td>0.119452</td>\n",
       "      <td>0.382923</td>\n",
       "      <td>0.083235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424229</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.360443</td>\n",
       "      <td>0.044648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.428364</td>\n",
       "      <td>0.103487</td>\n",
       "      <td>0.358263</td>\n",
       "      <td>0.045722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429295</td>\n",
       "      <td>0.047067</td>\n",
       "      <td>0.358879</td>\n",
       "      <td>0.044259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.430336</td>\n",
       "      <td>0.120297</td>\n",
       "      <td>0.376583</td>\n",
       "      <td>0.027833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.432541</td>\n",
       "      <td>0.046252</td>\n",
       "      <td>0.358313</td>\n",
       "      <td>0.045278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.434307</td>\n",
       "      <td>0.118357</td>\n",
       "      <td>0.347248</td>\n",
       "      <td>0.058813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.440372</td>\n",
       "      <td>0.112013</td>\n",
       "      <td>0.330115</td>\n",
       "      <td>0.041683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.444368</td>\n",
       "      <td>0.089932</td>\n",
       "      <td>0.367399</td>\n",
       "      <td>0.055825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.445358</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.382659</td>\n",
       "      <td>0.102536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.448137</td>\n",
       "      <td>0.122636</td>\n",
       "      <td>0.383618</td>\n",
       "      <td>0.069432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.449403</td>\n",
       "      <td>0.122695</td>\n",
       "      <td>0.385069</td>\n",
       "      <td>0.071419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.451370</td>\n",
       "      <td>0.103264</td>\n",
       "      <td>0.380979</td>\n",
       "      <td>0.100942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454054</td>\n",
       "      <td>0.132126</td>\n",
       "      <td>0.315666</td>\n",
       "      <td>0.106882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461523</td>\n",
       "      <td>0.173459</td>\n",
       "      <td>0.289125</td>\n",
       "      <td>0.116615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.461854</td>\n",
       "      <td>0.096370</td>\n",
       "      <td>0.405480</td>\n",
       "      <td>0.090314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.464370</td>\n",
       "      <td>0.086749</td>\n",
       "      <td>0.379242</td>\n",
       "      <td>0.052899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466510</td>\n",
       "      <td>0.117186</td>\n",
       "      <td>0.396555</td>\n",
       "      <td>0.057520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.467866</td>\n",
       "      <td>0.097298</td>\n",
       "      <td>0.402607</td>\n",
       "      <td>0.092475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472557</td>\n",
       "      <td>0.148355</td>\n",
       "      <td>0.302436</td>\n",
       "      <td>0.107734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.473013</td>\n",
       "      <td>0.195662</td>\n",
       "      <td>0.291899</td>\n",
       "      <td>0.126390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.478200</td>\n",
       "      <td>0.119285</td>\n",
       "      <td>0.387366</td>\n",
       "      <td>0.042656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480121</td>\n",
       "      <td>0.100510</td>\n",
       "      <td>0.398473</td>\n",
       "      <td>0.065728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489016</td>\n",
       "      <td>0.207582</td>\n",
       "      <td>0.296340</td>\n",
       "      <td>0.129145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.493577</td>\n",
       "      <td>0.117880</td>\n",
       "      <td>0.312339</td>\n",
       "      <td>0.060948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.499653</td>\n",
       "      <td>0.096259</td>\n",
       "      <td>0.362227</td>\n",
       "      <td>0.097563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.502822</td>\n",
       "      <td>0.100139</td>\n",
       "      <td>0.361978</td>\n",
       "      <td>0.102082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.507049</td>\n",
       "      <td>0.097899</td>\n",
       "      <td>0.361764</td>\n",
       "      <td>0.099570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.511832</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.301636</td>\n",
       "      <td>0.133976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.512380</td>\n",
       "      <td>0.094652</td>\n",
       "      <td>0.361665</td>\n",
       "      <td>0.095136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.518654</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.362942</td>\n",
       "      <td>0.088194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.522704</td>\n",
       "      <td>0.085456</td>\n",
       "      <td>0.364082</td>\n",
       "      <td>0.083227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.523301</td>\n",
       "      <td>0.140519</td>\n",
       "      <td>0.325794</td>\n",
       "      <td>0.104411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.526495</td>\n",
       "      <td>0.123807</td>\n",
       "      <td>0.320069</td>\n",
       "      <td>0.047102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.536704</td>\n",
       "      <td>0.076729</td>\n",
       "      <td>0.346011</td>\n",
       "      <td>0.100224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.544565</td>\n",
       "      <td>0.225024</td>\n",
       "      <td>0.310404</td>\n",
       "      <td>0.143766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.545108</td>\n",
       "      <td>0.063569</td>\n",
       "      <td>0.320370</td>\n",
       "      <td>0.083951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.561784</td>\n",
       "      <td>0.173821</td>\n",
       "      <td>0.321289</td>\n",
       "      <td>0.050937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.566935</td>\n",
       "      <td>0.228406</td>\n",
       "      <td>0.317194</td>\n",
       "      <td>0.152693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.596004</td>\n",
       "      <td>0.090069</td>\n",
       "      <td>0.365594</td>\n",
       "      <td>0.074140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.713331</td>\n",
       "      <td>0.111084</td>\n",
       "      <td>0.375372</td>\n",
       "      <td>0.105467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.727017</td>\n",
       "      <td>0.119346</td>\n",
       "      <td>0.374649</td>\n",
       "      <td>0.117402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.746293</td>\n",
       "      <td>0.118352</td>\n",
       "      <td>0.374461</td>\n",
       "      <td>0.123196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.774504</td>\n",
       "      <td>0.116585</td>\n",
       "      <td>0.373094</td>\n",
       "      <td>0.126595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.818049</td>\n",
       "      <td>0.111638</td>\n",
       "      <td>0.372241</td>\n",
       "      <td>0.127303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.850947</td>\n",
       "      <td>0.107508</td>\n",
       "      <td>0.371522</td>\n",
       "      <td>0.120208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.333023</td>\n",
       "      <td>0.195543</td>\n",
       "      <td>0.349056</td>\n",
       "      <td>0.079967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.413131</td>\n",
       "      <td>0.230617</td>\n",
       "      <td>0.355897</td>\n",
       "      <td>0.086493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.525383</td>\n",
       "      <td>0.263500</td>\n",
       "      <td>0.367714</td>\n",
       "      <td>0.089035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.688133</td>\n",
       "      <td>0.306258</td>\n",
       "      <td>0.378217</td>\n",
       "      <td>0.095781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.964433</td>\n",
       "      <td>0.371450</td>\n",
       "      <td>0.387395</td>\n",
       "      <td>0.121841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.234851</td>\n",
       "      <td>0.394234</td>\n",
       "      <td>0.386955</td>\n",
       "      <td>0.147258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.238603</td>\n",
       "      <td>0.021717</td>\n",
       "      <td>0.021717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>-0.132500</td>\n",
       "      <td>0.011149</td>\n",
       "      <td>0.011149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NCS_like_responsibility</td>\n",
       "      <td>-0.068217</td>\n",
       "      <td>0.004660</td>\n",
       "      <td>0.004660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NCS_thinking_not_exciting</td>\n",
       "      <td>-0.047636</td>\n",
       "      <td>0.003824</td>\n",
       "      <td>0.003824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NCS_intellectual_task</td>\n",
       "      <td>-0.030438</td>\n",
       "      <td>0.002054</td>\n",
       "      <td>0.002054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>IMI_perceived_competence*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>IMI_perceived_choice*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>IMI_effort_importance*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>BFI_openness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>PCS*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NCS_new_solutions_to_problems</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NCS_think_minimally</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NCS_thinking_not_fun</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>NCS_deliberating_issues*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_total</th>\n",
       "      <td>-0.133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_like_responsibility</th>\n",
       "      <td>-0.068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_thinking_not_exciting</th>\n",
       "      <td>-0.048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_intellectual_task</th>\n",
       "      <td>-0.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.15\n",
      "2                          BIS_11               -0.15\n",
      "1                             EDM                0.15\n",
      "38       NCS_small_daily_projects                0.00\n",
      "37                      NCS_total                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "23          NCS_intellectual_task                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "21       IMI_perceived_competence                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                0.15\n",
      "5                            TRSQ                0.15\n",
      "6       ACES_neglectful_parenting               -0.15\n",
      "0                            BSCS                0.00\n",
      "31             NCS_prefer_complex                0.00\n",
      "24        NCS_deliberating_issues                0.00\n",
      "25        NCS_like_responsibility                0.00\n",
      "26      NCS_thinking_not_exciting                0.00\n",
      "27                NCS_avoid_depth                0.00\n",
      "28           NCS_thinking_not_fun                0.00\n",
      "29          NCS_thought_appealing                0.00\n",
      "30            NCS_think_minimally                0.00\n",
      "33    NCS_relief_not_satisfaction                0.00\n",
      "32      NCS_prefer_little_thought                0.00\n",
      "22               NCS_get_job_done                0.00\n",
      "34       NCS_tasks_little_thought                0.00\n",
      "35  NCS_new_solutions_to_problems                0.00\n",
      "36          NCS_abstract_thinking                0.00\n",
      "37                      NCS_total                0.00\n",
      "38       NCS_small_daily_projects                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14229584469909184, 0.07270145124282834, -0.05946581417025287, 0.1844848755077767, -0.27738575558235135]\n",
      "overall_score:\n",
      "0.012526120339418533\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.450054</td>\n",
       "      <td>0.093190</td>\n",
       "      <td>0.368450</td>\n",
       "      <td>0.094423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.485738</td>\n",
       "      <td>0.168661</td>\n",
       "      <td>0.339724</td>\n",
       "      <td>0.156880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.496913</td>\n",
       "      <td>0.185469</td>\n",
       "      <td>0.338385</td>\n",
       "      <td>0.171961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.512106</td>\n",
       "      <td>0.194681</td>\n",
       "      <td>0.338621</td>\n",
       "      <td>0.178575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.514341</td>\n",
       "      <td>0.094782</td>\n",
       "      <td>0.383499</td>\n",
       "      <td>0.069080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.531656</td>\n",
       "      <td>0.204962</td>\n",
       "      <td>0.339684</td>\n",
       "      <td>0.186489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.561325</td>\n",
       "      <td>0.211536</td>\n",
       "      <td>0.344609</td>\n",
       "      <td>0.187964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572432</td>\n",
       "      <td>0.051176</td>\n",
       "      <td>0.409638</td>\n",
       "      <td>0.093495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.577876</td>\n",
       "      <td>0.089977</td>\n",
       "      <td>0.349342</td>\n",
       "      <td>0.068828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.582080</td>\n",
       "      <td>0.214437</td>\n",
       "      <td>0.350583</td>\n",
       "      <td>0.187450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.593261</td>\n",
       "      <td>0.055832</td>\n",
       "      <td>0.404322</td>\n",
       "      <td>0.083083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.593401</td>\n",
       "      <td>0.056760</td>\n",
       "      <td>0.416855</td>\n",
       "      <td>0.091944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.594110</td>\n",
       "      <td>0.120727</td>\n",
       "      <td>0.391185</td>\n",
       "      <td>0.053993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.595509</td>\n",
       "      <td>0.060297</td>\n",
       "      <td>0.417521</td>\n",
       "      <td>0.097609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598330</td>\n",
       "      <td>0.060858</td>\n",
       "      <td>0.418039</td>\n",
       "      <td>0.098240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598640</td>\n",
       "      <td>0.106847</td>\n",
       "      <td>0.358844</td>\n",
       "      <td>0.103019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.601561</td>\n",
       "      <td>0.061582</td>\n",
       "      <td>0.418732</td>\n",
       "      <td>0.099223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.605215</td>\n",
       "      <td>0.095136</td>\n",
       "      <td>0.389683</td>\n",
       "      <td>0.043027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.605834</td>\n",
       "      <td>0.062703</td>\n",
       "      <td>0.419200</td>\n",
       "      <td>0.101190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.606960</td>\n",
       "      <td>0.108673</td>\n",
       "      <td>0.346533</td>\n",
       "      <td>0.115732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.606969</td>\n",
       "      <td>0.096389</td>\n",
       "      <td>0.390540</td>\n",
       "      <td>0.042278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.606969</td>\n",
       "      <td>0.096389</td>\n",
       "      <td>0.390540</td>\n",
       "      <td>0.042278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.608083</td>\n",
       "      <td>0.111107</td>\n",
       "      <td>0.384224</td>\n",
       "      <td>0.061829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.608626</td>\n",
       "      <td>0.063582</td>\n",
       "      <td>0.419247</td>\n",
       "      <td>0.102816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.611634</td>\n",
       "      <td>0.120112</td>\n",
       "      <td>0.393744</td>\n",
       "      <td>0.057486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.612052</td>\n",
       "      <td>0.098766</td>\n",
       "      <td>0.377466</td>\n",
       "      <td>0.052165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.620634</td>\n",
       "      <td>0.068104</td>\n",
       "      <td>0.329741</td>\n",
       "      <td>0.098835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.623286</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.034416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.623286</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.034416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.623286</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.388519</td>\n",
       "      <td>0.034416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.627416</td>\n",
       "      <td>0.079055</td>\n",
       "      <td>0.386703</td>\n",
       "      <td>0.057161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.634273</td>\n",
       "      <td>0.094338</td>\n",
       "      <td>0.386963</td>\n",
       "      <td>0.049567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.635986</td>\n",
       "      <td>0.122028</td>\n",
       "      <td>0.375689</td>\n",
       "      <td>0.080582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.642580</td>\n",
       "      <td>0.082099</td>\n",
       "      <td>0.389458</td>\n",
       "      <td>0.051180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.643297</td>\n",
       "      <td>0.113259</td>\n",
       "      <td>0.405086</td>\n",
       "      <td>0.076258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.648739</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.382868</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.648739</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.382868</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.648739</td>\n",
       "      <td>0.076141</td>\n",
       "      <td>0.382868</td>\n",
       "      <td>0.038574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.649446</td>\n",
       "      <td>0.139237</td>\n",
       "      <td>0.429966</td>\n",
       "      <td>0.197280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650667</td>\n",
       "      <td>0.092962</td>\n",
       "      <td>0.386611</td>\n",
       "      <td>0.047898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.651083</td>\n",
       "      <td>0.135278</td>\n",
       "      <td>0.396923</td>\n",
       "      <td>0.063828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653138</td>\n",
       "      <td>0.147986</td>\n",
       "      <td>0.381367</td>\n",
       "      <td>0.082533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.653736</td>\n",
       "      <td>0.072570</td>\n",
       "      <td>0.349982</td>\n",
       "      <td>0.155481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.653814</td>\n",
       "      <td>0.074908</td>\n",
       "      <td>0.346735</td>\n",
       "      <td>0.166604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.655078</td>\n",
       "      <td>0.072700</td>\n",
       "      <td>0.343085</td>\n",
       "      <td>0.168054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.657487</td>\n",
       "      <td>0.131601</td>\n",
       "      <td>0.398876</td>\n",
       "      <td>0.089117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.657675</td>\n",
       "      <td>0.069073</td>\n",
       "      <td>0.338699</td>\n",
       "      <td>0.169848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.657810</td>\n",
       "      <td>0.088641</td>\n",
       "      <td>0.384189</td>\n",
       "      <td>0.047016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.660076</td>\n",
       "      <td>0.146554</td>\n",
       "      <td>0.433561</td>\n",
       "      <td>0.193144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.662239</td>\n",
       "      <td>0.063309</td>\n",
       "      <td>0.333006</td>\n",
       "      <td>0.171985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.663022</td>\n",
       "      <td>0.118041</td>\n",
       "      <td>0.373532</td>\n",
       "      <td>0.102400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.663447</td>\n",
       "      <td>0.084908</td>\n",
       "      <td>0.382994</td>\n",
       "      <td>0.044348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.665413</td>\n",
       "      <td>0.128366</td>\n",
       "      <td>0.399310</td>\n",
       "      <td>0.087358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.666010</td>\n",
       "      <td>0.059772</td>\n",
       "      <td>0.329161</td>\n",
       "      <td>0.172949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668140</td>\n",
       "      <td>0.087355</td>\n",
       "      <td>0.380062</td>\n",
       "      <td>0.043838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668165</td>\n",
       "      <td>0.143420</td>\n",
       "      <td>0.409441</td>\n",
       "      <td>0.117277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.683902</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>0.364069</td>\n",
       "      <td>0.060008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.683902</td>\n",
       "      <td>0.130702</td>\n",
       "      <td>0.364069</td>\n",
       "      <td>0.060008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.685277</td>\n",
       "      <td>0.131073</td>\n",
       "      <td>0.363593</td>\n",
       "      <td>0.059875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.685664</td>\n",
       "      <td>0.155312</td>\n",
       "      <td>0.312070</td>\n",
       "      <td>0.108024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.685738</td>\n",
       "      <td>0.131213</td>\n",
       "      <td>0.364028</td>\n",
       "      <td>0.059996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.693684</td>\n",
       "      <td>0.105919</td>\n",
       "      <td>0.374451</td>\n",
       "      <td>0.039649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.695217</td>\n",
       "      <td>0.102723</td>\n",
       "      <td>0.363091</td>\n",
       "      <td>0.043116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.697882</td>\n",
       "      <td>0.150329</td>\n",
       "      <td>0.308626</td>\n",
       "      <td>0.104821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.711148</td>\n",
       "      <td>0.140391</td>\n",
       "      <td>0.417479</td>\n",
       "      <td>0.090843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.712722</td>\n",
       "      <td>0.132018</td>\n",
       "      <td>0.422825</td>\n",
       "      <td>0.083009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.718950</td>\n",
       "      <td>0.093191</td>\n",
       "      <td>0.396167</td>\n",
       "      <td>0.155384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.729862</td>\n",
       "      <td>0.127007</td>\n",
       "      <td>0.396962</td>\n",
       "      <td>0.176899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.730125</td>\n",
       "      <td>0.153334</td>\n",
       "      <td>0.396496</td>\n",
       "      <td>0.209006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.730801</td>\n",
       "      <td>0.153502</td>\n",
       "      <td>0.418317</td>\n",
       "      <td>0.201542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.740770</td>\n",
       "      <td>0.127905</td>\n",
       "      <td>0.406284</td>\n",
       "      <td>0.173822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.745126</td>\n",
       "      <td>0.070340</td>\n",
       "      <td>0.399565</td>\n",
       "      <td>0.151126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.761789</td>\n",
       "      <td>0.071378</td>\n",
       "      <td>0.353640</td>\n",
       "      <td>0.186010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.775468</td>\n",
       "      <td>0.126347</td>\n",
       "      <td>0.387221</td>\n",
       "      <td>0.186813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.787230</td>\n",
       "      <td>0.061684</td>\n",
       "      <td>0.352444</td>\n",
       "      <td>0.189301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.798937</td>\n",
       "      <td>0.128195</td>\n",
       "      <td>0.415114</td>\n",
       "      <td>0.171272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.867541</td>\n",
       "      <td>0.109331</td>\n",
       "      <td>0.401789</td>\n",
       "      <td>0.021452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.880687</td>\n",
       "      <td>0.115865</td>\n",
       "      <td>0.400198</td>\n",
       "      <td>0.025391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.898135</td>\n",
       "      <td>0.115434</td>\n",
       "      <td>0.398219</td>\n",
       "      <td>0.031898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.920551</td>\n",
       "      <td>0.116131</td>\n",
       "      <td>0.396454</td>\n",
       "      <td>0.041688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.955951</td>\n",
       "      <td>0.124355</td>\n",
       "      <td>0.396553</td>\n",
       "      <td>0.057148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.985552</td>\n",
       "      <td>0.133378</td>\n",
       "      <td>0.397825</td>\n",
       "      <td>0.064584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.364064</td>\n",
       "      <td>0.199810</td>\n",
       "      <td>0.353947</td>\n",
       "      <td>0.092500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.440828</td>\n",
       "      <td>0.233985</td>\n",
       "      <td>0.359904</td>\n",
       "      <td>0.098834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.547609</td>\n",
       "      <td>0.265410</td>\n",
       "      <td>0.371417</td>\n",
       "      <td>0.100132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.707803</td>\n",
       "      <td>0.306913</td>\n",
       "      <td>0.384993</td>\n",
       "      <td>0.103903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.976005</td>\n",
       "      <td>0.370748</td>\n",
       "      <td>0.395870</td>\n",
       "      <td>0.126708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.241799</td>\n",
       "      <td>0.393611</td>\n",
       "      <td>0.393878</td>\n",
       "      <td>0.151201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.041942</td>\n",
       "      <td>1.647198</td>\n",
       "      <td>1.647198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-2.542596</td>\n",
       "      <td>0.700008</td>\n",
       "      <td>0.700008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.166368</td>\n",
       "      <td>0.161784</td>\n",
       "      <td>0.161784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.946608</td>\n",
       "      <td>0.094176</td>\n",
       "      <td>0.094176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.417645</td>\n",
       "      <td>0.023726</td>\n",
       "      <td>0.023726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.273041</td>\n",
       "      <td>0.012167</td>\n",
       "      <td>0.012167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.252060</td>\n",
       "      <td>0.011861</td>\n",
       "      <td>0.011861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.337238</td>\n",
       "      <td>0.010134</td>\n",
       "      <td>0.010134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.180189</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.003167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.173151</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.002656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.064868</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.001658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.066425</td>\n",
       "      <td>0.000966</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>1.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.543</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.166</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.066</td>\n",
       "      <td>-0.947</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.094</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.418</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.273</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.337</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.18</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.173</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.2\n",
      "2                          BIS_11                -0.2\n",
      "1                             EDM                 0.2\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "23          NCS_intellectual_task                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "21       IMI_perceived_competence                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                     feature_name  interaction_effect\n",
      "4                              RS                 0.2\n",
      "5                            TRSQ                 0.2\n",
      "6       ACES_neglectful_parenting                -0.2\n",
      "0                            BSCS                 0.0\n",
      "31             NCS_prefer_complex                 0.0\n",
      "24        NCS_deliberating_issues                 0.0\n",
      "25        NCS_like_responsibility                 0.0\n",
      "26      NCS_thinking_not_exciting                 0.0\n",
      "27                NCS_avoid_depth                 0.0\n",
      "28           NCS_thinking_not_fun                 0.0\n",
      "29          NCS_thought_appealing                 0.0\n",
      "30            NCS_think_minimally                 0.0\n",
      "33    NCS_relief_not_satisfaction                 0.0\n",
      "32      NCS_prefer_little_thought                 0.0\n",
      "22               NCS_get_job_done                 0.0\n",
      "34       NCS_tasks_little_thought                 0.0\n",
      "35  NCS_new_solutions_to_problems                 0.0\n",
      "36          NCS_abstract_thinking                 0.0\n",
      "37                      NCS_total                 0.0\n",
      "38       NCS_small_daily_projects                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 40)\n",
      "(275, 40)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 14 candidates, totalling 56 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180550dc0>], 'feature_selection__k': [20, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.23955957810293216, 0.2878064479899831, 0.3574069788355615, 0.2398166264775432, -0.08179426646722598]\n",
      "overall_score:\n",
      "0.2085590729877588\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491394</td>\n",
       "      <td>0.127494</td>\n",
       "      <td>0.376282</td>\n",
       "      <td>0.153759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505468</td>\n",
       "      <td>0.153665</td>\n",
       "      <td>0.396627</td>\n",
       "      <td>0.178225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.514534</td>\n",
       "      <td>0.168815</td>\n",
       "      <td>0.396060</td>\n",
       "      <td>0.188700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.528333</td>\n",
       "      <td>0.174366</td>\n",
       "      <td>0.395568</td>\n",
       "      <td>0.188186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.549900</td>\n",
       "      <td>0.179824</td>\n",
       "      <td>0.398038</td>\n",
       "      <td>0.187624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.581833</td>\n",
       "      <td>0.184607</td>\n",
       "      <td>0.401970</td>\n",
       "      <td>0.183567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604678</td>\n",
       "      <td>0.187035</td>\n",
       "      <td>0.406160</td>\n",
       "      <td>0.178239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.636612</td>\n",
       "      <td>0.153686</td>\n",
       "      <td>0.399966</td>\n",
       "      <td>0.127176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.679815</td>\n",
       "      <td>0.074358</td>\n",
       "      <td>0.332131</td>\n",
       "      <td>0.113183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.726658</td>\n",
       "      <td>0.103021</td>\n",
       "      <td>0.375983</td>\n",
       "      <td>0.115727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.808584</td>\n",
       "      <td>0.099608</td>\n",
       "      <td>0.456877</td>\n",
       "      <td>0.135156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.810064</td>\n",
       "      <td>0.070929</td>\n",
       "      <td>0.469691</td>\n",
       "      <td>0.165834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.810620</td>\n",
       "      <td>0.071979</td>\n",
       "      <td>0.471945</td>\n",
       "      <td>0.176085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.812255</td>\n",
       "      <td>0.069140</td>\n",
       "      <td>0.473328</td>\n",
       "      <td>0.175221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.815823</td>\n",
       "      <td>0.067164</td>\n",
       "      <td>0.473605</td>\n",
       "      <td>0.173759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.821358</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.473974</td>\n",
       "      <td>0.170925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.821379</td>\n",
       "      <td>0.135132</td>\n",
       "      <td>0.399167</td>\n",
       "      <td>0.080991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.824956</td>\n",
       "      <td>0.065872</td>\n",
       "      <td>0.474490</td>\n",
       "      <td>0.168904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.832035</td>\n",
       "      <td>0.126823</td>\n",
       "      <td>0.393458</td>\n",
       "      <td>0.108622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.851608</td>\n",
       "      <td>0.115791</td>\n",
       "      <td>0.402772</td>\n",
       "      <td>0.097978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.867071</td>\n",
       "      <td>0.109569</td>\n",
       "      <td>0.427864</td>\n",
       "      <td>0.089494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.879549</td>\n",
       "      <td>0.134879</td>\n",
       "      <td>0.401810</td>\n",
       "      <td>0.093942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.882720</td>\n",
       "      <td>0.135476</td>\n",
       "      <td>0.412303</td>\n",
       "      <td>0.124233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.882764</td>\n",
       "      <td>0.111225</td>\n",
       "      <td>0.407051</td>\n",
       "      <td>0.096847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.884657</td>\n",
       "      <td>0.113485</td>\n",
       "      <td>0.415697</td>\n",
       "      <td>0.074714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.888427</td>\n",
       "      <td>0.111840</td>\n",
       "      <td>0.415117</td>\n",
       "      <td>0.075382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.889802</td>\n",
       "      <td>0.151053</td>\n",
       "      <td>0.368624</td>\n",
       "      <td>0.107000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.891290</td>\n",
       "      <td>0.105063</td>\n",
       "      <td>0.411330</td>\n",
       "      <td>0.077729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.898470</td>\n",
       "      <td>0.136219</td>\n",
       "      <td>0.419561</td>\n",
       "      <td>0.112609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.909460</td>\n",
       "      <td>0.112347</td>\n",
       "      <td>0.409957</td>\n",
       "      <td>0.112787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.913469</td>\n",
       "      <td>0.117477</td>\n",
       "      <td>0.418868</td>\n",
       "      <td>0.091369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.913469</td>\n",
       "      <td>0.117477</td>\n",
       "      <td>0.418868</td>\n",
       "      <td>0.091369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.914268</td>\n",
       "      <td>0.162547</td>\n",
       "      <td>0.338188</td>\n",
       "      <td>0.148904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.914758</td>\n",
       "      <td>0.161997</td>\n",
       "      <td>0.339352</td>\n",
       "      <td>0.149962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.916009</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.419151</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.916009</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.419151</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.916009</td>\n",
       "      <td>0.093523</td>\n",
       "      <td>0.419151</td>\n",
       "      <td>0.059044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.923370</td>\n",
       "      <td>0.106362</td>\n",
       "      <td>0.379841</td>\n",
       "      <td>0.175472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.923755</td>\n",
       "      <td>0.104621</td>\n",
       "      <td>0.384244</td>\n",
       "      <td>0.175182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.923869</td>\n",
       "      <td>0.106858</td>\n",
       "      <td>0.376990</td>\n",
       "      <td>0.174508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.925684</td>\n",
       "      <td>0.102663</td>\n",
       "      <td>0.387319</td>\n",
       "      <td>0.173821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.927161</td>\n",
       "      <td>0.101264</td>\n",
       "      <td>0.389914</td>\n",
       "      <td>0.172328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.928648</td>\n",
       "      <td>0.094221</td>\n",
       "      <td>0.392161</td>\n",
       "      <td>0.160975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.930199</td>\n",
       "      <td>0.101324</td>\n",
       "      <td>0.416457</td>\n",
       "      <td>0.133898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.935482</td>\n",
       "      <td>0.092767</td>\n",
       "      <td>0.413982</td>\n",
       "      <td>0.071522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.937043</td>\n",
       "      <td>0.120440</td>\n",
       "      <td>0.424782</td>\n",
       "      <td>0.157504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.940025</td>\n",
       "      <td>0.122883</td>\n",
       "      <td>0.415760</td>\n",
       "      <td>0.154654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.941037</td>\n",
       "      <td>0.182519</td>\n",
       "      <td>0.419582</td>\n",
       "      <td>0.080687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.941804</td>\n",
       "      <td>0.104747</td>\n",
       "      <td>0.410547</td>\n",
       "      <td>0.073061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.941818</td>\n",
       "      <td>0.181094</td>\n",
       "      <td>0.420543</td>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.950385</td>\n",
       "      <td>0.073665</td>\n",
       "      <td>0.413867</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.950385</td>\n",
       "      <td>0.073665</td>\n",
       "      <td>0.413867</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.950385</td>\n",
       "      <td>0.073665</td>\n",
       "      <td>0.413867</td>\n",
       "      <td>0.044047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.956908</td>\n",
       "      <td>0.097216</td>\n",
       "      <td>0.418638</td>\n",
       "      <td>0.069312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.963242</td>\n",
       "      <td>0.196825</td>\n",
       "      <td>0.369450</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.968814</td>\n",
       "      <td>0.106371</td>\n",
       "      <td>0.415526</td>\n",
       "      <td>0.065266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.973879</td>\n",
       "      <td>0.100813</td>\n",
       "      <td>0.418136</td>\n",
       "      <td>0.065604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.979364</td>\n",
       "      <td>0.069568</td>\n",
       "      <td>0.373115</td>\n",
       "      <td>0.135693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.983985</td>\n",
       "      <td>0.063530</td>\n",
       "      <td>0.374146</td>\n",
       "      <td>0.133729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.988226</td>\n",
       "      <td>0.096973</td>\n",
       "      <td>0.412345</td>\n",
       "      <td>0.058237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.989042</td>\n",
       "      <td>0.137049</td>\n",
       "      <td>0.415411</td>\n",
       "      <td>0.204009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.989523</td>\n",
       "      <td>0.096124</td>\n",
       "      <td>0.410850</td>\n",
       "      <td>0.060024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.992269</td>\n",
       "      <td>0.179993</td>\n",
       "      <td>0.411651</td>\n",
       "      <td>0.109653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-3.998812</td>\n",
       "      <td>0.092993</td>\n",
       "      <td>0.378690</td>\n",
       "      <td>0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.999541</td>\n",
       "      <td>0.116340</td>\n",
       "      <td>0.419571</td>\n",
       "      <td>0.227532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.002493</td>\n",
       "      <td>0.061183</td>\n",
       "      <td>0.365666</td>\n",
       "      <td>0.130460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.006431</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.353427</td>\n",
       "      <td>0.119677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.017730</td>\n",
       "      <td>0.104066</td>\n",
       "      <td>0.391047</td>\n",
       "      <td>0.052299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.018734</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>0.421983</td>\n",
       "      <td>0.074995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-4.018734</td>\n",
       "      <td>0.156175</td>\n",
       "      <td>0.421983</td>\n",
       "      <td>0.074995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.020278</td>\n",
       "      <td>0.156566</td>\n",
       "      <td>0.421111</td>\n",
       "      <td>0.074806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-4.020278</td>\n",
       "      <td>0.156566</td>\n",
       "      <td>0.421111</td>\n",
       "      <td>0.074806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.023935</td>\n",
       "      <td>0.135372</td>\n",
       "      <td>0.383211</td>\n",
       "      <td>0.203799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.030376</td>\n",
       "      <td>0.117116</td>\n",
       "      <td>0.421302</td>\n",
       "      <td>0.088019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 20, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.032982</td>\n",
       "      <td>0.123376</td>\n",
       "      <td>0.368956</td>\n",
       "      <td>0.217018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.036510</td>\n",
       "      <td>0.122107</td>\n",
       "      <td>0.425334</td>\n",
       "      <td>0.092250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.047173</td>\n",
       "      <td>0.122408</td>\n",
       "      <td>0.430309</td>\n",
       "      <td>0.091251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.063108</td>\n",
       "      <td>0.128634</td>\n",
       "      <td>0.436813</td>\n",
       "      <td>0.091071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.087965</td>\n",
       "      <td>0.135934</td>\n",
       "      <td>0.445765</td>\n",
       "      <td>0.093907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.096602</td>\n",
       "      <td>0.084163</td>\n",
       "      <td>0.276896</td>\n",
       "      <td>0.130605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.107962</td>\n",
       "      <td>0.139312</td>\n",
       "      <td>0.449717</td>\n",
       "      <td>0.100601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x180550dc0&gt;}</th>\n",
       "      <td>-4.127509</td>\n",
       "      <td>0.086756</td>\n",
       "      <td>0.308495</td>\n",
       "      <td>0.145817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.404505</td>\n",
       "      <td>0.199584</td>\n",
       "      <td>0.358103</td>\n",
       "      <td>0.105365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.476224</td>\n",
       "      <td>0.233541</td>\n",
       "      <td>0.366025</td>\n",
       "      <td>0.111453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.575807</td>\n",
       "      <td>0.265595</td>\n",
       "      <td>0.376426</td>\n",
       "      <td>0.111782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.731985</td>\n",
       "      <td>0.305593</td>\n",
       "      <td>0.392543</td>\n",
       "      <td>0.113139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.991981</td>\n",
       "      <td>0.368549</td>\n",
       "      <td>0.404643</td>\n",
       "      <td>0.132348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-5.249842</td>\n",
       "      <td>0.393133</td>\n",
       "      <td>0.401434</td>\n",
       "      <td>0.155153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.540987</td>\n",
       "      <td>2.517312</td>\n",
       "      <td>2.517312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.457666</td>\n",
       "      <td>1.640721</td>\n",
       "      <td>1.640721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.321439</td>\n",
       "      <td>0.455755</td>\n",
       "      <td>0.455755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-1.340184</td>\n",
       "      <td>0.162157</td>\n",
       "      <td>0.162157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.492771</td>\n",
       "      <td>0.024445</td>\n",
       "      <td>0.024445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.421082</td>\n",
       "      <td>0.018296</td>\n",
       "      <td>0.018296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.322238</td>\n",
       "      <td>0.011071</td>\n",
       "      <td>0.011071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.303110</td>\n",
       "      <td>0.010067</td>\n",
       "      <td>0.010067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.212698</td>\n",
       "      <td>0.004146</td>\n",
       "      <td>0.004146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.108653</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.018880</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.003337</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:349: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.541</td>\n",
       "      <td>-0.493</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.517</td>\n",
       "      <td>0.024</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.632</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>2.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.624</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>0.464</td>\n",
       "      <td>0.456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.109</td>\n",
       "      <td>-1.340</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.162</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.423</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.421</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.322</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.213</td>\n",
       "      <td>-0.019</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_27475/3204600133.py:6: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "overall_scores = pd.DataFrame(columns=['n_features','effect_size', 'overall_score'])\n",
    "for predictors in [10,20,40]:\n",
    "    for es in [0.06, 0.08, 0.1, 0.15, 0.2]:\n",
    "        #run the analysis with a limited number of predictors\n",
    "        overall_score = run_full_limited_predictor_analysis(predictors, outcome_measures, analysis_data_imputed, effect_size=es)\n",
    "        overall_scores = overall_scores.append({'n_features':predictors,'effect_size':es, 'overall_score':overall_score},ignore_index=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion so far\n",
    "\n",
    "The feature selection applied here hasn't helped very much. That surprises me because in test_limited_predictors, I got clear evidence that cutting down irrelevant predictors improved model performance.\n",
    "\n",
    "One reason might be that we've actually cut down on useful predictors--unlike in `test_limited_predictors.ipynb`, we can't cheat by removing predictors we know to be irrelevant. That means we're left with less information in the model itself.\n",
    "\n",
    "We've only really tried SelectKBest(); there might be other feature selection mechanisms that could do the job. But I don't know yet."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014247d405695287815678bf9349a8dffb2674e9fe9a5bd4bb9820af018d638d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
