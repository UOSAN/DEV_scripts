{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dev_interaction_util import *\n",
    "from DevCvAnalysis import DevCvAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config.yml\") \n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic structure is the following:\n",
    "\n",
    "1. Run the following cross-validated analyses:\n",
    "   1. Predicting change by condition only\n",
    "   2. Predicting change by condition and neural and behavioral measures\n",
    "   3. Predicting change by condition, neural and behavioral measures, and their interactions\n",
    "2. Measure the predictivity of the three models above using anova\n",
    "3. Repeat the steps above separately for three outcome variables, change in: FFQ, ASA-24, and BFP\n",
    "4. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks to do to get this job done (not in order):\n",
    "\n",
    "1. Write the analysis pipeline above\n",
    "2. Get the neural data\n",
    "3. Get the behavioral data\n",
    "\n",
    "\n",
    "We have the behavioral data. Do we have the neural data already?\n",
    "\n",
    "What could we delegate here? Behavioral data we already have. We have mostly writen the analysis pipeline. The neural data could be passed on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from InterventionCVManager import *\n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n",
    "\n",
    "icvm = InterventionCVManager(dropbox_data_dir)\n",
    "icvm.mode = 'full_pipeline_test'\n",
    "\n",
    "#dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict change"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sets of variables to run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up a function that loops runs the scoring loop above (which does one cross-validation analysis), and the nadditionally:\n",
    "- selects the best model based on the overall results\n",
    "- Runs a final fit\n",
    "- presents model results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we include functions that compare models with and without individual differences and interactions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should manually verify that in the following list, the intervention_group allocations are randomized (if we're running a test run) or that they are accurate (if it's not a test run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>intervention_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV001</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV004</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV005</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEV008</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV009</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>willamette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>umpqua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>willamette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>mckenzie</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>244 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID intervention_group\n",
       "0    DEV001             umpqua\n",
       "1    DEV004             umpqua\n",
       "2    DEV005             umpqua\n",
       "3    DEV008             umpqua\n",
       "4    DEV009             umpqua\n",
       "..      ...                ...\n",
       "239  DEV308         willamette\n",
       "240  DEV309             umpqua\n",
       "241  DEV310           mckenzie\n",
       "242  DEV311         willamette\n",
       "243  DEV312           mckenzie\n",
       "\n",
       "[244 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    dev_cv_analysis.outcome_measures['SID'],\n",
    "      dev_cv_analysis.group_assignments\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SID', 'cancer_promoting_minus_preventing_FFQ', 'cancer_promoting_FFQ',\n",
       "       'bf', 'NUTRIENT_DENSITY_2wkAverage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_cv_analysis.outcome_measures.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_cols = dev_cv_analysis.group_assignment_onehots.columns.tolist()\n",
    "inddiff_cols = dev_cv_analysis.get_predictors_main_names()\n",
    "\n",
    "interaction_cols = [id + \"*\" + cond for id in inddiff_cols for cond in condition_cols]\n",
    "\n",
    "predictor_sets = {\n",
    "    'condition_inddiff_interactions': condition_cols + inddiff_cols + interaction_cols,\n",
    "    'condition_inddiff': condition_cols + inddiff_cols,\n",
    "    'condition_only': condition_cols\n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "outcome_vars_to_try = [ 'bf','cancer_promoting_FFQ',\n",
    "       'NUTRIENT_DENSITY_2wkAverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BSCS, EDM, BIS_11, PCS, RS, TRSQ, ACES_sum, BFI_agreeableness, BFI_conscientiousness, BFI_extraversion, BFI_neuroticism, BFI_openness, IMI_effort_importance, IMI_interest_enjoyment, NCS_total, PLAN_cognitive_strategies, PLAN_mental_flexibility, PLAN_temporal_orientation, RMQ_assessment, TESQ_E_sum, SRHI_healthy_minus_unhealthy, RTFS_f1_minus_f2, cancer_promoting_minus_preventing_craved_FCI, cancer_promoting_minus_preventing_liked_FCI, cSES, age365, education_own, SST_SSD, SST_mean_ssrt_0, ROC_Crave_Regulate_Minus_Look, WTP_unhealthy_minus_healthy, wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero, wtp_liked_value_association-test_z_FDR_0.01, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01, roc_reappraiseCrave_abstract_association-test_z_FDR_0.01, roc_reappraiseCrave_multivariate_regulation, roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero, sst_CorrectGo_striatum_joint_mask, sst_CorrectGo_finger movements_association-test_z_FDR_0.01, sst_CorrectStop_motor_control_striatum_joint_mask, sst_CorrectStop_response inhibition_association-test_z_FDR_0.01, sst_FailedStop_motor_control_striatum_joint_mask, sst_CorrectGoFollowingFailedStop_striatum_joint_mask, birthsex_factor_Male, mckenzie, willamette, BSCS*mckenzie, EDM*mckenzie, BIS_11*mckenzie, PCS*mckenzie, RS*mckenzie, TRSQ*mckenzie, ACES_sum*mckenzie, BFI_agreeableness*mckenzie, BFI_conscientiousness*mckenzie, BFI_extraversion*mckenzie, BFI_neuroticism*mckenzie, BFI_openness*mckenzie, IMI_effort_importance*mckenzie, IMI_interest_enjoyment*mckenzie, NCS_total*mckenzie, PLAN_cognitive_strategies*mckenzie, PLAN_mental_flexibility*mckenzie, PLAN_temporal_orientation*mckenzie, RMQ_assessment*mckenzie, TESQ_E_sum*mckenzie, SRHI_healthy_minus_unhealthy*mckenzie, RTFS_f1_minus_f2*mckenzie, cancer_promoting_minus_preventing_craved_FCI*mckenzie, cancer_promoting_minus_preventing_liked_FCI*mckenzie, cSES*mckenzie, age365*mckenzie, education_own*mckenzie, SST_SSD*mckenzie, SST_mean_ssrt_0*mckenzie, ROC_Crave_Regulate_Minus_Look*mckenzie, WTP_unhealthy_minus_healthy*mckenzie, wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie, wtp_liked_value_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*mckenzie, roc_reappraiseCrave_multivariate_regulation*mckenzie, roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie, sst_CorrectGo_striatum_joint_mask*mckenzie, sst_CorrectGo_finger movements_association-test_z_FDR_0.01*mckenzie, sst_CorrectStop_motor_control_striatum_joint_mask*mckenzie, sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*mckenzie, sst_FailedStop_motor_control_striatum_joint_mask*mckenzie, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie, birthsex_factor_Male*mckenzie, BSCS*willamette, EDM*willamette, BIS_11*willamette, PCS*willamette, RS*willamette, TRSQ*willamette, ACES_sum*willamette, BFI_agreeableness*willamette, BFI_conscientiousness*willamette, BFI_extraversion*willamette, BFI_neuroticism*willamette, BFI_openness*willamette, IMI_effort_importance*willamette, IMI_interest_enjoyment*willamette, NCS_total*willamette, PLAN_cognitive_strategies*willamette, PLAN_mental_flexibility*willamette, PLAN_temporal_orientation*willamette, RMQ_assessment*willamette, TESQ_E_sum*willamette, SRHI_healthy_minus_unhealthy*willamette, RTFS_f1_minus_f2*willamette, cancer_promoting_minus_preventing_craved_FCI*willamette, cancer_promoting_minus_preventing_liked_FCI*willamette, cSES*willamette, age365*willamette, education_own*willamette, SST_SSD*willamette, SST_mean_ssrt_0*willamette, ROC_Crave_Regulate_Minus_Look*willamette, WTP_unhealthy_minus_healthy*willamette, wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette, wtp_liked_value_association-test_z_FDR_0.01*willamette, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*willamette, roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*willamette, roc_reappraiseCrave_multivariate_regulation*willamette, roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette, sst_CorrectGo_striatum_joint_mask*willamette, sst_CorrectGo_finger movements_association-test_z_FDR_0.01*willamette, sst_CorrectStop_motor_control_striatum_joint_mask*willamette, sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*willamette, sst_FailedStop_motor_control_striatum_joint_mask*willamette, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*willamette, birthsex_factor_Male*willamette\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.get_predictor_data().columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Fat Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict bf with 134 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are mckenzie willamette BSCS EDM BIS_11 PCS RS TRSQ ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_flexibility PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_abstract_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero sst_CorrectGo_striatum_joint_mask sst_CorrectGo_finger movements_association-test_z_FDR_0.01 sst_CorrectStop_motor_control_striatum_joint_mask sst_CorrectStop_response inhibition_association-test_z_FDR_0.01 sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask birthsex_factor_Male BSCS*mckenzie BSCS*willamette EDM*mckenzie EDM*willamette BIS_11*mckenzie BIS_11*willamette PCS*mckenzie PCS*willamette RS*mckenzie RS*willamette TRSQ*mckenzie TRSQ*willamette ACES_sum*mckenzie ACES_sum*willamette BFI_agreeableness*mckenzie BFI_agreeableness*willamette BFI_conscientiousness*mckenzie BFI_conscientiousness*willamette BFI_extraversion*mckenzie BFI_extraversion*willamette BFI_neuroticism*mckenzie BFI_neuroticism*willamette BFI_openness*mckenzie BFI_openness*willamette IMI_effort_importance*mckenzie IMI_effort_importance*willamette IMI_interest_enjoyment*mckenzie IMI_interest_enjoyment*willamette NCS_total*mckenzie NCS_total*willamette PLAN_cognitive_strategies*mckenzie PLAN_cognitive_strategies*willamette PLAN_mental_flexibility*mckenzie PLAN_mental_flexibility*willamette PLAN_temporal_orientation*mckenzie PLAN_temporal_orientation*willamette RMQ_assessment*mckenzie RMQ_assessment*willamette TESQ_E_sum*mckenzie TESQ_E_sum*willamette SRHI_healthy_minus_unhealthy*mckenzie SRHI_healthy_minus_unhealthy*willamette RTFS_f1_minus_f2*mckenzie RTFS_f1_minus_f2*willamette cancer_promoting_minus_preventing_craved_FCI*mckenzie cancer_promoting_minus_preventing_craved_FCI*willamette cancer_promoting_minus_preventing_liked_FCI*mckenzie cancer_promoting_minus_preventing_liked_FCI*willamette cSES*mckenzie cSES*willamette age365*mckenzie age365*willamette education_own*mckenzie education_own*willamette SST_SSD*mckenzie SST_SSD*willamette SST_mean_ssrt_0*mckenzie SST_mean_ssrt_0*willamette ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Regulate_Minus_Look*willamette WTP_unhealthy_minus_healthy*mckenzie WTP_unhealthy_minus_healthy*willamette wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette wtp_liked_value_association-test_z_FDR_0.01*mckenzie wtp_liked_value_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_multivariate_regulation*mckenzie roc_reappraiseCrave_multivariate_regulation*willamette roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette sst_CorrectGo_striatum_joint_mask*mckenzie sst_CorrectGo_striatum_joint_mask*willamette sst_CorrectGo_finger movements_association-test_z_FDR_0.01*mckenzie sst_CorrectGo_finger movements_association-test_z_FDR_0.01*willamette sst_CorrectStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectStop_motor_control_striatum_joint_mask*willamette sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*mckenzie sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*willamette sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*willamette sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*willamette birthsex_factor_Male*mckenzie birthsex_factor_Male*willamette\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores:\n",
      "[-0.0008332924335445746, -0.35685302348360337, -0.22191645107293612, -0.0009780782431259016, -0.02128188803652664]\n",
      "overall_score:\n",
      "-0.12037254665394732\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-1.117753</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>0.102578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117753</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>0.102578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117753</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>0.102578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117753</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>0.138082</td>\n",
       "      <td>0.102578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.120883</td>\n",
       "      <td>0.028780</td>\n",
       "      <td>0.141590</td>\n",
       "      <td>0.098530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.121040</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>0.142073</td>\n",
       "      <td>0.098052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.122091</td>\n",
       "      <td>0.024763</td>\n",
       "      <td>0.137884</td>\n",
       "      <td>0.099079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.126409</td>\n",
       "      <td>0.029639</td>\n",
       "      <td>0.144295</td>\n",
       "      <td>0.094476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.127217</td>\n",
       "      <td>0.030425</td>\n",
       "      <td>0.146261</td>\n",
       "      <td>0.090635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-1.129188</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.128174</td>\n",
       "      <td>0.097617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.129383</td>\n",
       "      <td>0.021571</td>\n",
       "      <td>0.128949</td>\n",
       "      <td>0.096642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.129738</td>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.138031</td>\n",
       "      <td>0.102010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.130689</td>\n",
       "      <td>0.021990</td>\n",
       "      <td>0.129809</td>\n",
       "      <td>0.097558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.131094</td>\n",
       "      <td>0.022514</td>\n",
       "      <td>0.127429</td>\n",
       "      <td>0.096270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.155872</td>\n",
       "      <td>0.031580</td>\n",
       "      <td>0.142420</td>\n",
       "      <td>0.087508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.159049</td>\n",
       "      <td>0.033368</td>\n",
       "      <td>0.142441</td>\n",
       "      <td>0.093242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.159086</td>\n",
       "      <td>0.032177</td>\n",
       "      <td>0.121381</td>\n",
       "      <td>0.079152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.159713</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>0.139962</td>\n",
       "      <td>0.066972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.159713</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>0.139962</td>\n",
       "      <td>0.066972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.159713</td>\n",
       "      <td>0.038763</td>\n",
       "      <td>0.139962</td>\n",
       "      <td>0.066972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.160014</td>\n",
       "      <td>0.025159</td>\n",
       "      <td>0.117598</td>\n",
       "      <td>0.088273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.162783</td>\n",
       "      <td>0.033300</td>\n",
       "      <td>0.142682</td>\n",
       "      <td>0.093756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"16\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.162938</td>\n",
       "      <td>0.037877</td>\n",
       "      <td>0.142555</td>\n",
       "      <td>0.073470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.162938</td>\n",
       "      <td>0.037877</td>\n",
       "      <td>0.142555</td>\n",
       "      <td>0.073470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.162938</td>\n",
       "      <td>0.037877</td>\n",
       "      <td>0.142555</td>\n",
       "      <td>0.073470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.163509</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>0.066692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.163509</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>0.066692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.163509</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.130526</td>\n",
       "      <td>0.066692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.164753</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.128206</td>\n",
       "      <td>0.077633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.164753</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.128206</td>\n",
       "      <td>0.077633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.164753</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>0.128206</td>\n",
       "      <td>0.077633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165037</td>\n",
       "      <td>0.040673</td>\n",
       "      <td>0.144014</td>\n",
       "      <td>0.072754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165056</td>\n",
       "      <td>0.040661</td>\n",
       "      <td>0.144014</td>\n",
       "      <td>0.072754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165056</td>\n",
       "      <td>0.040661</td>\n",
       "      <td>0.144014</td>\n",
       "      <td>0.072754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165560</td>\n",
       "      <td>0.040927</td>\n",
       "      <td>0.143550</td>\n",
       "      <td>0.073431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165560</td>\n",
       "      <td>0.040927</td>\n",
       "      <td>0.143550</td>\n",
       "      <td>0.073431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165579</td>\n",
       "      <td>0.040915</td>\n",
       "      <td>0.143551</td>\n",
       "      <td>0.073431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.165659</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>0.139538</td>\n",
       "      <td>0.061278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.167325</td>\n",
       "      <td>0.029171</td>\n",
       "      <td>0.112332</td>\n",
       "      <td>0.079371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.167338</td>\n",
       "      <td>0.033319</td>\n",
       "      <td>0.143237</td>\n",
       "      <td>0.094324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.168852</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.138530</td>\n",
       "      <td>0.089105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.168852</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.138530</td>\n",
       "      <td>0.089105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.168852</td>\n",
       "      <td>0.040491</td>\n",
       "      <td>0.138530</td>\n",
       "      <td>0.089105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169272</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.089169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169272</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.089169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169272</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.089169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169272</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.089169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169272</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.089169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169272</td>\n",
       "      <td>0.041018</td>\n",
       "      <td>0.141951</td>\n",
       "      <td>0.089169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169765</td>\n",
       "      <td>0.051725</td>\n",
       "      <td>0.133696</td>\n",
       "      <td>0.081123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169765</td>\n",
       "      <td>0.051725</td>\n",
       "      <td>0.133696</td>\n",
       "      <td>0.081123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169765</td>\n",
       "      <td>0.051725</td>\n",
       "      <td>0.133696</td>\n",
       "      <td>0.081123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169785</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.133690</td>\n",
       "      <td>0.081128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169785</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.133690</td>\n",
       "      <td>0.081128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169785</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.133690</td>\n",
       "      <td>0.081128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-1.169912</td>\n",
       "      <td>0.028589</td>\n",
       "      <td>0.112437</td>\n",
       "      <td>0.075026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169918</td>\n",
       "      <td>0.046101</td>\n",
       "      <td>0.142954</td>\n",
       "      <td>0.082437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169918</td>\n",
       "      <td>0.046101</td>\n",
       "      <td>0.142954</td>\n",
       "      <td>0.082437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169918</td>\n",
       "      <td>0.046101</td>\n",
       "      <td>0.142954</td>\n",
       "      <td>0.082437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169942</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.047268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169942</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.139865</td>\n",
       "      <td>0.047268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169948</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.149540</td>\n",
       "      <td>0.056376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.169948</td>\n",
       "      <td>0.020440</td>\n",
       "      <td>0.149540</td>\n",
       "      <td>0.056376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.170001</td>\n",
       "      <td>0.042466</td>\n",
       "      <td>0.136151</td>\n",
       "      <td>0.050216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.173208</td>\n",
       "      <td>0.027445</td>\n",
       "      <td>0.119321</td>\n",
       "      <td>0.080132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.173440</td>\n",
       "      <td>0.033906</td>\n",
       "      <td>0.144065</td>\n",
       "      <td>0.094791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.173762</td>\n",
       "      <td>0.034479</td>\n",
       "      <td>0.112156</td>\n",
       "      <td>0.073521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.177148</td>\n",
       "      <td>0.034268</td>\n",
       "      <td>0.144552</td>\n",
       "      <td>0.095081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.178081</td>\n",
       "      <td>0.022982</td>\n",
       "      <td>0.123545</td>\n",
       "      <td>0.093635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.179653</td>\n",
       "      <td>0.036185</td>\n",
       "      <td>0.115741</td>\n",
       "      <td>0.074187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.179653</td>\n",
       "      <td>0.036185</td>\n",
       "      <td>0.115741</td>\n",
       "      <td>0.074187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.181212</td>\n",
       "      <td>0.029908</td>\n",
       "      <td>0.122178</td>\n",
       "      <td>0.081452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.183732</td>\n",
       "      <td>0.032928</td>\n",
       "      <td>0.122876</td>\n",
       "      <td>0.073794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.185494</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.089438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.185494</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.089438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.185494</td>\n",
       "      <td>0.021641</td>\n",
       "      <td>0.140969</td>\n",
       "      <td>0.089438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.186850</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.116881</td>\n",
       "      <td>0.085845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.186850</td>\n",
       "      <td>0.031430</td>\n",
       "      <td>0.116881</td>\n",
       "      <td>0.085845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.187352</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.136703</td>\n",
       "      <td>0.083841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.187352</td>\n",
       "      <td>0.019499</td>\n",
       "      <td>0.136703</td>\n",
       "      <td>0.083841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.187493</td>\n",
       "      <td>0.033166</td>\n",
       "      <td>0.129190</td>\n",
       "      <td>0.078343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.190504</td>\n",
       "      <td>0.033188</td>\n",
       "      <td>0.151225</td>\n",
       "      <td>0.109597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.190504</td>\n",
       "      <td>0.033188</td>\n",
       "      <td>0.151225</td>\n",
       "      <td>0.109597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.190504</td>\n",
       "      <td>0.033188</td>\n",
       "      <td>0.151225</td>\n",
       "      <td>0.109597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.195353</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>0.095155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.195353</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>0.095155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.195353</td>\n",
       "      <td>0.042434</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>0.095155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.196006</td>\n",
       "      <td>0.035922</td>\n",
       "      <td>0.129625</td>\n",
       "      <td>0.073863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.196445</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.131273</td>\n",
       "      <td>0.105101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.196445</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.131273</td>\n",
       "      <td>0.105101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.196445</td>\n",
       "      <td>0.040579</td>\n",
       "      <td>0.131273</td>\n",
       "      <td>0.105101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.198890</td>\n",
       "      <td>0.049925</td>\n",
       "      <td>0.107914</td>\n",
       "      <td>0.056272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.199314</td>\n",
       "      <td>0.040588</td>\n",
       "      <td>0.126372</td>\n",
       "      <td>0.083762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.199314</td>\n",
       "      <td>0.040588</td>\n",
       "      <td>0.126372</td>\n",
       "      <td>0.083762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.200812</td>\n",
       "      <td>0.020046</td>\n",
       "      <td>0.127132</td>\n",
       "      <td>0.099315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.203201</td>\n",
       "      <td>0.053480</td>\n",
       "      <td>0.155680</td>\n",
       "      <td>0.056325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.204163</td>\n",
       "      <td>0.047532</td>\n",
       "      <td>0.142121</td>\n",
       "      <td>0.086851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.205272</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.134112</td>\n",
       "      <td>0.065883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.205272</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.134112</td>\n",
       "      <td>0.065883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.205272</td>\n",
       "      <td>0.015143</td>\n",
       "      <td>0.134112</td>\n",
       "      <td>0.065883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.207058</td>\n",
       "      <td>0.027986</td>\n",
       "      <td>0.137084</td>\n",
       "      <td>0.093703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.207106</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.056449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.207106</td>\n",
       "      <td>0.047805</td>\n",
       "      <td>0.112606</td>\n",
       "      <td>0.056449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.208632</td>\n",
       "      <td>0.059958</td>\n",
       "      <td>0.144616</td>\n",
       "      <td>0.033259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.208797</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>0.157177</td>\n",
       "      <td>0.100255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.208797</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>0.157177</td>\n",
       "      <td>0.100255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.208797</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>0.157177</td>\n",
       "      <td>0.100255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.209955</td>\n",
       "      <td>0.044866</td>\n",
       "      <td>0.163004</td>\n",
       "      <td>0.060263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.209955</td>\n",
       "      <td>0.044866</td>\n",
       "      <td>0.163004</td>\n",
       "      <td>0.060263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.212202</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>0.142401</td>\n",
       "      <td>0.092276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212276</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.124745</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212276</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.124745</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212276</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.124745</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212276</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.124745</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212276</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.124745</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212276</td>\n",
       "      <td>0.027326</td>\n",
       "      <td>0.124745</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.212848</td>\n",
       "      <td>0.025451</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.074244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.213075</td>\n",
       "      <td>0.027014</td>\n",
       "      <td>0.115389</td>\n",
       "      <td>0.078703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.213304</td>\n",
       "      <td>0.027034</td>\n",
       "      <td>0.115394</td>\n",
       "      <td>0.078658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.213534</td>\n",
       "      <td>0.027055</td>\n",
       "      <td>0.115399</td>\n",
       "      <td>0.078613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.213765</td>\n",
       "      <td>0.027077</td>\n",
       "      <td>0.115403</td>\n",
       "      <td>0.078569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.213881</td>\n",
       "      <td>0.027089</td>\n",
       "      <td>0.115406</td>\n",
       "      <td>0.078547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.215517</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>0.135345</td>\n",
       "      <td>0.093351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.215517</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>0.135345</td>\n",
       "      <td>0.093351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.215517</td>\n",
       "      <td>0.046030</td>\n",
       "      <td>0.135345</td>\n",
       "      <td>0.093351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.217281</td>\n",
       "      <td>0.060107</td>\n",
       "      <td>0.160479</td>\n",
       "      <td>0.047009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.217800</td>\n",
       "      <td>0.029160</td>\n",
       "      <td>0.147338</td>\n",
       "      <td>0.116906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.220181</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.220181</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.220181</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.220181</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.220181</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.220181</td>\n",
       "      <td>0.043934</td>\n",
       "      <td>0.150691</td>\n",
       "      <td>0.093800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.220829</td>\n",
       "      <td>0.020291</td>\n",
       "      <td>0.142292</td>\n",
       "      <td>0.073894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.220948</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.153790</td>\n",
       "      <td>0.041768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.221870</td>\n",
       "      <td>0.051388</td>\n",
       "      <td>0.142669</td>\n",
       "      <td>0.092421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.222633</td>\n",
       "      <td>0.028198</td>\n",
       "      <td>0.139762</td>\n",
       "      <td>0.114201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.222674</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.150710</td>\n",
       "      <td>0.079096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.222674</td>\n",
       "      <td>0.032033</td>\n",
       "      <td>0.150710</td>\n",
       "      <td>0.079096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.222711</td>\n",
       "      <td>0.054181</td>\n",
       "      <td>0.154856</td>\n",
       "      <td>0.040419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.222961</td>\n",
       "      <td>0.030826</td>\n",
       "      <td>0.144477</td>\n",
       "      <td>0.078758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.223478</td>\n",
       "      <td>0.015069</td>\n",
       "      <td>0.148844</td>\n",
       "      <td>0.091489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.226581</td>\n",
       "      <td>0.056390</td>\n",
       "      <td>0.157979</td>\n",
       "      <td>0.088910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.227817</td>\n",
       "      <td>0.041160</td>\n",
       "      <td>0.145788</td>\n",
       "      <td>0.089046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.228030</td>\n",
       "      <td>0.053650</td>\n",
       "      <td>0.160022</td>\n",
       "      <td>0.068829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.228960</td>\n",
       "      <td>0.047606</td>\n",
       "      <td>0.122761</td>\n",
       "      <td>0.082740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.229947</td>\n",
       "      <td>0.049730</td>\n",
       "      <td>0.159246</td>\n",
       "      <td>0.069091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.231059</td>\n",
       "      <td>0.024061</td>\n",
       "      <td>0.143561</td>\n",
       "      <td>0.071514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.231227</td>\n",
       "      <td>0.048644</td>\n",
       "      <td>0.142919</td>\n",
       "      <td>0.067902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.231295</td>\n",
       "      <td>0.066796</td>\n",
       "      <td>0.154849</td>\n",
       "      <td>0.089362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.232303</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.134481</td>\n",
       "      <td>0.084310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233070</td>\n",
       "      <td>0.050464</td>\n",
       "      <td>0.156737</td>\n",
       "      <td>0.068607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233639</td>\n",
       "      <td>0.052091</td>\n",
       "      <td>0.142831</td>\n",
       "      <td>0.092898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234110</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.144093</td>\n",
       "      <td>0.110962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234110</td>\n",
       "      <td>0.043216</td>\n",
       "      <td>0.144093</td>\n",
       "      <td>0.110962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234290</td>\n",
       "      <td>0.036296</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>0.061480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234677</td>\n",
       "      <td>0.038751</td>\n",
       "      <td>0.098858</td>\n",
       "      <td>0.065119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234938</td>\n",
       "      <td>0.032121</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>0.092014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234938</td>\n",
       "      <td>0.032121</td>\n",
       "      <td>0.152102</td>\n",
       "      <td>0.092014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.235075</td>\n",
       "      <td>0.039026</td>\n",
       "      <td>0.098706</td>\n",
       "      <td>0.065028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.235488</td>\n",
       "      <td>0.039326</td>\n",
       "      <td>0.098544</td>\n",
       "      <td>0.064934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.235532</td>\n",
       "      <td>0.049802</td>\n",
       "      <td>0.137339</td>\n",
       "      <td>0.114738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.235916</td>\n",
       "      <td>0.039653</td>\n",
       "      <td>0.098373</td>\n",
       "      <td>0.064836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.236029</td>\n",
       "      <td>0.036414</td>\n",
       "      <td>0.152093</td>\n",
       "      <td>0.067720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.236156</td>\n",
       "      <td>0.039827</td>\n",
       "      <td>0.098254</td>\n",
       "      <td>0.064807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.238439</td>\n",
       "      <td>0.048486</td>\n",
       "      <td>0.137469</td>\n",
       "      <td>0.114571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.238693</td>\n",
       "      <td>0.028960</td>\n",
       "      <td>0.145009</td>\n",
       "      <td>0.091941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.238802</td>\n",
       "      <td>0.041458</td>\n",
       "      <td>0.145269</td>\n",
       "      <td>0.108577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239113</td>\n",
       "      <td>0.038241</td>\n",
       "      <td>0.128481</td>\n",
       "      <td>0.050077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239145</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.124982</td>\n",
       "      <td>0.078042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239145</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.124982</td>\n",
       "      <td>0.078042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239145</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.124982</td>\n",
       "      <td>0.078042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239145</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.124982</td>\n",
       "      <td>0.078042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239145</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.124982</td>\n",
       "      <td>0.078042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239145</td>\n",
       "      <td>0.048161</td>\n",
       "      <td>0.124982</td>\n",
       "      <td>0.078042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.239855</td>\n",
       "      <td>0.041083</td>\n",
       "      <td>0.128716</td>\n",
       "      <td>0.052619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.240609</td>\n",
       "      <td>0.041670</td>\n",
       "      <td>0.129041</td>\n",
       "      <td>0.052051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.241224</td>\n",
       "      <td>0.052170</td>\n",
       "      <td>0.105679</td>\n",
       "      <td>0.048674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.241378</td>\n",
       "      <td>0.042335</td>\n",
       "      <td>0.129487</td>\n",
       "      <td>0.051392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242410</td>\n",
       "      <td>0.043253</td>\n",
       "      <td>0.129694</td>\n",
       "      <td>0.050919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.242483</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.167209</td>\n",
       "      <td>0.079372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.242483</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.167209</td>\n",
       "      <td>0.079372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.242483</td>\n",
       "      <td>0.030325</td>\n",
       "      <td>0.167209</td>\n",
       "      <td>0.079372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.243043</td>\n",
       "      <td>0.043820</td>\n",
       "      <td>0.129694</td>\n",
       "      <td>0.050764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.244975</td>\n",
       "      <td>0.066062</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.043636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.245684</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>0.141478</td>\n",
       "      <td>0.085772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.246658</td>\n",
       "      <td>0.051891</td>\n",
       "      <td>0.143465</td>\n",
       "      <td>0.092228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.246685</td>\n",
       "      <td>0.058326</td>\n",
       "      <td>0.114733</td>\n",
       "      <td>0.067454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.248125</td>\n",
       "      <td>0.053457</td>\n",
       "      <td>0.143080</td>\n",
       "      <td>0.093688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.250387</td>\n",
       "      <td>0.023290</td>\n",
       "      <td>0.136211</td>\n",
       "      <td>0.094032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.251142</td>\n",
       "      <td>0.053591</td>\n",
       "      <td>0.142729</td>\n",
       "      <td>0.103000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.255039</td>\n",
       "      <td>0.064985</td>\n",
       "      <td>0.148890</td>\n",
       "      <td>0.089261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.256311</td>\n",
       "      <td>0.036732</td>\n",
       "      <td>0.151353</td>\n",
       "      <td>0.087868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.256311</td>\n",
       "      <td>0.036732</td>\n",
       "      <td>0.151353</td>\n",
       "      <td>0.087868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.256770</td>\n",
       "      <td>0.054393</td>\n",
       "      <td>0.143273</td>\n",
       "      <td>0.094181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.257018</td>\n",
       "      <td>0.063589</td>\n",
       "      <td>0.145505</td>\n",
       "      <td>0.092493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.257522</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>0.151847</td>\n",
       "      <td>0.089972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.257522</td>\n",
       "      <td>0.039193</td>\n",
       "      <td>0.151847</td>\n",
       "      <td>0.089972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.261842</td>\n",
       "      <td>0.026331</td>\n",
       "      <td>0.136206</td>\n",
       "      <td>0.098513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.261846</td>\n",
       "      <td>0.061995</td>\n",
       "      <td>0.153549</td>\n",
       "      <td>0.052653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.261946</td>\n",
       "      <td>0.063397</td>\n",
       "      <td>0.141836</td>\n",
       "      <td>0.093047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.262483</td>\n",
       "      <td>0.045114</td>\n",
       "      <td>0.145050</td>\n",
       "      <td>0.098462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.263349</td>\n",
       "      <td>0.044487</td>\n",
       "      <td>0.138774</td>\n",
       "      <td>0.119027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.264816</td>\n",
       "      <td>0.040091</td>\n",
       "      <td>0.107892</td>\n",
       "      <td>0.057879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.265955</td>\n",
       "      <td>0.043170</td>\n",
       "      <td>0.135881</td>\n",
       "      <td>0.121592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.266305</td>\n",
       "      <td>0.071623</td>\n",
       "      <td>0.107716</td>\n",
       "      <td>0.058396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.267917</td>\n",
       "      <td>0.036543</td>\n",
       "      <td>0.130303</td>\n",
       "      <td>0.088936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267942</td>\n",
       "      <td>0.076034</td>\n",
       "      <td>0.162590</td>\n",
       "      <td>0.107944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.268452</td>\n",
       "      <td>0.059093</td>\n",
       "      <td>0.124310</td>\n",
       "      <td>0.062496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.268638</td>\n",
       "      <td>0.072255</td>\n",
       "      <td>0.132380</td>\n",
       "      <td>0.100259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.268891</td>\n",
       "      <td>0.050935</td>\n",
       "      <td>0.113583</td>\n",
       "      <td>0.048776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.269948</td>\n",
       "      <td>0.049954</td>\n",
       "      <td>0.114950</td>\n",
       "      <td>0.047486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.269961</td>\n",
       "      <td>0.056933</td>\n",
       "      <td>0.121326</td>\n",
       "      <td>0.065576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.270998</td>\n",
       "      <td>0.087113</td>\n",
       "      <td>0.155988</td>\n",
       "      <td>0.100905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.271091</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.271091</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.271091</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.271091</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.271091</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.271091</td>\n",
       "      <td>0.024647</td>\n",
       "      <td>0.170248</td>\n",
       "      <td>0.074576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.272266</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>0.142876</td>\n",
       "      <td>0.079961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.275021</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.090898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.275021</td>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.131722</td>\n",
       "      <td>0.090898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.275583</td>\n",
       "      <td>0.028513</td>\n",
       "      <td>0.135994</td>\n",
       "      <td>0.097945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.276141</td>\n",
       "      <td>0.026101</td>\n",
       "      <td>0.137829</td>\n",
       "      <td>0.093229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.276655</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.152561</td>\n",
       "      <td>0.098370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.276655</td>\n",
       "      <td>0.045296</td>\n",
       "      <td>0.152561</td>\n",
       "      <td>0.098370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.280495</td>\n",
       "      <td>0.068073</td>\n",
       "      <td>0.157094</td>\n",
       "      <td>0.081961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.281574</td>\n",
       "      <td>0.046546</td>\n",
       "      <td>0.149061</td>\n",
       "      <td>0.066618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.283830</td>\n",
       "      <td>0.056518</td>\n",
       "      <td>0.140995</td>\n",
       "      <td>0.072543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.285862</td>\n",
       "      <td>0.050838</td>\n",
       "      <td>0.139880</td>\n",
       "      <td>0.058157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.286783</td>\n",
       "      <td>0.072437</td>\n",
       "      <td>0.163511</td>\n",
       "      <td>0.062732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.287491</td>\n",
       "      <td>0.074707</td>\n",
       "      <td>0.160222</td>\n",
       "      <td>0.057123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.289146</td>\n",
       "      <td>0.092541</td>\n",
       "      <td>0.123897</td>\n",
       "      <td>0.098264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.292265</td>\n",
       "      <td>0.031432</td>\n",
       "      <td>0.135706</td>\n",
       "      <td>0.098048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.292594</td>\n",
       "      <td>0.087851</td>\n",
       "      <td>0.130362</td>\n",
       "      <td>0.097672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.293124</td>\n",
       "      <td>0.079380</td>\n",
       "      <td>0.159409</td>\n",
       "      <td>0.088718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.295041</td>\n",
       "      <td>0.070549</td>\n",
       "      <td>0.151613</td>\n",
       "      <td>0.072946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.297135</td>\n",
       "      <td>0.072499</td>\n",
       "      <td>0.125877</td>\n",
       "      <td>0.061916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.298661</td>\n",
       "      <td>0.078368</td>\n",
       "      <td>0.127231</td>\n",
       "      <td>0.038901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.298792</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>0.155345</td>\n",
       "      <td>0.084715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.298861</td>\n",
       "      <td>0.071794</td>\n",
       "      <td>0.117544</td>\n",
       "      <td>0.076098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.298923</td>\n",
       "      <td>0.039429</td>\n",
       "      <td>0.118596</td>\n",
       "      <td>0.061329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.302635</td>\n",
       "      <td>0.073059</td>\n",
       "      <td>0.121503</td>\n",
       "      <td>0.041733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.305212</td>\n",
       "      <td>0.049658</td>\n",
       "      <td>0.118980</td>\n",
       "      <td>0.058779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.311635</td>\n",
       "      <td>0.055591</td>\n",
       "      <td>0.134153</td>\n",
       "      <td>0.079690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.311862</td>\n",
       "      <td>0.028153</td>\n",
       "      <td>0.163785</td>\n",
       "      <td>0.052690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.313477</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.135753</td>\n",
       "      <td>0.098021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.315454</td>\n",
       "      <td>0.088779</td>\n",
       "      <td>0.143144</td>\n",
       "      <td>0.079995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.317740</td>\n",
       "      <td>0.048783</td>\n",
       "      <td>0.124356</td>\n",
       "      <td>0.083313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.318498</td>\n",
       "      <td>0.030620</td>\n",
       "      <td>0.152654</td>\n",
       "      <td>0.054707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.318555</td>\n",
       "      <td>0.064726</td>\n",
       "      <td>0.143244</td>\n",
       "      <td>0.069790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.319415</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.149920</td>\n",
       "      <td>0.081081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.322980</td>\n",
       "      <td>0.058155</td>\n",
       "      <td>0.157672</td>\n",
       "      <td>0.100564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.325481</td>\n",
       "      <td>0.051933</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.079549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.325481</td>\n",
       "      <td>0.051933</td>\n",
       "      <td>0.153743</td>\n",
       "      <td>0.079549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.326770</td>\n",
       "      <td>0.039218</td>\n",
       "      <td>0.136787</td>\n",
       "      <td>0.096537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.329296</td>\n",
       "      <td>0.062698</td>\n",
       "      <td>0.141063</td>\n",
       "      <td>0.080485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.330934</td>\n",
       "      <td>0.055458</td>\n",
       "      <td>0.148899</td>\n",
       "      <td>0.071392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.331627</td>\n",
       "      <td>0.062429</td>\n",
       "      <td>0.142831</td>\n",
       "      <td>0.078222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.336418</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.142777</td>\n",
       "      <td>0.087594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.341043</td>\n",
       "      <td>0.072806</td>\n",
       "      <td>0.125710</td>\n",
       "      <td>0.105713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.342679</td>\n",
       "      <td>0.050755</td>\n",
       "      <td>0.153508</td>\n",
       "      <td>0.090288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.342928</td>\n",
       "      <td>0.054523</td>\n",
       "      <td>0.161746</td>\n",
       "      <td>0.085092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.344777</td>\n",
       "      <td>0.042085</td>\n",
       "      <td>0.124665</td>\n",
       "      <td>0.091692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.348630</td>\n",
       "      <td>0.043766</td>\n",
       "      <td>0.127447</td>\n",
       "      <td>0.088443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.348901</td>\n",
       "      <td>0.066733</td>\n",
       "      <td>0.157592</td>\n",
       "      <td>0.098181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.351681</td>\n",
       "      <td>0.082890</td>\n",
       "      <td>0.124362</td>\n",
       "      <td>0.076555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.352127</td>\n",
       "      <td>0.083934</td>\n",
       "      <td>0.125102</td>\n",
       "      <td>0.075882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.353592</td>\n",
       "      <td>0.089017</td>\n",
       "      <td>0.174185</td>\n",
       "      <td>0.072310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.353746</td>\n",
       "      <td>0.074738</td>\n",
       "      <td>0.155387</td>\n",
       "      <td>0.087254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.355219</td>\n",
       "      <td>0.079269</td>\n",
       "      <td>0.134082</td>\n",
       "      <td>0.121690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.360776</td>\n",
       "      <td>0.060266</td>\n",
       "      <td>0.157940</td>\n",
       "      <td>0.071271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.361930</td>\n",
       "      <td>0.060430</td>\n",
       "      <td>0.157604</td>\n",
       "      <td>0.070829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.363242</td>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.178036</td>\n",
       "      <td>0.072240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.369475</td>\n",
       "      <td>0.035650</td>\n",
       "      <td>0.112546</td>\n",
       "      <td>0.057750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.371879</td>\n",
       "      <td>0.062469</td>\n",
       "      <td>0.141149</td>\n",
       "      <td>0.062518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.375056</td>\n",
       "      <td>0.021285</td>\n",
       "      <td>0.148657</td>\n",
       "      <td>0.086756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.376539</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>0.068229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.376539</td>\n",
       "      <td>0.058431</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>0.068229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.384978</td>\n",
       "      <td>0.056917</td>\n",
       "      <td>0.149532</td>\n",
       "      <td>0.067549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.406522</td>\n",
       "      <td>0.034885</td>\n",
       "      <td>0.156980</td>\n",
       "      <td>0.092610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.410410</td>\n",
       "      <td>0.043063</td>\n",
       "      <td>0.131984</td>\n",
       "      <td>0.071989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.420171</td>\n",
       "      <td>0.071415</td>\n",
       "      <td>0.142874</td>\n",
       "      <td>0.074804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.422739</td>\n",
       "      <td>0.108148</td>\n",
       "      <td>0.136636</td>\n",
       "      <td>0.067310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.424747</td>\n",
       "      <td>0.082315</td>\n",
       "      <td>0.134220</td>\n",
       "      <td>0.085589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.426343</td>\n",
       "      <td>0.079817</td>\n",
       "      <td>0.132801</td>\n",
       "      <td>0.086824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.427195</td>\n",
       "      <td>0.072731</td>\n",
       "      <td>0.146189</td>\n",
       "      <td>0.076577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.427995</td>\n",
       "      <td>0.071432</td>\n",
       "      <td>0.134119</td>\n",
       "      <td>0.083076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.437623</td>\n",
       "      <td>0.086945</td>\n",
       "      <td>0.144729</td>\n",
       "      <td>0.057918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.438331</td>\n",
       "      <td>0.079804</td>\n",
       "      <td>0.145628</td>\n",
       "      <td>0.064563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.442348</td>\n",
       "      <td>0.074465</td>\n",
       "      <td>0.147855</td>\n",
       "      <td>0.046566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.452866</td>\n",
       "      <td>0.095065</td>\n",
       "      <td>0.153741</td>\n",
       "      <td>0.041221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.456944</td>\n",
       "      <td>0.068733</td>\n",
       "      <td>0.121595</td>\n",
       "      <td>0.079213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.457218</td>\n",
       "      <td>0.031304</td>\n",
       "      <td>0.135266</td>\n",
       "      <td>0.063965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.459880</td>\n",
       "      <td>0.075160</td>\n",
       "      <td>0.123323</td>\n",
       "      <td>0.078803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.482074</td>\n",
       "      <td>0.053818</td>\n",
       "      <td>0.145540</td>\n",
       "      <td>0.071594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.483836</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.142400</td>\n",
       "      <td>0.076293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.514272</td>\n",
       "      <td>0.051665</td>\n",
       "      <td>0.143000</td>\n",
       "      <td>0.067651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.522426</td>\n",
       "      <td>0.060776</td>\n",
       "      <td>0.137073</td>\n",
       "      <td>0.073251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.522506</td>\n",
       "      <td>0.128627</td>\n",
       "      <td>0.149767</td>\n",
       "      <td>0.076871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.534662</td>\n",
       "      <td>0.126565</td>\n",
       "      <td>0.167724</td>\n",
       "      <td>0.075941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.536031</td>\n",
       "      <td>0.074429</td>\n",
       "      <td>0.165688</td>\n",
       "      <td>0.094593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.565023</td>\n",
       "      <td>0.015402</td>\n",
       "      <td>0.190134</td>\n",
       "      <td>0.068075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.572394</td>\n",
       "      <td>0.102353</td>\n",
       "      <td>0.191021</td>\n",
       "      <td>0.110262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.613108</td>\n",
       "      <td>0.056555</td>\n",
       "      <td>0.174954</td>\n",
       "      <td>0.062511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-1.799653</td>\n",
       "      <td>0.116373</td>\n",
       "      <td>0.140282</td>\n",
       "      <td>0.044786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-1.851987</td>\n",
       "      <td>0.123392</td>\n",
       "      <td>0.151339</td>\n",
       "      <td>0.047571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-1.924947</td>\n",
       "      <td>0.121366</td>\n",
       "      <td>0.164793</td>\n",
       "      <td>0.050140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-2.038256</td>\n",
       "      <td>0.120790</td>\n",
       "      <td>0.180968</td>\n",
       "      <td>0.063108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-2.267543</td>\n",
       "      <td>0.131642</td>\n",
       "      <td>0.203219</td>\n",
       "      <td>0.111357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-2.541728</td>\n",
       "      <td>0.133638</td>\n",
       "      <td>0.234603</td>\n",
       "      <td>0.152618</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>TESQ_E_sum*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>education_own*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>age365*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>age365*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>cSES*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>cSES*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cancer_promoting_minus_preventing_craved_FCI*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>cancer_promoting_minus_preventing_craved_FCI*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RTFS_f1_minus_f2*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RTFS_f1_minus_f2*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>TESQ_E_sum*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RMQ_assessment*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>SST_SSD*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RMQ_assessment*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>PLAN_temporal_orientation*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict bf with 46 predictors in the set condition_inddiff\n",
      "predictors in that set are mckenzie willamette BSCS EDM BIS_11 PCS RS TRSQ ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_flexibility PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_abstract_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero sst_CorrectGo_striatum_joint_mask sst_CorrectGo_finger movements_association-test_z_FDR_0.01 sst_CorrectStop_motor_control_striatum_joint_mask sst_CorrectStop_response inhibition_association-test_z_FDR_0.01 sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "scores:\n",
      "[0.004645058226758647, -0.1061088942844699, -0.015240918448945262, 0.003806321558438186, -0.02128188803652664]\n",
      "overall_score:\n",
      "-0.026836064196948995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.115909</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.133122</td>\n",
       "      <td>0.096002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117344</td>\n",
       "      <td>0.025111</td>\n",
       "      <td>0.138526</td>\n",
       "      <td>0.102044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.117893</td>\n",
       "      <td>0.024812</td>\n",
       "      <td>0.129337</td>\n",
       "      <td>0.095123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.118477</td>\n",
       "      <td>0.024294</td>\n",
       "      <td>0.127995</td>\n",
       "      <td>0.093968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.118498</td>\n",
       "      <td>0.022196</td>\n",
       "      <td>0.129240</td>\n",
       "      <td>0.096049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.118978</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>0.095180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.118978</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>0.095180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-1.118978</td>\n",
       "      <td>0.021769</td>\n",
       "      <td>0.129024</td>\n",
       "      <td>0.095180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.133414</td>\n",
       "      <td>0.023880</td>\n",
       "      <td>0.117423</td>\n",
       "      <td>0.076979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.146187</td>\n",
       "      <td>0.024266</td>\n",
       "      <td>0.116677</td>\n",
       "      <td>0.083096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.146975</td>\n",
       "      <td>0.034762</td>\n",
       "      <td>0.111200</td>\n",
       "      <td>0.077622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.152465</td>\n",
       "      <td>0.031097</td>\n",
       "      <td>0.116653</td>\n",
       "      <td>0.077678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.154383</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.108314</td>\n",
       "      <td>0.075258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.156911</td>\n",
       "      <td>0.032254</td>\n",
       "      <td>0.111276</td>\n",
       "      <td>0.074442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-1.160348</td>\n",
       "      <td>0.034771</td>\n",
       "      <td>0.109805</td>\n",
       "      <td>0.071169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.191205</td>\n",
       "      <td>0.036251</td>\n",
       "      <td>0.148270</td>\n",
       "      <td>0.084291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.194146</td>\n",
       "      <td>0.026513</td>\n",
       "      <td>0.129595</td>\n",
       "      <td>0.081311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.196741</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>0.131310</td>\n",
       "      <td>0.081217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.196741</td>\n",
       "      <td>0.030464</td>\n",
       "      <td>0.131310</td>\n",
       "      <td>0.081217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.197083</td>\n",
       "      <td>0.030768</td>\n",
       "      <td>0.111379</td>\n",
       "      <td>0.074876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.197276</td>\n",
       "      <td>0.032663</td>\n",
       "      <td>0.111344</td>\n",
       "      <td>0.079383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.197470</td>\n",
       "      <td>0.032691</td>\n",
       "      <td>0.111309</td>\n",
       "      <td>0.079348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.197665</td>\n",
       "      <td>0.032719</td>\n",
       "      <td>0.111274</td>\n",
       "      <td>0.079312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.197860</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>0.111238</td>\n",
       "      <td>0.079277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.197958</td>\n",
       "      <td>0.032761</td>\n",
       "      <td>0.111221</td>\n",
       "      <td>0.079259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.198032</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>0.149023</td>\n",
       "      <td>0.087579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.198032</td>\n",
       "      <td>0.039258</td>\n",
       "      <td>0.149023</td>\n",
       "      <td>0.087579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.199064</td>\n",
       "      <td>0.029827</td>\n",
       "      <td>0.129518</td>\n",
       "      <td>0.061979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.199064</td>\n",
       "      <td>0.029827</td>\n",
       "      <td>0.129518</td>\n",
       "      <td>0.061979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.199064</td>\n",
       "      <td>0.029827</td>\n",
       "      <td>0.129518</td>\n",
       "      <td>0.061979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.199965</td>\n",
       "      <td>0.025569</td>\n",
       "      <td>0.130172</td>\n",
       "      <td>0.092657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.201119</td>\n",
       "      <td>0.044541</td>\n",
       "      <td>0.108709</td>\n",
       "      <td>0.049483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.201684</td>\n",
       "      <td>0.047429</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.052456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.202258</td>\n",
       "      <td>0.047618</td>\n",
       "      <td>0.108693</td>\n",
       "      <td>0.052430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.202840</td>\n",
       "      <td>0.047813</td>\n",
       "      <td>0.108693</td>\n",
       "      <td>0.052410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.203434</td>\n",
       "      <td>0.048013</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.052395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.203735</td>\n",
       "      <td>0.048115</td>\n",
       "      <td>0.108705</td>\n",
       "      <td>0.052390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.205262</td>\n",
       "      <td>0.032395</td>\n",
       "      <td>0.131125</td>\n",
       "      <td>0.080574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.205744</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.119477</td>\n",
       "      <td>0.088324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.205744</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.119477</td>\n",
       "      <td>0.088324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.205744</td>\n",
       "      <td>0.033027</td>\n",
       "      <td>0.119477</td>\n",
       "      <td>0.088324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.206388</td>\n",
       "      <td>0.030385</td>\n",
       "      <td>0.123275</td>\n",
       "      <td>0.090682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.206630</td>\n",
       "      <td>0.045557</td>\n",
       "      <td>0.131345</td>\n",
       "      <td>0.088444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.209439</td>\n",
       "      <td>0.058121</td>\n",
       "      <td>0.147045</td>\n",
       "      <td>0.083956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.209439</td>\n",
       "      <td>0.058121</td>\n",
       "      <td>0.147045</td>\n",
       "      <td>0.083956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.209439</td>\n",
       "      <td>0.058121</td>\n",
       "      <td>0.147045</td>\n",
       "      <td>0.083956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.209513</td>\n",
       "      <td>0.026843</td>\n",
       "      <td>0.120160</td>\n",
       "      <td>0.093944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.213666</td>\n",
       "      <td>0.039480</td>\n",
       "      <td>0.130007</td>\n",
       "      <td>0.075149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.213666</td>\n",
       "      <td>0.039480</td>\n",
       "      <td>0.130007</td>\n",
       "      <td>0.075149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.214271</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>0.143526</td>\n",
       "      <td>0.070357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.214271</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>0.143526</td>\n",
       "      <td>0.070357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.214271</td>\n",
       "      <td>0.030590</td>\n",
       "      <td>0.143526</td>\n",
       "      <td>0.070357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.216631</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.076617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.216631</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.076617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.216631</td>\n",
       "      <td>0.036409</td>\n",
       "      <td>0.136994</td>\n",
       "      <td>0.076617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.219117</td>\n",
       "      <td>0.014992</td>\n",
       "      <td>0.170267</td>\n",
       "      <td>0.081825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.219470</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>0.060029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.219470</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>0.060029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.219470</td>\n",
       "      <td>0.034045</td>\n",
       "      <td>0.135764</td>\n",
       "      <td>0.060029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.219873</td>\n",
       "      <td>0.067992</td>\n",
       "      <td>0.117519</td>\n",
       "      <td>0.092910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.219873</td>\n",
       "      <td>0.067992</td>\n",
       "      <td>0.117519</td>\n",
       "      <td>0.092910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.219873</td>\n",
       "      <td>0.067992</td>\n",
       "      <td>0.117519</td>\n",
       "      <td>0.092910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.219938</td>\n",
       "      <td>0.035384</td>\n",
       "      <td>0.171305</td>\n",
       "      <td>0.086861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.220667</td>\n",
       "      <td>0.014810</td>\n",
       "      <td>0.163449</td>\n",
       "      <td>0.085920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.222949</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>0.130044</td>\n",
       "      <td>0.096476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.222949</td>\n",
       "      <td>0.048879</td>\n",
       "      <td>0.130044</td>\n",
       "      <td>0.096476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.223736</td>\n",
       "      <td>0.032157</td>\n",
       "      <td>0.129986</td>\n",
       "      <td>0.082967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.226624</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>0.170283</td>\n",
       "      <td>0.079396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.226624</td>\n",
       "      <td>0.037008</td>\n",
       "      <td>0.170283</td>\n",
       "      <td>0.079396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.226867</td>\n",
       "      <td>0.039956</td>\n",
       "      <td>0.128543</td>\n",
       "      <td>0.094271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.228382</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.162860</td>\n",
       "      <td>0.090620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.228382</td>\n",
       "      <td>0.018687</td>\n",
       "      <td>0.162860</td>\n",
       "      <td>0.090620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.229717</td>\n",
       "      <td>0.036077</td>\n",
       "      <td>0.112837</td>\n",
       "      <td>0.060973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.230052</td>\n",
       "      <td>0.038330</td>\n",
       "      <td>0.112841</td>\n",
       "      <td>0.064588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.230391</td>\n",
       "      <td>0.038396</td>\n",
       "      <td>0.112846</td>\n",
       "      <td>0.064505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.230731</td>\n",
       "      <td>0.038461</td>\n",
       "      <td>0.112852</td>\n",
       "      <td>0.064420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.231074</td>\n",
       "      <td>0.038528</td>\n",
       "      <td>0.112860</td>\n",
       "      <td>0.064335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.231168</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>0.123323</td>\n",
       "      <td>0.082414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.231249</td>\n",
       "      <td>0.038563</td>\n",
       "      <td>0.112862</td>\n",
       "      <td>0.064292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.231336</td>\n",
       "      <td>0.019624</td>\n",
       "      <td>0.159884</td>\n",
       "      <td>0.083153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.231503</td>\n",
       "      <td>0.040245</td>\n",
       "      <td>0.124976</td>\n",
       "      <td>0.091287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.231971</td>\n",
       "      <td>0.034670</td>\n",
       "      <td>0.135984</td>\n",
       "      <td>0.079887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.232587</td>\n",
       "      <td>0.017196</td>\n",
       "      <td>0.129269</td>\n",
       "      <td>0.077808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233415</td>\n",
       "      <td>0.041133</td>\n",
       "      <td>0.139043</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233415</td>\n",
       "      <td>0.041133</td>\n",
       "      <td>0.139043</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233415</td>\n",
       "      <td>0.041133</td>\n",
       "      <td>0.139043</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.233555</td>\n",
       "      <td>0.020607</td>\n",
       "      <td>0.129152</td>\n",
       "      <td>0.079318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233803</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.132976</td>\n",
       "      <td>0.075486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233803</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.132976</td>\n",
       "      <td>0.075486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.233803</td>\n",
       "      <td>0.046572</td>\n",
       "      <td>0.132976</td>\n",
       "      <td>0.075486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.233936</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.121639</td>\n",
       "      <td>0.081188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.233936</td>\n",
       "      <td>0.008111</td>\n",
       "      <td>0.121639</td>\n",
       "      <td>0.081188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234436</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>0.081636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234436</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>0.081636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.234436</td>\n",
       "      <td>0.061129</td>\n",
       "      <td>0.132066</td>\n",
       "      <td>0.081636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.234461</td>\n",
       "      <td>0.020796</td>\n",
       "      <td>0.155520</td>\n",
       "      <td>0.088567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.234813</td>\n",
       "      <td>0.041416</td>\n",
       "      <td>0.142079</td>\n",
       "      <td>0.063369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.235074</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.235074</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.235074</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.235074</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.235074</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.235074</td>\n",
       "      <td>0.026978</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.236464</td>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.123195</td>\n",
       "      <td>0.084367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.237150</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.237150</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.237150</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.237150</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.237150</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.237150</td>\n",
       "      <td>0.056776</td>\n",
       "      <td>0.132773</td>\n",
       "      <td>0.060120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.241343</td>\n",
       "      <td>0.018948</td>\n",
       "      <td>0.168413</td>\n",
       "      <td>0.082323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.241523</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.123972</td>\n",
       "      <td>0.075588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.241523</td>\n",
       "      <td>0.013050</td>\n",
       "      <td>0.123972</td>\n",
       "      <td>0.075588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242626</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.135694</td>\n",
       "      <td>0.091469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242626</td>\n",
       "      <td>0.042969</td>\n",
       "      <td>0.135694</td>\n",
       "      <td>0.091469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242936</td>\n",
       "      <td>0.034259</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.100605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242936</td>\n",
       "      <td>0.034259</td>\n",
       "      <td>0.139400</td>\n",
       "      <td>0.100605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242973</td>\n",
       "      <td>0.070358</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>0.087061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242973</td>\n",
       "      <td>0.070358</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>0.087061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.242973</td>\n",
       "      <td>0.070358</td>\n",
       "      <td>0.126388</td>\n",
       "      <td>0.087061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.244594</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.111583</td>\n",
       "      <td>0.085920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.244594</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.111583</td>\n",
       "      <td>0.085920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.244594</td>\n",
       "      <td>0.038214</td>\n",
       "      <td>0.111583</td>\n",
       "      <td>0.085920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.247956</td>\n",
       "      <td>0.013165</td>\n",
       "      <td>0.165375</td>\n",
       "      <td>0.087824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.248583</td>\n",
       "      <td>0.024374</td>\n",
       "      <td>0.119791</td>\n",
       "      <td>0.087664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.248798</td>\n",
       "      <td>0.012659</td>\n",
       "      <td>0.164886</td>\n",
       "      <td>0.087895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249699</td>\n",
       "      <td>0.053974</td>\n",
       "      <td>0.128583</td>\n",
       "      <td>0.097766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249740</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.088261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249740</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.088261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249740</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.088261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249740</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.088261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249740</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.088261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249740</td>\n",
       "      <td>0.072767</td>\n",
       "      <td>0.119300</td>\n",
       "      <td>0.088261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249804</td>\n",
       "      <td>0.054076</td>\n",
       "      <td>0.128638</td>\n",
       "      <td>0.097735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.249810</td>\n",
       "      <td>0.032191</td>\n",
       "      <td>0.097210</td>\n",
       "      <td>0.057296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250164</td>\n",
       "      <td>0.034157</td>\n",
       "      <td>0.097166</td>\n",
       "      <td>0.060630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250524</td>\n",
       "      <td>0.034167</td>\n",
       "      <td>0.097119</td>\n",
       "      <td>0.060481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250722</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.083883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250722</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.083883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250722</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.083883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250722</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.083883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250722</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.083883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250722</td>\n",
       "      <td>0.035359</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.083883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.250885</td>\n",
       "      <td>0.034177</td>\n",
       "      <td>0.097072</td>\n",
       "      <td>0.060331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.251249</td>\n",
       "      <td>0.034187</td>\n",
       "      <td>0.097025</td>\n",
       "      <td>0.060179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.251432</td>\n",
       "      <td>0.034192</td>\n",
       "      <td>0.097002</td>\n",
       "      <td>0.060103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.252227</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.252227</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.252227</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.252227</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.252227</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.252227</td>\n",
       "      <td>0.053527</td>\n",
       "      <td>0.135117</td>\n",
       "      <td>0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.253826</td>\n",
       "      <td>0.014781</td>\n",
       "      <td>0.158914</td>\n",
       "      <td>0.082518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.253871</td>\n",
       "      <td>0.061280</td>\n",
       "      <td>0.140042</td>\n",
       "      <td>0.065469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.253871</td>\n",
       "      <td>0.061280</td>\n",
       "      <td>0.140042</td>\n",
       "      <td>0.065469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.254262</td>\n",
       "      <td>0.038073</td>\n",
       "      <td>0.135825</td>\n",
       "      <td>0.081991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.259685</td>\n",
       "      <td>0.045416</td>\n",
       "      <td>0.165949</td>\n",
       "      <td>0.076257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.260767</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.138532</td>\n",
       "      <td>0.069982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.260767</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.138532</td>\n",
       "      <td>0.069982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.260767</td>\n",
       "      <td>0.069254</td>\n",
       "      <td>0.138532</td>\n",
       "      <td>0.069982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.262465</td>\n",
       "      <td>0.032440</td>\n",
       "      <td>0.134917</td>\n",
       "      <td>0.069528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.263779</td>\n",
       "      <td>0.053549</td>\n",
       "      <td>0.131194</td>\n",
       "      <td>0.088459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.263983</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.176013</td>\n",
       "      <td>0.068849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.263983</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.176013</td>\n",
       "      <td>0.068849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.265112</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.117960</td>\n",
       "      <td>0.078402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.265531</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.155781</td>\n",
       "      <td>0.080796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.266475</td>\n",
       "      <td>0.034048</td>\n",
       "      <td>0.122707</td>\n",
       "      <td>0.056891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.267854</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.153860</td>\n",
       "      <td>0.079271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267857</td>\n",
       "      <td>0.073283</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267857</td>\n",
       "      <td>0.073283</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267857</td>\n",
       "      <td>0.073283</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267857</td>\n",
       "      <td>0.073283</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267857</td>\n",
       "      <td>0.073283</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.267857</td>\n",
       "      <td>0.073283</td>\n",
       "      <td>0.134813</td>\n",
       "      <td>0.068945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.268199</td>\n",
       "      <td>0.042515</td>\n",
       "      <td>0.121169</td>\n",
       "      <td>0.092461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.272188</td>\n",
       "      <td>0.058089</td>\n",
       "      <td>0.109993</td>\n",
       "      <td>0.041628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.272974</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>0.067548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.272974</td>\n",
       "      <td>0.020559</td>\n",
       "      <td>0.140128</td>\n",
       "      <td>0.067548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.273374</td>\n",
       "      <td>0.061793</td>\n",
       "      <td>0.110095</td>\n",
       "      <td>0.044032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.273504</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.081399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.273504</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.081399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.273504</td>\n",
       "      <td>0.052585</td>\n",
       "      <td>0.152512</td>\n",
       "      <td>0.081399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.273691</td>\n",
       "      <td>0.047910</td>\n",
       "      <td>0.120935</td>\n",
       "      <td>0.065285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.274343</td>\n",
       "      <td>0.040718</td>\n",
       "      <td>0.125986</td>\n",
       "      <td>0.080588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.274577</td>\n",
       "      <td>0.061976</td>\n",
       "      <td>0.110205</td>\n",
       "      <td>0.043914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.275265</td>\n",
       "      <td>0.038067</td>\n",
       "      <td>0.125691</td>\n",
       "      <td>0.080886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.275668</td>\n",
       "      <td>0.046720</td>\n",
       "      <td>0.126549</td>\n",
       "      <td>0.093628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.275671</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>0.064407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.275671</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>0.125219</td>\n",
       "      <td>0.064407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.275704</td>\n",
       "      <td>0.032943</td>\n",
       "      <td>0.127872</td>\n",
       "      <td>0.060687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.275704</td>\n",
       "      <td>0.032943</td>\n",
       "      <td>0.127872</td>\n",
       "      <td>0.060687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.275800</td>\n",
       "      <td>0.062161</td>\n",
       "      <td>0.110321</td>\n",
       "      <td>0.043800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.277041</td>\n",
       "      <td>0.062348</td>\n",
       "      <td>0.110446</td>\n",
       "      <td>0.043690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.277669</td>\n",
       "      <td>0.062442</td>\n",
       "      <td>0.110511</td>\n",
       "      <td>0.043637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.280130</td>\n",
       "      <td>0.052559</td>\n",
       "      <td>0.121474</td>\n",
       "      <td>0.062216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.280566</td>\n",
       "      <td>0.022534</td>\n",
       "      <td>0.128209</td>\n",
       "      <td>0.078390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.281368</td>\n",
       "      <td>0.048201</td>\n",
       "      <td>0.118978</td>\n",
       "      <td>0.084506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.284440</td>\n",
       "      <td>0.016795</td>\n",
       "      <td>0.165688</td>\n",
       "      <td>0.081773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.290987</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.071536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.290987</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.071536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.290987</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.071536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.290987</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.071536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.290987</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.071536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.290987</td>\n",
       "      <td>0.054512</td>\n",
       "      <td>0.148970</td>\n",
       "      <td>0.071536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.291206</td>\n",
       "      <td>0.024435</td>\n",
       "      <td>0.172960</td>\n",
       "      <td>0.076612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.292399</td>\n",
       "      <td>0.031513</td>\n",
       "      <td>0.176038</td>\n",
       "      <td>0.078652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.293079</td>\n",
       "      <td>0.028183</td>\n",
       "      <td>0.125268</td>\n",
       "      <td>0.072231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.293116</td>\n",
       "      <td>0.023758</td>\n",
       "      <td>0.121019</td>\n",
       "      <td>0.070694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.310081</td>\n",
       "      <td>0.052135</td>\n",
       "      <td>0.144739</td>\n",
       "      <td>0.077488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.310458</td>\n",
       "      <td>0.040190</td>\n",
       "      <td>0.138757</td>\n",
       "      <td>0.078110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.313964</td>\n",
       "      <td>0.036958</td>\n",
       "      <td>0.138189</td>\n",
       "      <td>0.078128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.318246</td>\n",
       "      <td>0.021488</td>\n",
       "      <td>0.128121</td>\n",
       "      <td>0.077087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.321541</td>\n",
       "      <td>0.036524</td>\n",
       "      <td>0.175760</td>\n",
       "      <td>0.064619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.321969</td>\n",
       "      <td>0.038433</td>\n",
       "      <td>0.171221</td>\n",
       "      <td>0.069653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.323238</td>\n",
       "      <td>0.074697</td>\n",
       "      <td>0.179069</td>\n",
       "      <td>0.084030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.325367</td>\n",
       "      <td>0.055425</td>\n",
       "      <td>0.158098</td>\n",
       "      <td>0.034743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.330341</td>\n",
       "      <td>0.025130</td>\n",
       "      <td>0.145993</td>\n",
       "      <td>0.032612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.336028</td>\n",
       "      <td>0.055732</td>\n",
       "      <td>0.114748</td>\n",
       "      <td>0.058997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.337029</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.101990</td>\n",
       "      <td>0.042707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.338843</td>\n",
       "      <td>0.052788</td>\n",
       "      <td>0.102181</td>\n",
       "      <td>0.045496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.340697</td>\n",
       "      <td>0.052776</td>\n",
       "      <td>0.102385</td>\n",
       "      <td>0.045707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.342603</td>\n",
       "      <td>0.052756</td>\n",
       "      <td>0.102597</td>\n",
       "      <td>0.045937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.344561</td>\n",
       "      <td>0.052717</td>\n",
       "      <td>0.102810</td>\n",
       "      <td>0.046166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.344618</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.116823</td>\n",
       "      <td>0.076787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.345554</td>\n",
       "      <td>0.052696</td>\n",
       "      <td>0.102924</td>\n",
       "      <td>0.046284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.345670</td>\n",
       "      <td>0.044738</td>\n",
       "      <td>0.126342</td>\n",
       "      <td>0.049591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.346065</td>\n",
       "      <td>0.042502</td>\n",
       "      <td>0.158384</td>\n",
       "      <td>0.056682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.348400</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>0.118995</td>\n",
       "      <td>0.073466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.348400</td>\n",
       "      <td>0.050985</td>\n",
       "      <td>0.118995</td>\n",
       "      <td>0.073466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.349665</td>\n",
       "      <td>0.037189</td>\n",
       "      <td>0.169625</td>\n",
       "      <td>0.102934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.349920</td>\n",
       "      <td>0.038184</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>0.080758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.351866</td>\n",
       "      <td>0.017256</td>\n",
       "      <td>0.104097</td>\n",
       "      <td>0.043210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.353709</td>\n",
       "      <td>0.049256</td>\n",
       "      <td>0.113235</td>\n",
       "      <td>0.051215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.354494</td>\n",
       "      <td>0.039108</td>\n",
       "      <td>0.148401</td>\n",
       "      <td>0.074663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.357293</td>\n",
       "      <td>0.070601</td>\n",
       "      <td>0.139517</td>\n",
       "      <td>0.072770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.359229</td>\n",
       "      <td>0.030827</td>\n",
       "      <td>0.127699</td>\n",
       "      <td>0.086866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.360069</td>\n",
       "      <td>0.029473</td>\n",
       "      <td>0.128622</td>\n",
       "      <td>0.086034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.368533</td>\n",
       "      <td>0.047739</td>\n",
       "      <td>0.156767</td>\n",
       "      <td>0.071220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.371050</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>0.178097</td>\n",
       "      <td>0.084029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.371050</td>\n",
       "      <td>0.033495</td>\n",
       "      <td>0.178097</td>\n",
       "      <td>0.084029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.372119</td>\n",
       "      <td>0.051126</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.084456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.372900</td>\n",
       "      <td>0.051356</td>\n",
       "      <td>0.159817</td>\n",
       "      <td>0.071727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.372900</td>\n",
       "      <td>0.051356</td>\n",
       "      <td>0.159817</td>\n",
       "      <td>0.071727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.377503</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.117756</td>\n",
       "      <td>0.067644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.377503</td>\n",
       "      <td>0.049755</td>\n",
       "      <td>0.117756</td>\n",
       "      <td>0.067644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.380379</td>\n",
       "      <td>0.064956</td>\n",
       "      <td>0.114007</td>\n",
       "      <td>0.056379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.381950</td>\n",
       "      <td>0.066732</td>\n",
       "      <td>0.115507</td>\n",
       "      <td>0.055183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.381996</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.164116</td>\n",
       "      <td>0.064217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.382445</td>\n",
       "      <td>0.036099</td>\n",
       "      <td>0.161350</td>\n",
       "      <td>0.063697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.383427</td>\n",
       "      <td>0.081645</td>\n",
       "      <td>0.136388</td>\n",
       "      <td>0.046223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.383933</td>\n",
       "      <td>0.063660</td>\n",
       "      <td>0.110381</td>\n",
       "      <td>0.054692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.387768</td>\n",
       "      <td>0.081136</td>\n",
       "      <td>0.117239</td>\n",
       "      <td>0.039929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.388000</td>\n",
       "      <td>0.037093</td>\n",
       "      <td>0.127084</td>\n",
       "      <td>0.093674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.388761</td>\n",
       "      <td>0.052981</td>\n",
       "      <td>0.105707</td>\n",
       "      <td>0.078041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.390148</td>\n",
       "      <td>0.021961</td>\n",
       "      <td>0.140293</td>\n",
       "      <td>0.055722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.393381</td>\n",
       "      <td>0.042361</td>\n",
       "      <td>0.173898</td>\n",
       "      <td>0.064955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.394224</td>\n",
       "      <td>0.043577</td>\n",
       "      <td>0.155831</td>\n",
       "      <td>0.074535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.398146</td>\n",
       "      <td>0.040184</td>\n",
       "      <td>0.117303</td>\n",
       "      <td>0.050480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-1.405769</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.091118</td>\n",
       "      <td>0.059188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.406450</td>\n",
       "      <td>0.088804</td>\n",
       "      <td>0.118808</td>\n",
       "      <td>0.046195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.407730</td>\n",
       "      <td>0.047838</td>\n",
       "      <td>0.122728</td>\n",
       "      <td>0.043910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-1.408483</td>\n",
       "      <td>0.051620</td>\n",
       "      <td>0.091129</td>\n",
       "      <td>0.063793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.410162</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.163376</td>\n",
       "      <td>0.066425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-1.411296</td>\n",
       "      <td>0.051883</td>\n",
       "      <td>0.091148</td>\n",
       "      <td>0.064860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.413718</td>\n",
       "      <td>0.055991</td>\n",
       "      <td>0.150958</td>\n",
       "      <td>0.062717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-1.414241</td>\n",
       "      <td>0.052136</td>\n",
       "      <td>0.091173</td>\n",
       "      <td>0.065976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.416918</td>\n",
       "      <td>0.031478</td>\n",
       "      <td>0.152024</td>\n",
       "      <td>0.023960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-1.417279</td>\n",
       "      <td>0.052410</td>\n",
       "      <td>0.091215</td>\n",
       "      <td>0.067166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-1.418838</td>\n",
       "      <td>0.052559</td>\n",
       "      <td>0.091246</td>\n",
       "      <td>0.067787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.419123</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>0.161607</td>\n",
       "      <td>0.084991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.422587</td>\n",
       "      <td>0.042130</td>\n",
       "      <td>0.111252</td>\n",
       "      <td>0.049640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.425918</td>\n",
       "      <td>0.070737</td>\n",
       "      <td>0.077556</td>\n",
       "      <td>0.024876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.426272</td>\n",
       "      <td>0.093185</td>\n",
       "      <td>0.124975</td>\n",
       "      <td>0.055031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.427173</td>\n",
       "      <td>0.045708</td>\n",
       "      <td>0.149873</td>\n",
       "      <td>0.104194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.430876</td>\n",
       "      <td>0.069198</td>\n",
       "      <td>0.197203</td>\n",
       "      <td>0.084818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.430929</td>\n",
       "      <td>0.095520</td>\n",
       "      <td>0.113886</td>\n",
       "      <td>0.057461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.431075</td>\n",
       "      <td>0.093497</td>\n",
       "      <td>0.113268</td>\n",
       "      <td>0.055676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.431985</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>0.072711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.431985</td>\n",
       "      <td>0.061113</td>\n",
       "      <td>0.114063</td>\n",
       "      <td>0.072711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.432573</td>\n",
       "      <td>0.041723</td>\n",
       "      <td>0.151444</td>\n",
       "      <td>0.050371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.433253</td>\n",
       "      <td>0.074152</td>\n",
       "      <td>0.197178</td>\n",
       "      <td>0.067459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.436225</td>\n",
       "      <td>0.053598</td>\n",
       "      <td>0.173780</td>\n",
       "      <td>0.073162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.438548</td>\n",
       "      <td>0.049917</td>\n",
       "      <td>0.171256</td>\n",
       "      <td>0.072668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.439181</td>\n",
       "      <td>0.034901</td>\n",
       "      <td>0.138488</td>\n",
       "      <td>0.047931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.445062</td>\n",
       "      <td>0.085426</td>\n",
       "      <td>0.137899</td>\n",
       "      <td>0.060466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.445979</td>\n",
       "      <td>0.086540</td>\n",
       "      <td>0.137456</td>\n",
       "      <td>0.060716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.453229</td>\n",
       "      <td>0.050708</td>\n",
       "      <td>0.139833</td>\n",
       "      <td>0.043491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.457705</td>\n",
       "      <td>0.051513</td>\n",
       "      <td>0.147711</td>\n",
       "      <td>0.036717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.459910</td>\n",
       "      <td>0.084198</td>\n",
       "      <td>0.173494</td>\n",
       "      <td>0.086887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.459910</td>\n",
       "      <td>0.084198</td>\n",
       "      <td>0.173494</td>\n",
       "      <td>0.086887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.476561</td>\n",
       "      <td>0.035188</td>\n",
       "      <td>0.149274</td>\n",
       "      <td>0.080980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-1.478496</td>\n",
       "      <td>0.053941</td>\n",
       "      <td>0.132771</td>\n",
       "      <td>0.036530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.481882</td>\n",
       "      <td>0.033879</td>\n",
       "      <td>0.145012</td>\n",
       "      <td>0.079126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.488497</td>\n",
       "      <td>0.054021</td>\n",
       "      <td>0.150813</td>\n",
       "      <td>0.105095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.489188</td>\n",
       "      <td>0.054612</td>\n",
       "      <td>0.153716</td>\n",
       "      <td>0.105159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.533469</td>\n",
       "      <td>0.051946</td>\n",
       "      <td>0.138342</td>\n",
       "      <td>0.063992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.550483</td>\n",
       "      <td>0.064370</td>\n",
       "      <td>0.145963</td>\n",
       "      <td>0.063939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.557542</td>\n",
       "      <td>0.068035</td>\n",
       "      <td>0.156206</td>\n",
       "      <td>0.042503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.561155</td>\n",
       "      <td>0.082873</td>\n",
       "      <td>0.163004</td>\n",
       "      <td>0.053637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.562966</td>\n",
       "      <td>0.144241</td>\n",
       "      <td>0.104645</td>\n",
       "      <td>0.056595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.564588</td>\n",
       "      <td>0.066182</td>\n",
       "      <td>0.156574</td>\n",
       "      <td>0.011764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.565806</td>\n",
       "      <td>0.127889</td>\n",
       "      <td>0.109241</td>\n",
       "      <td>0.039993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.593888</td>\n",
       "      <td>0.079051</td>\n",
       "      <td>0.163141</td>\n",
       "      <td>0.032444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.594729</td>\n",
       "      <td>0.096063</td>\n",
       "      <td>0.157421</td>\n",
       "      <td>0.048835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.595423</td>\n",
       "      <td>0.056194</td>\n",
       "      <td>0.136368</td>\n",
       "      <td>0.051619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.602976</td>\n",
       "      <td>0.104948</td>\n",
       "      <td>0.166327</td>\n",
       "      <td>0.064024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-1.604719</td>\n",
       "      <td>0.062053</td>\n",
       "      <td>0.142517</td>\n",
       "      <td>0.057290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.638063</td>\n",
       "      <td>0.102277</td>\n",
       "      <td>0.145519</td>\n",
       "      <td>0.032732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.660017</td>\n",
       "      <td>0.094933</td>\n",
       "      <td>0.171314</td>\n",
       "      <td>0.035375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SST_SSD</td>\n",
       "      <td>-0.064910</td>\n",
       "      <td>0.017071</td>\n",
       "      <td>0.017071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>age365</td>\n",
       "      <td>-0.039396</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.008514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>PLAN_mental_flexibility</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict bf with 2 predictors in the set condition_only\n",
      "predictors in that set are mckenzie willamette\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2853: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/numpy/lib/function_base.py:2854: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "scores:\n",
      "[-0.0008332924335445746, -0.10416793129470392, -0.019841073635882278, -0.0009780782431259016, -0.024608983002196716]\n",
      "overall_score:\n",
      "-0.03008587172189068\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.024504</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.096850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.116811</td>\n",
       "      <td>0.025991</td>\n",
       "      <td>0.138900</td>\n",
       "      <td>0.102725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-1.117240</td>\n",
       "      <td>0.026262</td>\n",
       "      <td>0.139261</td>\n",
       "      <td>0.102170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.117240</td>\n",
       "      <td>0.026262</td>\n",
       "      <td>0.139261</td>\n",
       "      <td>0.102170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.117240</td>\n",
       "      <td>0.026262</td>\n",
       "      <td>0.139261</td>\n",
       "      <td>0.102170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.121902</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>0.097039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-1.121902</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>0.097039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.121902</td>\n",
       "      <td>0.029123</td>\n",
       "      <td>0.143666</td>\n",
       "      <td>0.097039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-1.128039</td>\n",
       "      <td>0.030493</td>\n",
       "      <td>0.146784</td>\n",
       "      <td>0.082249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128039</td>\n",
       "      <td>0.030493</td>\n",
       "      <td>0.146784</td>\n",
       "      <td>0.082249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128039</td>\n",
       "      <td>0.030493</td>\n",
       "      <td>0.146784</td>\n",
       "      <td>0.082249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-1.128086</td>\n",
       "      <td>0.032358</td>\n",
       "      <td>0.146790</td>\n",
       "      <td>0.087197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128086</td>\n",
       "      <td>0.032358</td>\n",
       "      <td>0.146790</td>\n",
       "      <td>0.087197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128086</td>\n",
       "      <td>0.032358</td>\n",
       "      <td>0.146790</td>\n",
       "      <td>0.087197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-1.128133</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.146796</td>\n",
       "      <td>0.087157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128133</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.146796</td>\n",
       "      <td>0.087157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128133</td>\n",
       "      <td>0.032375</td>\n",
       "      <td>0.146796</td>\n",
       "      <td>0.087157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128181</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.146803</td>\n",
       "      <td>0.087116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-1.128181</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.146803</td>\n",
       "      <td>0.087116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128181</td>\n",
       "      <td>0.032391</td>\n",
       "      <td>0.146803</td>\n",
       "      <td>0.087116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-1.128228</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.087075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128228</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.087075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128228</td>\n",
       "      <td>0.032408</td>\n",
       "      <td>0.146809</td>\n",
       "      <td>0.087075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128252</td>\n",
       "      <td>0.032416</td>\n",
       "      <td>0.146812</td>\n",
       "      <td>0.087054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128252</td>\n",
       "      <td>0.032416</td>\n",
       "      <td>0.146812</td>\n",
       "      <td>0.087054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-1.128252</td>\n",
       "      <td>0.032416</td>\n",
       "      <td>0.146812</td>\n",
       "      <td>0.087054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-1.128276</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.087033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-1.128276</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.087033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-1.128276</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>0.146815</td>\n",
       "      <td>0.087033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_inddiff_interactions': -0.12037254665394732, 'condition_inddiff': -0.026836064196948995, 'condition_only': -0.03008587172189068}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, outcome_vars_to_try[0], dev_cv_analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unhealthy foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict cancer_promoting_FFQ with 134 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are mckenzie willamette BSCS EDM BIS_11 PCS RS TRSQ ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_flexibility PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_abstract_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero sst_CorrectGo_striatum_joint_mask sst_CorrectGo_finger movements_association-test_z_FDR_0.01 sst_CorrectStop_motor_control_striatum_joint_mask sst_CorrectStop_response inhibition_association-test_z_FDR_0.01 sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask birthsex_factor_Male BSCS*mckenzie BSCS*willamette EDM*mckenzie EDM*willamette BIS_11*mckenzie BIS_11*willamette PCS*mckenzie PCS*willamette RS*mckenzie RS*willamette TRSQ*mckenzie TRSQ*willamette ACES_sum*mckenzie ACES_sum*willamette BFI_agreeableness*mckenzie BFI_agreeableness*willamette BFI_conscientiousness*mckenzie BFI_conscientiousness*willamette BFI_extraversion*mckenzie BFI_extraversion*willamette BFI_neuroticism*mckenzie BFI_neuroticism*willamette BFI_openness*mckenzie BFI_openness*willamette IMI_effort_importance*mckenzie IMI_effort_importance*willamette IMI_interest_enjoyment*mckenzie IMI_interest_enjoyment*willamette NCS_total*mckenzie NCS_total*willamette PLAN_cognitive_strategies*mckenzie PLAN_cognitive_strategies*willamette PLAN_mental_flexibility*mckenzie PLAN_mental_flexibility*willamette PLAN_temporal_orientation*mckenzie PLAN_temporal_orientation*willamette RMQ_assessment*mckenzie RMQ_assessment*willamette TESQ_E_sum*mckenzie TESQ_E_sum*willamette SRHI_healthy_minus_unhealthy*mckenzie SRHI_healthy_minus_unhealthy*willamette RTFS_f1_minus_f2*mckenzie RTFS_f1_minus_f2*willamette cancer_promoting_minus_preventing_craved_FCI*mckenzie cancer_promoting_minus_preventing_craved_FCI*willamette cancer_promoting_minus_preventing_liked_FCI*mckenzie cancer_promoting_minus_preventing_liked_FCI*willamette cSES*mckenzie cSES*willamette age365*mckenzie age365*willamette education_own*mckenzie education_own*willamette SST_SSD*mckenzie SST_SSD*willamette SST_mean_ssrt_0*mckenzie SST_mean_ssrt_0*willamette ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Regulate_Minus_Look*willamette WTP_unhealthy_minus_healthy*mckenzie WTP_unhealthy_minus_healthy*willamette wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette wtp_liked_value_association-test_z_FDR_0.01*mckenzie wtp_liked_value_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_multivariate_regulation*mckenzie roc_reappraiseCrave_multivariate_regulation*willamette roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette sst_CorrectGo_striatum_joint_mask*mckenzie sst_CorrectGo_striatum_joint_mask*willamette sst_CorrectGo_finger movements_association-test_z_FDR_0.01*mckenzie sst_CorrectGo_finger movements_association-test_z_FDR_0.01*willamette sst_CorrectStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectStop_motor_control_striatum_joint_mask*willamette sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*mckenzie sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*willamette sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*willamette sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*willamette birthsex_factor_Male*mckenzie birthsex_factor_Male*willamette\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "scores:\n",
      "[-0.13731048337241014, -0.03574225448543067, -0.08522129887269769, 0.08065869966829464, -0.00031745956633755235]\n",
      "overall_score:\n",
      "-0.035586559325716284\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.178919</td>\n",
       "      <td>0.003884</td>\n",
       "      <td>0.013407</td>\n",
       "      <td>0.006665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.179184</td>\n",
       "      <td>0.004328</td>\n",
       "      <td>0.013541</td>\n",
       "      <td>0.007300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.179561</td>\n",
       "      <td>0.004531</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.007585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180128</td>\n",
       "      <td>0.004694</td>\n",
       "      <td>0.013839</td>\n",
       "      <td>0.007987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180354</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.013634</td>\n",
       "      <td>0.005208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180684</td>\n",
       "      <td>0.003608</td>\n",
       "      <td>0.014227</td>\n",
       "      <td>0.004949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180754</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180754</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180754</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.011848</td>\n",
       "      <td>0.003251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.180886</td>\n",
       "      <td>0.004798</td>\n",
       "      <td>0.014013</td>\n",
       "      <td>0.008526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181067</td>\n",
       "      <td>0.003858</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.003744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181121</td>\n",
       "      <td>0.003796</td>\n",
       "      <td>0.015234</td>\n",
       "      <td>0.004671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181182</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.014815</td>\n",
       "      <td>0.003771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181196</td>\n",
       "      <td>0.003681</td>\n",
       "      <td>0.015294</td>\n",
       "      <td>0.004726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181375</td>\n",
       "      <td>0.004817</td>\n",
       "      <td>0.014145</td>\n",
       "      <td>0.008843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"44\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181547</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181547</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181547</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181547</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181547</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181547</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181703</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.003360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181703</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.003360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181703</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.013867</td>\n",
       "      <td>0.003360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181723</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181723</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181723</td>\n",
       "      <td>0.002316</td>\n",
       "      <td>0.011850</td>\n",
       "      <td>0.002548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181777</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181777</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.181777</td>\n",
       "      <td>0.003753</td>\n",
       "      <td>0.012418</td>\n",
       "      <td>0.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183397</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183397</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183397</td>\n",
       "      <td>0.003726</td>\n",
       "      <td>0.010862</td>\n",
       "      <td>0.002422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183596</td>\n",
       "      <td>0.002759</td>\n",
       "      <td>0.011756</td>\n",
       "      <td>0.006031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183889</td>\n",
       "      <td>0.003499</td>\n",
       "      <td>0.013079</td>\n",
       "      <td>0.007182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183999</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183999</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183999</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183999</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183999</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.183999</td>\n",
       "      <td>0.003464</td>\n",
       "      <td>0.011087</td>\n",
       "      <td>0.002727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184193</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.003357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184193</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.003357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184193</td>\n",
       "      <td>0.004023</td>\n",
       "      <td>0.012435</td>\n",
       "      <td>0.003357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184334</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.007013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184334</td>\n",
       "      <td>0.003475</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.007013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184580</td>\n",
       "      <td>0.004399</td>\n",
       "      <td>0.012882</td>\n",
       "      <td>0.004684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.184791</td>\n",
       "      <td>0.004224</td>\n",
       "      <td>0.014035</td>\n",
       "      <td>0.005352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.185672</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.008118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.185672</td>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.012811</td>\n",
       "      <td>0.008118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.185696</td>\n",
       "      <td>0.003147</td>\n",
       "      <td>0.012316</td>\n",
       "      <td>0.007272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.185764</td>\n",
       "      <td>0.004544</td>\n",
       "      <td>0.014771</td>\n",
       "      <td>0.007655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.186084</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.186084</td>\n",
       "      <td>0.004918</td>\n",
       "      <td>0.014842</td>\n",
       "      <td>0.004900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.186530</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.016908</td>\n",
       "      <td>0.003625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.186577</td>\n",
       "      <td>0.007217</td>\n",
       "      <td>0.016916</td>\n",
       "      <td>0.003853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.186584</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.005430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.186584</td>\n",
       "      <td>0.006623</td>\n",
       "      <td>0.014728</td>\n",
       "      <td>0.005430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.186626</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>0.016924</td>\n",
       "      <td>0.003863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.186643</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.014662</td>\n",
       "      <td>0.005379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.186677</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.016933</td>\n",
       "      <td>0.003873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.186731</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.016944</td>\n",
       "      <td>0.003885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.186759</td>\n",
       "      <td>0.007237</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.003891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187012</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.012944</td>\n",
       "      <td>0.006485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187244</td>\n",
       "      <td>0.003770</td>\n",
       "      <td>0.014858</td>\n",
       "      <td>0.006643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187390</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.013659</td>\n",
       "      <td>0.008418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187400</td>\n",
       "      <td>0.003640</td>\n",
       "      <td>0.014640</td>\n",
       "      <td>0.007142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187403</td>\n",
       "      <td>0.003839</td>\n",
       "      <td>0.014484</td>\n",
       "      <td>0.008689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187451</td>\n",
       "      <td>0.004115</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.008648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.187804</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>0.002292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.187804</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>0.002292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.187804</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.016259</td>\n",
       "      <td>0.002292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.187908</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.013061</td>\n",
       "      <td>0.007138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.188043</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.188043</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.188043</td>\n",
       "      <td>0.005696</td>\n",
       "      <td>0.014841</td>\n",
       "      <td>0.003501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.188382</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.013671</td>\n",
       "      <td>0.007465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.188647</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.188647</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.188647</td>\n",
       "      <td>0.003777</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.002552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.188984</td>\n",
       "      <td>0.004043</td>\n",
       "      <td>0.013225</td>\n",
       "      <td>0.007468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.189186</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.189186</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.189186</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.017009</td>\n",
       "      <td>0.003368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.189258</td>\n",
       "      <td>0.004637</td>\n",
       "      <td>0.013706</td>\n",
       "      <td>0.003884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.189401</td>\n",
       "      <td>0.006089</td>\n",
       "      <td>0.013794</td>\n",
       "      <td>0.003718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.189561</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.015189</td>\n",
       "      <td>0.008542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.189649</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.003978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.189649</td>\n",
       "      <td>0.006410</td>\n",
       "      <td>0.011590</td>\n",
       "      <td>0.003978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.189694</td>\n",
       "      <td>0.007523</td>\n",
       "      <td>0.015557</td>\n",
       "      <td>0.008033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190157</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190157</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190157</td>\n",
       "      <td>0.007159</td>\n",
       "      <td>0.016843</td>\n",
       "      <td>0.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.190376</td>\n",
       "      <td>0.004024</td>\n",
       "      <td>0.013426</td>\n",
       "      <td>0.007845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190398</td>\n",
       "      <td>0.004469</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.005945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.190449</td>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.011818</td>\n",
       "      <td>0.006729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190449</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190449</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.190449</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.018717</td>\n",
       "      <td>0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.190500</td>\n",
       "      <td>0.006413</td>\n",
       "      <td>0.012394</td>\n",
       "      <td>0.009275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.190511</td>\n",
       "      <td>0.003562</td>\n",
       "      <td>0.013771</td>\n",
       "      <td>0.008923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191035</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191035</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191035</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191035</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191035</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191035</td>\n",
       "      <td>0.006561</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191072</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191072</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191072</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191072</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191072</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.191072</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>0.015771</td>\n",
       "      <td>0.004075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191084</td>\n",
       "      <td>0.003142</td>\n",
       "      <td>0.013773</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192245</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.008324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192341</td>\n",
       "      <td>0.005698</td>\n",
       "      <td>0.016864</td>\n",
       "      <td>0.005530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192384</td>\n",
       "      <td>0.005378</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.004260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192391</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192391</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.016534</td>\n",
       "      <td>0.006099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.192402</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>0.004797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.192402</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>0.004797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.192402</td>\n",
       "      <td>0.005037</td>\n",
       "      <td>0.017043</td>\n",
       "      <td>0.004797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192512</td>\n",
       "      <td>0.005661</td>\n",
       "      <td>0.015621</td>\n",
       "      <td>0.004567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192629</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0.005881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192629</td>\n",
       "      <td>0.003132</td>\n",
       "      <td>0.015397</td>\n",
       "      <td>0.005881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192653</td>\n",
       "      <td>0.005613</td>\n",
       "      <td>0.015612</td>\n",
       "      <td>0.004624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192810</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.015599</td>\n",
       "      <td>0.004691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192819</td>\n",
       "      <td>0.007734</td>\n",
       "      <td>0.014651</td>\n",
       "      <td>0.005008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192938</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.012473</td>\n",
       "      <td>0.007759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192987</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.015592</td>\n",
       "      <td>0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193031</td>\n",
       "      <td>0.003307</td>\n",
       "      <td>0.015813</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193052</td>\n",
       "      <td>0.007822</td>\n",
       "      <td>0.012393</td>\n",
       "      <td>0.007622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193087</td>\n",
       "      <td>0.005487</td>\n",
       "      <td>0.015591</td>\n",
       "      <td>0.004826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193144</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.019687</td>\n",
       "      <td>0.003612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193170</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>0.012290</td>\n",
       "      <td>0.005662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193426</td>\n",
       "      <td>0.007158</td>\n",
       "      <td>0.012281</td>\n",
       "      <td>0.005133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193490</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.013942</td>\n",
       "      <td>0.008622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193552</td>\n",
       "      <td>0.003540</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>0.004186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193603</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.020530</td>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193608</td>\n",
       "      <td>0.005191</td>\n",
       "      <td>0.021009</td>\n",
       "      <td>0.002882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193752</td>\n",
       "      <td>0.006389</td>\n",
       "      <td>0.017920</td>\n",
       "      <td>0.006235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193760</td>\n",
       "      <td>0.003332</td>\n",
       "      <td>0.019936</td>\n",
       "      <td>0.004202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193811</td>\n",
       "      <td>0.005521</td>\n",
       "      <td>0.020591</td>\n",
       "      <td>0.003166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193812</td>\n",
       "      <td>0.002335</td>\n",
       "      <td>0.015301</td>\n",
       "      <td>0.004185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.194288</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.003717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194457</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>0.005065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194457</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.016151</td>\n",
       "      <td>0.005065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194724</td>\n",
       "      <td>0.007952</td>\n",
       "      <td>0.017695</td>\n",
       "      <td>0.004323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195157</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>0.004677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195157</td>\n",
       "      <td>0.007888</td>\n",
       "      <td>0.017514</td>\n",
       "      <td>0.004677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195183</td>\n",
       "      <td>0.006731</td>\n",
       "      <td>0.018054</td>\n",
       "      <td>0.006735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195472</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>0.014404</td>\n",
       "      <td>0.007817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195873</td>\n",
       "      <td>0.002218</td>\n",
       "      <td>0.014259</td>\n",
       "      <td>0.007349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196109</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.015826</td>\n",
       "      <td>0.005084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196766</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.011086</td>\n",
       "      <td>0.006755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.196835</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.003338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.196835</td>\n",
       "      <td>0.007012</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.003338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.196870</td>\n",
       "      <td>0.004178</td>\n",
       "      <td>0.014554</td>\n",
       "      <td>0.003712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196914</td>\n",
       "      <td>0.006608</td>\n",
       "      <td>0.018271</td>\n",
       "      <td>0.006863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197088</td>\n",
       "      <td>0.006233</td>\n",
       "      <td>0.016761</td>\n",
       "      <td>0.004948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197090</td>\n",
       "      <td>0.004848</td>\n",
       "      <td>0.011082</td>\n",
       "      <td>0.006564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197616</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.004883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197631</td>\n",
       "      <td>0.007477</td>\n",
       "      <td>0.014782</td>\n",
       "      <td>0.005870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197653</td>\n",
       "      <td>0.007501</td>\n",
       "      <td>0.014834</td>\n",
       "      <td>0.005939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197713</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>0.015336</td>\n",
       "      <td>0.003627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197999</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.015966</td>\n",
       "      <td>0.002813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198048</td>\n",
       "      <td>0.006589</td>\n",
       "      <td>0.015270</td>\n",
       "      <td>0.003942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198066</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.004126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198066</td>\n",
       "      <td>0.004247</td>\n",
       "      <td>0.015080</td>\n",
       "      <td>0.004126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198093</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.014075</td>\n",
       "      <td>0.007343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198120</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>0.005358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198120</td>\n",
       "      <td>0.009404</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>0.005358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198134</td>\n",
       "      <td>0.004628</td>\n",
       "      <td>0.014443</td>\n",
       "      <td>0.005165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198235</td>\n",
       "      <td>0.004647</td>\n",
       "      <td>0.014067</td>\n",
       "      <td>0.004524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198432</td>\n",
       "      <td>0.006599</td>\n",
       "      <td>0.015203</td>\n",
       "      <td>0.004052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198901</td>\n",
       "      <td>0.006598</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0.004152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.199179</td>\n",
       "      <td>0.006530</td>\n",
       "      <td>0.018554</td>\n",
       "      <td>0.007035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.199263</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>0.013435</td>\n",
       "      <td>0.004446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.199371</td>\n",
       "      <td>0.008253</td>\n",
       "      <td>0.014341</td>\n",
       "      <td>0.008044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.199492</td>\n",
       "      <td>0.006607</td>\n",
       "      <td>0.015088</td>\n",
       "      <td>0.004245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.199592</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.014084</td>\n",
       "      <td>0.004909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.199812</td>\n",
       "      <td>0.008087</td>\n",
       "      <td>0.017292</td>\n",
       "      <td>0.005978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.199876</td>\n",
       "      <td>0.006621</td>\n",
       "      <td>0.015089</td>\n",
       "      <td>0.004316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.200092</td>\n",
       "      <td>0.004837</td>\n",
       "      <td>0.017683</td>\n",
       "      <td>0.004164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.200435</td>\n",
       "      <td>0.008838</td>\n",
       "      <td>0.015957</td>\n",
       "      <td>0.005282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.200533</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.200533</td>\n",
       "      <td>0.008844</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.005408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.200657</td>\n",
       "      <td>0.008984</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>0.004752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.200726</td>\n",
       "      <td>0.005114</td>\n",
       "      <td>0.017899</td>\n",
       "      <td>0.005811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.200984</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.015122</td>\n",
       "      <td>0.004475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.201234</td>\n",
       "      <td>0.006258</td>\n",
       "      <td>0.015108</td>\n",
       "      <td>0.004463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.201386</td>\n",
       "      <td>0.004308</td>\n",
       "      <td>0.013441</td>\n",
       "      <td>0.006610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.201588</td>\n",
       "      <td>0.009605</td>\n",
       "      <td>0.016224</td>\n",
       "      <td>0.007484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.201708</td>\n",
       "      <td>0.011647</td>\n",
       "      <td>0.016665</td>\n",
       "      <td>0.014012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.201890</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.004993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.201890</td>\n",
       "      <td>0.008945</td>\n",
       "      <td>0.016585</td>\n",
       "      <td>0.004993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.201988</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.201988</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.201988</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.201988</td>\n",
       "      <td>0.008966</td>\n",
       "      <td>0.016446</td>\n",
       "      <td>0.005142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.202054</td>\n",
       "      <td>0.006119</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>0.005437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.202181</td>\n",
       "      <td>0.005048</td>\n",
       "      <td>0.015316</td>\n",
       "      <td>0.005287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.202474</td>\n",
       "      <td>0.006528</td>\n",
       "      <td>0.019023</td>\n",
       "      <td>0.007321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.202712</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.015470</td>\n",
       "      <td>0.005459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.202833</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.009121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.202833</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.009121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.202942</td>\n",
       "      <td>0.003661</td>\n",
       "      <td>0.016182</td>\n",
       "      <td>0.006999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203024</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.015072</td>\n",
       "      <td>0.007138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203178</td>\n",
       "      <td>0.004439</td>\n",
       "      <td>0.016507</td>\n",
       "      <td>0.006939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.203184</td>\n",
       "      <td>0.013681</td>\n",
       "      <td>0.018764</td>\n",
       "      <td>0.004568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203316</td>\n",
       "      <td>0.004094</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.006374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.203904</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.013583</td>\n",
       "      <td>0.005421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.204165</td>\n",
       "      <td>0.005750</td>\n",
       "      <td>0.013947</td>\n",
       "      <td>0.008916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.204285</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.014044</td>\n",
       "      <td>0.008851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.204507</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.014111</td>\n",
       "      <td>0.002816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.204808</td>\n",
       "      <td>0.006873</td>\n",
       "      <td>0.019436</td>\n",
       "      <td>0.007615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.207638</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.015501</td>\n",
       "      <td>0.006009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.207769</td>\n",
       "      <td>0.009666</td>\n",
       "      <td>0.016618</td>\n",
       "      <td>0.010505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.208267</td>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.015334</td>\n",
       "      <td>0.007632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.208863</td>\n",
       "      <td>0.006783</td>\n",
       "      <td>0.017744</td>\n",
       "      <td>0.008612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.209097</td>\n",
       "      <td>0.005707</td>\n",
       "      <td>0.017697</td>\n",
       "      <td>0.006079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.209134</td>\n",
       "      <td>0.009676</td>\n",
       "      <td>0.016682</td>\n",
       "      <td>0.008676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.209523</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.209523</td>\n",
       "      <td>0.009010</td>\n",
       "      <td>0.013599</td>\n",
       "      <td>0.003990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.209765</td>\n",
       "      <td>0.006273</td>\n",
       "      <td>0.016005</td>\n",
       "      <td>0.008803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.209963</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.007358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.209963</td>\n",
       "      <td>0.014986</td>\n",
       "      <td>0.015383</td>\n",
       "      <td>0.007358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.210076</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.210076</td>\n",
       "      <td>0.007998</td>\n",
       "      <td>0.015698</td>\n",
       "      <td>0.001041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.211283</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.013830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.211380</td>\n",
       "      <td>0.008840</td>\n",
       "      <td>0.015308</td>\n",
       "      <td>0.003089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.211499</td>\n",
       "      <td>0.009977</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.008351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.211721</td>\n",
       "      <td>0.010161</td>\n",
       "      <td>0.012992</td>\n",
       "      <td>0.008202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.211960</td>\n",
       "      <td>0.011046</td>\n",
       "      <td>0.015570</td>\n",
       "      <td>0.008877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.212383</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.019148</td>\n",
       "      <td>0.006499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.213198</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.019260</td>\n",
       "      <td>0.005696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.213557</td>\n",
       "      <td>0.009044</td>\n",
       "      <td>0.020424</td>\n",
       "      <td>0.003441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"17\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.213676</td>\n",
       "      <td>0.009523</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>0.005176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.214340</td>\n",
       "      <td>0.008387</td>\n",
       "      <td>0.016451</td>\n",
       "      <td>0.007560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.214398</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>0.014801</td>\n",
       "      <td>0.005674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.214578</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.005246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.214578</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>0.017168</td>\n",
       "      <td>0.005246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.216269</td>\n",
       "      <td>0.007223</td>\n",
       "      <td>0.014087</td>\n",
       "      <td>0.006790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.216442</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.003493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.216442</td>\n",
       "      <td>0.010293</td>\n",
       "      <td>0.015945</td>\n",
       "      <td>0.003493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217222</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.005232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217607</td>\n",
       "      <td>0.010984</td>\n",
       "      <td>0.015405</td>\n",
       "      <td>0.010542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217737</td>\n",
       "      <td>0.011135</td>\n",
       "      <td>0.015407</td>\n",
       "      <td>0.010544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217849</td>\n",
       "      <td>0.010042</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>0.005971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.218719</td>\n",
       "      <td>0.013244</td>\n",
       "      <td>0.018650</td>\n",
       "      <td>0.007709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219645</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>0.014790</td>\n",
       "      <td>0.006751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.220551</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.015148</td>\n",
       "      <td>0.007531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.221261</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.012436</td>\n",
       "      <td>0.005760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.222510</td>\n",
       "      <td>0.007739</td>\n",
       "      <td>0.013884</td>\n",
       "      <td>0.007172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.222610</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>0.017644</td>\n",
       "      <td>0.008399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.223119</td>\n",
       "      <td>0.011324</td>\n",
       "      <td>0.018265</td>\n",
       "      <td>0.008063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.223228</td>\n",
       "      <td>0.011229</td>\n",
       "      <td>0.018462</td>\n",
       "      <td>0.008409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.223853</td>\n",
       "      <td>0.007384</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.010169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.224828</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.021536</td>\n",
       "      <td>0.011723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.225616</td>\n",
       "      <td>0.009622</td>\n",
       "      <td>0.019665</td>\n",
       "      <td>0.011022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.226111</td>\n",
       "      <td>0.011945</td>\n",
       "      <td>0.015681</td>\n",
       "      <td>0.007331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.226905</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.015907</td>\n",
       "      <td>0.008237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.227796</td>\n",
       "      <td>0.006434</td>\n",
       "      <td>0.020303</td>\n",
       "      <td>0.010137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.228560</td>\n",
       "      <td>0.009146</td>\n",
       "      <td>0.016662</td>\n",
       "      <td>0.008725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.228687</td>\n",
       "      <td>0.009561</td>\n",
       "      <td>0.016549</td>\n",
       "      <td>0.008318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.234880</td>\n",
       "      <td>0.015137</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.007797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.235189</td>\n",
       "      <td>0.009168</td>\n",
       "      <td>0.019146</td>\n",
       "      <td>0.012131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.235666</td>\n",
       "      <td>0.008781</td>\n",
       "      <td>0.020071</td>\n",
       "      <td>0.012292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.237599</td>\n",
       "      <td>0.017790</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>0.007370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.238430</td>\n",
       "      <td>0.010040</td>\n",
       "      <td>0.011640</td>\n",
       "      <td>0.001636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.238548</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.009203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.238899</td>\n",
       "      <td>0.008912</td>\n",
       "      <td>0.017688</td>\n",
       "      <td>0.009758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.238939</td>\n",
       "      <td>0.011663</td>\n",
       "      <td>0.018145</td>\n",
       "      <td>0.004078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.241934</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.012308</td>\n",
       "      <td>0.002495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.242326</td>\n",
       "      <td>0.009589</td>\n",
       "      <td>0.018101</td>\n",
       "      <td>0.012745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.242616</td>\n",
       "      <td>0.010841</td>\n",
       "      <td>0.021105</td>\n",
       "      <td>0.006278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.259134</td>\n",
       "      <td>0.008150</td>\n",
       "      <td>0.016435</td>\n",
       "      <td>0.011229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.262965</td>\n",
       "      <td>0.013465</td>\n",
       "      <td>0.020234</td>\n",
       "      <td>0.009214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.301613</td>\n",
       "      <td>0.025263</td>\n",
       "      <td>0.019376</td>\n",
       "      <td>0.004305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.311671</td>\n",
       "      <td>0.028451</td>\n",
       "      <td>0.020486</td>\n",
       "      <td>0.004159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.325479</td>\n",
       "      <td>0.030840</td>\n",
       "      <td>0.022293</td>\n",
       "      <td>0.003737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.345923</td>\n",
       "      <td>0.035075</td>\n",
       "      <td>0.025426</td>\n",
       "      <td>0.004994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.385714</td>\n",
       "      <td>0.043955</td>\n",
       "      <td>0.031086</td>\n",
       "      <td>0.012165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.433235</td>\n",
       "      <td>0.054194</td>\n",
       "      <td>0.036214</td>\n",
       "      <td>0.017072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>TESQ_E_sum*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>education_own*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>age365*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>age365*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>cSES*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>cSES*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>cancer_promoting_minus_preventing_craved_FCI*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>cancer_promoting_minus_preventing_craved_FCI*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>RTFS_f1_minus_f2*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>RTFS_f1_minus_f2*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*mckenzie</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>TESQ_E_sum*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>RMQ_assessment*willamette</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>SST_SSD*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>RMQ_assessment*mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>PLAN_temporal_orientation*willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict cancer_promoting_FFQ with 46 predictors in the set condition_inddiff\n",
      "predictors in that set are mckenzie willamette BSCS EDM BIS_11 PCS RS TRSQ ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_flexibility PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_abstract_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero sst_CorrectGo_striatum_joint_mask sst_CorrectGo_finger movements_association-test_z_FDR_0.01 sst_CorrectStop_motor_control_striatum_joint_mask sst_CorrectStop_response inhibition_association-test_z_FDR_0.01 sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "scores:\n",
      "[-0.0010570182196534272, -0.03574225448543067, -0.008748080240950529, -0.0056894747720031, -0.00031745956633755235]\n",
      "overall_score:\n",
      "-0.010310857456875055\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.188943</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.003124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.188943</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.003124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.188943</td>\n",
       "      <td>0.007817</td>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.003124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191014</td>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.014226</td>\n",
       "      <td>0.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191089</td>\n",
       "      <td>0.003612</td>\n",
       "      <td>0.014238</td>\n",
       "      <td>0.001933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191165</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.014249</td>\n",
       "      <td>0.001957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191243</td>\n",
       "      <td>0.003618</td>\n",
       "      <td>0.014262</td>\n",
       "      <td>0.001981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191322</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.014275</td>\n",
       "      <td>0.002006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.191363</td>\n",
       "      <td>0.003624</td>\n",
       "      <td>0.014282</td>\n",
       "      <td>0.002019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192049</td>\n",
       "      <td>0.006508</td>\n",
       "      <td>0.013830</td>\n",
       "      <td>0.002426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192080</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.013836</td>\n",
       "      <td>0.002585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192111</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>0.013842</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192142</td>\n",
       "      <td>0.006947</td>\n",
       "      <td>0.013848</td>\n",
       "      <td>0.002609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.192167</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.004998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.192167</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.004998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.192167</td>\n",
       "      <td>0.008640</td>\n",
       "      <td>0.012857</td>\n",
       "      <td>0.004998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192174</td>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.013854</td>\n",
       "      <td>0.002621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192190</td>\n",
       "      <td>0.006969</td>\n",
       "      <td>0.013857</td>\n",
       "      <td>0.002628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192246</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.005085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192246</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.005085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192246</td>\n",
       "      <td>0.005863</td>\n",
       "      <td>0.012462</td>\n",
       "      <td>0.005085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192274</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.012445</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192274</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.012445</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192274</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.012445</td>\n",
       "      <td>0.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192564</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.002486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192564</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.002486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.192564</td>\n",
       "      <td>0.004329</td>\n",
       "      <td>0.011503</td>\n",
       "      <td>0.002486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192756</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192756</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.192756</td>\n",
       "      <td>0.006857</td>\n",
       "      <td>0.012960</td>\n",
       "      <td>0.004614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193166</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193166</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193166</td>\n",
       "      <td>0.006728</td>\n",
       "      <td>0.013272</td>\n",
       "      <td>0.005974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193202</td>\n",
       "      <td>0.006019</td>\n",
       "      <td>0.015896</td>\n",
       "      <td>0.003493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193264</td>\n",
       "      <td>0.006406</td>\n",
       "      <td>0.015935</td>\n",
       "      <td>0.003724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193327</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>0.015974</td>\n",
       "      <td>0.003743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193329</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193329</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193329</td>\n",
       "      <td>0.006337</td>\n",
       "      <td>0.012958</td>\n",
       "      <td>0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193357</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193357</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193357</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193357</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193357</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193357</td>\n",
       "      <td>0.006222</td>\n",
       "      <td>0.012017</td>\n",
       "      <td>0.005638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193391</td>\n",
       "      <td>0.006453</td>\n",
       "      <td>0.016016</td>\n",
       "      <td>0.003763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193400</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.004362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193456</td>\n",
       "      <td>0.006477</td>\n",
       "      <td>0.016057</td>\n",
       "      <td>0.003783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193488</td>\n",
       "      <td>0.006489</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.003793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.193775</td>\n",
       "      <td>0.008457</td>\n",
       "      <td>0.013738</td>\n",
       "      <td>0.004484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193904</td>\n",
       "      <td>0.005288</td>\n",
       "      <td>0.012669</td>\n",
       "      <td>0.001507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193931</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.193931</td>\n",
       "      <td>0.011792</td>\n",
       "      <td>0.012803</td>\n",
       "      <td>0.005003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193944</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.012680</td>\n",
       "      <td>0.001599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.193984</td>\n",
       "      <td>0.005645</td>\n",
       "      <td>0.012692</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194024</td>\n",
       "      <td>0.005663</td>\n",
       "      <td>0.012703</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194065</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.012715</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194085</td>\n",
       "      <td>0.005691</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>0.001601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194169</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.013192</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194169</td>\n",
       "      <td>0.005153</td>\n",
       "      <td>0.013192</td>\n",
       "      <td>0.004251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194171</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194171</td>\n",
       "      <td>0.007563</td>\n",
       "      <td>0.012279</td>\n",
       "      <td>0.005535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194365</td>\n",
       "      <td>0.006953</td>\n",
       "      <td>0.013825</td>\n",
       "      <td>0.003128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.194391</td>\n",
       "      <td>0.009960</td>\n",
       "      <td>0.014137</td>\n",
       "      <td>0.006336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194437</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.002768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194437</td>\n",
       "      <td>0.006376</td>\n",
       "      <td>0.012508</td>\n",
       "      <td>0.002768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194567</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194567</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194567</td>\n",
       "      <td>0.006625</td>\n",
       "      <td>0.013154</td>\n",
       "      <td>0.003306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194668</td>\n",
       "      <td>0.007455</td>\n",
       "      <td>0.013347</td>\n",
       "      <td>0.002676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194705</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.012602</td>\n",
       "      <td>0.005050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194847</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194847</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194847</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194847</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194847</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.194847</td>\n",
       "      <td>0.006250</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.003186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.194961</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.003779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.194961</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.003779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.194961</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.012898</td>\n",
       "      <td>0.003779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195165</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195165</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195165</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195165</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195165</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195165</td>\n",
       "      <td>0.004259</td>\n",
       "      <td>0.012122</td>\n",
       "      <td>0.004602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195323</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195323</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195323</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195323</td>\n",
       "      <td>0.008487</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>0.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195445</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.005009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195445</td>\n",
       "      <td>0.008681</td>\n",
       "      <td>0.014289</td>\n",
       "      <td>0.005009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195563</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.006437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195563</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.006437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195563</td>\n",
       "      <td>0.008416</td>\n",
       "      <td>0.013574</td>\n",
       "      <td>0.006437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195587</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.015408</td>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195669</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.005815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195669</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.005815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195669</td>\n",
       "      <td>0.007895</td>\n",
       "      <td>0.014363</td>\n",
       "      <td>0.005815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195671</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195671</td>\n",
       "      <td>0.005888</td>\n",
       "      <td>0.011620</td>\n",
       "      <td>0.002713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195729</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.006354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195729</td>\n",
       "      <td>0.008628</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.006354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.195822</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.012729</td>\n",
       "      <td>0.002750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.195901</td>\n",
       "      <td>0.011829</td>\n",
       "      <td>0.014241</td>\n",
       "      <td>0.006191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195908</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195908</td>\n",
       "      <td>0.008183</td>\n",
       "      <td>0.012878</td>\n",
       "      <td>0.005339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195974</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195974</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195974</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195974</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195974</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.195974</td>\n",
       "      <td>0.008546</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.007014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.196062</td>\n",
       "      <td>0.008201</td>\n",
       "      <td>0.012207</td>\n",
       "      <td>0.006990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196158</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.014140</td>\n",
       "      <td>0.004562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.196270</td>\n",
       "      <td>0.007953</td>\n",
       "      <td>0.012336</td>\n",
       "      <td>0.007187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.196609</td>\n",
       "      <td>0.008009</td>\n",
       "      <td>0.013003</td>\n",
       "      <td>0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.196620</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.005480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.196620</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.005480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.196620</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.016297</td>\n",
       "      <td>0.005480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196706</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.006588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196706</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.014676</td>\n",
       "      <td>0.006588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.196745</td>\n",
       "      <td>0.007234</td>\n",
       "      <td>0.015424</td>\n",
       "      <td>0.006289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197007</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.007704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197007</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.007704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197007</td>\n",
       "      <td>0.007467</td>\n",
       "      <td>0.015304</td>\n",
       "      <td>0.007704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197024</td>\n",
       "      <td>0.006396</td>\n",
       "      <td>0.015516</td>\n",
       "      <td>0.006220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.197150</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.013507</td>\n",
       "      <td>0.007654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197267</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197267</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197267</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197267</td>\n",
       "      <td>0.008233</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.007732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197673</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>0.007663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197673</td>\n",
       "      <td>0.008516</td>\n",
       "      <td>0.015446</td>\n",
       "      <td>0.007663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197675</td>\n",
       "      <td>0.005679</td>\n",
       "      <td>0.015960</td>\n",
       "      <td>0.006124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.197740</td>\n",
       "      <td>0.006643</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>0.009574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197792</td>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.014476</td>\n",
       "      <td>0.006787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197808</td>\n",
       "      <td>0.008133</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.004892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.197840</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.016007</td>\n",
       "      <td>0.006516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.197953</td>\n",
       "      <td>0.007416</td>\n",
       "      <td>0.009368</td>\n",
       "      <td>0.004360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198000</td>\n",
       "      <td>0.006691</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.006917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198008</td>\n",
       "      <td>0.006135</td>\n",
       "      <td>0.016055</td>\n",
       "      <td>0.006535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198115</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>0.012746</td>\n",
       "      <td>0.004580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.198161</td>\n",
       "      <td>0.007075</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>0.004630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198186</td>\n",
       "      <td>0.006187</td>\n",
       "      <td>0.016100</td>\n",
       "      <td>0.006547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198366</td>\n",
       "      <td>0.006241</td>\n",
       "      <td>0.016146</td>\n",
       "      <td>0.006557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.198457</td>\n",
       "      <td>0.006269</td>\n",
       "      <td>0.016170</td>\n",
       "      <td>0.006562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.198572</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.198572</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.198572</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.198572</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.198572</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.198572</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.017156</td>\n",
       "      <td>0.005989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.199571</td>\n",
       "      <td>0.008597</td>\n",
       "      <td>0.012066</td>\n",
       "      <td>0.006249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.199978</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.005165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.199978</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>0.013428</td>\n",
       "      <td>0.005165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.201363</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.016681</td>\n",
       "      <td>0.004181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.201572</td>\n",
       "      <td>0.006444</td>\n",
       "      <td>0.013691</td>\n",
       "      <td>0.007087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.202851</td>\n",
       "      <td>0.009053</td>\n",
       "      <td>0.013340</td>\n",
       "      <td>0.002255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203242</td>\n",
       "      <td>0.007344</td>\n",
       "      <td>0.016255</td>\n",
       "      <td>0.006362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.203264</td>\n",
       "      <td>0.008498</td>\n",
       "      <td>0.017605</td>\n",
       "      <td>0.007172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203379</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.006835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203379</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>0.011350</td>\n",
       "      <td>0.006835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203468</td>\n",
       "      <td>0.007859</td>\n",
       "      <td>0.016290</td>\n",
       "      <td>0.006786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203699</td>\n",
       "      <td>0.007929</td>\n",
       "      <td>0.016325</td>\n",
       "      <td>0.006824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.203782</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.203915</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.013259</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.203915</td>\n",
       "      <td>0.009924</td>\n",
       "      <td>0.013259</td>\n",
       "      <td>0.004485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203934</td>\n",
       "      <td>0.007999</td>\n",
       "      <td>0.016362</td>\n",
       "      <td>0.006864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.203956</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>0.013862</td>\n",
       "      <td>0.007266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.204002</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.013913</td>\n",
       "      <td>0.007231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.204009</td>\n",
       "      <td>0.009701</td>\n",
       "      <td>0.011035</td>\n",
       "      <td>0.002522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.204149</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.011195</td>\n",
       "      <td>0.002663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.204173</td>\n",
       "      <td>0.008071</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>0.006906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.204294</td>\n",
       "      <td>0.008108</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.006927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.204436</td>\n",
       "      <td>0.005682</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.004677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.204464</td>\n",
       "      <td>0.007768</td>\n",
       "      <td>0.014756</td>\n",
       "      <td>0.002068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.205002</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>0.013087</td>\n",
       "      <td>0.005290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.205406</td>\n",
       "      <td>0.006602</td>\n",
       "      <td>0.018610</td>\n",
       "      <td>0.008338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.205970</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>0.002214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.205970</td>\n",
       "      <td>0.006931</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>0.002214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.206417</td>\n",
       "      <td>0.010892</td>\n",
       "      <td>0.018210</td>\n",
       "      <td>0.006180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.206517</td>\n",
       "      <td>0.009176</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>0.001998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.206554</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.017943</td>\n",
       "      <td>0.008869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.206718</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.010023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.206718</td>\n",
       "      <td>0.010410</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>0.010023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.206780</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.014126</td>\n",
       "      <td>0.005486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.207350</td>\n",
       "      <td>0.010779</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>0.006857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.207863</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.208123</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.013403</td>\n",
       "      <td>0.007130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.208159</td>\n",
       "      <td>0.011442</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>0.009822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.208180</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.014026</td>\n",
       "      <td>0.004164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.208596</td>\n",
       "      <td>0.011894</td>\n",
       "      <td>0.018528</td>\n",
       "      <td>0.007746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.208701</td>\n",
       "      <td>0.011940</td>\n",
       "      <td>0.018522</td>\n",
       "      <td>0.007742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.208842</td>\n",
       "      <td>0.012028</td>\n",
       "      <td>0.013207</td>\n",
       "      <td>0.006992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.209308</td>\n",
       "      <td>0.010415</td>\n",
       "      <td>0.018340</td>\n",
       "      <td>0.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.209324</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.012059</td>\n",
       "      <td>0.005915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.209348</td>\n",
       "      <td>0.009366</td>\n",
       "      <td>0.012404</td>\n",
       "      <td>0.005692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.209562</td>\n",
       "      <td>0.010378</td>\n",
       "      <td>0.018512</td>\n",
       "      <td>0.007423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.209891</td>\n",
       "      <td>0.012524</td>\n",
       "      <td>0.019223</td>\n",
       "      <td>0.008909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.209900</td>\n",
       "      <td>0.012217</td>\n",
       "      <td>0.011233</td>\n",
       "      <td>0.004062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.210841</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.022020</td>\n",
       "      <td>0.010797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.211458</td>\n",
       "      <td>0.011901</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.010866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.211607</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.003632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.211914</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.211914</td>\n",
       "      <td>0.014690</td>\n",
       "      <td>0.013909</td>\n",
       "      <td>0.007503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.212764</td>\n",
       "      <td>0.007757</td>\n",
       "      <td>0.014865</td>\n",
       "      <td>0.006458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.213014</td>\n",
       "      <td>0.006874</td>\n",
       "      <td>0.013489</td>\n",
       "      <td>0.002804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.213228</td>\n",
       "      <td>0.008272</td>\n",
       "      <td>0.014890</td>\n",
       "      <td>0.006973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.213545</td>\n",
       "      <td>0.005062</td>\n",
       "      <td>0.020923</td>\n",
       "      <td>0.012990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.213589</td>\n",
       "      <td>0.012288</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.006984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.213717</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>0.014909</td>\n",
       "      <td>0.007103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.213739</td>\n",
       "      <td>0.010808</td>\n",
       "      <td>0.014926</td>\n",
       "      <td>0.004580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.214149</td>\n",
       "      <td>0.008078</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.003297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.214240</td>\n",
       "      <td>0.008346</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.007239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.214793</td>\n",
       "      <td>0.008383</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>0.007384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.214951</td>\n",
       "      <td>0.013321</td>\n",
       "      <td>0.010326</td>\n",
       "      <td>0.004454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.215078</td>\n",
       "      <td>0.008407</td>\n",
       "      <td>0.014950</td>\n",
       "      <td>0.007464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.215282</td>\n",
       "      <td>0.019298</td>\n",
       "      <td>0.022452</td>\n",
       "      <td>0.007482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.215523</td>\n",
       "      <td>0.006685</td>\n",
       "      <td>0.017332</td>\n",
       "      <td>0.006758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.215684</td>\n",
       "      <td>0.009457</td>\n",
       "      <td>0.014845</td>\n",
       "      <td>0.003307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.216288</td>\n",
       "      <td>0.016668</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>0.005852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.216640</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.216640</td>\n",
       "      <td>0.013890</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.006410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.216867</td>\n",
       "      <td>0.011795</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.005724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217078</td>\n",
       "      <td>0.013546</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.006108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217221</td>\n",
       "      <td>0.014843</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.007176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.217843</td>\n",
       "      <td>0.013490</td>\n",
       "      <td>0.010125</td>\n",
       "      <td>0.004746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.217982</td>\n",
       "      <td>0.010063</td>\n",
       "      <td>0.014052</td>\n",
       "      <td>0.005137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.218515</td>\n",
       "      <td>0.014463</td>\n",
       "      <td>0.015436</td>\n",
       "      <td>0.007650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.218637</td>\n",
       "      <td>0.007955</td>\n",
       "      <td>0.024288</td>\n",
       "      <td>0.012019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219018</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.017816</td>\n",
       "      <td>0.004773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219066</td>\n",
       "      <td>0.009983</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.005600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.219510</td>\n",
       "      <td>0.007241</td>\n",
       "      <td>0.016688</td>\n",
       "      <td>0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219555</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.019362</td>\n",
       "      <td>0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219555</td>\n",
       "      <td>0.011871</td>\n",
       "      <td>0.019362</td>\n",
       "      <td>0.005129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219602</td>\n",
       "      <td>0.009931</td>\n",
       "      <td>0.012314</td>\n",
       "      <td>0.003797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.219828</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>0.018564</td>\n",
       "      <td>0.004287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.220677</td>\n",
       "      <td>0.011281</td>\n",
       "      <td>0.018126</td>\n",
       "      <td>0.005727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.221124</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.006035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.221439</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.006338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.222556</td>\n",
       "      <td>0.014814</td>\n",
       "      <td>0.012625</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.222604</td>\n",
       "      <td>0.014272</td>\n",
       "      <td>0.013834</td>\n",
       "      <td>0.007253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.222778</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>0.017105</td>\n",
       "      <td>0.010468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.222912</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>0.006144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.223207</td>\n",
       "      <td>0.011296</td>\n",
       "      <td>0.015465</td>\n",
       "      <td>0.005774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.223289</td>\n",
       "      <td>0.011448</td>\n",
       "      <td>0.015117</td>\n",
       "      <td>0.005558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.223484</td>\n",
       "      <td>0.010968</td>\n",
       "      <td>0.016480</td>\n",
       "      <td>0.010879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.223555</td>\n",
       "      <td>0.014339</td>\n",
       "      <td>0.014157</td>\n",
       "      <td>0.007567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.224504</td>\n",
       "      <td>0.007678</td>\n",
       "      <td>0.016364</td>\n",
       "      <td>0.011800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.224654</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.015899</td>\n",
       "      <td>0.008478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.224670</td>\n",
       "      <td>0.012913</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.010394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.224729</td>\n",
       "      <td>0.006965</td>\n",
       "      <td>0.016357</td>\n",
       "      <td>0.011722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.225333</td>\n",
       "      <td>0.014806</td>\n",
       "      <td>0.017852</td>\n",
       "      <td>0.004932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.227088</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>0.004815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.227088</td>\n",
       "      <td>0.010966</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>0.004815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.227116</td>\n",
       "      <td>0.008262</td>\n",
       "      <td>0.021310</td>\n",
       "      <td>0.008028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.227234</td>\n",
       "      <td>0.010457</td>\n",
       "      <td>0.013562</td>\n",
       "      <td>0.003517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.227471</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.021823</td>\n",
       "      <td>0.010454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.227703</td>\n",
       "      <td>0.010857</td>\n",
       "      <td>0.014357</td>\n",
       "      <td>0.004553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.227853</td>\n",
       "      <td>0.012455</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.003968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.227867</td>\n",
       "      <td>0.011154</td>\n",
       "      <td>0.017329</td>\n",
       "      <td>0.009132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.229000</td>\n",
       "      <td>0.013591</td>\n",
       "      <td>0.013718</td>\n",
       "      <td>0.003651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.229517</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>0.021927</td>\n",
       "      <td>0.008744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.229687</td>\n",
       "      <td>0.009359</td>\n",
       "      <td>0.015247</td>\n",
       "      <td>0.005973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.230031</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>0.016414</td>\n",
       "      <td>0.009284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.230478</td>\n",
       "      <td>0.013885</td>\n",
       "      <td>0.016215</td>\n",
       "      <td>0.011104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.230653</td>\n",
       "      <td>0.011313</td>\n",
       "      <td>0.020990</td>\n",
       "      <td>0.008081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.231208</td>\n",
       "      <td>0.013081</td>\n",
       "      <td>0.015906</td>\n",
       "      <td>0.010708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.231705</td>\n",
       "      <td>0.007309</td>\n",
       "      <td>0.022019</td>\n",
       "      <td>0.009369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.231871</td>\n",
       "      <td>0.004750</td>\n",
       "      <td>0.019378</td>\n",
       "      <td>0.007239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.232142</td>\n",
       "      <td>0.007226</td>\n",
       "      <td>0.020946</td>\n",
       "      <td>0.006796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.234052</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.020367</td>\n",
       "      <td>0.008496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.234177</td>\n",
       "      <td>0.007380</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>0.011178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.234413</td>\n",
       "      <td>0.006767</td>\n",
       "      <td>0.017626</td>\n",
       "      <td>0.011510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.235032</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.021336</td>\n",
       "      <td>0.007192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-0.237805</td>\n",
       "      <td>0.009776</td>\n",
       "      <td>0.013777</td>\n",
       "      <td>0.006613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.238482</td>\n",
       "      <td>0.014429</td>\n",
       "      <td>0.024027</td>\n",
       "      <td>0.008043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.239245</td>\n",
       "      <td>0.010610</td>\n",
       "      <td>0.016042</td>\n",
       "      <td>0.008449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.241326</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.025224</td>\n",
       "      <td>0.010409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.243024</td>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.023905</td>\n",
       "      <td>0.014041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.243949</td>\n",
       "      <td>0.009102</td>\n",
       "      <td>0.020165</td>\n",
       "      <td>0.011029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.243965</td>\n",
       "      <td>0.014522</td>\n",
       "      <td>0.023040</td>\n",
       "      <td>0.007499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.244376</td>\n",
       "      <td>0.010196</td>\n",
       "      <td>0.017685</td>\n",
       "      <td>0.010245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.245220</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.025168</td>\n",
       "      <td>0.011048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.246452</td>\n",
       "      <td>0.011566</td>\n",
       "      <td>0.020206</td>\n",
       "      <td>0.009010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.250221</td>\n",
       "      <td>0.010097</td>\n",
       "      <td>0.019728</td>\n",
       "      <td>0.005872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.250315</td>\n",
       "      <td>0.008712</td>\n",
       "      <td>0.022225</td>\n",
       "      <td>0.005891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.250883</td>\n",
       "      <td>0.012312</td>\n",
       "      <td>0.015702</td>\n",
       "      <td>0.008125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.251490</td>\n",
       "      <td>0.009534</td>\n",
       "      <td>0.015528</td>\n",
       "      <td>0.011864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.254207</td>\n",
       "      <td>0.009664</td>\n",
       "      <td>0.019890</td>\n",
       "      <td>0.006462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.259895</td>\n",
       "      <td>0.010453</td>\n",
       "      <td>0.024260</td>\n",
       "      <td>0.008506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-0.261325</td>\n",
       "      <td>0.012458</td>\n",
       "      <td>0.024325</td>\n",
       "      <td>0.006633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.262812</td>\n",
       "      <td>0.014303</td>\n",
       "      <td>0.026529</td>\n",
       "      <td>0.004160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>wtp_liked_value_association-test_z_FDR_0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>cancer_promoting_minus_preventing_liked_FCI</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>cSES</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>age365</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>education_own</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SST_SSD</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>WTP_unhealthy_minus_healthy</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>roc_reappraiseCrave_abstract_association-test_z_FDR_0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>roc_reappraiseCrave_multivariate_regulation</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>sst_CorrectGo_striatum_joint_mask</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>sst_CorrectGo_finger movements_association-test_z_FDR_0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>sst_CorrectStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>sst_CorrectStop_response inhibition_association-test_z_FDR_0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict cancer_promoting_FFQ with 2 predictors in the set condition_only\n",
      "predictors in that set are mckenzie willamette\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "scores:\n",
      "[-0.0757585923750439, -0.03574225448543067, -0.008748080240950529, -0.0056894747720031, -0.00031745956633755235]\n",
      "overall_score:\n",
      "-0.02525117228795315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.002859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.177167</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.003032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.177847</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177847</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177847</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.014194</td>\n",
       "      <td>0.003277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.177855</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177855</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177855</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>0.003481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.177862</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.003486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177862</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.003486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177862</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>0.014191</td>\n",
       "      <td>0.003486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177870</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.003491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.177870</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.003491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177870</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.014190</td>\n",
       "      <td>0.003491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.177878</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177878</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177878</td>\n",
       "      <td>0.002144</td>\n",
       "      <td>0.014189</td>\n",
       "      <td>0.003497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177881</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177881</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.177881</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.177885</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.003502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-0.177885</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.003502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-0.177885</td>\n",
       "      <td>0.002145</td>\n",
       "      <td>0.014188</td>\n",
       "      <td>0.003502</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willamette</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_inddiff_interactions': -0.035586559325716284, 'condition_inddiff': -0.010310857456875055, 'condition_only': -0.02525117228795315}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'cancer_promoting_FFQ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutrient density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 134 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are mckenzie willamette BSCS EDM BIS_11 PCS RS TRSQ ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_flexibility PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_abstract_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero sst_CorrectGo_striatum_joint_mask sst_CorrectGo_finger movements_association-test_z_FDR_0.01 sst_CorrectStop_motor_control_striatum_joint_mask sst_CorrectStop_response inhibition_association-test_z_FDR_0.01 sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask birthsex_factor_Male BSCS*mckenzie BSCS*willamette EDM*mckenzie EDM*willamette BIS_11*mckenzie BIS_11*willamette PCS*mckenzie PCS*willamette RS*mckenzie RS*willamette TRSQ*mckenzie TRSQ*willamette ACES_sum*mckenzie ACES_sum*willamette BFI_agreeableness*mckenzie BFI_agreeableness*willamette BFI_conscientiousness*mckenzie BFI_conscientiousness*willamette BFI_extraversion*mckenzie BFI_extraversion*willamette BFI_neuroticism*mckenzie BFI_neuroticism*willamette BFI_openness*mckenzie BFI_openness*willamette IMI_effort_importance*mckenzie IMI_effort_importance*willamette IMI_interest_enjoyment*mckenzie IMI_interest_enjoyment*willamette NCS_total*mckenzie NCS_total*willamette PLAN_cognitive_strategies*mckenzie PLAN_cognitive_strategies*willamette PLAN_mental_flexibility*mckenzie PLAN_mental_flexibility*willamette PLAN_temporal_orientation*mckenzie PLAN_temporal_orientation*willamette RMQ_assessment*mckenzie RMQ_assessment*willamette TESQ_E_sum*mckenzie TESQ_E_sum*willamette SRHI_healthy_minus_unhealthy*mckenzie SRHI_healthy_minus_unhealthy*willamette RTFS_f1_minus_f2*mckenzie RTFS_f1_minus_f2*willamette cancer_promoting_minus_preventing_craved_FCI*mckenzie cancer_promoting_minus_preventing_craved_FCI*willamette cancer_promoting_minus_preventing_liked_FCI*mckenzie cancer_promoting_minus_preventing_liked_FCI*willamette cSES*mckenzie cSES*willamette age365*mckenzie age365*willamette education_own*mckenzie education_own*willamette SST_SSD*mckenzie SST_SSD*willamette SST_mean_ssrt_0*mckenzie SST_mean_ssrt_0*willamette ROC_Crave_Regulate_Minus_Look*mckenzie ROC_Crave_Regulate_Minus_Look*willamette WTP_unhealthy_minus_healthy*mckenzie WTP_unhealthy_minus_healthy*willamette wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette wtp_liked_value_association-test_z_FDR_0.01*mckenzie wtp_liked_value_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*mckenzie roc_reappraiseCrave_abstract_association-test_z_FDR_0.01*willamette roc_reappraiseCrave_multivariate_regulation*mckenzie roc_reappraiseCrave_multivariate_regulation*willamette roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*mckenzie roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero*willamette sst_CorrectGo_striatum_joint_mask*mckenzie sst_CorrectGo_striatum_joint_mask*willamette sst_CorrectGo_finger movements_association-test_z_FDR_0.01*mckenzie sst_CorrectGo_finger movements_association-test_z_FDR_0.01*willamette sst_CorrectStop_motor_control_striatum_joint_mask*mckenzie sst_CorrectStop_motor_control_striatum_joint_mask*willamette sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*mckenzie sst_CorrectStop_response inhibition_association-test_z_FDR_0.01*willamette sst_FailedStop_motor_control_striatum_joint_mask*mckenzie sst_FailedStop_motor_control_striatum_joint_mask*willamette sst_CorrectGoFollowingFailedStop_striatum_joint_mask*mckenzie sst_CorrectGoFollowingFailedStop_striatum_joint_mask*willamette birthsex_factor_Male*mckenzie birthsex_factor_Male*willamette\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.355e+00, tolerance: 3.297e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.230e+02, tolerance: 3.832e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.370e+02, tolerance: 3.702e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.205e+02, tolerance: 3.054e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.354e+01, tolerance: 3.832e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.243e+03, tolerance: 3.690e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.801e+02, tolerance: 3.390e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.659e+00, tolerance: 2.747e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.989e+02, tolerance: 3.553e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.866e+01, tolerance: 3.690e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.271e+01, tolerance: 3.390e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.380e+00, tolerance: 3.553e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.231e+01, tolerance: 2.886e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.351e+02, tolerance: 3.307e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.756e+01, tolerance: 3.571e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.381e+01, tolerance: 2.878e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.506e+01, tolerance: 3.307e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.510e+00, tolerance: 3.571e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.360e+01, tolerance: 3.721e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.172e+02, tolerance: 3.625e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.528e+02, tolerance: 3.520e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.035e+01, tolerance: 3.380e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.779e+02, tolerance: 3.978e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.797e+02, tolerance: 3.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.217e+02, tolerance: 4.026e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.188e+01, tolerance: 3.626e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.899e+01, tolerance: 3.978e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.521e+01, tolerance: 3.105e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.861e+00, tolerance: 4.026e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.712e+00, tolerance: 3.626e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "scores:\n",
      "[-0.027442988846308358, -0.05796232750499697, -0.018860589367594383, 0.011876001098583444, -0.011276813656221574]\n",
      "overall_score:\n",
      "-0.020733343655307566\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.677937</td>\n",
       "      <td>0.599311</td>\n",
       "      <td>1.680303</td>\n",
       "      <td>0.585234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.692072</td>\n",
       "      <td>0.517375</td>\n",
       "      <td>1.762757</td>\n",
       "      <td>0.574266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.728520</td>\n",
       "      <td>0.639618</td>\n",
       "      <td>1.681660</td>\n",
       "      <td>0.626096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.753583</td>\n",
       "      <td>0.529326</td>\n",
       "      <td>1.769020</td>\n",
       "      <td>0.598688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.761190</td>\n",
       "      <td>0.645112</td>\n",
       "      <td>1.704735</td>\n",
       "      <td>0.625176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.800928</td>\n",
       "      <td>0.517471</td>\n",
       "      <td>1.784597</td>\n",
       "      <td>0.597387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.809465</td>\n",
       "      <td>0.639149</td>\n",
       "      <td>1.744452</td>\n",
       "      <td>0.636057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.874409</td>\n",
       "      <td>0.708605</td>\n",
       "      <td>1.909484</td>\n",
       "      <td>0.735440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.874409</td>\n",
       "      <td>0.708605</td>\n",
       "      <td>1.909484</td>\n",
       "      <td>0.735440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.874409</td>\n",
       "      <td>0.708605</td>\n",
       "      <td>1.909484</td>\n",
       "      <td>0.735440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.925547</td>\n",
       "      <td>0.505268</td>\n",
       "      <td>1.828940</td>\n",
       "      <td>0.628327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.961587</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>1.909992</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.961587</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>1.909992</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.961587</td>\n",
       "      <td>0.736581</td>\n",
       "      <td>1.909992</td>\n",
       "      <td>0.702400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.962627</td>\n",
       "      <td>0.734320</td>\n",
       "      <td>1.910697</td>\n",
       "      <td>0.701576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.969672</td>\n",
       "      <td>0.742963</td>\n",
       "      <td>1.917240</td>\n",
       "      <td>0.693987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.969672</td>\n",
       "      <td>0.742963</td>\n",
       "      <td>1.917240</td>\n",
       "      <td>0.693987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.969672</td>\n",
       "      <td>0.742963</td>\n",
       "      <td>1.917240</td>\n",
       "      <td>0.693987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.970712</td>\n",
       "      <td>0.740707</td>\n",
       "      <td>1.917945</td>\n",
       "      <td>0.693143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.970712</td>\n",
       "      <td>0.740707</td>\n",
       "      <td>1.917945</td>\n",
       "      <td>0.693143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.992543</td>\n",
       "      <td>0.748961</td>\n",
       "      <td>1.855093</td>\n",
       "      <td>0.645535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.992543</td>\n",
       "      <td>0.748961</td>\n",
       "      <td>1.855093</td>\n",
       "      <td>0.645535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.992543</td>\n",
       "      <td>0.748961</td>\n",
       "      <td>1.855093</td>\n",
       "      <td>0.645535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.007273</td>\n",
       "      <td>0.562304</td>\n",
       "      <td>1.707646</td>\n",
       "      <td>0.554334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"23\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.031742</td>\n",
       "      <td>0.773182</td>\n",
       "      <td>1.881625</td>\n",
       "      <td>0.531557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.031742</td>\n",
       "      <td>0.773182</td>\n",
       "      <td>1.881625</td>\n",
       "      <td>0.531557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.031742</td>\n",
       "      <td>0.773182</td>\n",
       "      <td>1.881625</td>\n",
       "      <td>0.531557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.039609</td>\n",
       "      <td>0.880919</td>\n",
       "      <td>1.590884</td>\n",
       "      <td>0.868362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.039609</td>\n",
       "      <td>0.880919</td>\n",
       "      <td>1.590884</td>\n",
       "      <td>0.868362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.039609</td>\n",
       "      <td>0.880919</td>\n",
       "      <td>1.590884</td>\n",
       "      <td>0.868362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.047694</td>\n",
       "      <td>0.895261</td>\n",
       "      <td>1.593154</td>\n",
       "      <td>0.866217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.047694</td>\n",
       "      <td>0.895261</td>\n",
       "      <td>1.593154</td>\n",
       "      <td>0.866217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.047694</td>\n",
       "      <td>0.895261</td>\n",
       "      <td>1.593154</td>\n",
       "      <td>0.866217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.047694</td>\n",
       "      <td>0.895261</td>\n",
       "      <td>1.593154</td>\n",
       "      <td>0.866217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.047694</td>\n",
       "      <td>0.895261</td>\n",
       "      <td>1.593154</td>\n",
       "      <td>0.866217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.047694</td>\n",
       "      <td>0.895261</td>\n",
       "      <td>1.593154</td>\n",
       "      <td>0.866217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.053045</td>\n",
       "      <td>0.867695</td>\n",
       "      <td>1.579771</td>\n",
       "      <td>0.858850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.053045</td>\n",
       "      <td>0.867695</td>\n",
       "      <td>1.579771</td>\n",
       "      <td>0.858850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.053045</td>\n",
       "      <td>0.867695</td>\n",
       "      <td>1.579771</td>\n",
       "      <td>0.858850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.069414</td>\n",
       "      <td>1.118267</td>\n",
       "      <td>1.772654</td>\n",
       "      <td>0.719346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.069414</td>\n",
       "      <td>1.118267</td>\n",
       "      <td>1.772654</td>\n",
       "      <td>0.719346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.079744</td>\n",
       "      <td>0.670728</td>\n",
       "      <td>1.923341</td>\n",
       "      <td>0.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.079744</td>\n",
       "      <td>0.670728</td>\n",
       "      <td>1.923341</td>\n",
       "      <td>0.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.079744</td>\n",
       "      <td>0.670728</td>\n",
       "      <td>1.923341</td>\n",
       "      <td>0.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.079744</td>\n",
       "      <td>0.670728</td>\n",
       "      <td>1.923341</td>\n",
       "      <td>0.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.079744</td>\n",
       "      <td>0.670728</td>\n",
       "      <td>1.923341</td>\n",
       "      <td>0.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.079744</td>\n",
       "      <td>0.670728</td>\n",
       "      <td>1.923341</td>\n",
       "      <td>0.477828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.083248</td>\n",
       "      <td>0.774716</td>\n",
       "      <td>1.734781</td>\n",
       "      <td>0.686070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.143299</td>\n",
       "      <td>0.607535</td>\n",
       "      <td>1.723445</td>\n",
       "      <td>0.581023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.146142</td>\n",
       "      <td>1.131144</td>\n",
       "      <td>1.668074</td>\n",
       "      <td>0.719788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.175590</td>\n",
       "      <td>0.632719</td>\n",
       "      <td>1.844207</td>\n",
       "      <td>0.548677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.175590</td>\n",
       "      <td>0.632719</td>\n",
       "      <td>1.844207</td>\n",
       "      <td>0.548677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.208338</td>\n",
       "      <td>0.772314</td>\n",
       "      <td>1.699633</td>\n",
       "      <td>0.567008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.257926</td>\n",
       "      <td>0.384150</td>\n",
       "      <td>1.462051</td>\n",
       "      <td>0.389612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.258673</td>\n",
       "      <td>0.402414</td>\n",
       "      <td>1.334358</td>\n",
       "      <td>0.430198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.273543</td>\n",
       "      <td>1.165418</td>\n",
       "      <td>1.551912</td>\n",
       "      <td>0.644305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.316676</td>\n",
       "      <td>0.589196</td>\n",
       "      <td>1.784785</td>\n",
       "      <td>0.519495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.320720</td>\n",
       "      <td>0.732129</td>\n",
       "      <td>1.719527</td>\n",
       "      <td>0.573891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.345469</td>\n",
       "      <td>0.795640</td>\n",
       "      <td>1.779804</td>\n",
       "      <td>0.283984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.350875</td>\n",
       "      <td>0.418454</td>\n",
       "      <td>1.448595</td>\n",
       "      <td>0.390848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.362625</td>\n",
       "      <td>0.429591</td>\n",
       "      <td>1.308440</td>\n",
       "      <td>0.447060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.363711</td>\n",
       "      <td>0.743756</td>\n",
       "      <td>1.594447</td>\n",
       "      <td>0.450271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.367871</td>\n",
       "      <td>0.841257</td>\n",
       "      <td>1.756005</td>\n",
       "      <td>0.333762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.390526</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>1.706171</td>\n",
       "      <td>0.596568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.412619</td>\n",
       "      <td>0.603282</td>\n",
       "      <td>1.828720</td>\n",
       "      <td>0.784640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.415291</td>\n",
       "      <td>1.092422</td>\n",
       "      <td>1.627894</td>\n",
       "      <td>0.640451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.438311</td>\n",
       "      <td>1.404351</td>\n",
       "      <td>1.434024</td>\n",
       "      <td>0.644016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.439086</td>\n",
       "      <td>0.922243</td>\n",
       "      <td>1.672368</td>\n",
       "      <td>0.593652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.449017</td>\n",
       "      <td>0.431211</td>\n",
       "      <td>1.433088</td>\n",
       "      <td>0.365637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.450677</td>\n",
       "      <td>0.513675</td>\n",
       "      <td>1.735062</td>\n",
       "      <td>0.466274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.450677</td>\n",
       "      <td>0.513675</td>\n",
       "      <td>1.735062</td>\n",
       "      <td>0.466274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.454597</td>\n",
       "      <td>0.861112</td>\n",
       "      <td>1.656533</td>\n",
       "      <td>0.555554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.458080</td>\n",
       "      <td>0.624799</td>\n",
       "      <td>1.648490</td>\n",
       "      <td>0.562036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.458471</td>\n",
       "      <td>0.419949</td>\n",
       "      <td>1.396281</td>\n",
       "      <td>0.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.458471</td>\n",
       "      <td>0.419949</td>\n",
       "      <td>1.396281</td>\n",
       "      <td>0.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.458471</td>\n",
       "      <td>0.419949</td>\n",
       "      <td>1.396281</td>\n",
       "      <td>0.273800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.464929</td>\n",
       "      <td>0.860239</td>\n",
       "      <td>1.653003</td>\n",
       "      <td>0.548103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.468189</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>1.507170</td>\n",
       "      <td>0.609606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.471046</td>\n",
       "      <td>1.434836</td>\n",
       "      <td>1.402430</td>\n",
       "      <td>0.640912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.475999</td>\n",
       "      <td>0.842005</td>\n",
       "      <td>1.691690</td>\n",
       "      <td>0.580833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.481186</td>\n",
       "      <td>0.422647</td>\n",
       "      <td>1.292972</td>\n",
       "      <td>0.431710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.484884</td>\n",
       "      <td>0.958924</td>\n",
       "      <td>1.576193</td>\n",
       "      <td>0.563385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.490939</td>\n",
       "      <td>1.351793</td>\n",
       "      <td>1.651849</td>\n",
       "      <td>0.611410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.510424</td>\n",
       "      <td>0.423325</td>\n",
       "      <td>1.439470</td>\n",
       "      <td>0.535101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.566442</td>\n",
       "      <td>0.423383</td>\n",
       "      <td>1.435240</td>\n",
       "      <td>0.332483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.566659</td>\n",
       "      <td>0.862890</td>\n",
       "      <td>1.705657</td>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.566659</td>\n",
       "      <td>0.862890</td>\n",
       "      <td>1.705657</td>\n",
       "      <td>0.680679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.580760</td>\n",
       "      <td>1.030062</td>\n",
       "      <td>1.925628</td>\n",
       "      <td>0.242729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.581308</td>\n",
       "      <td>1.123720</td>\n",
       "      <td>1.713107</td>\n",
       "      <td>0.626846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.581308</td>\n",
       "      <td>1.123720</td>\n",
       "      <td>1.713107</td>\n",
       "      <td>0.626846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.588556</td>\n",
       "      <td>0.891485</td>\n",
       "      <td>1.674325</td>\n",
       "      <td>0.552183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.589829</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>1.450279</td>\n",
       "      <td>0.334532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.589829</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>1.450279</td>\n",
       "      <td>0.334532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.589829</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>1.450279</td>\n",
       "      <td>0.334532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.589829</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>1.450279</td>\n",
       "      <td>0.334532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.589829</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>1.450279</td>\n",
       "      <td>0.334532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.589829</td>\n",
       "      <td>0.547178</td>\n",
       "      <td>1.450279</td>\n",
       "      <td>0.334532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.592592</td>\n",
       "      <td>0.550219</td>\n",
       "      <td>1.454539</td>\n",
       "      <td>0.330530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.592592</td>\n",
       "      <td>0.550219</td>\n",
       "      <td>1.454539</td>\n",
       "      <td>0.330530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.592592</td>\n",
       "      <td>0.550219</td>\n",
       "      <td>1.454539</td>\n",
       "      <td>0.330530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.608928</td>\n",
       "      <td>0.914179</td>\n",
       "      <td>1.823375</td>\n",
       "      <td>0.470105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.629164</td>\n",
       "      <td>0.410453</td>\n",
       "      <td>1.298772</td>\n",
       "      <td>0.411735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.635628</td>\n",
       "      <td>1.244448</td>\n",
       "      <td>1.666089</td>\n",
       "      <td>0.502716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.642854</td>\n",
       "      <td>1.158550</td>\n",
       "      <td>1.805903</td>\n",
       "      <td>0.417987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.659316</td>\n",
       "      <td>0.446576</td>\n",
       "      <td>1.429694</td>\n",
       "      <td>0.563878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.678067</td>\n",
       "      <td>0.705203</td>\n",
       "      <td>1.125286</td>\n",
       "      <td>0.500048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.679325</td>\n",
       "      <td>0.665228</td>\n",
       "      <td>1.166641</td>\n",
       "      <td>0.504460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.682144</td>\n",
       "      <td>0.604519</td>\n",
       "      <td>1.912541</td>\n",
       "      <td>0.494021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.688738</td>\n",
       "      <td>0.413777</td>\n",
       "      <td>1.439218</td>\n",
       "      <td>0.307009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.707261</td>\n",
       "      <td>0.800078</td>\n",
       "      <td>1.457492</td>\n",
       "      <td>0.569193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.723530</td>\n",
       "      <td>0.959806</td>\n",
       "      <td>1.427182</td>\n",
       "      <td>0.471265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.723530</td>\n",
       "      <td>0.959806</td>\n",
       "      <td>1.427182</td>\n",
       "      <td>0.471265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.723530</td>\n",
       "      <td>0.959806</td>\n",
       "      <td>1.427182</td>\n",
       "      <td>0.471265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.725328</td>\n",
       "      <td>0.914503</td>\n",
       "      <td>1.353728</td>\n",
       "      <td>0.366189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.725328</td>\n",
       "      <td>0.914503</td>\n",
       "      <td>1.353728</td>\n",
       "      <td>0.366189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.725328</td>\n",
       "      <td>0.914503</td>\n",
       "      <td>1.353728</td>\n",
       "      <td>0.366189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.731504</td>\n",
       "      <td>0.567222</td>\n",
       "      <td>1.150543</td>\n",
       "      <td>0.476804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.733826</td>\n",
       "      <td>0.961560</td>\n",
       "      <td>1.664015</td>\n",
       "      <td>0.505504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.745828</td>\n",
       "      <td>0.412004</td>\n",
       "      <td>1.439118</td>\n",
       "      <td>0.301097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.748955</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>0.336010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.748955</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>0.336010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.748955</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>0.336010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.748955</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>0.336010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.748955</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>0.336010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.748955</td>\n",
       "      <td>0.934955</td>\n",
       "      <td>1.391142</td>\n",
       "      <td>0.336010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.755932</td>\n",
       "      <td>1.018249</td>\n",
       "      <td>1.356844</td>\n",
       "      <td>0.460182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.755932</td>\n",
       "      <td>1.018249</td>\n",
       "      <td>1.356844</td>\n",
       "      <td>0.460182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.755932</td>\n",
       "      <td>1.018249</td>\n",
       "      <td>1.356844</td>\n",
       "      <td>0.460182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.769833</td>\n",
       "      <td>0.435051</td>\n",
       "      <td>1.409199</td>\n",
       "      <td>0.261774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.770696</td>\n",
       "      <td>1.783225</td>\n",
       "      <td>1.751237</td>\n",
       "      <td>0.633392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.783705</td>\n",
       "      <td>0.405132</td>\n",
       "      <td>1.291167</td>\n",
       "      <td>0.422030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.794080</td>\n",
       "      <td>0.380023</td>\n",
       "      <td>1.427977</td>\n",
       "      <td>0.288524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.794182</td>\n",
       "      <td>0.430480</td>\n",
       "      <td>1.370861</td>\n",
       "      <td>0.337429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.794182</td>\n",
       "      <td>0.430480</td>\n",
       "      <td>1.370861</td>\n",
       "      <td>0.337429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.798211</td>\n",
       "      <td>0.402380</td>\n",
       "      <td>1.428514</td>\n",
       "      <td>0.305892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.802374</td>\n",
       "      <td>0.401650</td>\n",
       "      <td>1.429073</td>\n",
       "      <td>0.305803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.806569</td>\n",
       "      <td>0.400884</td>\n",
       "      <td>1.429653</td>\n",
       "      <td>0.305761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.810198</td>\n",
       "      <td>1.698243</td>\n",
       "      <td>1.750190</td>\n",
       "      <td>0.655803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.810794</td>\n",
       "      <td>0.400077</td>\n",
       "      <td>1.430256</td>\n",
       "      <td>0.305768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.811636</td>\n",
       "      <td>0.816532</td>\n",
       "      <td>1.875937</td>\n",
       "      <td>0.538164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.812918</td>\n",
       "      <td>0.399657</td>\n",
       "      <td>1.430566</td>\n",
       "      <td>0.305791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.820566</td>\n",
       "      <td>0.749576</td>\n",
       "      <td>1.856047</td>\n",
       "      <td>0.512613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.823941</td>\n",
       "      <td>1.009821</td>\n",
       "      <td>1.667497</td>\n",
       "      <td>0.468868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.832007</td>\n",
       "      <td>0.427768</td>\n",
       "      <td>1.426952</td>\n",
       "      <td>0.552908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.833898</td>\n",
       "      <td>0.989298</td>\n",
       "      <td>1.316330</td>\n",
       "      <td>0.461272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.833898</td>\n",
       "      <td>0.989298</td>\n",
       "      <td>1.316330</td>\n",
       "      <td>0.461272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.833898</td>\n",
       "      <td>0.989298</td>\n",
       "      <td>1.316330</td>\n",
       "      <td>0.461272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.839033</td>\n",
       "      <td>1.402170</td>\n",
       "      <td>1.760997</td>\n",
       "      <td>0.621262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.849660</td>\n",
       "      <td>1.325471</td>\n",
       "      <td>1.559945</td>\n",
       "      <td>0.757487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.858191</td>\n",
       "      <td>0.470640</td>\n",
       "      <td>1.188466</td>\n",
       "      <td>0.506127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.860088</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.351191</td>\n",
       "      <td>0.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.860088</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.351191</td>\n",
       "      <td>0.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.860088</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.351191</td>\n",
       "      <td>0.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.860088</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.351191</td>\n",
       "      <td>0.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.860088</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.351191</td>\n",
       "      <td>0.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.860088</td>\n",
       "      <td>1.023052</td>\n",
       "      <td>1.351191</td>\n",
       "      <td>0.408555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.895795</td>\n",
       "      <td>0.431982</td>\n",
       "      <td>1.303980</td>\n",
       "      <td>0.422321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.909264</td>\n",
       "      <td>0.591334</td>\n",
       "      <td>1.101225</td>\n",
       "      <td>0.502743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.917196</td>\n",
       "      <td>0.555331</td>\n",
       "      <td>1.207086</td>\n",
       "      <td>0.484460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.919141</td>\n",
       "      <td>0.432285</td>\n",
       "      <td>1.478044</td>\n",
       "      <td>0.445609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.919141</td>\n",
       "      <td>0.432285</td>\n",
       "      <td>1.478044</td>\n",
       "      <td>0.445609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.927814</td>\n",
       "      <td>1.425745</td>\n",
       "      <td>1.714466</td>\n",
       "      <td>0.596702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.960919</td>\n",
       "      <td>0.623343</td>\n",
       "      <td>1.761821</td>\n",
       "      <td>0.637689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.968185</td>\n",
       "      <td>0.427077</td>\n",
       "      <td>1.372571</td>\n",
       "      <td>0.491570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.975212</td>\n",
       "      <td>0.630848</td>\n",
       "      <td>1.104478</td>\n",
       "      <td>0.612605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.976730</td>\n",
       "      <td>0.621476</td>\n",
       "      <td>1.178816</td>\n",
       "      <td>0.512369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.983688</td>\n",
       "      <td>1.566072</td>\n",
       "      <td>1.928089</td>\n",
       "      <td>0.627727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.984851</td>\n",
       "      <td>0.653569</td>\n",
       "      <td>1.200979</td>\n",
       "      <td>0.608994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.984851</td>\n",
       "      <td>0.653569</td>\n",
       "      <td>1.200979</td>\n",
       "      <td>0.608994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.987027</td>\n",
       "      <td>0.416195</td>\n",
       "      <td>1.339974</td>\n",
       "      <td>0.408385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-14.987480</td>\n",
       "      <td>0.834493</td>\n",
       "      <td>1.312442</td>\n",
       "      <td>0.192377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-14.987480</td>\n",
       "      <td>0.834493</td>\n",
       "      <td>1.312442</td>\n",
       "      <td>0.192377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-14.987480</td>\n",
       "      <td>0.834493</td>\n",
       "      <td>1.312442</td>\n",
       "      <td>0.192377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.987982</td>\n",
       "      <td>0.582063</td>\n",
       "      <td>1.181357</td>\n",
       "      <td>0.666645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.995508</td>\n",
       "      <td>0.626457</td>\n",
       "      <td>1.182608</td>\n",
       "      <td>0.507540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.996028</td>\n",
       "      <td>0.442746</td>\n",
       "      <td>1.340436</td>\n",
       "      <td>0.432569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.996200</td>\n",
       "      <td>1.568456</td>\n",
       "      <td>1.930535</td>\n",
       "      <td>0.611867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.996480</td>\n",
       "      <td>1.522662</td>\n",
       "      <td>1.987112</td>\n",
       "      <td>0.572644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.996480</td>\n",
       "      <td>1.522662</td>\n",
       "      <td>1.987112</td>\n",
       "      <td>0.572644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.005224</td>\n",
       "      <td>0.444155</td>\n",
       "      <td>1.340669</td>\n",
       "      <td>0.431727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.014613</td>\n",
       "      <td>0.445691</td>\n",
       "      <td>1.340527</td>\n",
       "      <td>0.430496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.024834</td>\n",
       "      <td>1.264028</td>\n",
       "      <td>1.478153</td>\n",
       "      <td>0.632004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.025500</td>\n",
       "      <td>0.447401</td>\n",
       "      <td>1.339501</td>\n",
       "      <td>0.428518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.029209</td>\n",
       "      <td>0.769662</td>\n",
       "      <td>1.729492</td>\n",
       "      <td>0.652923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.031235</td>\n",
       "      <td>0.448347</td>\n",
       "      <td>1.338573</td>\n",
       "      <td>0.427165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.032866</td>\n",
       "      <td>1.135528</td>\n",
       "      <td>1.619478</td>\n",
       "      <td>0.366013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.039709</td>\n",
       "      <td>0.740302</td>\n",
       "      <td>1.221034</td>\n",
       "      <td>0.319387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.040492</td>\n",
       "      <td>0.396531</td>\n",
       "      <td>1.442771</td>\n",
       "      <td>0.523250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.043226</td>\n",
       "      <td>0.756478</td>\n",
       "      <td>1.242372</td>\n",
       "      <td>0.337798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.044206</td>\n",
       "      <td>0.693421</td>\n",
       "      <td>1.226501</td>\n",
       "      <td>0.378823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.070327</td>\n",
       "      <td>1.248641</td>\n",
       "      <td>1.522672</td>\n",
       "      <td>0.750732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.076012</td>\n",
       "      <td>0.696744</td>\n",
       "      <td>1.740244</td>\n",
       "      <td>0.641731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.102963</td>\n",
       "      <td>1.238908</td>\n",
       "      <td>1.510514</td>\n",
       "      <td>0.746444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.124733</td>\n",
       "      <td>0.961242</td>\n",
       "      <td>1.320024</td>\n",
       "      <td>0.608806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.131545</td>\n",
       "      <td>0.563573</td>\n",
       "      <td>1.258565</td>\n",
       "      <td>0.429133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.134726</td>\n",
       "      <td>1.868755</td>\n",
       "      <td>1.604049</td>\n",
       "      <td>0.705164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.212967</td>\n",
       "      <td>1.141110</td>\n",
       "      <td>1.704043</td>\n",
       "      <td>0.508866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.219620</td>\n",
       "      <td>0.741892</td>\n",
       "      <td>1.718012</td>\n",
       "      <td>0.593668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.240896</td>\n",
       "      <td>1.173266</td>\n",
       "      <td>1.685721</td>\n",
       "      <td>0.798751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.248035</td>\n",
       "      <td>0.947471</td>\n",
       "      <td>1.723299</td>\n",
       "      <td>0.603017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-15.274907</td>\n",
       "      <td>0.799925</td>\n",
       "      <td>1.332031</td>\n",
       "      <td>0.302219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.276949</td>\n",
       "      <td>1.205309</td>\n",
       "      <td>1.701052</td>\n",
       "      <td>0.802214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.287378</td>\n",
       "      <td>0.563782</td>\n",
       "      <td>1.223594</td>\n",
       "      <td>0.432722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.287378</td>\n",
       "      <td>0.563782</td>\n",
       "      <td>1.223594</td>\n",
       "      <td>0.432722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.297321</td>\n",
       "      <td>0.830276</td>\n",
       "      <td>1.457895</td>\n",
       "      <td>0.708076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.297321</td>\n",
       "      <td>0.830276</td>\n",
       "      <td>1.457895</td>\n",
       "      <td>0.708076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.305398</td>\n",
       "      <td>0.412163</td>\n",
       "      <td>1.464395</td>\n",
       "      <td>0.451922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.326774</td>\n",
       "      <td>1.812841</td>\n",
       "      <td>1.656875</td>\n",
       "      <td>0.681761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.348394</td>\n",
       "      <td>1.430190</td>\n",
       "      <td>1.767958</td>\n",
       "      <td>0.805181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.403250</td>\n",
       "      <td>0.795770</td>\n",
       "      <td>1.687479</td>\n",
       "      <td>0.530688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.435335</td>\n",
       "      <td>1.084914</td>\n",
       "      <td>1.428095</td>\n",
       "      <td>0.409948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.435335</td>\n",
       "      <td>1.084914</td>\n",
       "      <td>1.428095</td>\n",
       "      <td>0.409948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.435335</td>\n",
       "      <td>1.084914</td>\n",
       "      <td>1.428095</td>\n",
       "      <td>0.409948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.469664</td>\n",
       "      <td>1.108930</td>\n",
       "      <td>1.705276</td>\n",
       "      <td>0.738640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.471133</td>\n",
       "      <td>1.101344</td>\n",
       "      <td>1.416377</td>\n",
       "      <td>0.402282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.471133</td>\n",
       "      <td>1.101344</td>\n",
       "      <td>1.416377</td>\n",
       "      <td>0.402282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.471133</td>\n",
       "      <td>1.101344</td>\n",
       "      <td>1.416377</td>\n",
       "      <td>0.402282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.471133</td>\n",
       "      <td>1.101344</td>\n",
       "      <td>1.416377</td>\n",
       "      <td>0.402282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.471133</td>\n",
       "      <td>1.101344</td>\n",
       "      <td>1.416377</td>\n",
       "      <td>0.402282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.471133</td>\n",
       "      <td>1.101344</td>\n",
       "      <td>1.416377</td>\n",
       "      <td>0.402282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.480852</td>\n",
       "      <td>0.805957</td>\n",
       "      <td>1.434034</td>\n",
       "      <td>0.627824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.495493</td>\n",
       "      <td>1.137048</td>\n",
       "      <td>1.725551</td>\n",
       "      <td>0.741506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.516999</td>\n",
       "      <td>0.416796</td>\n",
       "      <td>1.480318</td>\n",
       "      <td>0.427134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.556797</td>\n",
       "      <td>1.241046</td>\n",
       "      <td>1.680790</td>\n",
       "      <td>0.707845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.619328</td>\n",
       "      <td>0.218884</td>\n",
       "      <td>1.210822</td>\n",
       "      <td>0.434788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.634564</td>\n",
       "      <td>0.874762</td>\n",
       "      <td>1.659548</td>\n",
       "      <td>0.477365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.657725</td>\n",
       "      <td>1.245619</td>\n",
       "      <td>1.785953</td>\n",
       "      <td>0.486608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.668431</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>2.130585</td>\n",
       "      <td>0.542097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.671888</td>\n",
       "      <td>0.391656</td>\n",
       "      <td>1.513524</td>\n",
       "      <td>0.377417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.691965</td>\n",
       "      <td>0.416896</td>\n",
       "      <td>1.513660</td>\n",
       "      <td>0.400125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.714625</td>\n",
       "      <td>0.541527</td>\n",
       "      <td>1.072111</td>\n",
       "      <td>0.320564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.714994</td>\n",
       "      <td>0.420736</td>\n",
       "      <td>1.511780</td>\n",
       "      <td>0.402382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.720258</td>\n",
       "      <td>1.348571</td>\n",
       "      <td>1.676636</td>\n",
       "      <td>0.781121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.728333</td>\n",
       "      <td>0.716017</td>\n",
       "      <td>1.216731</td>\n",
       "      <td>0.592454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.742341</td>\n",
       "      <td>0.635457</td>\n",
       "      <td>1.381904</td>\n",
       "      <td>0.858145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.745103</td>\n",
       "      <td>0.431861</td>\n",
       "      <td>1.504252</td>\n",
       "      <td>0.411689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.771685</td>\n",
       "      <td>1.374538</td>\n",
       "      <td>1.697899</td>\n",
       "      <td>0.696791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-15.772673</td>\n",
       "      <td>0.935200</td>\n",
       "      <td>1.358359</td>\n",
       "      <td>0.343264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.779824</td>\n",
       "      <td>0.928140</td>\n",
       "      <td>1.647870</td>\n",
       "      <td>0.475608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.788664</td>\n",
       "      <td>0.455082</td>\n",
       "      <td>1.492364</td>\n",
       "      <td>0.432193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.816310</td>\n",
       "      <td>2.037708</td>\n",
       "      <td>1.864658</td>\n",
       "      <td>0.455645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.816430</td>\n",
       "      <td>0.655290</td>\n",
       "      <td>1.483360</td>\n",
       "      <td>0.785453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.821314</td>\n",
       "      <td>0.481346</td>\n",
       "      <td>1.484158</td>\n",
       "      <td>0.447922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.834196</td>\n",
       "      <td>0.837480</td>\n",
       "      <td>1.188156</td>\n",
       "      <td>0.567863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.867908</td>\n",
       "      <td>2.221810</td>\n",
       "      <td>1.757248</td>\n",
       "      <td>0.537072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.871180</td>\n",
       "      <td>0.701809</td>\n",
       "      <td>1.147236</td>\n",
       "      <td>0.729618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.884229</td>\n",
       "      <td>1.350637</td>\n",
       "      <td>1.467066</td>\n",
       "      <td>0.453437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.893639</td>\n",
       "      <td>1.269522</td>\n",
       "      <td>1.734839</td>\n",
       "      <td>0.706253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.894422</td>\n",
       "      <td>0.502373</td>\n",
       "      <td>1.371234</td>\n",
       "      <td>0.355138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.962944</td>\n",
       "      <td>0.563140</td>\n",
       "      <td>1.202552</td>\n",
       "      <td>0.558018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.962944</td>\n",
       "      <td>0.563140</td>\n",
       "      <td>1.202552</td>\n",
       "      <td>0.558018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.991726</td>\n",
       "      <td>0.748226</td>\n",
       "      <td>1.156844</td>\n",
       "      <td>0.535190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.992105</td>\n",
       "      <td>0.835633</td>\n",
       "      <td>1.135455</td>\n",
       "      <td>0.595596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.013317</td>\n",
       "      <td>1.208265</td>\n",
       "      <td>1.515753</td>\n",
       "      <td>0.538339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.031633</td>\n",
       "      <td>0.715985</td>\n",
       "      <td>1.052742</td>\n",
       "      <td>0.754985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.031633</td>\n",
       "      <td>0.715985</td>\n",
       "      <td>1.052742</td>\n",
       "      <td>0.754985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.087022</td>\n",
       "      <td>1.205207</td>\n",
       "      <td>1.891892</td>\n",
       "      <td>0.524557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.094130</td>\n",
       "      <td>1.296571</td>\n",
       "      <td>1.978451</td>\n",
       "      <td>0.436406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.140142</td>\n",
       "      <td>1.311312</td>\n",
       "      <td>1.652917</td>\n",
       "      <td>0.518682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.158072</td>\n",
       "      <td>0.417729</td>\n",
       "      <td>1.422843</td>\n",
       "      <td>0.576102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-16.158314</td>\n",
       "      <td>0.775214</td>\n",
       "      <td>1.552597</td>\n",
       "      <td>0.679610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.199310</td>\n",
       "      <td>0.358774</td>\n",
       "      <td>1.412020</td>\n",
       "      <td>0.553175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-16.256162</td>\n",
       "      <td>0.725060</td>\n",
       "      <td>1.840910</td>\n",
       "      <td>0.591142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-16.285079</td>\n",
       "      <td>0.510924</td>\n",
       "      <td>1.345358</td>\n",
       "      <td>0.614052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-16.288283</td>\n",
       "      <td>0.515512</td>\n",
       "      <td>1.342712</td>\n",
       "      <td>0.615790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-16.339613</td>\n",
       "      <td>0.714482</td>\n",
       "      <td>1.830666</td>\n",
       "      <td>0.578212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.376629</td>\n",
       "      <td>0.849952</td>\n",
       "      <td>1.258309</td>\n",
       "      <td>0.483268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-16.380241</td>\n",
       "      <td>0.671379</td>\n",
       "      <td>1.801923</td>\n",
       "      <td>0.543950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-16.496314</td>\n",
       "      <td>1.078696</td>\n",
       "      <td>1.425513</td>\n",
       "      <td>0.472303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.507251</td>\n",
       "      <td>1.841883</td>\n",
       "      <td>1.894771</td>\n",
       "      <td>0.456329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.521379</td>\n",
       "      <td>0.707796</td>\n",
       "      <td>1.513086</td>\n",
       "      <td>0.480872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.600288</td>\n",
       "      <td>0.651186</td>\n",
       "      <td>1.471495</td>\n",
       "      <td>0.509548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.625643</td>\n",
       "      <td>0.905313</td>\n",
       "      <td>1.308414</td>\n",
       "      <td>0.366029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.662684</td>\n",
       "      <td>0.653823</td>\n",
       "      <td>2.259769</td>\n",
       "      <td>0.545397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.675040</td>\n",
       "      <td>0.950229</td>\n",
       "      <td>1.583918</td>\n",
       "      <td>0.925051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.679149</td>\n",
       "      <td>0.610388</td>\n",
       "      <td>1.079537</td>\n",
       "      <td>0.589697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.684181</td>\n",
       "      <td>0.862725</td>\n",
       "      <td>2.207147</td>\n",
       "      <td>0.489747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.687429</td>\n",
       "      <td>0.593854</td>\n",
       "      <td>1.065261</td>\n",
       "      <td>0.557931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.691615</td>\n",
       "      <td>1.954994</td>\n",
       "      <td>1.790618</td>\n",
       "      <td>0.622751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.728458</td>\n",
       "      <td>1.133373</td>\n",
       "      <td>1.990121</td>\n",
       "      <td>0.626629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.768381</td>\n",
       "      <td>1.150557</td>\n",
       "      <td>1.395914</td>\n",
       "      <td>0.237431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-16.828674</td>\n",
       "      <td>0.740095</td>\n",
       "      <td>1.602848</td>\n",
       "      <td>0.634866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.833855</td>\n",
       "      <td>0.888593</td>\n",
       "      <td>1.389267</td>\n",
       "      <td>0.454281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.849062</td>\n",
       "      <td>0.740832</td>\n",
       "      <td>2.261529</td>\n",
       "      <td>0.563231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.851835</td>\n",
       "      <td>0.852688</td>\n",
       "      <td>1.360734</td>\n",
       "      <td>0.373806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-16.885115</td>\n",
       "      <td>0.717876</td>\n",
       "      <td>1.666075</td>\n",
       "      <td>0.774002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.943273</td>\n",
       "      <td>1.671896</td>\n",
       "      <td>1.581735</td>\n",
       "      <td>0.616673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.944398</td>\n",
       "      <td>1.021561</td>\n",
       "      <td>1.441015</td>\n",
       "      <td>0.622115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.956554</td>\n",
       "      <td>1.005193</td>\n",
       "      <td>1.426513</td>\n",
       "      <td>0.616179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.958169</td>\n",
       "      <td>0.743756</td>\n",
       "      <td>1.359177</td>\n",
       "      <td>0.453923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.991126</td>\n",
       "      <td>0.713264</td>\n",
       "      <td>1.308327</td>\n",
       "      <td>0.493997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-17.050943</td>\n",
       "      <td>0.607780</td>\n",
       "      <td>1.609688</td>\n",
       "      <td>0.719950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.070923</td>\n",
       "      <td>0.807034</td>\n",
       "      <td>2.261027</td>\n",
       "      <td>0.541910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.148052</td>\n",
       "      <td>1.686276</td>\n",
       "      <td>1.540496</td>\n",
       "      <td>1.019939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.237829</td>\n",
       "      <td>1.519585</td>\n",
       "      <td>1.631276</td>\n",
       "      <td>0.483669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.260773</td>\n",
       "      <td>1.537866</td>\n",
       "      <td>1.631327</td>\n",
       "      <td>0.348653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.342916</td>\n",
       "      <td>0.893527</td>\n",
       "      <td>2.259344</td>\n",
       "      <td>0.503193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.400418</td>\n",
       "      <td>1.183458</td>\n",
       "      <td>1.842725</td>\n",
       "      <td>1.168044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.406237</td>\n",
       "      <td>1.194720</td>\n",
       "      <td>1.666523</td>\n",
       "      <td>0.098263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.410945</td>\n",
       "      <td>1.180779</td>\n",
       "      <td>1.660394</td>\n",
       "      <td>0.111392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-17.515052</td>\n",
       "      <td>1.120062</td>\n",
       "      <td>1.514807</td>\n",
       "      <td>0.681851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.522413</td>\n",
       "      <td>1.262752</td>\n",
       "      <td>1.452239</td>\n",
       "      <td>0.309374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-17.525307</td>\n",
       "      <td>1.139615</td>\n",
       "      <td>1.425558</td>\n",
       "      <td>0.627264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.581294</td>\n",
       "      <td>0.994377</td>\n",
       "      <td>1.886061</td>\n",
       "      <td>1.206239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.609548</td>\n",
       "      <td>1.523490</td>\n",
       "      <td>2.017584</td>\n",
       "      <td>1.084303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.691736</td>\n",
       "      <td>1.581221</td>\n",
       "      <td>1.936360</td>\n",
       "      <td>1.163318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.706854</td>\n",
       "      <td>1.027598</td>\n",
       "      <td>2.264459</td>\n",
       "      <td>0.445345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-17.883463</td>\n",
       "      <td>1.107210</td>\n",
       "      <td>1.236782</td>\n",
       "      <td>0.668726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.935042</td>\n",
       "      <td>0.735377</td>\n",
       "      <td>1.590944</td>\n",
       "      <td>0.669880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-17.944237</td>\n",
       "      <td>1.151459</td>\n",
       "      <td>1.187516</td>\n",
       "      <td>0.707997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.956498</td>\n",
       "      <td>1.104494</td>\n",
       "      <td>2.272588</td>\n",
       "      <td>0.410046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.968000</td>\n",
       "      <td>0.708325</td>\n",
       "      <td>1.535920</td>\n",
       "      <td>0.706092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.014569</td>\n",
       "      <td>1.482831</td>\n",
       "      <td>1.429163</td>\n",
       "      <td>0.832839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-18.310970</td>\n",
       "      <td>1.233091</td>\n",
       "      <td>1.542729</td>\n",
       "      <td>0.661209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-18.503320</td>\n",
       "      <td>1.180180</td>\n",
       "      <td>1.351537</td>\n",
       "      <td>0.565271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-18.786067</td>\n",
       "      <td>1.340081</td>\n",
       "      <td>1.723239</td>\n",
       "      <td>0.549714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.817505</td>\n",
       "      <td>1.460543</td>\n",
       "      <td>1.829639</td>\n",
       "      <td>0.792123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-18.831726</td>\n",
       "      <td>1.132617</td>\n",
       "      <td>1.596157</td>\n",
       "      <td>0.431476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.974423</td>\n",
       "      <td>1.372375</td>\n",
       "      <td>1.953937</td>\n",
       "      <td>0.817238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-19.175040</td>\n",
       "      <td>1.131854</td>\n",
       "      <td>1.127865</td>\n",
       "      <td>0.353083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-19.202593</td>\n",
       "      <td>1.004637</td>\n",
       "      <td>1.020420</td>\n",
       "      <td>0.288255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-19.329466</td>\n",
       "      <td>0.974700</td>\n",
       "      <td>1.555009</td>\n",
       "      <td>0.612731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-19.413966</td>\n",
       "      <td>1.329359</td>\n",
       "      <td>1.559005</td>\n",
       "      <td>0.952003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.548671</td>\n",
       "      <td>1.455584</td>\n",
       "      <td>2.069065</td>\n",
       "      <td>0.518279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.590095</td>\n",
       "      <td>1.628691</td>\n",
       "      <td>2.105194</td>\n",
       "      <td>0.763815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.596794</td>\n",
       "      <td>1.221310</td>\n",
       "      <td>1.679076</td>\n",
       "      <td>0.989011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.644335</td>\n",
       "      <td>1.619092</td>\n",
       "      <td>1.734040</td>\n",
       "      <td>0.725054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-20.845059</td>\n",
       "      <td>1.219018</td>\n",
       "      <td>1.530843</td>\n",
       "      <td>0.848074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-21.238983</td>\n",
       "      <td>1.413066</td>\n",
       "      <td>1.597968</td>\n",
       "      <td>1.218252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-21.965692</td>\n",
       "      <td>1.450841</td>\n",
       "      <td>2.279199</td>\n",
       "      <td>0.887891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-23.499210</td>\n",
       "      <td>1.721301</td>\n",
       "      <td>2.203084</td>\n",
       "      <td>1.035999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-24.250159</td>\n",
       "      <td>1.998656</td>\n",
       "      <td>2.274742</td>\n",
       "      <td>1.016902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-25.280365</td>\n",
       "      <td>2.244560</td>\n",
       "      <td>2.344062</td>\n",
       "      <td>0.941149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-26.801299</td>\n",
       "      <td>2.610600</td>\n",
       "      <td>2.474707</td>\n",
       "      <td>0.914173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-29.547988</td>\n",
       "      <td>3.378655</td>\n",
       "      <td>2.662096</td>\n",
       "      <td>0.785241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-32.338760</td>\n",
       "      <td>4.157037</td>\n",
       "      <td>2.900928</td>\n",
       "      <td>0.779664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>RS*mckenzie</td>\n",
       "      <td>-0.400255</td>\n",
       "      <td>0.002622</td>\n",
       "      <td>0.002622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>BFI_agreeableness*mckenzie</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>BFI_conscientiousness*mckenzie</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>BFI_openness*mckenzie</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>IMI_effort_importance*mckenzie</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 46 predictors in the set condition_inddiff\n",
      "predictors in that set are mckenzie willamette BSCS EDM BIS_11 PCS RS TRSQ ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness IMI_effort_importance IMI_interest_enjoyment NCS_total PLAN_cognitive_strategies PLAN_mental_flexibility PLAN_temporal_orientation RMQ_assessment TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_craved_FCI cancer_promoting_minus_preventing_liked_FCI cSES age365 education_own SST_SSD SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look WTP_unhealthy_minus_healthy wtp_liked_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_abstract_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation roc_lookCrave_koban_kober_craving_wmapN99_boot10K_02-May-2022_notzero sst_CorrectGo_striatum_joint_mask sst_CorrectGo_finger movements_association-test_z_FDR_0.01 sst_CorrectStop_motor_control_striatum_joint_mask sst_CorrectStop_response inhibition_association-test_z_FDR_0.01 sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "scores:\n",
      "[-0.14149647699409273, -0.19597450382319037, -0.14890754588677702, -0.12989100507523288, -0.4445072856846486]\n",
      "overall_score:\n",
      "-0.21215536349278832\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.115852</td>\n",
       "      <td>0.438003</td>\n",
       "      <td>1.559084</td>\n",
       "      <td>0.547139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.217356</td>\n",
       "      <td>0.455315</td>\n",
       "      <td>1.550770</td>\n",
       "      <td>0.595152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.283529</td>\n",
       "      <td>0.356864</td>\n",
       "      <td>1.505316</td>\n",
       "      <td>0.470108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.374563</td>\n",
       "      <td>0.446430</td>\n",
       "      <td>1.521249</td>\n",
       "      <td>0.630559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.388603</td>\n",
       "      <td>0.359303</td>\n",
       "      <td>1.500272</td>\n",
       "      <td>0.490877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.435807</td>\n",
       "      <td>0.400701</td>\n",
       "      <td>1.652958</td>\n",
       "      <td>0.649068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.499474</td>\n",
       "      <td>0.338549</td>\n",
       "      <td>1.494395</td>\n",
       "      <td>0.487251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.548163</td>\n",
       "      <td>0.286860</td>\n",
       "      <td>1.579934</td>\n",
       "      <td>0.577682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.594422</td>\n",
       "      <td>0.519504</td>\n",
       "      <td>1.648973</td>\n",
       "      <td>0.690638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-14.601286</td>\n",
       "      <td>0.436082</td>\n",
       "      <td>1.556627</td>\n",
       "      <td>0.660944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.606222</td>\n",
       "      <td>0.361328</td>\n",
       "      <td>1.631490</td>\n",
       "      <td>0.507468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.613430</td>\n",
       "      <td>0.320922</td>\n",
       "      <td>1.487280</td>\n",
       "      <td>0.485738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.620650</td>\n",
       "      <td>0.465040</td>\n",
       "      <td>1.455323</td>\n",
       "      <td>0.677476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.663189</td>\n",
       "      <td>0.450865</td>\n",
       "      <td>1.657192</td>\n",
       "      <td>0.805819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.731898</td>\n",
       "      <td>0.310057</td>\n",
       "      <td>1.481841</td>\n",
       "      <td>0.485375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.737676</td>\n",
       "      <td>0.317837</td>\n",
       "      <td>1.583616</td>\n",
       "      <td>0.620705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.793515</td>\n",
       "      <td>0.397881</td>\n",
       "      <td>1.639376</td>\n",
       "      <td>0.538280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.793665</td>\n",
       "      <td>0.303009</td>\n",
       "      <td>1.478649</td>\n",
       "      <td>0.485025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.834027</td>\n",
       "      <td>0.277026</td>\n",
       "      <td>1.478039</td>\n",
       "      <td>0.458413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.838073</td>\n",
       "      <td>0.293385</td>\n",
       "      <td>1.477932</td>\n",
       "      <td>0.486282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.842226</td>\n",
       "      <td>0.292875</td>\n",
       "      <td>1.477891</td>\n",
       "      <td>0.486496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.846424</td>\n",
       "      <td>0.292352</td>\n",
       "      <td>1.477865</td>\n",
       "      <td>0.486756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.850202</td>\n",
       "      <td>0.725647</td>\n",
       "      <td>1.745141</td>\n",
       "      <td>0.716271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.850202</td>\n",
       "      <td>0.725647</td>\n",
       "      <td>1.745141</td>\n",
       "      <td>0.716271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.850202</td>\n",
       "      <td>0.725647</td>\n",
       "      <td>1.745141</td>\n",
       "      <td>0.716271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.850647</td>\n",
       "      <td>0.291829</td>\n",
       "      <td>1.477838</td>\n",
       "      <td>0.487031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.852768</td>\n",
       "      <td>0.291569</td>\n",
       "      <td>1.477824</td>\n",
       "      <td>0.487174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.881601</td>\n",
       "      <td>0.964739</td>\n",
       "      <td>1.455385</td>\n",
       "      <td>0.533195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.881601</td>\n",
       "      <td>0.964739</td>\n",
       "      <td>1.455385</td>\n",
       "      <td>0.533195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.881601</td>\n",
       "      <td>0.964739</td>\n",
       "      <td>1.455385</td>\n",
       "      <td>0.533195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-14.885311</td>\n",
       "      <td>0.506617</td>\n",
       "      <td>1.570621</td>\n",
       "      <td>0.749937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.892467</td>\n",
       "      <td>0.491397</td>\n",
       "      <td>1.401408</td>\n",
       "      <td>0.728612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.898675</td>\n",
       "      <td>0.905565</td>\n",
       "      <td>1.325655</td>\n",
       "      <td>0.388404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.898675</td>\n",
       "      <td>0.905565</td>\n",
       "      <td>1.325655</td>\n",
       "      <td>0.388404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.898675</td>\n",
       "      <td>0.905565</td>\n",
       "      <td>1.325655</td>\n",
       "      <td>0.388404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.917337</td>\n",
       "      <td>0.758382</td>\n",
       "      <td>1.490061</td>\n",
       "      <td>0.443961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.932914</td>\n",
       "      <td>0.655447</td>\n",
       "      <td>1.659272</td>\n",
       "      <td>0.827417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.957285</td>\n",
       "      <td>0.330218</td>\n",
       "      <td>1.589364</td>\n",
       "      <td>0.637710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.982025</td>\n",
       "      <td>0.759470</td>\n",
       "      <td>1.696809</td>\n",
       "      <td>0.726788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.982025</td>\n",
       "      <td>0.759470</td>\n",
       "      <td>1.696809</td>\n",
       "      <td>0.726788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-14.982025</td>\n",
       "      <td>0.759470</td>\n",
       "      <td>1.696809</td>\n",
       "      <td>0.726788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-14.995491</td>\n",
       "      <td>0.407700</td>\n",
       "      <td>1.653151</td>\n",
       "      <td>0.541671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.004228</td>\n",
       "      <td>0.505014</td>\n",
       "      <td>1.646791</td>\n",
       "      <td>0.877255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.036144</td>\n",
       "      <td>1.003983</td>\n",
       "      <td>1.628936</td>\n",
       "      <td>0.544518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.039542</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>1.530624</td>\n",
       "      <td>0.637318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.039542</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>1.530624</td>\n",
       "      <td>0.637318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.039542</td>\n",
       "      <td>0.926472</td>\n",
       "      <td>1.530624</td>\n",
       "      <td>0.637318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.039683</td>\n",
       "      <td>0.500110</td>\n",
       "      <td>1.376473</td>\n",
       "      <td>0.760709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.045518</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>1.280796</td>\n",
       "      <td>0.447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.045518</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>1.280796</td>\n",
       "      <td>0.447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.045518</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>1.280796</td>\n",
       "      <td>0.447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.045518</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>1.280796</td>\n",
       "      <td>0.447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.045518</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>1.280796</td>\n",
       "      <td>0.447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.045518</td>\n",
       "      <td>0.863677</td>\n",
       "      <td>1.280796</td>\n",
       "      <td>0.447007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.084218</td>\n",
       "      <td>0.877408</td>\n",
       "      <td>1.347472</td>\n",
       "      <td>0.359639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.084218</td>\n",
       "      <td>0.877408</td>\n",
       "      <td>1.347472</td>\n",
       "      <td>0.359639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.084218</td>\n",
       "      <td>0.877408</td>\n",
       "      <td>1.347472</td>\n",
       "      <td>0.359639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.093118</td>\n",
       "      <td>0.823114</td>\n",
       "      <td>1.350441</td>\n",
       "      <td>0.470834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.113980</td>\n",
       "      <td>0.624179</td>\n",
       "      <td>1.452107</td>\n",
       "      <td>0.560332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.116904</td>\n",
       "      <td>0.471442</td>\n",
       "      <td>1.371014</td>\n",
       "      <td>0.732159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.124431</td>\n",
       "      <td>1.022705</td>\n",
       "      <td>1.559860</td>\n",
       "      <td>0.680394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.124431</td>\n",
       "      <td>1.022705</td>\n",
       "      <td>1.559860</td>\n",
       "      <td>0.680394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.124431</td>\n",
       "      <td>1.022705</td>\n",
       "      <td>1.559860</td>\n",
       "      <td>0.680394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.130746</td>\n",
       "      <td>0.501456</td>\n",
       "      <td>1.368429</td>\n",
       "      <td>0.779390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.132326</td>\n",
       "      <td>0.771385</td>\n",
       "      <td>1.090031</td>\n",
       "      <td>0.383237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.144857</td>\n",
       "      <td>0.503026</td>\n",
       "      <td>1.365824</td>\n",
       "      <td>0.782244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.151205</td>\n",
       "      <td>0.637081</td>\n",
       "      <td>1.516550</td>\n",
       "      <td>0.249224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.151205</td>\n",
       "      <td>0.637081</td>\n",
       "      <td>1.516550</td>\n",
       "      <td>0.249224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.154861</td>\n",
       "      <td>0.808544</td>\n",
       "      <td>1.533994</td>\n",
       "      <td>0.822939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.154861</td>\n",
       "      <td>0.808544</td>\n",
       "      <td>1.533994</td>\n",
       "      <td>0.822939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.154861</td>\n",
       "      <td>0.808544</td>\n",
       "      <td>1.533994</td>\n",
       "      <td>0.822939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.159281</td>\n",
       "      <td>0.504780</td>\n",
       "      <td>1.363208</td>\n",
       "      <td>0.785132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.162070</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>1.539414</td>\n",
       "      <td>0.819266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.162070</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>1.539414</td>\n",
       "      <td>0.819266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.162070</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>1.539414</td>\n",
       "      <td>0.819266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.162070</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>1.539414</td>\n",
       "      <td>0.819266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.162070</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>1.539414</td>\n",
       "      <td>0.819266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.162070</td>\n",
       "      <td>0.811517</td>\n",
       "      <td>1.539414</td>\n",
       "      <td>0.819266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.165598</td>\n",
       "      <td>0.699454</td>\n",
       "      <td>1.495601</td>\n",
       "      <td>0.444691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.174053</td>\n",
       "      <td>0.506745</td>\n",
       "      <td>1.360590</td>\n",
       "      <td>0.788052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.181556</td>\n",
       "      <td>0.507803</td>\n",
       "      <td>1.359281</td>\n",
       "      <td>0.789526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.195842</td>\n",
       "      <td>0.953629</td>\n",
       "      <td>1.407256</td>\n",
       "      <td>0.610585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.195842</td>\n",
       "      <td>0.953629</td>\n",
       "      <td>1.407256</td>\n",
       "      <td>0.610585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.195842</td>\n",
       "      <td>0.953629</td>\n",
       "      <td>1.407256</td>\n",
       "      <td>0.610585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.195842</td>\n",
       "      <td>0.953629</td>\n",
       "      <td>1.407256</td>\n",
       "      <td>0.610585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.195842</td>\n",
       "      <td>0.953629</td>\n",
       "      <td>1.407256</td>\n",
       "      <td>0.610585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.195842</td>\n",
       "      <td>0.953629</td>\n",
       "      <td>1.407256</td>\n",
       "      <td>0.610585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.198859</td>\n",
       "      <td>0.663037</td>\n",
       "      <td>1.470524</td>\n",
       "      <td>0.391522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.205404</td>\n",
       "      <td>0.425007</td>\n",
       "      <td>1.667523</td>\n",
       "      <td>0.548713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.217064</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>1.699928</td>\n",
       "      <td>0.818664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.217064</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>1.699928</td>\n",
       "      <td>0.818664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.217064</td>\n",
       "      <td>0.830876</td>\n",
       "      <td>1.699928</td>\n",
       "      <td>0.818664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.228916</td>\n",
       "      <td>0.361685</td>\n",
       "      <td>1.608447</td>\n",
       "      <td>0.671305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.234542</td>\n",
       "      <td>0.958194</td>\n",
       "      <td>1.468793</td>\n",
       "      <td>0.548452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.234542</td>\n",
       "      <td>0.958194</td>\n",
       "      <td>1.468793</td>\n",
       "      <td>0.548452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.234542</td>\n",
       "      <td>0.958194</td>\n",
       "      <td>1.468793</td>\n",
       "      <td>0.548452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.250126</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>1.740220</td>\n",
       "      <td>0.777460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.250126</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>1.740220</td>\n",
       "      <td>0.777460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.250126</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>1.740220</td>\n",
       "      <td>0.777460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.250126</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>1.740220</td>\n",
       "      <td>0.777460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.250126</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>1.740220</td>\n",
       "      <td>0.777460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.250126</td>\n",
       "      <td>0.861754</td>\n",
       "      <td>1.740220</td>\n",
       "      <td>0.777460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.256386</td>\n",
       "      <td>0.865294</td>\n",
       "      <td>1.592928</td>\n",
       "      <td>0.423083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.256386</td>\n",
       "      <td>0.865294</td>\n",
       "      <td>1.592928</td>\n",
       "      <td>0.423083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.256386</td>\n",
       "      <td>0.865294</td>\n",
       "      <td>1.592928</td>\n",
       "      <td>0.423083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.262523</td>\n",
       "      <td>0.974027</td>\n",
       "      <td>1.530700</td>\n",
       "      <td>0.581034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.283094</td>\n",
       "      <td>1.043768</td>\n",
       "      <td>1.444158</td>\n",
       "      <td>0.648173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.283094</td>\n",
       "      <td>1.043768</td>\n",
       "      <td>1.444158</td>\n",
       "      <td>0.648173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.283094</td>\n",
       "      <td>1.043768</td>\n",
       "      <td>1.444158</td>\n",
       "      <td>0.648173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.286485</td>\n",
       "      <td>1.046027</td>\n",
       "      <td>1.446266</td>\n",
       "      <td>0.644684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.286485</td>\n",
       "      <td>1.046027</td>\n",
       "      <td>1.446266</td>\n",
       "      <td>0.644684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.286485</td>\n",
       "      <td>1.046027</td>\n",
       "      <td>1.446266</td>\n",
       "      <td>0.644684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.286485</td>\n",
       "      <td>1.046027</td>\n",
       "      <td>1.446266</td>\n",
       "      <td>0.644684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.286485</td>\n",
       "      <td>1.046027</td>\n",
       "      <td>1.446266</td>\n",
       "      <td>0.644684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.286485</td>\n",
       "      <td>1.046027</td>\n",
       "      <td>1.446266</td>\n",
       "      <td>0.644684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.296821</td>\n",
       "      <td>0.812231</td>\n",
       "      <td>1.114083</td>\n",
       "      <td>0.263149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.296821</td>\n",
       "      <td>0.812231</td>\n",
       "      <td>1.114083</td>\n",
       "      <td>0.263149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.297232</td>\n",
       "      <td>0.715034</td>\n",
       "      <td>1.553619</td>\n",
       "      <td>0.537791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-15.310600</td>\n",
       "      <td>0.532864</td>\n",
       "      <td>1.635891</td>\n",
       "      <td>0.737486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.316579</td>\n",
       "      <td>0.614090</td>\n",
       "      <td>1.790771</td>\n",
       "      <td>0.589457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.317724</td>\n",
       "      <td>0.876693</td>\n",
       "      <td>1.633127</td>\n",
       "      <td>0.491902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.317724</td>\n",
       "      <td>0.876693</td>\n",
       "      <td>1.633127</td>\n",
       "      <td>0.491902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.323147</td>\n",
       "      <td>0.599094</td>\n",
       "      <td>1.558682</td>\n",
       "      <td>0.205121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.341702</td>\n",
       "      <td>1.005903</td>\n",
       "      <td>1.518495</td>\n",
       "      <td>0.495370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.342781</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.405281</td>\n",
       "      <td>0.846698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.342781</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.405281</td>\n",
       "      <td>0.846698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.342781</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.405281</td>\n",
       "      <td>0.846698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.342781</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.405281</td>\n",
       "      <td>0.846698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.342781</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.405281</td>\n",
       "      <td>0.846698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.342781</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>1.405281</td>\n",
       "      <td>0.846698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.343833</td>\n",
       "      <td>0.825703</td>\n",
       "      <td>1.288949</td>\n",
       "      <td>0.307974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.365885</td>\n",
       "      <td>0.911284</td>\n",
       "      <td>1.408965</td>\n",
       "      <td>0.843346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.365885</td>\n",
       "      <td>0.911284</td>\n",
       "      <td>1.408965</td>\n",
       "      <td>0.843346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.365885</td>\n",
       "      <td>0.911284</td>\n",
       "      <td>1.408965</td>\n",
       "      <td>0.843346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.427702</td>\n",
       "      <td>0.771185</td>\n",
       "      <td>1.673259</td>\n",
       "      <td>0.899976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.441692</td>\n",
       "      <td>0.768421</td>\n",
       "      <td>1.273264</td>\n",
       "      <td>0.333858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.445315</td>\n",
       "      <td>0.453442</td>\n",
       "      <td>1.665212</td>\n",
       "      <td>0.586285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.449159</td>\n",
       "      <td>0.949169</td>\n",
       "      <td>1.554354</td>\n",
       "      <td>0.397369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.449159</td>\n",
       "      <td>0.949169</td>\n",
       "      <td>1.554354</td>\n",
       "      <td>0.397369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.471312</td>\n",
       "      <td>1.105730</td>\n",
       "      <td>1.329749</td>\n",
       "      <td>0.760651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.473585</td>\n",
       "      <td>0.595878</td>\n",
       "      <td>1.621275</td>\n",
       "      <td>0.848718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.482158</td>\n",
       "      <td>0.916432</td>\n",
       "      <td>1.756796</td>\n",
       "      <td>0.488154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-15.488921</td>\n",
       "      <td>0.656808</td>\n",
       "      <td>1.612823</td>\n",
       "      <td>0.454986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.493992</td>\n",
       "      <td>0.829347</td>\n",
       "      <td>1.596899</td>\n",
       "      <td>0.183587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.493992</td>\n",
       "      <td>0.829347</td>\n",
       "      <td>1.596899</td>\n",
       "      <td>0.183587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.516266</td>\n",
       "      <td>1.013990</td>\n",
       "      <td>1.594378</td>\n",
       "      <td>0.284894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.522770</td>\n",
       "      <td>1.002188</td>\n",
       "      <td>1.585231</td>\n",
       "      <td>0.283891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.566805</td>\n",
       "      <td>0.370535</td>\n",
       "      <td>1.628011</td>\n",
       "      <td>0.729874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.571077</td>\n",
       "      <td>0.981514</td>\n",
       "      <td>1.253417</td>\n",
       "      <td>0.813390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.576276</td>\n",
       "      <td>0.819341</td>\n",
       "      <td>1.315368</td>\n",
       "      <td>0.547915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.578418</td>\n",
       "      <td>0.617410</td>\n",
       "      <td>1.537265</td>\n",
       "      <td>0.260680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.578418</td>\n",
       "      <td>0.617410</td>\n",
       "      <td>1.537265</td>\n",
       "      <td>0.260680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.582304</td>\n",
       "      <td>0.503208</td>\n",
       "      <td>1.735037</td>\n",
       "      <td>0.439502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.582304</td>\n",
       "      <td>0.503208</td>\n",
       "      <td>1.735037</td>\n",
       "      <td>0.439502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.585555</td>\n",
       "      <td>0.464161</td>\n",
       "      <td>1.652366</td>\n",
       "      <td>0.621364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.596291</td>\n",
       "      <td>0.875127</td>\n",
       "      <td>1.258505</td>\n",
       "      <td>0.473462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.625386</td>\n",
       "      <td>1.215780</td>\n",
       "      <td>1.903020</td>\n",
       "      <td>0.785655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.641681</td>\n",
       "      <td>0.938782</td>\n",
       "      <td>1.480730</td>\n",
       "      <td>0.715059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.644728</td>\n",
       "      <td>0.862487</td>\n",
       "      <td>1.239112</td>\n",
       "      <td>0.400611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.647153</td>\n",
       "      <td>0.772757</td>\n",
       "      <td>1.203317</td>\n",
       "      <td>0.498495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.651330</td>\n",
       "      <td>0.839351</td>\n",
       "      <td>1.222979</td>\n",
       "      <td>0.524445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.676861</td>\n",
       "      <td>0.844154</td>\n",
       "      <td>1.266276</td>\n",
       "      <td>0.541612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.683079</td>\n",
       "      <td>0.451228</td>\n",
       "      <td>1.646944</td>\n",
       "      <td>0.601647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.692485</td>\n",
       "      <td>0.479046</td>\n",
       "      <td>1.646088</td>\n",
       "      <td>0.641296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.695509</td>\n",
       "      <td>0.736713</td>\n",
       "      <td>1.220602</td>\n",
       "      <td>0.536193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.702014</td>\n",
       "      <td>0.479482</td>\n",
       "      <td>1.645195</td>\n",
       "      <td>0.644550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-15.703171</td>\n",
       "      <td>0.686705</td>\n",
       "      <td>1.870664</td>\n",
       "      <td>0.580683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.711770</td>\n",
       "      <td>0.479697</td>\n",
       "      <td>1.644211</td>\n",
       "      <td>0.647921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.717403</td>\n",
       "      <td>0.433359</td>\n",
       "      <td>1.477068</td>\n",
       "      <td>0.518233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.721652</td>\n",
       "      <td>0.479915</td>\n",
       "      <td>1.643190</td>\n",
       "      <td>0.651400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.726642</td>\n",
       "      <td>0.480025</td>\n",
       "      <td>1.642665</td>\n",
       "      <td>0.653181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.756324</td>\n",
       "      <td>0.862770</td>\n",
       "      <td>1.465436</td>\n",
       "      <td>0.498197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.757757</td>\n",
       "      <td>0.906183</td>\n",
       "      <td>1.449835</td>\n",
       "      <td>0.504568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-15.759420</td>\n",
       "      <td>0.628312</td>\n",
       "      <td>1.653050</td>\n",
       "      <td>0.306554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.770711</td>\n",
       "      <td>0.379718</td>\n",
       "      <td>1.649160</td>\n",
       "      <td>0.773752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.814137</td>\n",
       "      <td>0.880134</td>\n",
       "      <td>1.403305</td>\n",
       "      <td>0.926816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.814137</td>\n",
       "      <td>0.880134</td>\n",
       "      <td>1.403305</td>\n",
       "      <td>0.926816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.868020</td>\n",
       "      <td>1.085762</td>\n",
       "      <td>1.613130</td>\n",
       "      <td>0.737673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.892793</td>\n",
       "      <td>1.037427</td>\n",
       "      <td>1.620106</td>\n",
       "      <td>0.740869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.922137</td>\n",
       "      <td>0.355137</td>\n",
       "      <td>1.676821</td>\n",
       "      <td>0.752874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.935463</td>\n",
       "      <td>0.376880</td>\n",
       "      <td>1.676570</td>\n",
       "      <td>0.804460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.949159</td>\n",
       "      <td>0.377110</td>\n",
       "      <td>1.676293</td>\n",
       "      <td>0.810530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.951782</td>\n",
       "      <td>0.612863</td>\n",
       "      <td>1.919810</td>\n",
       "      <td>0.504847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.951782</td>\n",
       "      <td>0.612863</td>\n",
       "      <td>1.919810</td>\n",
       "      <td>0.504847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.957632</td>\n",
       "      <td>0.862715</td>\n",
       "      <td>1.448000</td>\n",
       "      <td>0.841786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.963234</td>\n",
       "      <td>0.377458</td>\n",
       "      <td>1.675954</td>\n",
       "      <td>0.816759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.975419</td>\n",
       "      <td>0.868106</td>\n",
       "      <td>1.356551</td>\n",
       "      <td>0.294098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.977744</td>\n",
       "      <td>0.377777</td>\n",
       "      <td>1.675611</td>\n",
       "      <td>0.823160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-15.985165</td>\n",
       "      <td>0.378035</td>\n",
       "      <td>1.675399</td>\n",
       "      <td>0.826423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-15.993580</td>\n",
       "      <td>0.847385</td>\n",
       "      <td>1.462758</td>\n",
       "      <td>0.829471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.012261</td>\n",
       "      <td>0.722220</td>\n",
       "      <td>1.635488</td>\n",
       "      <td>0.796402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.016241</td>\n",
       "      <td>1.332482</td>\n",
       "      <td>1.803060</td>\n",
       "      <td>0.935081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-16.028949</td>\n",
       "      <td>0.594089</td>\n",
       "      <td>1.627226</td>\n",
       "      <td>0.613465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.035008</td>\n",
       "      <td>0.864283</td>\n",
       "      <td>1.724087</td>\n",
       "      <td>0.892667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.055657</td>\n",
       "      <td>0.813965</td>\n",
       "      <td>1.654084</td>\n",
       "      <td>0.152844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.081521</td>\n",
       "      <td>1.012785</td>\n",
       "      <td>1.286851</td>\n",
       "      <td>0.423273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.081521</td>\n",
       "      <td>1.012785</td>\n",
       "      <td>1.286851</td>\n",
       "      <td>0.423273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.084939</td>\n",
       "      <td>0.531181</td>\n",
       "      <td>1.768826</td>\n",
       "      <td>0.759270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-16.085821</td>\n",
       "      <td>0.957257</td>\n",
       "      <td>1.783335</td>\n",
       "      <td>0.569083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.093150</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>1.535356</td>\n",
       "      <td>0.239322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.093150</td>\n",
       "      <td>0.659671</td>\n",
       "      <td>1.535356</td>\n",
       "      <td>0.239322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.098833</td>\n",
       "      <td>1.254934</td>\n",
       "      <td>1.517424</td>\n",
       "      <td>0.422574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.196501</td>\n",
       "      <td>1.035853</td>\n",
       "      <td>1.828494</td>\n",
       "      <td>0.695414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.211876</td>\n",
       "      <td>1.088028</td>\n",
       "      <td>1.937778</td>\n",
       "      <td>0.631208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.219640</td>\n",
       "      <td>0.682055</td>\n",
       "      <td>1.597572</td>\n",
       "      <td>0.459931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.225701</td>\n",
       "      <td>1.114798</td>\n",
       "      <td>1.961712</td>\n",
       "      <td>0.644122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-16.233574</td>\n",
       "      <td>0.678123</td>\n",
       "      <td>1.361489</td>\n",
       "      <td>0.620914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.242750</td>\n",
       "      <td>0.608479</td>\n",
       "      <td>1.456843</td>\n",
       "      <td>0.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.242750</td>\n",
       "      <td>0.608479</td>\n",
       "      <td>1.456843</td>\n",
       "      <td>0.615000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.256457</td>\n",
       "      <td>0.572066</td>\n",
       "      <td>1.231766</td>\n",
       "      <td>0.577253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.302043</td>\n",
       "      <td>0.791965</td>\n",
       "      <td>1.654658</td>\n",
       "      <td>0.765144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.306136</td>\n",
       "      <td>1.303322</td>\n",
       "      <td>1.844414</td>\n",
       "      <td>0.945169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.317490</td>\n",
       "      <td>0.742055</td>\n",
       "      <td>1.873105</td>\n",
       "      <td>0.606947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.321752</td>\n",
       "      <td>1.155120</td>\n",
       "      <td>1.523105</td>\n",
       "      <td>0.432678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.353227</td>\n",
       "      <td>0.844762</td>\n",
       "      <td>1.701752</td>\n",
       "      <td>0.686047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.364761</td>\n",
       "      <td>0.709763</td>\n",
       "      <td>1.356381</td>\n",
       "      <td>0.408189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.364761</td>\n",
       "      <td>0.709763</td>\n",
       "      <td>1.356381</td>\n",
       "      <td>0.408189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.375070</td>\n",
       "      <td>1.162139</td>\n",
       "      <td>1.424352</td>\n",
       "      <td>0.533490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.382482</td>\n",
       "      <td>1.199429</td>\n",
       "      <td>1.349173</td>\n",
       "      <td>0.483159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.411321</td>\n",
       "      <td>0.772335</td>\n",
       "      <td>1.065237</td>\n",
       "      <td>0.438450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.415949</td>\n",
       "      <td>0.924026</td>\n",
       "      <td>1.938088</td>\n",
       "      <td>0.693135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.415949</td>\n",
       "      <td>0.924026</td>\n",
       "      <td>1.938088</td>\n",
       "      <td>0.693135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-16.434366</td>\n",
       "      <td>0.660536</td>\n",
       "      <td>1.533380</td>\n",
       "      <td>0.536250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.435157</td>\n",
       "      <td>0.768432</td>\n",
       "      <td>1.415383</td>\n",
       "      <td>0.472159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-16.438505</td>\n",
       "      <td>0.727470</td>\n",
       "      <td>1.628532</td>\n",
       "      <td>0.700823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.448446</td>\n",
       "      <td>0.778888</td>\n",
       "      <td>1.670160</td>\n",
       "      <td>0.714134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.451002</td>\n",
       "      <td>1.593205</td>\n",
       "      <td>1.577315</td>\n",
       "      <td>0.706990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.478661</td>\n",
       "      <td>0.834999</td>\n",
       "      <td>1.671467</td>\n",
       "      <td>0.755199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.501690</td>\n",
       "      <td>0.627764</td>\n",
       "      <td>1.571158</td>\n",
       "      <td>0.337245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-16.501702</td>\n",
       "      <td>0.988884</td>\n",
       "      <td>1.591740</td>\n",
       "      <td>0.406232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.510118</td>\n",
       "      <td>0.843600</td>\n",
       "      <td>1.672680</td>\n",
       "      <td>0.752507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-16.525208</td>\n",
       "      <td>1.029810</td>\n",
       "      <td>1.583101</td>\n",
       "      <td>0.400803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.542260</td>\n",
       "      <td>0.852497</td>\n",
       "      <td>1.673962</td>\n",
       "      <td>0.749849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.559706</td>\n",
       "      <td>0.739310</td>\n",
       "      <td>1.767253</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.574999</td>\n",
       "      <td>0.861830</td>\n",
       "      <td>1.675410</td>\n",
       "      <td>0.747304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.589510</td>\n",
       "      <td>1.106751</td>\n",
       "      <td>1.843397</td>\n",
       "      <td>0.427901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.591600</td>\n",
       "      <td>0.866670</td>\n",
       "      <td>1.676204</td>\n",
       "      <td>0.746081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.603556</td>\n",
       "      <td>1.162980</td>\n",
       "      <td>1.909123</td>\n",
       "      <td>0.461458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.617448</td>\n",
       "      <td>0.673871</td>\n",
       "      <td>1.729257</td>\n",
       "      <td>0.236396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 3, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.631280</td>\n",
       "      <td>0.602288</td>\n",
       "      <td>1.419480</td>\n",
       "      <td>0.357871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.635043</td>\n",
       "      <td>0.965110</td>\n",
       "      <td>1.384577</td>\n",
       "      <td>0.656289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.732381</td>\n",
       "      <td>0.712375</td>\n",
       "      <td>1.397892</td>\n",
       "      <td>0.287088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.820251</td>\n",
       "      <td>0.869905</td>\n",
       "      <td>1.707610</td>\n",
       "      <td>0.905179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-16.868172</td>\n",
       "      <td>1.612000</td>\n",
       "      <td>1.481960</td>\n",
       "      <td>0.731246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.883601</td>\n",
       "      <td>0.968037</td>\n",
       "      <td>2.018741</td>\n",
       "      <td>0.464753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.918688</td>\n",
       "      <td>0.749117</td>\n",
       "      <td>1.704717</td>\n",
       "      <td>0.837605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-16.936696</td>\n",
       "      <td>0.734401</td>\n",
       "      <td>1.699453</td>\n",
       "      <td>0.843836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.035998</td>\n",
       "      <td>0.586187</td>\n",
       "      <td>1.509201</td>\n",
       "      <td>0.453982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.051786</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>2.066876</td>\n",
       "      <td>0.619894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.051786</td>\n",
       "      <td>0.912118</td>\n",
       "      <td>2.066876</td>\n",
       "      <td>0.619894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.090373</td>\n",
       "      <td>0.957110</td>\n",
       "      <td>2.040680</td>\n",
       "      <td>0.205853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.131144</td>\n",
       "      <td>0.687649</td>\n",
       "      <td>2.434511</td>\n",
       "      <td>0.489415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.164020</td>\n",
       "      <td>0.976971</td>\n",
       "      <td>1.808930</td>\n",
       "      <td>0.573385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-17.218284</td>\n",
       "      <td>1.257193</td>\n",
       "      <td>1.792544</td>\n",
       "      <td>0.772407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.226926</td>\n",
       "      <td>0.851007</td>\n",
       "      <td>1.465547</td>\n",
       "      <td>0.339050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-17.268859</td>\n",
       "      <td>0.581968</td>\n",
       "      <td>1.656484</td>\n",
       "      <td>0.596989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.278518</td>\n",
       "      <td>0.847441</td>\n",
       "      <td>1.687216</td>\n",
       "      <td>0.924378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.359123</td>\n",
       "      <td>0.982202</td>\n",
       "      <td>1.514130</td>\n",
       "      <td>0.313930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.380954</td>\n",
       "      <td>0.747912</td>\n",
       "      <td>1.691561</td>\n",
       "      <td>0.591556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-17.386588</td>\n",
       "      <td>1.207607</td>\n",
       "      <td>1.616769</td>\n",
       "      <td>0.952499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.387246</td>\n",
       "      <td>0.977390</td>\n",
       "      <td>1.526668</td>\n",
       "      <td>0.324177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.390728</td>\n",
       "      <td>0.741278</td>\n",
       "      <td>1.678092</td>\n",
       "      <td>0.585192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.428913</td>\n",
       "      <td>1.070472</td>\n",
       "      <td>1.665762</td>\n",
       "      <td>0.694950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.428913</td>\n",
       "      <td>1.070472</td>\n",
       "      <td>1.665762</td>\n",
       "      <td>0.694950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.431154</td>\n",
       "      <td>0.819794</td>\n",
       "      <td>1.963242</td>\n",
       "      <td>0.889167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.436885</td>\n",
       "      <td>1.274202</td>\n",
       "      <td>1.826508</td>\n",
       "      <td>0.376614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.474328</td>\n",
       "      <td>1.006668</td>\n",
       "      <td>1.887718</td>\n",
       "      <td>0.481067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.504879</td>\n",
       "      <td>1.695807</td>\n",
       "      <td>1.935382</td>\n",
       "      <td>0.501346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.527663</td>\n",
       "      <td>0.787723</td>\n",
       "      <td>1.679874</td>\n",
       "      <td>0.885880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.529987</td>\n",
       "      <td>0.694092</td>\n",
       "      <td>1.245008</td>\n",
       "      <td>0.710417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.529987</td>\n",
       "      <td>0.694092</td>\n",
       "      <td>1.245008</td>\n",
       "      <td>0.710417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-17.537306</td>\n",
       "      <td>1.075159</td>\n",
       "      <td>1.777880</td>\n",
       "      <td>0.702219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.560592</td>\n",
       "      <td>1.000711</td>\n",
       "      <td>1.874042</td>\n",
       "      <td>0.496646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.571486</td>\n",
       "      <td>0.833009</td>\n",
       "      <td>1.677213</td>\n",
       "      <td>0.940292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.616180</td>\n",
       "      <td>0.830272</td>\n",
       "      <td>1.674538</td>\n",
       "      <td>0.941080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.633317</td>\n",
       "      <td>0.771950</td>\n",
       "      <td>2.009609</td>\n",
       "      <td>0.853590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.661936</td>\n",
       "      <td>0.827106</td>\n",
       "      <td>1.672106</td>\n",
       "      <td>0.941727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.699330</td>\n",
       "      <td>0.568688</td>\n",
       "      <td>1.424970</td>\n",
       "      <td>0.479878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.699330</td>\n",
       "      <td>0.568688</td>\n",
       "      <td>1.424970</td>\n",
       "      <td>0.479878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.708622</td>\n",
       "      <td>0.823663</td>\n",
       "      <td>1.669677</td>\n",
       "      <td>0.942444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.717476</td>\n",
       "      <td>0.717336</td>\n",
       "      <td>1.834599</td>\n",
       "      <td>0.533054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.732316</td>\n",
       "      <td>0.821842</td>\n",
       "      <td>1.668450</td>\n",
       "      <td>0.942849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.742976</td>\n",
       "      <td>0.582044</td>\n",
       "      <td>1.724073</td>\n",
       "      <td>0.770470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.769481</td>\n",
       "      <td>0.793345</td>\n",
       "      <td>2.421558</td>\n",
       "      <td>0.892192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.906184</td>\n",
       "      <td>0.845428</td>\n",
       "      <td>2.118054</td>\n",
       "      <td>0.495566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.914120</td>\n",
       "      <td>1.685081</td>\n",
       "      <td>1.823480</td>\n",
       "      <td>0.437525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.942547</td>\n",
       "      <td>1.055427</td>\n",
       "      <td>1.499495</td>\n",
       "      <td>0.685262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-17.943135</td>\n",
       "      <td>1.025777</td>\n",
       "      <td>1.498396</td>\n",
       "      <td>0.691412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-17.998284</td>\n",
       "      <td>0.768171</td>\n",
       "      <td>2.080412</td>\n",
       "      <td>0.545136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-18.003816</td>\n",
       "      <td>1.079723</td>\n",
       "      <td>1.665802</td>\n",
       "      <td>0.999528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.059695</td>\n",
       "      <td>0.857721</td>\n",
       "      <td>1.234456</td>\n",
       "      <td>0.603841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.062395</td>\n",
       "      <td>0.647425</td>\n",
       "      <td>1.613915</td>\n",
       "      <td>0.687550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-18.066689</td>\n",
       "      <td>1.207958</td>\n",
       "      <td>1.706387</td>\n",
       "      <td>0.735711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.067954</td>\n",
       "      <td>0.868183</td>\n",
       "      <td>1.243999</td>\n",
       "      <td>0.595233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-18.078626</td>\n",
       "      <td>1.009441</td>\n",
       "      <td>1.486365</td>\n",
       "      <td>0.764814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-18.090010</td>\n",
       "      <td>1.295749</td>\n",
       "      <td>1.787574</td>\n",
       "      <td>0.650123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-18.160115</td>\n",
       "      <td>0.990788</td>\n",
       "      <td>1.438262</td>\n",
       "      <td>0.715940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-18.241958</td>\n",
       "      <td>0.493520</td>\n",
       "      <td>1.752967</td>\n",
       "      <td>0.733921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-18.283933</td>\n",
       "      <td>0.791997</td>\n",
       "      <td>1.700869</td>\n",
       "      <td>0.535537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-18.283933</td>\n",
       "      <td>0.791997</td>\n",
       "      <td>1.700869</td>\n",
       "      <td>0.535537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.533914</td>\n",
       "      <td>0.786048</td>\n",
       "      <td>1.330986</td>\n",
       "      <td>0.340053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-18.547615</td>\n",
       "      <td>0.407578</td>\n",
       "      <td>1.959275</td>\n",
       "      <td>0.447805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.548992</td>\n",
       "      <td>0.843109</td>\n",
       "      <td>1.303237</td>\n",
       "      <td>0.344495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-18.585372</td>\n",
       "      <td>1.861952</td>\n",
       "      <td>1.720160</td>\n",
       "      <td>0.383298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-18.585480</td>\n",
       "      <td>0.661270</td>\n",
       "      <td>1.874513</td>\n",
       "      <td>0.324299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-18.605421</td>\n",
       "      <td>0.946930</td>\n",
       "      <td>1.608536</td>\n",
       "      <td>0.813654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 5, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-18.608007</td>\n",
       "      <td>1.035790</td>\n",
       "      <td>1.699386</td>\n",
       "      <td>0.638824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.620045</td>\n",
       "      <td>1.082847</td>\n",
       "      <td>1.970890</td>\n",
       "      <td>0.451166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 5, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-18.688437</td>\n",
       "      <td>1.622359</td>\n",
       "      <td>1.520417</td>\n",
       "      <td>0.620952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-18.842432</td>\n",
       "      <td>1.208211</td>\n",
       "      <td>2.050897</td>\n",
       "      <td>0.409013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-18.929596</td>\n",
       "      <td>0.321734</td>\n",
       "      <td>1.788536</td>\n",
       "      <td>0.840365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-19.039828</td>\n",
       "      <td>0.349363</td>\n",
       "      <td>1.792571</td>\n",
       "      <td>0.923235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-19.155284</td>\n",
       "      <td>0.359472</td>\n",
       "      <td>1.797042</td>\n",
       "      <td>0.958061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-19.156320</td>\n",
       "      <td>0.753011</td>\n",
       "      <td>1.921632</td>\n",
       "      <td>0.918013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.237648</td>\n",
       "      <td>0.927945</td>\n",
       "      <td>1.876650</td>\n",
       "      <td>0.506985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-19.245861</td>\n",
       "      <td>0.877239</td>\n",
       "      <td>1.887787</td>\n",
       "      <td>1.001791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-19.277962</td>\n",
       "      <td>0.370622</td>\n",
       "      <td>1.801562</td>\n",
       "      <td>0.996839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-19.408401</td>\n",
       "      <td>0.385234</td>\n",
       "      <td>1.807124</td>\n",
       "      <td>1.040783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.426769</td>\n",
       "      <td>1.003124</td>\n",
       "      <td>1.767158</td>\n",
       "      <td>0.517802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-19.476451</td>\n",
       "      <td>0.394176</td>\n",
       "      <td>1.810239</td>\n",
       "      <td>1.064277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5}</th>\n",
       "      <td>-19.531707</td>\n",
       "      <td>0.638543</td>\n",
       "      <td>1.606231</td>\n",
       "      <td>0.272949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-19.588130</td>\n",
       "      <td>1.474421</td>\n",
       "      <td>1.357039</td>\n",
       "      <td>0.396787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.621769</td>\n",
       "      <td>1.117166</td>\n",
       "      <td>1.777179</td>\n",
       "      <td>0.856665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-19.675963</td>\n",
       "      <td>1.250930</td>\n",
       "      <td>1.918461</td>\n",
       "      <td>0.396679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-20.064699</td>\n",
       "      <td>2.154508</td>\n",
       "      <td>2.046818</td>\n",
       "      <td>0.713829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-20.174183</td>\n",
       "      <td>0.976596</td>\n",
       "      <td>1.854429</td>\n",
       "      <td>0.690242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-20.298584</td>\n",
       "      <td>0.893345</td>\n",
       "      <td>1.932317</td>\n",
       "      <td>0.627542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 10, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 5, 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-20.468223</td>\n",
       "      <td>2.193442</td>\n",
       "      <td>1.714668</td>\n",
       "      <td>0.719073</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SST_SSD</td>\n",
       "      <td>2.954679</td>\n",
       "      <td>0.075478</td>\n",
       "      <td>0.075478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>PLAN_temporal_orientation</td>\n",
       "      <td>1.659464</td>\n",
       "      <td>0.027706</td>\n",
       "      <td>0.027706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>-1.461655</td>\n",
       "      <td>0.020850</td>\n",
       "      <td>0.020850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>-1.496412</td>\n",
       "      <td>0.020235</td>\n",
       "      <td>0.020235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>1.436593</td>\n",
       "      <td>0.016443</td>\n",
       "      <td>0.016443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:918: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV280', 'DEV032', 'DEV022', 'DEV002', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(244, 44)\n",
      "(244, 44)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 2 predictors in the set condition_only\n",
      "predictors in that set are mckenzie willamette\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dbc67a0>], 'feature_selection__k': [2], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [2], 'feature_selection__step': [5], 'estimator__max_depth': [2], 'estimator__min_samples_split': [2], 'estimator__min_samples_leaf': [2]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "scores:\n",
      "[-0.02816292614492455, -0.10622789554194778, -0.038794715664683954, 0.007465645504230567, -0.05825767865334597]\n",
      "overall_score:\n",
      "-0.04479551410013434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-13.520285</td>\n",
       "      <td>0.438664</td>\n",
       "      <td>1.758824</td>\n",
       "      <td>0.513103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.520285</td>\n",
       "      <td>0.438664</td>\n",
       "      <td>1.758824</td>\n",
       "      <td>0.513103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.520285</td>\n",
       "      <td>0.438664</td>\n",
       "      <td>1.758824</td>\n",
       "      <td>0.513103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-13.521211</td>\n",
       "      <td>0.465719</td>\n",
       "      <td>1.758850</td>\n",
       "      <td>0.538238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.521211</td>\n",
       "      <td>0.465719</td>\n",
       "      <td>1.758850</td>\n",
       "      <td>0.538238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.521211</td>\n",
       "      <td>0.465719</td>\n",
       "      <td>1.758850</td>\n",
       "      <td>0.538238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-13.527433</td>\n",
       "      <td>0.468469</td>\n",
       "      <td>1.755259</td>\n",
       "      <td>0.531840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.527433</td>\n",
       "      <td>0.468469</td>\n",
       "      <td>1.755259</td>\n",
       "      <td>0.531840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.527433</td>\n",
       "      <td>0.468469</td>\n",
       "      <td>1.755259</td>\n",
       "      <td>0.531840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.540753</td>\n",
       "      <td>0.472058</td>\n",
       "      <td>1.755913</td>\n",
       "      <td>0.527193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.540753</td>\n",
       "      <td>0.472058</td>\n",
       "      <td>1.755913</td>\n",
       "      <td>0.527193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-13.540753</td>\n",
       "      <td>0.472058</td>\n",
       "      <td>1.755913</td>\n",
       "      <td>0.527193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-13.560584</td>\n",
       "      <td>0.481149</td>\n",
       "      <td>1.760704</td>\n",
       "      <td>0.521050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.560584</td>\n",
       "      <td>0.481149</td>\n",
       "      <td>1.760704</td>\n",
       "      <td>0.521050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.560584</td>\n",
       "      <td>0.481149</td>\n",
       "      <td>1.760704</td>\n",
       "      <td>0.521050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.572059</td>\n",
       "      <td>0.487354</td>\n",
       "      <td>1.764125</td>\n",
       "      <td>0.521538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-13.572059</td>\n",
       "      <td>0.487354</td>\n",
       "      <td>1.764125</td>\n",
       "      <td>0.521538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.572059</td>\n",
       "      <td>0.487354</td>\n",
       "      <td>1.764125</td>\n",
       "      <td>0.521538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-13.582890</td>\n",
       "      <td>0.459661</td>\n",
       "      <td>1.767781</td>\n",
       "      <td>0.491189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.582890</td>\n",
       "      <td>0.459661</td>\n",
       "      <td>1.767781</td>\n",
       "      <td>0.491189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.582890</td>\n",
       "      <td>0.459661</td>\n",
       "      <td>1.767781</td>\n",
       "      <td>0.491189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-13.583753</td>\n",
       "      <td>0.487927</td>\n",
       "      <td>1.767809</td>\n",
       "      <td>0.520635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.583753</td>\n",
       "      <td>0.487927</td>\n",
       "      <td>1.767809</td>\n",
       "      <td>0.520635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.583753</td>\n",
       "      <td>0.487927</td>\n",
       "      <td>1.767809</td>\n",
       "      <td>0.520635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-13.584621</td>\n",
       "      <td>0.488312</td>\n",
       "      <td>1.767839</td>\n",
       "      <td>0.520283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.584621</td>\n",
       "      <td>0.488312</td>\n",
       "      <td>1.767839</td>\n",
       "      <td>0.520283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.584621</td>\n",
       "      <td>0.488312</td>\n",
       "      <td>1.767839</td>\n",
       "      <td>0.520283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.585496</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>1.767872</td>\n",
       "      <td>0.519930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-13.585496</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>1.767872</td>\n",
       "      <td>0.519930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.585496</td>\n",
       "      <td>0.488700</td>\n",
       "      <td>1.767872</td>\n",
       "      <td>0.519930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-13.586376</td>\n",
       "      <td>0.489092</td>\n",
       "      <td>1.767907</td>\n",
       "      <td>0.519574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.586376</td>\n",
       "      <td>0.489092</td>\n",
       "      <td>1.767907</td>\n",
       "      <td>0.519574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.586376</td>\n",
       "      <td>0.489092</td>\n",
       "      <td>1.767907</td>\n",
       "      <td>0.519574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.586819</td>\n",
       "      <td>0.489289</td>\n",
       "      <td>1.767926</td>\n",
       "      <td>0.519396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.586819</td>\n",
       "      <td>0.489289</td>\n",
       "      <td>1.767926</td>\n",
       "      <td>0.519396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-13.586819</td>\n",
       "      <td>0.489289</td>\n",
       "      <td>1.767926</td>\n",
       "      <td>0.519396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__n_features_to_select': 2, 'feature_selection__step': 5}</th>\n",
       "      <td>-13.587263</td>\n",
       "      <td>0.489487</td>\n",
       "      <td>1.767945</td>\n",
       "      <td>0.519217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2, 'feature_selection__k': 2, 'feature_selection__score_func': &lt;function f_regression at 0x17dbc67a0&gt;}</th>\n",
       "      <td>-13.587263</td>\n",
       "      <td>0.489487</td>\n",
       "      <td>1.767945</td>\n",
       "      <td>0.519217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 2, 'estimator__min_samples_split': 2}</th>\n",
       "      <td>-13.587263</td>\n",
       "      <td>0.489487</td>\n",
       "      <td>1.767945</td>\n",
       "      <td>0.519217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>willamette</td>\n",
       "      <td>0.925242</td>\n",
       "      <td>0.012714</td>\n",
       "      <td>0.012714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mckenzie</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_inddiff_interactions': -0.020733343655307566, 'condition_inddiff': -0.21215536349278832, 'condition_only': -0.04479551410013434}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'NUTRIENT_DENSITY_2wkAverage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
