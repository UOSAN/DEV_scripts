{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from dev_interaction_util import *\n",
    "from DevCvAnalysis import DevCvAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"config.yml\") \n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic structure is the following:\n",
    "\n",
    "1. Run the following cross-validated analyses:\n",
    "   1. Predicting change by condition only\n",
    "   2. Predicting change by condition and neural and behavioral measures\n",
    "   3. Predicting change by condition, neural and behavioral measures, and their interactions\n",
    "2. Measure the predictivity of the three models above using anova\n",
    "3. Repeat the steps above separately for three outcome variables, change in: FFQ, ASA-24, and BFP\n",
    "4. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tasks to do to get this job done (not in order):\n",
    "\n",
    "1. Write the analysis pipeline above\n",
    "2. Get the neural data\n",
    "3. Get the behavioral data\n",
    "\n",
    "\n",
    "We have the behavioral data. Do we have the neural data already?\n",
    "\n",
    "What could we delegate here? Behavioral data we already have. We have mostly writen the analysis pipeline. The neural data could be passed on."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from InterventionCVManager import *\n",
    "\n",
    "dropbox_data_dir = config['dropbox_data_dir']\n",
    "\n",
    "icvm = InterventionCVManager(dropbox_data_dir)\n",
    "#icvm.mode = 'fast_pipeline_test'\n",
    "icvm.mode = 'full_analysis'\n",
    "#icvm.mode = 'full_pipeline_test'\n",
    "icvm.group_mode = 'dichotomous'\n",
    "#dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "dev_cv_analysis = icvm.get_prepopulated_dev_cv_analysis(set_as_random=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict change"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up sets of variables to run"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up a function that loops runs the scoring loop above (which does one cross-validation analysis), and the nadditionally:\n",
    "- selects the best model based on the overall results\n",
    "- Runs a final fit\n",
    "- presents model results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we include functions that compare models with and without individual differences and interactions."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should manually verify that in the following list, the intervention_group allocations are randomized (if we're running a test run) or that they are accurate (if it's not a test run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SID</th>\n",
       "      <th>intervention_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DEV004</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DEV005</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DEV008</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DEV009</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DEV010</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>DEV308</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>DEV309</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DEV310</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>DEV311</td>\n",
       "      <td>control</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>DEV312</td>\n",
       "      <td>intervention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>243 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SID intervention_group\n",
       "0    DEV004       intervention\n",
       "1    DEV005       intervention\n",
       "2    DEV008       intervention\n",
       "3    DEV009       intervention\n",
       "4    DEV010       intervention\n",
       "..      ...                ...\n",
       "238  DEV308            control\n",
       "239  DEV309       intervention\n",
       "240  DEV310       intervention\n",
       "241  DEV311            control\n",
       "242  DEV312       intervention\n",
       "\n",
       "[243 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([\n",
    "    dev_cv_analysis.outcome_measures['SID'],\n",
    "      dev_cv_analysis.group_assignments\n",
    "],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition_cols = dev_cv_analysis.group_assignment_onehots.columns.tolist()\n",
    "inddiff_cols = dev_cv_analysis.get_predictors_main_names()\n",
    "\n",
    "interaction_cols = [id + \"*\" + cond for id in inddiff_cols for cond in condition_cols]\n",
    "\n",
    "predictor_sets = {\n",
    "    'condition_only': condition_cols,\n",
    "    'condition_inddiff': condition_cols + inddiff_cols,\n",
    "    'condition_inddiff_interactions': condition_cols + inddiff_cols + interaction_cols\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "# outcome_vars_to_try = [ 'bf','cancer_promoting_FFQ',\n",
    "#        'NUTRIENT_DENSITY_2wkAverage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDM, BIS_11, PCS, ACES_sum, BFI_agreeableness, BFI_conscientiousness, BFI_extraversion, BFI_neuroticism, BFI_openness, NCS_total, TESQ_E_sum, SRHI_healthy_minus_unhealthy, RTFS_f1_minus_f2, cancer_promoting_minus_preventing_FCI, age365, education_own, household_income_per_person, SST_PostErrorSlowW1_mean, SST_mean_ssrt_0, ROC_Crave_Regulate_Minus_Look, ROC_Crave_Minus_Neutral, WTP_unhealthy_minus_healthy, wtp_liked_value_association-test_z_FDR_0.01, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01, roc_reappraiseCrave_multivariate_regulation, sst_CorrectGo_striatum_joint_mask, sst_FailedStop_motor_control_striatum_joint_mask, sst_CorrectGoFollowingFailedStop_striatum_joint_mask, Planning_aggregate, Restraint_aggregate, IMI_effort_importance_aggregate, wtp_roc_koban_kober_craving_combined, birthsex_factor_Male, intervention, EDM*intervention, BIS_11*intervention, PCS*intervention, ACES_sum*intervention, BFI_agreeableness*intervention, BFI_conscientiousness*intervention, BFI_extraversion*intervention, BFI_neuroticism*intervention, BFI_openness*intervention, NCS_total*intervention, TESQ_E_sum*intervention, SRHI_healthy_minus_unhealthy*intervention, RTFS_f1_minus_f2*intervention, cancer_promoting_minus_preventing_FCI*intervention, age365*intervention, education_own*intervention, household_income_per_person*intervention, SST_PostErrorSlowW1_mean*intervention, SST_mean_ssrt_0*intervention, ROC_Crave_Regulate_Minus_Look*intervention, ROC_Crave_Minus_Neutral*intervention, WTP_unhealthy_minus_healthy*intervention, wtp_liked_value_association-test_z_FDR_0.01*intervention, roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*intervention, roc_reappraiseCrave_multivariate_regulation*intervention, sst_CorrectGo_striatum_joint_mask*intervention, sst_FailedStop_motor_control_striatum_joint_mask*intervention, sst_CorrectGoFollowingFailedStop_striatum_joint_mask*intervention, Planning_aggregate*intervention, Restraint_aggregate*intervention, IMI_effort_importance_aggregate*intervention, wtp_roc_koban_kober_craving_combined*intervention, birthsex_factor_Male*intervention\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.get_predictor_data().columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SID, bf, NUTRIENT_DENSITY_2wkAverage, ANTINUTRIENT_DENSITY_2wkAverage, total_calorie\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(dev_cv_analysis.outcome_measures.columns))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Body Fat Percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict bf with 1 predictors in the set condition_only\n",
      "predictors in that set are intervention\n",
      "outer split0\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.07 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.07 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.34 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.51 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.01 seconds\n",
      "outer split1\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.08 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.34 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.52 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.01 seconds\n",
      "outer split2\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.34 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.52 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.01 seconds\n",
      "outer split3\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.35 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.52 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.01 seconds\n",
      "outer split4\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.34 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.51 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.01 seconds\n",
      "scores:\n",
      "[-0.0005645032023542385, -0.016659582514766846, -0.00017421390410321536, -0.13755914911158196, -0.021304541260803722]\n",
      "overall_score:\n",
      "-0.035252397998722\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.025953</td>\n",
       "      <td>0.026478</td>\n",
       "      <td>0.028637</td>\n",
       "      <td>0.036459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.026091</td>\n",
       "      <td>0.027368</td>\n",
       "      <td>0.029092</td>\n",
       "      <td>0.038126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.026138</td>\n",
       "      <td>0.026555</td>\n",
       "      <td>0.028680</td>\n",
       "      <td>0.036377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.026216</td>\n",
       "      <td>0.023719</td>\n",
       "      <td>0.027190</td>\n",
       "      <td>0.029904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.026292</td>\n",
       "      <td>0.023901</td>\n",
       "      <td>0.027293</td>\n",
       "      <td>0.030120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.026293</td>\n",
       "      <td>0.023906</td>\n",
       "      <td>0.027295</td>\n",
       "      <td>0.030125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.026939</td>\n",
       "      <td>0.025455</td>\n",
       "      <td>0.028087</td>\n",
       "      <td>0.031845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027117</td>\n",
       "      <td>0.025859</td>\n",
       "      <td>0.028303</td>\n",
       "      <td>0.032291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027138</td>\n",
       "      <td>0.025907</td>\n",
       "      <td>0.028328</td>\n",
       "      <td>0.032343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027190</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>0.030281</td>\n",
       "      <td>0.035773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027241</td>\n",
       "      <td>0.026873</td>\n",
       "      <td>0.030338</td>\n",
       "      <td>0.035977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027242</td>\n",
       "      <td>0.026875</td>\n",
       "      <td>0.030340</td>\n",
       "      <td>0.035981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.027283</td>\n",
       "      <td>0.030134</td>\n",
       "      <td>0.031193</td>\n",
       "      <td>0.043005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.027554</td>\n",
       "      <td>0.030044</td>\n",
       "      <td>0.031564</td>\n",
       "      <td>0.042845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027748</td>\n",
       "      <td>0.027719</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.037593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027885</td>\n",
       "      <td>0.027932</td>\n",
       "      <td>0.030939</td>\n",
       "      <td>0.038009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.027901</td>\n",
       "      <td>0.027956</td>\n",
       "      <td>0.030955</td>\n",
       "      <td>0.038058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.028301</td>\n",
       "      <td>0.029822</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.042420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.028378</td>\n",
       "      <td>0.028570</td>\n",
       "      <td>0.029806</td>\n",
       "      <td>0.035231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.028635</td>\n",
       "      <td>0.025161</td>\n",
       "      <td>0.029778</td>\n",
       "      <td>0.035070</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intervention</td>\n",
       "      <td>7.806256e-18</td>\n",
       "      <td>-6.661338e-17</td>\n",
       "      <td>6.661338e-17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict bf with 34 predictors in the set condition_inddiff\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.52 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 29.93 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 50.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 25.07 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 14.76 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.31 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 27.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 42.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 26.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 31.22 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.68 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.15 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 25.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 49.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 33.23 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 28.23 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.20 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 24.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 44.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 19.71 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 14.68 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.86 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 7.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 35.91 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 41.00 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 19.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 14.37 seconds\n",
      "scores:\n",
      "[0.0006565241427106683, -0.016531804648642456, -0.10669230362966808, -0.17204921516032856, -0.005814070305403485]\n",
      "overall_score:\n",
      "-0.060086173920266384\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.022695</td>\n",
       "      <td>0.025695</td>\n",
       "      <td>0.028084</td>\n",
       "      <td>0.035080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.022809</td>\n",
       "      <td>0.030229</td>\n",
       "      <td>0.037948</td>\n",
       "      <td>0.038396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.023150</td>\n",
       "      <td>0.028237</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.040724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.023525</td>\n",
       "      <td>0.026757</td>\n",
       "      <td>0.029202</td>\n",
       "      <td>0.036075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.023756</td>\n",
       "      <td>0.028436</td>\n",
       "      <td>0.029813</td>\n",
       "      <td>0.039436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024198</td>\n",
       "      <td>0.029886</td>\n",
       "      <td>0.031509</td>\n",
       "      <td>0.042141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024312</td>\n",
       "      <td>0.029804</td>\n",
       "      <td>0.031941</td>\n",
       "      <td>0.041430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024321</td>\n",
       "      <td>0.027325</td>\n",
       "      <td>0.031669</td>\n",
       "      <td>0.034925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024332</td>\n",
       "      <td>0.027957</td>\n",
       "      <td>0.029001</td>\n",
       "      <td>0.038101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024698</td>\n",
       "      <td>0.029302</td>\n",
       "      <td>0.030741</td>\n",
       "      <td>0.040460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024833</td>\n",
       "      <td>0.030607</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>0.041997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024869</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>0.029439</td>\n",
       "      <td>0.037928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024950</td>\n",
       "      <td>0.032661</td>\n",
       "      <td>0.035084</td>\n",
       "      <td>0.042361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024985</td>\n",
       "      <td>0.035032</td>\n",
       "      <td>0.034355</td>\n",
       "      <td>0.046341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.025008</td>\n",
       "      <td>0.030227</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.041937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.025016</td>\n",
       "      <td>0.028734</td>\n",
       "      <td>0.028941</td>\n",
       "      <td>0.038467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.025062</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.029889</td>\n",
       "      <td>0.040215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.025209</td>\n",
       "      <td>0.035840</td>\n",
       "      <td>0.039424</td>\n",
       "      <td>0.039079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.025430</td>\n",
       "      <td>0.028901</td>\n",
       "      <td>0.029487</td>\n",
       "      <td>0.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.025545</td>\n",
       "      <td>0.027299</td>\n",
       "      <td>0.030235</td>\n",
       "      <td>0.038362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sst_CorrectGoFollowingFailedStop_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.004959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sst_CorrectGo_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.004638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>household_income_per_person</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003514</td>\n",
       "      <td>0.003514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>0.003099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_conscientiousness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002579</td>\n",
       "      <td>0.002579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>0.002230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002081</td>\n",
       "      <td>0.002081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.001232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict bf with 67 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*intervention BIS_11*intervention PCS*intervention ACES_sum*intervention BFI_agreeableness*intervention BFI_conscientiousness*intervention BFI_extraversion*intervention BFI_neuroticism*intervention BFI_openness*intervention NCS_total*intervention TESQ_E_sum*intervention SRHI_healthy_minus_unhealthy*intervention RTFS_f1_minus_f2*intervention cancer_promoting_minus_preventing_FCI*intervention age365*intervention education_own*intervention household_income_per_person*intervention SST_PostErrorSlowW1_mean*intervention SST_mean_ssrt_0*intervention ROC_Crave_Regulate_Minus_Look*intervention ROC_Crave_Minus_Neutral*intervention WTP_unhealthy_minus_healthy*intervention wtp_liked_value_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_multivariate_regulation*intervention sst_CorrectGo_striatum_joint_mask*intervention sst_FailedStop_motor_control_striatum_joint_mask*intervention sst_CorrectGoFollowingFailedStop_striatum_joint_mask*intervention Planning_aggregate*intervention Restraint_aggregate*intervention IMI_effort_importance_aggregate*intervention wtp_roc_koban_kober_craving_combined*intervention birthsex_factor_Male*intervention\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 25.15 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 28.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 96.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 166.77 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 161.89 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 166.08 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 23.23 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 22.28 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 93.78 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 160.17 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 151.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 138.57 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 21.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 19.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 65.81 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 124.14 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 236.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 210.72 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 33.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 31.17 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 94.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 149.90 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 242.66 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 242.43 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 85.32 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 55.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 101.31 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 183.73 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 218.14 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 223.79 seconds\n",
      "scores:\n",
      "[-0.03722671440017167, 0.01717248657741599, -0.00768199004631831, -0.15598466674058242, -0.035895198619679825]\n",
      "overall_score:\n",
      "-0.04392321664586725\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.020974</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.036341</td>\n",
       "      <td>0.039054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.022089</td>\n",
       "      <td>0.032838</td>\n",
       "      <td>0.038379</td>\n",
       "      <td>0.030891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.022176</td>\n",
       "      <td>0.027911</td>\n",
       "      <td>0.029954</td>\n",
       "      <td>0.041074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.022728</td>\n",
       "      <td>0.027432</td>\n",
       "      <td>0.028405</td>\n",
       "      <td>0.038803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.023835</td>\n",
       "      <td>0.031857</td>\n",
       "      <td>0.035060</td>\n",
       "      <td>0.044695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024216</td>\n",
       "      <td>0.032170</td>\n",
       "      <td>0.036950</td>\n",
       "      <td>0.045739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024277</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.041982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.024297</td>\n",
       "      <td>0.034219</td>\n",
       "      <td>0.046679</td>\n",
       "      <td>0.031763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024454</td>\n",
       "      <td>0.028443</td>\n",
       "      <td>0.029129</td>\n",
       "      <td>0.038668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024716</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.034482</td>\n",
       "      <td>0.044032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.024994</td>\n",
       "      <td>0.031625</td>\n",
       "      <td>0.035938</td>\n",
       "      <td>0.047366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.025241</td>\n",
       "      <td>0.028218</td>\n",
       "      <td>0.035142</td>\n",
       "      <td>0.036180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.025386</td>\n",
       "      <td>0.037639</td>\n",
       "      <td>0.045423</td>\n",
       "      <td>0.051710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.025468</td>\n",
       "      <td>0.030097</td>\n",
       "      <td>0.036627</td>\n",
       "      <td>0.042425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.025807</td>\n",
       "      <td>0.031069</td>\n",
       "      <td>0.036593</td>\n",
       "      <td>0.034922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.025922</td>\n",
       "      <td>0.024705</td>\n",
       "      <td>0.033542</td>\n",
       "      <td>0.038347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.026079</td>\n",
       "      <td>0.031416</td>\n",
       "      <td>0.035305</td>\n",
       "      <td>0.042114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.026143</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>0.028161</td>\n",
       "      <td>0.032340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.026175</td>\n",
       "      <td>0.027643</td>\n",
       "      <td>0.032093</td>\n",
       "      <td>0.039619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.026209</td>\n",
       "      <td>0.023725</td>\n",
       "      <td>0.027230</td>\n",
       "      <td>0.029987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_conscientiousness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.016956</td>\n",
       "      <td>0.016956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>household_income_per_person*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.015091</td>\n",
       "      <td>0.015091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RTFS_f1_minus_f2*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.014829</td>\n",
       "      <td>0.014829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>sst_CorrectGo_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.014413</td>\n",
       "      <td>0.014413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BFI_neuroticism*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.013407</td>\n",
       "      <td>0.013407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>household_income_per_person</td>\n",
       "      <td>None</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.010663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>birthsex_factor_Male*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>0.009985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009769</td>\n",
       "      <td>0.009769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009644</td>\n",
       "      <td>0.009644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.009421</td>\n",
       "      <td>0.009421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008302</td>\n",
       "      <td>0.008302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>roc_reappraiseCrave_multivariate_regulation</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.007186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.006114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SST_PostErrorSlowW1_mean</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000884</td>\n",
       "      <td>0.000884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.035252397998722, 'condition_inddiff': -0.060086173920266384, 'condition_inddiff_interactions': -0.04392321664586725}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model_outcomes = icvm.do_predictor_set_comparison(\n",
    "    predictor_sets, 'bf', dev_cv_analysis)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nutrient density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 1 predictors in the set condition_only\n",
      "predictors in that set are intervention\n",
      "outer split0\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.15 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.16 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.11 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.65 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.35 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split1\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.16 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.16 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.13 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.63 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.01 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split2\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.14 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.17 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.16 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.89 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.08 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split3\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.12 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.12 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.11 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.72 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.29 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split4\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.13 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.12 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.10 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.62 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.10 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "scores:\n",
      "[-0.022954743155200852, -0.03892961549815199, -0.024311860089525794, -4.367451066644712e-05, -0.0005284542160475247]\n",
      "overall_score:\n",
      "-0.017353669493918523\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.020728</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>0.023047</td>\n",
       "      <td>0.014417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020773</td>\n",
       "      <td>0.007664</td>\n",
       "      <td>0.016077</td>\n",
       "      <td>0.007205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020776</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020776</td>\n",
       "      <td>0.007665</td>\n",
       "      <td>0.016073</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020797</td>\n",
       "      <td>0.007674</td>\n",
       "      <td>0.016044</td>\n",
       "      <td>0.007224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020802</td>\n",
       "      <td>0.007676</td>\n",
       "      <td>0.016037</td>\n",
       "      <td>0.007228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020803</td>\n",
       "      <td>0.007677</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>0.007229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020842</td>\n",
       "      <td>0.007691</td>\n",
       "      <td>0.015995</td>\n",
       "      <td>0.007253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.020899</td>\n",
       "      <td>0.013382</td>\n",
       "      <td>0.023602</td>\n",
       "      <td>0.015836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020956</td>\n",
       "      <td>0.007946</td>\n",
       "      <td>0.016031</td>\n",
       "      <td>0.007303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.021006</td>\n",
       "      <td>0.007993</td>\n",
       "      <td>0.016014</td>\n",
       "      <td>0.007340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.021035</td>\n",
       "      <td>0.008032</td>\n",
       "      <td>0.015986</td>\n",
       "      <td>0.007364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.021038</td>\n",
       "      <td>0.007784</td>\n",
       "      <td>0.015916</td>\n",
       "      <td>0.007222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.021076</td>\n",
       "      <td>0.007827</td>\n",
       "      <td>0.015877</td>\n",
       "      <td>0.007226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.021080</td>\n",
       "      <td>0.007832</td>\n",
       "      <td>0.015873</td>\n",
       "      <td>0.007225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.021249</td>\n",
       "      <td>0.008211</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.007316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.021251</td>\n",
       "      <td>0.008219</td>\n",
       "      <td>0.015978</td>\n",
       "      <td>0.007302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.021293</td>\n",
       "      <td>0.008135</td>\n",
       "      <td>0.015708</td>\n",
       "      <td>0.007062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.021301</td>\n",
       "      <td>0.008470</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.008343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.021303</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>0.017502</td>\n",
       "      <td>0.008344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intervention</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 34 predictors in the set condition_inddiff\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.30 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.64 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.93 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.03 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.25 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 13.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.14 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.44 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.77 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 13.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 15.69 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.62 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.48 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 4.82 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 13.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 15.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.17 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 3.97 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 15.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 11.82 seconds\n",
      "scores:\n",
      "[0.049519988770995726, 0.03269280931230323, -0.04658402046662413, 0.014513755370088366, -0.02806989692523465]\n",
      "overall_score:\n",
      "0.004414527212305707\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.007568</td>\n",
       "      <td>0.017495</td>\n",
       "      <td>0.021360</td>\n",
       "      <td>0.007159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.007669</td>\n",
       "      <td>0.015354</td>\n",
       "      <td>0.020039</td>\n",
       "      <td>0.007938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.007826</td>\n",
       "      <td>0.015485</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.008331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.008006</td>\n",
       "      <td>0.019416</td>\n",
       "      <td>0.021898</td>\n",
       "      <td>0.007781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.010406</td>\n",
       "      <td>0.029726</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.019341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.010669</td>\n",
       "      <td>0.029774</td>\n",
       "      <td>0.028857</td>\n",
       "      <td>0.019237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.011935</td>\n",
       "      <td>0.015545</td>\n",
       "      <td>0.020521</td>\n",
       "      <td>0.008524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.012460</td>\n",
       "      <td>0.015619</td>\n",
       "      <td>0.020319</td>\n",
       "      <td>0.009280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.012708</td>\n",
       "      <td>0.009999</td>\n",
       "      <td>0.018529</td>\n",
       "      <td>0.008185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.012710</td>\n",
       "      <td>0.009988</td>\n",
       "      <td>0.018782</td>\n",
       "      <td>0.008394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013586</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>0.009631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.014224</td>\n",
       "      <td>0.013071</td>\n",
       "      <td>0.021882</td>\n",
       "      <td>0.010194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.015461</td>\n",
       "      <td>0.021943</td>\n",
       "      <td>0.024669</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016698</td>\n",
       "      <td>0.022895</td>\n",
       "      <td>0.025449</td>\n",
       "      <td>0.003261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.016962</td>\n",
       "      <td>0.018268</td>\n",
       "      <td>0.027899</td>\n",
       "      <td>0.011882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.016970</td>\n",
       "      <td>0.018777</td>\n",
       "      <td>0.027565</td>\n",
       "      <td>0.012260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017024</td>\n",
       "      <td>0.013302</td>\n",
       "      <td>0.019884</td>\n",
       "      <td>0.006147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.017024</td>\n",
       "      <td>0.026583</td>\n",
       "      <td>0.028529</td>\n",
       "      <td>0.008209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.017195</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.008900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017268</td>\n",
       "      <td>0.013993</td>\n",
       "      <td>0.021361</td>\n",
       "      <td>0.005715</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.039817</td>\n",
       "      <td>0.039817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.019771</td>\n",
       "      <td>0.019771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RTFS_f1_minus_f2</td>\n",
       "      <td>None</td>\n",
       "      <td>0.013664</td>\n",
       "      <td>0.013664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>IMI_effort_importance_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.012547</td>\n",
       "      <td>0.012547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.012335</td>\n",
       "      <td>0.012335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCS</td>\n",
       "      <td>None</td>\n",
       "      <td>0.011194</td>\n",
       "      <td>0.011194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wtp_liked_value_association-test_z_FDR_0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.008950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>None</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BFI_neuroticism</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006982</td>\n",
       "      <td>0.006982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006520</td>\n",
       "      <td>0.006520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict NUTRIENT_DENSITY_2wkAverage with 67 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*intervention BIS_11*intervention PCS*intervention ACES_sum*intervention BFI_agreeableness*intervention BFI_conscientiousness*intervention BFI_extraversion*intervention BFI_neuroticism*intervention BFI_openness*intervention NCS_total*intervention TESQ_E_sum*intervention SRHI_healthy_minus_unhealthy*intervention RTFS_f1_minus_f2*intervention cancer_promoting_minus_preventing_FCI*intervention age365*intervention education_own*intervention household_income_per_person*intervention SST_PostErrorSlowW1_mean*intervention SST_mean_ssrt_0*intervention ROC_Crave_Regulate_Minus_Look*intervention ROC_Crave_Minus_Neutral*intervention WTP_unhealthy_minus_healthy*intervention wtp_liked_value_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_multivariate_regulation*intervention sst_CorrectGo_striatum_joint_mask*intervention sst_FailedStop_motor_control_striatum_joint_mask*intervention sst_CorrectGoFollowingFailedStop_striatum_joint_mask*intervention Planning_aggregate*intervention Restraint_aggregate*intervention IMI_effort_importance_aggregate*intervention wtp_roc_koban_kober_craving_combined*intervention birthsex_factor_Male*intervention\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 21.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.431e+01, tolerance: 5.226e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.454e+01, tolerance: 5.678e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.007e+01, tolerance: 5.302e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 21.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 45.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 100.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 156.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 154.53 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 24.46 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.950e+01, tolerance: 4.795e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 22.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 22.52 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 92.12 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 121.38 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 117.11 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 26.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 74.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 119.76 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 201.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 177.02 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 133.68 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 20.35 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 9.871e+00, tolerance: 5.766e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 21.02 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 17.88 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 93.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 122.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 111.01 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 30.74 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 59.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 31.12 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 98.19 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 162.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 108.05 seconds\n",
      "scores:\n",
      "[0.1331193385095426, -0.059897668274534466, -0.16052196536687013, -0.07190136158645255, 0.0393469163364748]\n",
      "overall_score:\n",
      "-0.02397094807636795\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>0.004674</td>\n",
       "      <td>0.024543</td>\n",
       "      <td>0.031050</td>\n",
       "      <td>0.008729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>0.004468</td>\n",
       "      <td>0.025563</td>\n",
       "      <td>0.030473</td>\n",
       "      <td>0.008711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.006573</td>\n",
       "      <td>0.030234</td>\n",
       "      <td>0.051594</td>\n",
       "      <td>0.036088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.006585</td>\n",
       "      <td>0.025860</td>\n",
       "      <td>0.036695</td>\n",
       "      <td>0.025022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.008160</td>\n",
       "      <td>0.023759</td>\n",
       "      <td>0.028301</td>\n",
       "      <td>0.009011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.009023</td>\n",
       "      <td>0.024683</td>\n",
       "      <td>0.027794</td>\n",
       "      <td>0.009372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.009914</td>\n",
       "      <td>0.019058</td>\n",
       "      <td>0.023538</td>\n",
       "      <td>0.011038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.010305</td>\n",
       "      <td>0.019635</td>\n",
       "      <td>0.025090</td>\n",
       "      <td>0.011239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.011102</td>\n",
       "      <td>0.015790</td>\n",
       "      <td>0.019331</td>\n",
       "      <td>0.009034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.012025</td>\n",
       "      <td>0.024273</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.007637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.012081</td>\n",
       "      <td>0.016501</td>\n",
       "      <td>0.020018</td>\n",
       "      <td>0.008678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013062</td>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.030338</td>\n",
       "      <td>0.019041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013193</td>\n",
       "      <td>0.013717</td>\n",
       "      <td>0.022691</td>\n",
       "      <td>0.009902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013317</td>\n",
       "      <td>0.013578</td>\n",
       "      <td>0.022776</td>\n",
       "      <td>0.010662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013317</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.024724</td>\n",
       "      <td>0.012939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013622</td>\n",
       "      <td>0.014293</td>\n",
       "      <td>0.025065</td>\n",
       "      <td>0.012864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.013627</td>\n",
       "      <td>0.045536</td>\n",
       "      <td>0.064496</td>\n",
       "      <td>0.040368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013946</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>0.016369</td>\n",
       "      <td>0.008825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.014575</td>\n",
       "      <td>0.012976</td>\n",
       "      <td>0.015827</td>\n",
       "      <td>0.009712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.014794</td>\n",
       "      <td>0.015332</td>\n",
       "      <td>0.018238</td>\n",
       "      <td>0.008257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACES_sum*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.028203</td>\n",
       "      <td>0.028203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.026457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.021187</td>\n",
       "      <td>0.021187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCS</td>\n",
       "      <td>None</td>\n",
       "      <td>0.006574</td>\n",
       "      <td>0.006574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>PCS*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.005303</td>\n",
       "      <td>0.005303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.017353669493918523, 'condition_inddiff': 0.004414527212305707, 'condition_inddiff_interactions': -0.02397094807636795}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(predictor_sets, 'NUTRIENT_DENSITY_2wkAverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anti-nutrient density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 1 predictors in the set condition_only\n",
      "predictors in that set are intervention\n",
      "outer split0\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.26 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.57 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.35 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 3.87 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 2.06 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split1\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.22 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.40 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.40 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 1.27 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.26 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.03 seconds\n",
      "outer split2\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.20 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.25 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.20 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.76 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.37 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.03 seconds\n",
      "outer split3\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 1.09 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.72 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.56 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 2.11 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.15 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split4\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.12 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.13 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.10 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.63 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.54 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.03 seconds\n",
      "scores:\n",
      "[-0.04013660036054434, -0.08856704750362132, -0.006097285103704664, -0.0006341862305780932, -0.001178976054734937]\n",
      "overall_score:\n",
      "-0.02732281905063667\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.047420</td>\n",
       "      <td>0.037953</td>\n",
       "      <td>0.044016</td>\n",
       "      <td>0.044404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.048861</td>\n",
       "      <td>0.040668</td>\n",
       "      <td>0.046224</td>\n",
       "      <td>0.047958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.050718</td>\n",
       "      <td>0.041117</td>\n",
       "      <td>0.048511</td>\n",
       "      <td>0.049084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.052773</td>\n",
       "      <td>0.041494</td>\n",
       "      <td>0.051010</td>\n",
       "      <td>0.050638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.055052</td>\n",
       "      <td>0.041781</td>\n",
       "      <td>0.053762</td>\n",
       "      <td>0.052674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.056329</td>\n",
       "      <td>0.042348</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.053653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.056767</td>\n",
       "      <td>0.040907</td>\n",
       "      <td>0.038673</td>\n",
       "      <td>0.021485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.056794</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.038678</td>\n",
       "      <td>0.021468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.056794</td>\n",
       "      <td>0.040905</td>\n",
       "      <td>0.038678</td>\n",
       "      <td>0.021468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.057048</td>\n",
       "      <td>0.040955</td>\n",
       "      <td>0.038705</td>\n",
       "      <td>0.021341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.057120</td>\n",
       "      <td>0.040980</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.021310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.057127</td>\n",
       "      <td>0.040983</td>\n",
       "      <td>0.038710</td>\n",
       "      <td>0.021307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-0.057491</td>\n",
       "      <td>0.040380</td>\n",
       "      <td>0.055833</td>\n",
       "      <td>0.051722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-0.057514</td>\n",
       "      <td>0.042837</td>\n",
       "      <td>0.055861</td>\n",
       "      <td>0.054877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-0.057538</td>\n",
       "      <td>0.042844</td>\n",
       "      <td>0.055888</td>\n",
       "      <td>0.054895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-0.057561</td>\n",
       "      <td>0.042851</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.054913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-0.057584</td>\n",
       "      <td>0.042858</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.054931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-0.057596</td>\n",
       "      <td>0.042862</td>\n",
       "      <td>0.055959</td>\n",
       "      <td>0.054940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.057641</td>\n",
       "      <td>0.041143</td>\n",
       "      <td>0.038707</td>\n",
       "      <td>0.021242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.058702</td>\n",
       "      <td>0.043699</td>\n",
       "      <td>0.036514</td>\n",
       "      <td>0.022780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intervention</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 34 predictors in the set condition_inddiff\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 10.11 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 7.15 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 29.59 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 27.72 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 78.85 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.11 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 8.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 23.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 21.92 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 14.72 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.41 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.83 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 8.19 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 16.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 25.21 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 18.58 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 8.53 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 19.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 23.61 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 17.68 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 3.85 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 3.04 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 6.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 18.42 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 18.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 13.14 seconds\n",
      "scores:\n",
      "[-0.10013189615872276, -0.04774321509214485, -0.23120857867255462, -0.09434751106604744, -0.0763891127705063]\n",
      "overall_score:\n",
      "-0.10996406275199519\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.046202</td>\n",
       "      <td>0.040143</td>\n",
       "      <td>0.043673</td>\n",
       "      <td>0.046242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.046217</td>\n",
       "      <td>0.040198</td>\n",
       "      <td>0.044084</td>\n",
       "      <td>0.047182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046264</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.046669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046272</td>\n",
       "      <td>0.040269</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.047578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.046517</td>\n",
       "      <td>0.040086</td>\n",
       "      <td>0.043620</td>\n",
       "      <td>0.047475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.046521</td>\n",
       "      <td>0.040027</td>\n",
       "      <td>0.043195</td>\n",
       "      <td>0.046535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.047067</td>\n",
       "      <td>0.037836</td>\n",
       "      <td>0.037549</td>\n",
       "      <td>0.024599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.047149</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.037112</td>\n",
       "      <td>0.024583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.047304</td>\n",
       "      <td>0.037698</td>\n",
       "      <td>0.037336</td>\n",
       "      <td>0.024733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.047506</td>\n",
       "      <td>0.037660</td>\n",
       "      <td>0.037237</td>\n",
       "      <td>0.023173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.047550</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.044323</td>\n",
       "      <td>0.023328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.047605</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>0.023123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.047771</td>\n",
       "      <td>0.037539</td>\n",
       "      <td>0.036992</td>\n",
       "      <td>0.023267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.047791</td>\n",
       "      <td>0.060107</td>\n",
       "      <td>0.048245</td>\n",
       "      <td>0.023494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.048153</td>\n",
       "      <td>0.046822</td>\n",
       "      <td>0.049240</td>\n",
       "      <td>0.043485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.048393</td>\n",
       "      <td>0.051493</td>\n",
       "      <td>0.038859</td>\n",
       "      <td>0.023785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.048407</td>\n",
       "      <td>0.041554</td>\n",
       "      <td>0.039158</td>\n",
       "      <td>0.023681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.048443</td>\n",
       "      <td>0.051181</td>\n",
       "      <td>0.044117</td>\n",
       "      <td>0.020701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.048541</td>\n",
       "      <td>0.041142</td>\n",
       "      <td>0.044374</td>\n",
       "      <td>0.021902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.048604</td>\n",
       "      <td>0.053314</td>\n",
       "      <td>0.043073</td>\n",
       "      <td>0.021191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>None</td>\n",
       "      <td>0.477601</td>\n",
       "      <td>0.477601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Planning_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.472656</td>\n",
       "      <td>0.472656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PCS</td>\n",
       "      <td>None</td>\n",
       "      <td>0.468333</td>\n",
       "      <td>0.468333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI</td>\n",
       "      <td>None</td>\n",
       "      <td>0.465573</td>\n",
       "      <td>0.465573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.461593</td>\n",
       "      <td>0.461593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.453555</td>\n",
       "      <td>0.453555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>age365</td>\n",
       "      <td>None</td>\n",
       "      <td>0.443656</td>\n",
       "      <td>0.443656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.432935</td>\n",
       "      <td>0.432935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.427093</td>\n",
       "      <td>0.427093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>WTP_unhealthy_minus_healthy</td>\n",
       "      <td>None</td>\n",
       "      <td>0.415729</td>\n",
       "      <td>0.415729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NCS_total</td>\n",
       "      <td>None</td>\n",
       "      <td>0.414361</td>\n",
       "      <td>0.414361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.411608</td>\n",
       "      <td>0.411608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>household_income_per_person</td>\n",
       "      <td>None</td>\n",
       "      <td>0.410979</td>\n",
       "      <td>0.410979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.391361</td>\n",
       "      <td>0.391361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>wtp_liked_value_association-test_z_FDR_0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>0.387629</td>\n",
       "      <td>0.387629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict ANTINUTRIENT_DENSITY_2wkAverage with 67 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*intervention BIS_11*intervention PCS*intervention ACES_sum*intervention BFI_agreeableness*intervention BFI_conscientiousness*intervention BFI_extraversion*intervention BFI_neuroticism*intervention BFI_openness*intervention NCS_total*intervention TESQ_E_sum*intervention SRHI_healthy_minus_unhealthy*intervention RTFS_f1_minus_f2*intervention cancer_promoting_minus_preventing_FCI*intervention age365*intervention education_own*intervention household_income_per_person*intervention SST_PostErrorSlowW1_mean*intervention SST_mean_ssrt_0*intervention ROC_Crave_Regulate_Minus_Look*intervention ROC_Crave_Minus_Neutral*intervention WTP_unhealthy_minus_healthy*intervention wtp_liked_value_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_multivariate_regulation*intervention sst_CorrectGo_striatum_joint_mask*intervention sst_FailedStop_motor_control_striatum_joint_mask*intervention sst_CorrectGoFollowingFailedStop_striatum_joint_mask*intervention Planning_aggregate*intervention Restraint_aggregate*intervention IMI_effort_importance_aggregate*intervention wtp_roc_koban_kober_craving_combined*intervention birthsex_factor_Male*intervention\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 20.88 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 20.39 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 21.20 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 91.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 115.52 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 140.50 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 21.59 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 21.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 28.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 119.05 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 151.16 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 114.20 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 20.16 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 22.17 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 22.10 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 109.75 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 119.07 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 690.98 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 358.69 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 296.02 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 272.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 773.37 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 157.60 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 165.99 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 29.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 52.26 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 30.63 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 121.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 136.29 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 89.28 seconds\n",
      "scores:\n",
      "[-0.0483365187922824, -0.24812224803001204, -0.14803675483453338, -0.0005046444864234001, -0.0008489695208742098]\n",
      "overall_score:\n",
      "-0.08916982713282509\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046264</td>\n",
       "      <td>0.040211</td>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.046669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.046272</td>\n",
       "      <td>0.040269</td>\n",
       "      <td>0.043133</td>\n",
       "      <td>0.047578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.047149</td>\n",
       "      <td>0.037847</td>\n",
       "      <td>0.037112</td>\n",
       "      <td>0.024583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.047605</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>0.023123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.049059</td>\n",
       "      <td>0.045957</td>\n",
       "      <td>0.042260</td>\n",
       "      <td>0.027355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.049112</td>\n",
       "      <td>0.042792</td>\n",
       "      <td>0.044834</td>\n",
       "      <td>0.049177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.049566</td>\n",
       "      <td>0.042971</td>\n",
       "      <td>0.044855</td>\n",
       "      <td>0.047894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.050645</td>\n",
       "      <td>0.039901</td>\n",
       "      <td>0.039464</td>\n",
       "      <td>0.024005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.050703</td>\n",
       "      <td>0.048475</td>\n",
       "      <td>0.038252</td>\n",
       "      <td>0.023880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.051149</td>\n",
       "      <td>0.045079</td>\n",
       "      <td>0.039414</td>\n",
       "      <td>0.025689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.051327</td>\n",
       "      <td>0.046347</td>\n",
       "      <td>0.044008</td>\n",
       "      <td>0.025256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.051431</td>\n",
       "      <td>0.047730</td>\n",
       "      <td>0.043818</td>\n",
       "      <td>0.026627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.051691</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.039381</td>\n",
       "      <td>0.022494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.052361</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>0.037818</td>\n",
       "      <td>0.023983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__kernel': 'linear', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.052541</td>\n",
       "      <td>0.050057</td>\n",
       "      <td>0.039450</td>\n",
       "      <td>0.021740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.053269</td>\n",
       "      <td>0.039629</td>\n",
       "      <td>0.042387</td>\n",
       "      <td>0.026209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.053361</td>\n",
       "      <td>0.045499</td>\n",
       "      <td>0.042078</td>\n",
       "      <td>0.026499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.054042</td>\n",
       "      <td>0.046683</td>\n",
       "      <td>0.042380</td>\n",
       "      <td>0.024994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.054141</td>\n",
       "      <td>0.046855</td>\n",
       "      <td>0.037145</td>\n",
       "      <td>0.022349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf', 'feature_selection__k': 5, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.054187</td>\n",
       "      <td>0.045084</td>\n",
       "      <td>0.038793</td>\n",
       "      <td>0.025368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>None</td>\n",
       "      <td>0.508102</td>\n",
       "      <td>0.508102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.495858</td>\n",
       "      <td>0.495858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>education_own*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.490123</td>\n",
       "      <td>0.490123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>ROC_Crave_Minus_Neutral*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.489896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.481003</td>\n",
       "      <td>0.481003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Planning_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.474102</td>\n",
       "      <td>0.474102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SRHI_healthy_minus_unhealthy*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.473041</td>\n",
       "      <td>0.473041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.472614</td>\n",
       "      <td>0.472614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>None</td>\n",
       "      <td>0.469174</td>\n",
       "      <td>0.469174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SST_PostErrorSlowW1_mean</td>\n",
       "      <td>None</td>\n",
       "      <td>0.461889</td>\n",
       "      <td>0.461889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.459341</td>\n",
       "      <td>0.459341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ROC_Crave_Regulate_Minus_Look</td>\n",
       "      <td>None</td>\n",
       "      <td>0.458195</td>\n",
       "      <td>0.458195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI</td>\n",
       "      <td>None</td>\n",
       "      <td>0.457134</td>\n",
       "      <td>0.457134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>age365</td>\n",
       "      <td>None</td>\n",
       "      <td>0.450981</td>\n",
       "      <td>0.450981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SST_mean_ssrt_0</td>\n",
       "      <td>None</td>\n",
       "      <td>0.450978</td>\n",
       "      <td>0.450978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>age365*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.447561</td>\n",
       "      <td>0.447561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ROC_Crave_Minus_Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.447556</td>\n",
       "      <td>0.447556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>wtp_roc_koban_kober_craving_combined</td>\n",
       "      <td>None</td>\n",
       "      <td>0.447468</td>\n",
       "      <td>0.447468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>SST_PostErrorSlowW1_mean*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.447192</td>\n",
       "      <td>0.447192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>None</td>\n",
       "      <td>0.446081</td>\n",
       "      <td>0.446081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.02732281905063667, 'condition_inddiff': -0.10996406275199519, 'condition_inddiff_interactions': -0.08916982713282509}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(predictor_sets, 'ANTINUTRIENT_DENSITY_2wkAverage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calorie count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## condition_only"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 1 predictors in the set condition_only\n",
      "predictors in that set are intervention\n",
      "outer split0\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.19 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.18 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.17 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.82 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.92 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split1\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.14 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.16 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.13 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.77 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.01 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split2\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.14 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.17 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.15 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.83 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.18 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "outer split3\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.15 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.16 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.13 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.83 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 0.94 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.01 seconds\n",
      "outer split4\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Ridge: 0.12 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Time elapsed for Lasso: 0.13 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Time elapsed for LinearSVR: 0.11 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Time elapsed for PolySVR: 0.65 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Time elapsed for RBFSVR: 1.25 seconds\n",
      "Only one feature, so skipping feature selection\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [1], 'estimator__min_samples_split': [1], 'estimator__min_samples_leaf': [1]}\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Error: \n",
      "All the 4 fits failed.\n",
      "It is very likely that your model is misconfigured.\n",
      "You can try to debug the error by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/pipeline.py\", line 405, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 177, in fit\n",
      "    self._validate_params()\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/base.py\", line 600, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 97, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'min_samples_split' parameter of DecisionTreeRegressor must be an int in the range [2, inf) or a float in the range (0.0, 1.0]. Got 1 instead.\n",
      " for DecisionTreeRegressor\n",
      "Skipping DecisionTreeRegressor\n",
      "Time elapsed for DecisionTreeRegressor: 0.02 seconds\n",
      "scores:\n",
      "[-0.126169564874006, -0.1844181524114339, -0.04388133245076764, -0.008609328692686713, -0.004748593572675208]\n",
      "overall_score:\n",
      "-0.07356539440031389\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"20\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020469</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.023947</td>\n",
       "      <td>0.007438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020480</td>\n",
       "      <td>0.006297</td>\n",
       "      <td>0.024204</td>\n",
       "      <td>0.007522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020480</td>\n",
       "      <td>0.006305</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020480</td>\n",
       "      <td>0.006298</td>\n",
       "      <td>0.024204</td>\n",
       "      <td>0.007522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020480</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.024206</td>\n",
       "      <td>0.007521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006287</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.007523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.024208</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.024189</td>\n",
       "      <td>0.007527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006291</td>\n",
       "      <td>0.024202</td>\n",
       "      <td>0.007523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006307</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__kernel': 'linear'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006308</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly'}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020482</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.024209</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020482</td>\n",
       "      <td>0.006278</td>\n",
       "      <td>0.024196</td>\n",
       "      <td>0.007525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.001, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020482</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.01, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020482</td>\n",
       "      <td>0.006309</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.007520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 34 predictors in the set condition_inddiff\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.19 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.43 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 10.93 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 15.13 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.94 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.47 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.70 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.59 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 11.84 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 15.73 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 11.79 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.51 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.66 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 11.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 17.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 11.76 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.33 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.66 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 1.64 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 12.49 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 15.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 11.98 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 2.17 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 2.25 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 2.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 10.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 16.09 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 12.07 seconds\n",
      "scores:\n",
      "[-0.02179660510736392, -0.1918243415788461, -0.0051538888540736405, 0.0016216893598746118, -0.07281565427907921]\n",
      "overall_score:\n",
      "-0.05799376009189765\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019952</td>\n",
       "      <td>0.006760</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>0.005765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020221</td>\n",
       "      <td>0.006878</td>\n",
       "      <td>0.024996</td>\n",
       "      <td>0.009044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020236</td>\n",
       "      <td>0.005708</td>\n",
       "      <td>0.024061</td>\n",
       "      <td>0.007997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 0.1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020236</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.024058</td>\n",
       "      <td>0.007986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020280</td>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.023778</td>\n",
       "      <td>0.007941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020281</td>\n",
       "      <td>0.006167</td>\n",
       "      <td>0.023777</td>\n",
       "      <td>0.007935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.020426</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.024242</td>\n",
       "      <td>0.008034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.020427</td>\n",
       "      <td>0.005966</td>\n",
       "      <td>0.024246</td>\n",
       "      <td>0.008042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020432</td>\n",
       "      <td>0.006606</td>\n",
       "      <td>0.024389</td>\n",
       "      <td>0.007809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020436</td>\n",
       "      <td>0.008056</td>\n",
       "      <td>0.026625</td>\n",
       "      <td>0.005890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020440</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>0.007819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020445</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>0.024248</td>\n",
       "      <td>0.007707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020446</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.024245</td>\n",
       "      <td>0.008054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020447</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.024250</td>\n",
       "      <td>0.008062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SVR()])</th>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020465</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.024257</td>\n",
       "      <td>0.008038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 100, 'estimator__epsilon': 0.5, 'estimator__gamma': 1, 'estimator__kernel': 'rbf'}</th>\n",
       "      <td>-0.020466</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.024261</td>\n",
       "      <td>0.008046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020475</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>0.024211</td>\n",
       "      <td>0.007537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020477</td>\n",
       "      <td>0.006302</td>\n",
       "      <td>0.024231</td>\n",
       "      <td>0.007494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.1, 'estimator__epsilon': 0.05, 'estimator__gamma': 1, 'estimator__kernel': 'rbf', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020480</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.024211</td>\n",
       "      <td>0.007522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 0.01, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.020481</td>\n",
       "      <td>0.006310</td>\n",
       "      <td>0.024210</td>\n",
       "      <td>0.007522</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ROC_Crave_Minus_Neutral</td>\n",
       "      <td>None</td>\n",
       "      <td>0.004227</td>\n",
       "      <td>0.004227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>sst_FailedStop_motor_control_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.003196</td>\n",
       "      <td>0.003196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>education_own</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>0.002465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.002430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>sst_CorrectGoFollowingFailedStop_striatum_joint_mask</td>\n",
       "      <td>None</td>\n",
       "      <td>0.002047</td>\n",
       "      <td>0.002047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001789</td>\n",
       "      <td>0.001789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BFI_neuroticism</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.001745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BFI_conscientiousness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BFI_openness</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001680</td>\n",
       "      <td>0.001680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Restraint_aggregate</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000755</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "## condition_inddiff_interactions"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading raw data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:998: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  ms_groups['intervention_group'] = ms_groups['group_raw'].str.replace(r\"\\(.*\\)\",\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: merging group codes with data_by_ppt resulted in a different number of participants\n",
      "pre merge: 275\n",
      "post merge: 270\n",
      "participants in pre merge but not post merge: {'DEV022', 'DEV002', 'DEV280', 'DEV032', 'DEV007'}\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'run', 'task'],\n",
      "      dtype='object')\n",
      "Index(['Unnamed: 0', 'subject_id', 'wave', 'spm_l2_path', 'condition',\n",
      "       'beta_name', 'mask_label', 'roi_activity', 'task', 'run'],\n",
      "      dtype='object')\n",
      "(243, 33)\n",
      " attempting to predict total_calorie with 67 predictors in the set condition_inddiff_interactions\n",
      "predictors in that set are intervention EDM BIS_11 PCS ACES_sum BFI_agreeableness BFI_conscientiousness BFI_extraversion BFI_neuroticism BFI_openness NCS_total TESQ_E_sum SRHI_healthy_minus_unhealthy RTFS_f1_minus_f2 cancer_promoting_minus_preventing_FCI age365 education_own household_income_per_person SST_PostErrorSlowW1_mean SST_mean_ssrt_0 ROC_Crave_Regulate_Minus_Look ROC_Crave_Minus_Neutral WTP_unhealthy_minus_healthy wtp_liked_value_association-test_z_FDR_0.01 roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01 roc_reappraiseCrave_multivariate_regulation sst_CorrectGo_striatum_joint_mask sst_FailedStop_motor_control_striatum_joint_mask sst_CorrectGoFollowingFailedStop_striatum_joint_mask Planning_aggregate Restraint_aggregate IMI_effort_importance_aggregate wtp_roc_koban_kober_craving_combined birthsex_factor_Male EDM*intervention BIS_11*intervention PCS*intervention ACES_sum*intervention BFI_agreeableness*intervention BFI_conscientiousness*intervention BFI_extraversion*intervention BFI_neuroticism*intervention BFI_openness*intervention NCS_total*intervention TESQ_E_sum*intervention SRHI_healthy_minus_unhealthy*intervention RTFS_f1_minus_f2*intervention cancer_promoting_minus_preventing_FCI*intervention age365*intervention education_own*intervention household_income_per_person*intervention SST_PostErrorSlowW1_mean*intervention SST_mean_ssrt_0*intervention ROC_Crave_Regulate_Minus_Look*intervention ROC_Crave_Minus_Neutral*intervention WTP_unhealthy_minus_healthy*intervention wtp_liked_value_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_reappraisal_association-test_z_FDR_0.01*intervention roc_reappraiseCrave_multivariate_regulation*intervention sst_CorrectGo_striatum_joint_mask*intervention sst_FailedStop_motor_control_striatum_joint_mask*intervention sst_CorrectGoFollowingFailedStop_striatum_joint_mask*intervention Planning_aggregate*intervention Restraint_aggregate*intervention IMI_effort_importance_aggregate*intervention wtp_roc_koban_kober_craving_combined*intervention birthsex_factor_Male*intervention\n",
      "outer split0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 19.68 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.727e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.654e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.936e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.752e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.625e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.556e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.767e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.484e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.429e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.362e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.459e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.960e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.248e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.149e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.172e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.458e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.083e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.993e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.919e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.987e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.934e+08, tolerance: 1.572e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.812e+08, tolerance: 1.361e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.698e+08, tolerance: 1.629e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.577e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.664e+08, tolerance: 2.041e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.140e+08, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e+06, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.634e+07, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.519e+07, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.339e+06, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.273e+06, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.778e+06, tolerance: 1.556e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 21.03 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 14.01 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 86.27 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 137.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 99.27 seconds\n",
      "outer split1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 19.58 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.653e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.585e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.739e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.716e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.458e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.560e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.466e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.638e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.601e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.378e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.224e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.448e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.377e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.216e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.973e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.283e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.161e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.063e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.716e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.140e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.912e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.911e+08, tolerance: 1.354e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.458e+08, tolerance: 1.484e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.997e+08, tolerance: 1.469e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.659e+08, tolerance: 1.258e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e+08, tolerance: 1.860e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 19.67 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 13.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 83.64 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 115.16 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 94.77 seconds\n",
      "outer split2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 19.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.985e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.548e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.630e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.666e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.141e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.790e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.365e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.621e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.388e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.022e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.123e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.523e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.777e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.787e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.414e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.552e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.581e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.461e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.288e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.119e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.525e+08, tolerance: 1.043e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.159e+08, tolerance: 1.467e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.141e+08, tolerance: 1.600e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.123e+07, tolerance: 1.904e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.098e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.679e+06, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.048e+08, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.098e+07, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.140e+07, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.300e+07, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.679e+06, tolerance: 1.595e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 19.69 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 13.80 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 80.66 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 108.57 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 95.99 seconds\n",
      "outer split3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 19.71 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.923e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.074e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.873e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.886e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.901e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.993e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.833e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.922e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.792e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.765e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.648e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.635e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.631e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.541e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.452e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.370e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.476e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.339e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.247e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.127e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.331e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.158e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.034e+08, tolerance: 1.213e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.901e+08, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.129e+08, tolerance: 1.263e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.993e+08, tolerance: 1.559e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.744e+08, tolerance: 1.764e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.708e+07, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.610e+05, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.797e+06, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.026e+06, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.169e+06, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.312e+05, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.610e+05, tolerance: 1.255e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed for Lasso: 20.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 13.62 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 83.18 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 111.08 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 99.90 seconds\n",
      "outer split4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Ridge: 20.50 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 7 candidates, totalling 28 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.886e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.999e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.162e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.488e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.902e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.812e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.841e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.917e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.431e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.640e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.458e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.465e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.311e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.424e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.080e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.112e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.183e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.225e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.693e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.835e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.048e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e+08, tolerance: 1.511e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.298e+08, tolerance: 1.353e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.610e+08, tolerance: 1.630e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.902e+08, tolerance: 1.604e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.368e+08, tolerance: 2.034e+05\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 21 candidates, totalling 84 fits\n",
      "Time elapsed for Lasso: 19.55 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['linear'], 'estimator__C': [0.01, 0.1, 1, 10, 100]}\n",
      "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n",
      "Time elapsed for LinearSVR: 14.45 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['poly'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__degree': [2, 3], 'estimator__coef0': [0.1, 0.333, 1]}\n",
      "Fitting 4 folds for each of 90 candidates, totalling 360 fits\n",
      "Time elapsed for PolySVR: 81.56 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', SVR())])\n",
      "{'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 40 candidates, totalling 160 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', SVR())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', SVR())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__kernel': ['rbf'], 'estimator__C': [0.01, 0.1, 1, 10, 100], 'estimator__gamma': [0.001, 0.01, 0.1, 1], 'estimator__epsilon': [0.05, 0.5]}\n",
      "Fitting 4 folds for each of 120 candidates, totalling 480 fits\n",
      "Time elapsed for RBFSVR: 112.99 seconds\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17dab7100>], 'feature_selection__k': [5, 10, 15], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [5, 10, 15], 'feature_selection__step': [5], 'estimator__max_depth': [2, 3, 5, 10], 'estimator__min_samples_split': [2, 5, 20], 'estimator__min_samples_leaf': [2, 5, 20]}\n",
      "Fitting 4 folds for each of 108 candidates, totalling 432 fits\n",
      "Time elapsed for DecisionTreeRegressor: 97.56 seconds\n",
      "scores:\n",
      "[-0.14549947062915658, -0.25390458472224675, -0.00538593462524295, -0.003474034139575366, -0.0021456156092103384]\n",
      "overall_score:\n",
      "-0.0820819279450864\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013351</td>\n",
       "      <td>0.011131</td>\n",
       "      <td>0.037265</td>\n",
       "      <td>0.025661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.013995</td>\n",
       "      <td>0.012109</td>\n",
       "      <td>0.037362</td>\n",
       "      <td>0.025395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016741</td>\n",
       "      <td>0.012379</td>\n",
       "      <td>0.032751</td>\n",
       "      <td>0.014247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016850</td>\n",
       "      <td>0.007372</td>\n",
       "      <td>0.025302</td>\n",
       "      <td>0.012583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.016973</td>\n",
       "      <td>0.006984</td>\n",
       "      <td>0.027028</td>\n",
       "      <td>0.011911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017106</td>\n",
       "      <td>0.009006</td>\n",
       "      <td>0.026887</td>\n",
       "      <td>0.014056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017107</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>0.031365</td>\n",
       "      <td>0.012944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017554</td>\n",
       "      <td>0.005110</td>\n",
       "      <td>0.026205</td>\n",
       "      <td>0.010074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.017776</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>0.026047</td>\n",
       "      <td>0.009595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018116</td>\n",
       "      <td>0.010353</td>\n",
       "      <td>0.030447</td>\n",
       "      <td>0.015657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.018126</td>\n",
       "      <td>0.016361</td>\n",
       "      <td>0.039059</td>\n",
       "      <td>0.026627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019251</td>\n",
       "      <td>0.014864</td>\n",
       "      <td>0.034338</td>\n",
       "      <td>0.013589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 15, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019280</td>\n",
       "      <td>0.005306</td>\n",
       "      <td>0.025747</td>\n",
       "      <td>0.008627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019629</td>\n",
       "      <td>0.005414</td>\n",
       "      <td>0.024748</td>\n",
       "      <td>0.009440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019674</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.024710</td>\n",
       "      <td>0.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), SVR()])</th>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__k': 15, 'feature_selection__score_func': &lt;function f_regression at 0x17dab7100&gt;}</th>\n",
       "      <td>-0.019685</td>\n",
       "      <td>0.009871</td>\n",
       "      <td>0.025895</td>\n",
       "      <td>0.005367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), SVR()])</th>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.333, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019905</td>\n",
       "      <td>0.005569</td>\n",
       "      <td>0.024552</td>\n",
       "      <td>0.007864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 1, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 5, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019920</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.024150</td>\n",
       "      <td>0.007986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 10, 'estimator__coef0': 0.333, 'estimator__degree': 2, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019979</td>\n",
       "      <td>0.006525</td>\n",
       "      <td>0.025867</td>\n",
       "      <td>0.009727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__C': 1, 'estimator__coef0': 0.1, 'estimator__degree': 3, 'estimator__kernel': 'poly', 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-0.019986</td>\n",
       "      <td>0.005681</td>\n",
       "      <td>0.024553</td>\n",
       "      <td>0.007781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n",
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis/lib/python3.11/site-packages/sklearn/impute/_iterative.py:785: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cancer_promoting_minus_preventing_FCI</td>\n",
       "      <td>None</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.004130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>birthsex_factor_Male*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.001434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>TESQ_E_sum*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001378</td>\n",
       "      <td>0.001378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>birthsex_factor_Male</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001157</td>\n",
       "      <td>0.001157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BFI_openness*intervention</td>\n",
       "      <td>None</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.001011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'condition_only': -0.07356539440031389, 'condition_inddiff': -0.05799376009189765, 'condition_inddiff_interactions': -0.0820819279450864}\n"
     ]
    }
   ],
   "source": [
    "model_outcomes = icvm.do_predictor_set_comparison(predictor_sets, 'total_calorie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
