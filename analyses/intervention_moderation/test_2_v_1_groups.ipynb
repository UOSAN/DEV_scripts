{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from socket import gethostname\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from dev_interaction_util import generate_synthetic_dev_outcomes, generate_synthetic_dev_data, set_up_interactions\n",
    "from dev_interaction_util import do_scoring_loop, get_best_model, summarize_overall_df_results, do_final_fit, present_model_results, present_results_vs_ground_truth_cors\n",
    "from dev_interaction_util import load_and_preprocess_data, impute_data, run_full_limited_predictor_analysis\n",
    "from ml_util import *\n",
    "# Imputing with MICE\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn import linear_model\n",
    "from ml_util import get_data_for_imputation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-2.local\n",
      "{'dropbox_data_dir': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "with open('config.yml') as f:\n",
    "    all_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "    if gethostname() in all_yaml.keys():\n",
    "        config = all_yaml[gethostname()]\n",
    "    else:\n",
    "        config = all_yaml['default']\n",
    "        \n",
    "print(config)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is derived from `test_feature_selection.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data, outcome_measures = load_and_preprocess_data(dropbox_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/impute/_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "analysis_data_imputed = impute_data(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_hyperparameter_selection_loop_r2(X,y,cv):\n",
    "    return(do_hyperparameter_selection_loop_w_metric(X,y,cv,'r2'))\n",
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop(X, y,cv):\n",
    "    return(do_hyperparameter_selection_loop_w_metric(X,y,cv,'neg_mean_absolute_error'))\n",
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop_w_metric(X, y,cv,metric):\n",
    "    #alpha parameters for Ridge and Lasso\n",
    "    alpha_10pow_lower = 1\n",
    "    alpha_10pow_upper = 0\n",
    "    alpha_increments=1\n",
    "    alpha_range = np.concatenate([np.power(10,np.linspace(-alpha_10pow_lower,alpha_10pow_upper,(alpha_10pow_lower+alpha_10pow_upper)*alpha_increments+1)),\n",
    "        [0.2,0.3,0.4,0.6,0.8,1.0]])\n",
    "    \n",
    "    all_cv_results = []\n",
    "\n",
    "    pipeline_estimator_name = 'estimator'\n",
    "    feature_selection_name = 'feature_selection'\n",
    "\n",
    "\n",
    "    #define the param_grid for the estimators\n",
    "    estimators_to_run = {\n",
    "        'Ridge':{\n",
    "            'estimator':linear_model.Ridge,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'Lasso':{\n",
    "            'estimator':linear_model.Lasso,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'DecisionTreeRegressor':{\n",
    "            'estimator':DecisionTreeRegressor,\n",
    "            'parameters':{\n",
    "                'max_depth':[2, 4],\n",
    "                'min_samples_split':[20,50],\n",
    "                'min_samples_leaf':[20,50]\n",
    "            }\n",
    "        }             \n",
    "    }\n",
    "\n",
    "    k_max_val = np.min([50,X.shape[1]])\n",
    "\n",
    "    for estimator_name,estimator_dict in estimators_to_run.items():\n",
    "        #param grid for the feature seelction\n",
    "        #this is here because we need to know the estimator to pass to the feature selector\n",
    "        feature_selectors_to_run = {\n",
    "            'None':None,\n",
    "            'KBest':{\n",
    "                'selector':SelectKBest(),\n",
    "                'parameters':{\n",
    "                    'score_func' : [f_regression], \n",
    "                    'k' : [10,25,k_max_val]\n",
    "                    }\n",
    "            },\n",
    "            'RFE':{\n",
    "                'selector':RFE(linear_model.LinearRegression()),\n",
    "                'parameters':{\n",
    "                    'n_features_to_select' : [10,25],\n",
    "                    #'verbose':[1],\n",
    "                    'step':[5]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for selector_name, selector_dict in feature_selectors_to_run.items():\n",
    "        #create the estimator\n",
    "            if selector_name == 'None':\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                     (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = {}\n",
    "            else:\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                     (feature_selection_name,selector_dict['selector']), \n",
    "                                     (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = selector_dict['parameters']\n",
    "\n",
    "            estimator_param_grid = {(pipeline_estimator_name + '__'+k):v for k,v in estimator_dict['parameters'].items()}\n",
    "            selector_param_grid = {(feature_selection_name + '__'+k):v for k,v in selector_params.items()}\n",
    "            #combine the two param grid dictionaries\n",
    "            full_param_grid = {**selector_param_grid, **estimator_param_grid}\n",
    "            print(pipeline)\n",
    "            print(full_param_grid)\n",
    "\n",
    "            \n",
    "        \n",
    "            gs_1 = GridSearchCV(estimator=pipeline, \n",
    "                                param_grid = full_param_grid, \n",
    "                                cv=cv,scoring=metric,verbose=1)\n",
    "            gs_1.fit(X,y)\n",
    "            all_cv_results.append(gs_1)\n",
    "\n",
    "    #create a dataframe with the best parameters, best mean_test_score, and name of the model\n",
    "\n",
    "    best_params_df = pd.DataFrame({\n",
    "        'model': [cv_result.estimator for cv_result in all_cv_results],\n",
    "        'model_name': [cv_result.estimator.__class__.__name__ for cv_result in all_cv_results],\n",
    "        'best_params': [extract_estimator_params_from_gridsearch(cv_result.best_params_) for cv_result in all_cv_results],\n",
    "        'best_score': [cv_result.best_score_ for cv_result in all_cv_results],\n",
    "        'best_raw_params' : [cv_result.best_params_ for cv_result in all_cv_results]\n",
    "        })\n",
    "    \n",
    "    best_params_df = best_params_df.sort_values('best_score',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    best_model = clone(best_params_df['model'][0])\n",
    "    best_model_params = best_params_df['best_raw_params'][0]\n",
    "    best_model.set_params(**best_model_params)\n",
    "\n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_params_df':best_params_df,\n",
    "        'raw_cv_results':all_cv_results\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving fit with manual theory-driven feature\n",
    "\n",
    "My past analysis showed that by manually removing some features before the analysis starts, we can improve performance beyond the chance performance otherwise seen.\n",
    "\n",
    "So, it might be useful to understand how much we can improve our performance by manual feature selection before the automatic feature selection applies.\n",
    "\n",
    "This was previously done in `test_limited_predictors.ipynb`. We tested as few as 2 distractor features. In that test, predictor features generally had correlations in the range of |r|=0.06 to 0.53, with most around 0.4 (we should confirm that because it seems fishy that PCS was detegted as an effect, but didn't model as a large predictor). With most `|r|=0.4`, this seems unrealistically high to expect, and we should aim to build a pipeline capable of detecting more subtle effects than that. An approximate `|r|=0.3` can be achieved by mixing in a predictor scaled to 8% of normal scale.\n",
    "\n",
    "I can imagine it is plausible to cut down to as few as two self-report, one behavioral, and one neural measure per intervention, plus sex and age. That would yield 10 different variables. At the other end, we might want 10 self-report, two behavioral, and five neural measures per intervention tested, plus 6 different demographic variables--a total of 40 variables. Let's see how these would perform, as well as mid-range of 20 predictor variables. In each case we'll restrict to three valid predictors per intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_2_group_predictor_analysis(total_predictor_count, outcome_measures, analysis_data_imputed, effect_size, hyperparameter_optimizer,\n",
    "                                        custom_interaction_effects=None\n",
    "                                        ):\n",
    "\n",
    "    #set np random seed\n",
    "    np.random.seed(3161527)\n",
    "\n",
    "    group_names = ['ichi','ni','san']\n",
    "    #assign each row randomly to a group\n",
    "    group_assignments_3 = np.random.choice(group_names,analysis_data_imputed.shape[0])\n",
    "    \n",
    "    #two-group analysis, comparing ichi vs ni and san\n",
    "    group_assignments_2 = group_assignments_3.copy()\n",
    "    group_assignments_2[group_assignments_2=='ni'] = 'nisan'\n",
    "    group_assignments_2[group_assignments_2=='san'] = 'nisan'\n",
    "\n",
    "\n",
    "    #synthetic outcomes\n",
    "    outcome_measures = generate_synthetic_dev_outcomes(outcome_measures)\n",
    "\n",
    "    #create a limited set of predictors\n",
    "    analysis_data_smol = analysis_data_imputed.iloc[:,0:total_predictor_count]\n",
    "\n",
    "    # add synthetic primary and interaction effects\n",
    "\n",
    "    if custom_interaction_effects is None:\n",
    "        #set up the interaction effects\n",
    "        #0.08 will give us correlations around 0.3 between the interaction effects and the outcome\n",
    "        custom_interaction_effects_g1 = [0]*analysis_data_smol.shape[1]\n",
    "        custom_interaction_effects_g1[0] = effect_size\n",
    "        custom_interaction_effects_g1[1] = effect_size\n",
    "        custom_interaction_effects_g1[2] = -effect_size\n",
    "\n",
    "\n",
    "        custom_interaction_effects = {'nisan':custom_interaction_effects_g1}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    synthetic_data = generate_synthetic_dev_data(analysis_data_smol, group_assignments_2,outcome_measures, group_interaction_effects = custom_interaction_effects)\n",
    "    interaction_effect_df = synthetic_data['X_weights']\n",
    "    outcome_measures = synthetic_data['y']\n",
    "\n",
    "    # Set up outcome measures and group assignment one-hot\n",
    "\n",
    "    outcome_measures = calculate_outcome_changes(outcome_measures)\n",
    "    \n",
    "\n",
    "    group_assignment_onehots = pd.get_dummies(group_assignments_2).loc[:,['nisan']]\n",
    "\n",
    "    predictor_data = set_up_interactions(analysis_data_smol, group_assignment_onehots)\n",
    "\n",
    "\n",
    "    #remove any NA values for this outcome measure in both the predictor data and the outcome data\n",
    "    outcome_nas = outcome_measures['d_bf'].isna()\n",
    "\n",
    "    outcome_measures_nona = outcome_measures.loc[~outcome_nas,:]\n",
    "    predictor_data_nona = predictor_data.loc[~outcome_nas,:]\n",
    "    group_assignment_onehots_nonan = group_assignment_onehots.loc[~outcome_nas,:]\n",
    "    group_assignments_nona = group_assignments_2[~outcome_nas]\n",
    "\n",
    "    ### Try out CV with simple gridsearch\n",
    "\n",
    "    scoring_data = do_scoring_loop(X=predictor_data_nona, y= outcome_measures_nona['d_bf'], \n",
    "                    groups = group_assignments_nona, \n",
    "                    hyperparameter_selection_on_fold=hyperparameter_optimizer,\n",
    "                    outer_folds=5)\n",
    "\n",
    "    scores = scoring_data['scores']\n",
    "    best_models = scoring_data['best_models']\n",
    "    best_params_df_list = scoring_data['best_params_df_list']\n",
    "    raw_cv_results_list = scoring_data['raw_cv_results_list']\n",
    "\n",
    "    print(\"scores:\")\n",
    "    print(scores)\n",
    "    overall_score = np.mean(scores)\n",
    "    print(\"overall_score:\")\n",
    "    print(overall_score)\n",
    "\n",
    "\n",
    "\n",
    "    best_model = get_best_model(summarize_overall_df_results(raw_cv_results_list))\n",
    "    final_fit = do_final_fit(X=predictor_data_nona, y= outcome_measures_nona['d_bf'], final_model=best_model)\n",
    "    final_results = present_model_results(X=predictor_data_nona, final_fit=final_fit, y=outcome_measures_nona['d_bf'])\n",
    "\n",
    "    #print rows of final_results where feature_name is the list of features to check\n",
    "    base_regressors = interaction_effect_df.predictor[interaction_effect_df.interaction_effect!=0]\n",
    "    regressors_to_check = [x+y for y in ['','*nisan'] for x in base_regressors]\n",
    "    final_results['planned_regression'] = final_results['predictor'].isin(regressors_to_check)\n",
    "\n",
    "    present_results_vs_ground_truth_cors(predictor_data_nona,outcome_measures_nona,group_assignments_nona,final_results,base_regressors)\n",
    "\n",
    "    return(overall_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.011029072644280769, 0.05103383687350138, -0.10485951827373197, 0.037046924382313384, -0.38575629856163185]\n",
      "overall_score:\n",
      "-0.07830119658705366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.250385</td>\n",
       "      <td>0.053035</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.081511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.253106</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.289953</td>\n",
       "      <td>0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.253106</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.289953</td>\n",
       "      <td>0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.264384</td>\n",
       "      <td>0.061781</td>\n",
       "      <td>0.327677</td>\n",
       "      <td>0.069726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.267684</td>\n",
       "      <td>0.049697</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267684</td>\n",
       "      <td>0.049697</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.279107</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>0.339821</td>\n",
       "      <td>0.050708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.279376</td>\n",
       "      <td>0.066624</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.043856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.279376</td>\n",
       "      <td>0.066624</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.043856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281872</td>\n",
       "      <td>0.081962</td>\n",
       "      <td>0.257870</td>\n",
       "      <td>0.092071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.283315</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>0.357960</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.284202</td>\n",
       "      <td>0.067280</td>\n",
       "      <td>0.341063</td>\n",
       "      <td>0.046535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285404</td>\n",
       "      <td>0.072023</td>\n",
       "      <td>0.343528</td>\n",
       "      <td>0.049963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.286469</td>\n",
       "      <td>0.083171</td>\n",
       "      <td>0.350206</td>\n",
       "      <td>0.042443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.286801</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.348245</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.286801</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.348245</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.287008</td>\n",
       "      <td>0.078122</td>\n",
       "      <td>0.348216</td>\n",
       "      <td>0.043031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.288373</td>\n",
       "      <td>0.086073</td>\n",
       "      <td>0.348183</td>\n",
       "      <td>0.041424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.289511</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>0.322922</td>\n",
       "      <td>0.086736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290555</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.341598</td>\n",
       "      <td>0.087181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290663</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>0.095559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.291705</td>\n",
       "      <td>0.052861</td>\n",
       "      <td>0.326872</td>\n",
       "      <td>0.056337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.291741</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.353814</td>\n",
       "      <td>0.046674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.292240</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>0.352827</td>\n",
       "      <td>0.039541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.293070</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>0.346690</td>\n",
       "      <td>0.040574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293392</td>\n",
       "      <td>0.073605</td>\n",
       "      <td>0.352856</td>\n",
       "      <td>0.043913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.298844</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>0.345626</td>\n",
       "      <td>0.039949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299437</td>\n",
       "      <td>0.066993</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.036018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300071</td>\n",
       "      <td>0.070655</td>\n",
       "      <td>0.353187</td>\n",
       "      <td>0.037746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301186</td>\n",
       "      <td>0.094844</td>\n",
       "      <td>0.258220</td>\n",
       "      <td>0.092990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301434</td>\n",
       "      <td>0.071783</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.038996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301640</td>\n",
       "      <td>0.065566</td>\n",
       "      <td>0.350558</td>\n",
       "      <td>0.034295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.301688</td>\n",
       "      <td>0.034013</td>\n",
       "      <td>0.295086</td>\n",
       "      <td>0.058242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303563</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305983</td>\n",
       "      <td>0.067095</td>\n",
       "      <td>0.349222</td>\n",
       "      <td>0.035289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.311036</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>0.336489</td>\n",
       "      <td>0.038642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312155</td>\n",
       "      <td>0.058151</td>\n",
       "      <td>0.342988</td>\n",
       "      <td>0.043755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.314560</td>\n",
       "      <td>0.073926</td>\n",
       "      <td>0.334561</td>\n",
       "      <td>0.044023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.315396</td>\n",
       "      <td>0.098410</td>\n",
       "      <td>0.258818</td>\n",
       "      <td>0.089979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.318666</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.332368</td>\n",
       "      <td>0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.324171</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.329467</td>\n",
       "      <td>0.052956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324518</td>\n",
       "      <td>0.099955</td>\n",
       "      <td>0.259418</td>\n",
       "      <td>0.088546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.325360</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.325360</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.326397</td>\n",
       "      <td>0.081598</td>\n",
       "      <td>0.375988</td>\n",
       "      <td>0.113371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.327817</td>\n",
       "      <td>0.072968</td>\n",
       "      <td>0.327884</td>\n",
       "      <td>0.055946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.330718</td>\n",
       "      <td>0.069918</td>\n",
       "      <td>0.328412</td>\n",
       "      <td>0.056157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.332245</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>0.326097</td>\n",
       "      <td>0.059363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.333225</td>\n",
       "      <td>0.074841</td>\n",
       "      <td>0.375473</td>\n",
       "      <td>0.112484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.335583</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>0.109870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.335583</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>0.109870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335657</td>\n",
       "      <td>0.101631</td>\n",
       "      <td>0.260564</td>\n",
       "      <td>0.087354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337336</td>\n",
       "      <td>0.130104</td>\n",
       "      <td>0.390732</td>\n",
       "      <td>0.043883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.337488</td>\n",
       "      <td>0.071748</td>\n",
       "      <td>0.324063</td>\n",
       "      <td>0.063663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.339295</td>\n",
       "      <td>0.130873</td>\n",
       "      <td>0.393410</td>\n",
       "      <td>0.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.342433</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>0.255656</td>\n",
       "      <td>0.073663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.344328</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>0.316097</td>\n",
       "      <td>0.060761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.347025</td>\n",
       "      <td>0.033794</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.079528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348129</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.305526</td>\n",
       "      <td>0.034893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350150</td>\n",
       "      <td>0.102973</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.085574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350708</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.302595</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.352324</td>\n",
       "      <td>0.035266</td>\n",
       "      <td>0.255594</td>\n",
       "      <td>0.081496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353707</td>\n",
       "      <td>0.039670</td>\n",
       "      <td>0.299160</td>\n",
       "      <td>0.028737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357318</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.295012</td>\n",
       "      <td>0.023589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.359366</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.083043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359466</td>\n",
       "      <td>0.039734</td>\n",
       "      <td>0.292563</td>\n",
       "      <td>0.020651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362008</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.289711</td>\n",
       "      <td>0.017463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.363831</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.216066</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.363831</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.216066</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.364414</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>0.255698</td>\n",
       "      <td>0.082776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365126</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.286342</td>\n",
       "      <td>0.014032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.371146</td>\n",
       "      <td>0.044645</td>\n",
       "      <td>0.256015</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.374608</td>\n",
       "      <td>0.067666</td>\n",
       "      <td>0.337801</td>\n",
       "      <td>0.125979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.375624</td>\n",
       "      <td>0.123566</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>0.059611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376963</td>\n",
       "      <td>0.109118</td>\n",
       "      <td>0.300138</td>\n",
       "      <td>0.125292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.377514</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.377514</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378659</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>0.373034</td>\n",
       "      <td>0.062625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380412</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.256345</td>\n",
       "      <td>0.082113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390867</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.277128</td>\n",
       "      <td>0.148082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.394970</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.218784</td>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.394970</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.218784</td>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.406245</td>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.328546</td>\n",
       "      <td>0.131979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.417910</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.417910</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433097</td>\n",
       "      <td>0.085431</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.046248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433097</td>\n",
       "      <td>0.085431</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.046248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.443822</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.111131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.443822</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.111131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452620</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452620</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.479704</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.053432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479704</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.053432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.490854</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.490854</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.382029</td>\n",
       "      <td>0.382029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.096467</td>\n",
       "      <td>0.096467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.050630</td>\n",
       "      <td>0.050630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.028504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.009089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.004410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.02522862129908343, 0.025163581636640342, -0.07364967084625151, -0.21854703231558892, -0.36320442525420504]\n",
      "overall_score:\n",
      "-0.12100178509606434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.285414</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.298713</td>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.285414</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.298713</td>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300585</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.319323</td>\n",
       "      <td>0.067024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304495</td>\n",
       "      <td>0.120749</td>\n",
       "      <td>0.276454</td>\n",
       "      <td>0.067585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.311944</td>\n",
       "      <td>0.131912</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.070760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321352</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0.276253</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.324230</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.324230</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327913</td>\n",
       "      <td>0.067239</td>\n",
       "      <td>0.341078</td>\n",
       "      <td>0.061043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334452</td>\n",
       "      <td>0.140091</td>\n",
       "      <td>0.276935</td>\n",
       "      <td>0.070247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.337538</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.368947</td>\n",
       "      <td>0.077641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.342223</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.368398</td>\n",
       "      <td>0.076590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343175</td>\n",
       "      <td>0.142158</td>\n",
       "      <td>0.278188</td>\n",
       "      <td>0.070289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.344851</td>\n",
       "      <td>0.061754</td>\n",
       "      <td>0.337880</td>\n",
       "      <td>0.033026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.345440</td>\n",
       "      <td>0.064166</td>\n",
       "      <td>0.334902</td>\n",
       "      <td>0.036291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.347131</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>0.331073</td>\n",
       "      <td>0.037787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.348110</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.355173</td>\n",
       "      <td>0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.348110</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.355173</td>\n",
       "      <td>0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.349669</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.326368</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350318</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.349656</td>\n",
       "      <td>0.046702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.351702</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.323294</td>\n",
       "      <td>0.041930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353826</td>\n",
       "      <td>0.144244</td>\n",
       "      <td>0.280347</td>\n",
       "      <td>0.070758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.354124</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.312422</td>\n",
       "      <td>0.057298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.354698</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.319875</td>\n",
       "      <td>0.043896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355962</td>\n",
       "      <td>0.119837</td>\n",
       "      <td>0.348240</td>\n",
       "      <td>0.090726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.358862</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.315860</td>\n",
       "      <td>0.047020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359631</td>\n",
       "      <td>0.113483</td>\n",
       "      <td>0.344839</td>\n",
       "      <td>0.073175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.359868</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.354737</td>\n",
       "      <td>0.043573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.363585</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.363585</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.364220</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.364533</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.037108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.365554</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365554</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.366133</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.359814</td>\n",
       "      <td>0.038225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367200</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>0.284069</td>\n",
       "      <td>0.071861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.368016</td>\n",
       "      <td>0.092195</td>\n",
       "      <td>0.359188</td>\n",
       "      <td>0.035592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.368472</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.336913</td>\n",
       "      <td>0.056795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370383</td>\n",
       "      <td>0.078174</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>0.045049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.370514</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.363814</td>\n",
       "      <td>0.041289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.372614</td>\n",
       "      <td>0.092474</td>\n",
       "      <td>0.358390</td>\n",
       "      <td>0.036465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.372665</td>\n",
       "      <td>0.086650</td>\n",
       "      <td>0.358909</td>\n",
       "      <td>0.029829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.374045</td>\n",
       "      <td>0.070226</td>\n",
       "      <td>0.333590</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374292</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.388962</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.374292</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.388962</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376441</td>\n",
       "      <td>0.043951</td>\n",
       "      <td>0.256594</td>\n",
       "      <td>0.071256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.378945</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>0.221267</td>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.378945</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>0.221267</td>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.379681</td>\n",
       "      <td>0.097342</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.148586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.379681</td>\n",
       "      <td>0.097342</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.148586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380595</td>\n",
       "      <td>0.047816</td>\n",
       "      <td>0.255355</td>\n",
       "      <td>0.079440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383012</td>\n",
       "      <td>0.075569</td>\n",
       "      <td>0.359680</td>\n",
       "      <td>0.041392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385123</td>\n",
       "      <td>0.072903</td>\n",
       "      <td>0.359459</td>\n",
       "      <td>0.039081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.385716</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.254623</td>\n",
       "      <td>0.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.386045</td>\n",
       "      <td>0.070844</td>\n",
       "      <td>0.354320</td>\n",
       "      <td>0.037626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.387811</td>\n",
       "      <td>0.068986</td>\n",
       "      <td>0.350749</td>\n",
       "      <td>0.038258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388910</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.318575</td>\n",
       "      <td>0.074520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389411</td>\n",
       "      <td>0.076709</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.038957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390217</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.357353</td>\n",
       "      <td>0.035709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.392408</td>\n",
       "      <td>0.051154</td>\n",
       "      <td>0.253489</td>\n",
       "      <td>0.088712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393555</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.346417</td>\n",
       "      <td>0.040194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.395240</td>\n",
       "      <td>0.083594</td>\n",
       "      <td>0.401948</td>\n",
       "      <td>0.154185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.395730</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>0.044928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.395730</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>0.044928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.397175</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.251956</td>\n",
       "      <td>0.090524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.400629</td>\n",
       "      <td>0.076749</td>\n",
       "      <td>0.399760</td>\n",
       "      <td>0.154282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.403833</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>0.250554</td>\n",
       "      <td>0.092793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.405266</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.037445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413535</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.095563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.418534</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.418534</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424915</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>0.300880</td>\n",
       "      <td>0.027111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.425065</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>0.028502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.425614</td>\n",
       "      <td>0.050878</td>\n",
       "      <td>0.300536</td>\n",
       "      <td>0.028191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.427059</td>\n",
       "      <td>0.051088</td>\n",
       "      <td>0.300229</td>\n",
       "      <td>0.028005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.428107</td>\n",
       "      <td>0.051122</td>\n",
       "      <td>0.300102</td>\n",
       "      <td>0.027869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429290</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>0.299920</td>\n",
       "      <td>0.027793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.430592</td>\n",
       "      <td>0.050967</td>\n",
       "      <td>0.299757</td>\n",
       "      <td>0.027724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433229</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.228778</td>\n",
       "      <td>0.045213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433229</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.228778</td>\n",
       "      <td>0.045213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.435098</td>\n",
       "      <td>0.093692</td>\n",
       "      <td>0.363372</td>\n",
       "      <td>0.072388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.436364</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.073816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450775</td>\n",
       "      <td>0.098792</td>\n",
       "      <td>0.375888</td>\n",
       "      <td>0.155372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.462844</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.368592</td>\n",
       "      <td>0.074591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466339</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>0.284734</td>\n",
       "      <td>0.118238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.469952</td>\n",
       "      <td>0.089226</td>\n",
       "      <td>0.372521</td>\n",
       "      <td>0.075975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.470453</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.470453</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.471184</td>\n",
       "      <td>0.110872</td>\n",
       "      <td>0.266708</td>\n",
       "      <td>0.127714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.479305</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.053128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479305</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.053128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.484671</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>0.356781</td>\n",
       "      <td>0.151985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.493742</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.366265</td>\n",
       "      <td>0.163585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.493742</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.366265</td>\n",
       "      <td>0.163585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.520835</td>\n",
       "      <td>0.280856</td>\n",
       "      <td>0.280856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.053674</td>\n",
       "      <td>0.053674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>0.521283</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.037669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.454181</td>\n",
       "      <td>0.030541</td>\n",
       "      <td>0.030541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.443326</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.030219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.452073</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.028686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.448212</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>0.331615</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.022058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.301765</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.017198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>-0.325563</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.262815</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.010228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.190043</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.005946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RS</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.003983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.118715</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.111035</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.138684</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.072272</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.036881</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.521</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.443</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.119</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.448</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.12\n",
      "1          EDM                0.12\n",
      "2       BIS_11               -0.12\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.12\n",
      "5                       TRSQ                0.12\n",
      "6  ACES_neglectful_parenting               -0.12\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.07167791037502114, 0.24492189245152451, -0.03458314399518536, 0.06626360968232647, -0.3269010931716918]\n",
      "overall_score:\n",
      "0.004275835068398992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292519</td>\n",
       "      <td>0.099375</td>\n",
       "      <td>0.274949</td>\n",
       "      <td>0.104974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298002</td>\n",
       "      <td>0.110155</td>\n",
       "      <td>0.276507</td>\n",
       "      <td>0.108841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305850</td>\n",
       "      <td>0.115535</td>\n",
       "      <td>0.278478</td>\n",
       "      <td>0.107369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.315633</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.303890</td>\n",
       "      <td>0.040323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.315633</td>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.303890</td>\n",
       "      <td>0.040323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.316877</td>\n",
       "      <td>0.120681</td>\n",
       "      <td>0.280725</td>\n",
       "      <td>0.105875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324399</td>\n",
       "      <td>0.122960</td>\n",
       "      <td>0.282225</td>\n",
       "      <td>0.104459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334027</td>\n",
       "      <td>0.125584</td>\n",
       "      <td>0.285072</td>\n",
       "      <td>0.103018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342245</td>\n",
       "      <td>0.058045</td>\n",
       "      <td>0.321634</td>\n",
       "      <td>0.095602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346213</td>\n",
       "      <td>0.128463</td>\n",
       "      <td>0.289095</td>\n",
       "      <td>0.100940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.367643</td>\n",
       "      <td>0.079562</td>\n",
       "      <td>0.226238</td>\n",
       "      <td>0.047589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.367643</td>\n",
       "      <td>0.079562</td>\n",
       "      <td>0.226238</td>\n",
       "      <td>0.047589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380499</td>\n",
       "      <td>0.084927</td>\n",
       "      <td>0.225908</td>\n",
       "      <td>0.047948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380499</td>\n",
       "      <td>0.084927</td>\n",
       "      <td>0.225908</td>\n",
       "      <td>0.047948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388322</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.352111</td>\n",
       "      <td>0.055689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.388322</td>\n",
       "      <td>0.044583</td>\n",
       "      <td>0.352111</td>\n",
       "      <td>0.055689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.393458</td>\n",
       "      <td>0.039661</td>\n",
       "      <td>0.288909</td>\n",
       "      <td>0.067836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.396111</td>\n",
       "      <td>0.042904</td>\n",
       "      <td>0.287466</td>\n",
       "      <td>0.076282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.396794</td>\n",
       "      <td>0.085091</td>\n",
       "      <td>0.226318</td>\n",
       "      <td>0.044876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.396794</td>\n",
       "      <td>0.085091</td>\n",
       "      <td>0.226318</td>\n",
       "      <td>0.044876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.398875</td>\n",
       "      <td>0.064958</td>\n",
       "      <td>0.343910</td>\n",
       "      <td>0.071566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.399459</td>\n",
       "      <td>0.045712</td>\n",
       "      <td>0.329425</td>\n",
       "      <td>0.053475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.400005</td>\n",
       "      <td>0.043610</td>\n",
       "      <td>0.285539</td>\n",
       "      <td>0.081671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.405297</td>\n",
       "      <td>0.044748</td>\n",
       "      <td>0.283145</td>\n",
       "      <td>0.088169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.409047</td>\n",
       "      <td>0.045946</td>\n",
       "      <td>0.280895</td>\n",
       "      <td>0.091644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.414088</td>\n",
       "      <td>0.072566</td>\n",
       "      <td>0.314818</td>\n",
       "      <td>0.039976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.414268</td>\n",
       "      <td>0.071231</td>\n",
       "      <td>0.311500</td>\n",
       "      <td>0.039523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.414419</td>\n",
       "      <td>0.073211</td>\n",
       "      <td>0.317402</td>\n",
       "      <td>0.040642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.414754</td>\n",
       "      <td>0.047981</td>\n",
       "      <td>0.278977</td>\n",
       "      <td>0.095506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415580</td>\n",
       "      <td>0.074423</td>\n",
       "      <td>0.321611</td>\n",
       "      <td>0.042193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415643</td>\n",
       "      <td>0.069446</td>\n",
       "      <td>0.306860</td>\n",
       "      <td>0.040289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.416912</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>0.324860</td>\n",
       "      <td>0.043550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.418065</td>\n",
       "      <td>0.072689</td>\n",
       "      <td>0.327607</td>\n",
       "      <td>0.042087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.419252</td>\n",
       "      <td>0.085585</td>\n",
       "      <td>0.228943</td>\n",
       "      <td>0.043293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.419252</td>\n",
       "      <td>0.085585</td>\n",
       "      <td>0.228943</td>\n",
       "      <td>0.043293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.419631</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.363284</td>\n",
       "      <td>0.044207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.419631</td>\n",
       "      <td>0.072793</td>\n",
       "      <td>0.363284</td>\n",
       "      <td>0.044207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.422526</td>\n",
       "      <td>0.050606</td>\n",
       "      <td>0.276800</td>\n",
       "      <td>0.100375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.426528</td>\n",
       "      <td>0.074025</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.058233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.431978</td>\n",
       "      <td>0.072443</td>\n",
       "      <td>0.376571</td>\n",
       "      <td>0.090512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433570</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.231204</td>\n",
       "      <td>0.044279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433570</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.231204</td>\n",
       "      <td>0.044279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.434043</td>\n",
       "      <td>0.074056</td>\n",
       "      <td>0.384107</td>\n",
       "      <td>0.145374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.434043</td>\n",
       "      <td>0.074056</td>\n",
       "      <td>0.384107</td>\n",
       "      <td>0.145374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.434576</td>\n",
       "      <td>0.091508</td>\n",
       "      <td>0.380436</td>\n",
       "      <td>0.154988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.434576</td>\n",
       "      <td>0.091508</td>\n",
       "      <td>0.380436</td>\n",
       "      <td>0.154988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.437685</td>\n",
       "      <td>0.068730</td>\n",
       "      <td>0.375729</td>\n",
       "      <td>0.091438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.439356</td>\n",
       "      <td>0.069140</td>\n",
       "      <td>0.353403</td>\n",
       "      <td>0.055166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.439685</td>\n",
       "      <td>0.077324</td>\n",
       "      <td>0.366048</td>\n",
       "      <td>0.044254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.441275</td>\n",
       "      <td>0.121245</td>\n",
       "      <td>0.377220</td>\n",
       "      <td>0.099869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.441936</td>\n",
       "      <td>0.133588</td>\n",
       "      <td>0.378679</td>\n",
       "      <td>0.113190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442319</td>\n",
       "      <td>0.126417</td>\n",
       "      <td>0.358963</td>\n",
       "      <td>0.067249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442319</td>\n",
       "      <td>0.126417</td>\n",
       "      <td>0.358963</td>\n",
       "      <td>0.067249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442319</td>\n",
       "      <td>0.126417</td>\n",
       "      <td>0.358963</td>\n",
       "      <td>0.067249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442319</td>\n",
       "      <td>0.126417</td>\n",
       "      <td>0.358963</td>\n",
       "      <td>0.067249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.445969</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>0.373372</td>\n",
       "      <td>0.039973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.445969</td>\n",
       "      <td>0.084368</td>\n",
       "      <td>0.373372</td>\n",
       "      <td>0.039973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.448246</td>\n",
       "      <td>0.085051</td>\n",
       "      <td>0.373125</td>\n",
       "      <td>0.040256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452239</td>\n",
       "      <td>0.083428</td>\n",
       "      <td>0.234745</td>\n",
       "      <td>0.047679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452239</td>\n",
       "      <td>0.083428</td>\n",
       "      <td>0.234745</td>\n",
       "      <td>0.047679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.452338</td>\n",
       "      <td>0.081125</td>\n",
       "      <td>0.360736</td>\n",
       "      <td>0.043918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.454779</td>\n",
       "      <td>0.087553</td>\n",
       "      <td>0.370841</td>\n",
       "      <td>0.037578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.457254</td>\n",
       "      <td>0.088520</td>\n",
       "      <td>0.369335</td>\n",
       "      <td>0.038879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459062</td>\n",
       "      <td>0.083996</td>\n",
       "      <td>0.373782</td>\n",
       "      <td>0.039639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.459264</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.373705</td>\n",
       "      <td>0.039670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459264</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.373705</td>\n",
       "      <td>0.039670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459264</td>\n",
       "      <td>0.084273</td>\n",
       "      <td>0.373705</td>\n",
       "      <td>0.039670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.462372</td>\n",
       "      <td>0.089842</td>\n",
       "      <td>0.367133</td>\n",
       "      <td>0.044121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466246</td>\n",
       "      <td>0.081251</td>\n",
       "      <td>0.369643</td>\n",
       "      <td>0.043781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468815</td>\n",
       "      <td>0.091337</td>\n",
       "      <td>0.363959</td>\n",
       "      <td>0.043586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.470570</td>\n",
       "      <td>0.073873</td>\n",
       "      <td>0.385477</td>\n",
       "      <td>0.133868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.471103</td>\n",
       "      <td>0.090865</td>\n",
       "      <td>0.383086</td>\n",
       "      <td>0.138240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.477174</td>\n",
       "      <td>0.082891</td>\n",
       "      <td>0.371898</td>\n",
       "      <td>0.040294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.477174</td>\n",
       "      <td>0.082891</td>\n",
       "      <td>0.371898</td>\n",
       "      <td>0.040294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.477174</td>\n",
       "      <td>0.082891</td>\n",
       "      <td>0.371898</td>\n",
       "      <td>0.040294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.477174</td>\n",
       "      <td>0.082891</td>\n",
       "      <td>0.371898</td>\n",
       "      <td>0.040294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478247</td>\n",
       "      <td>0.083574</td>\n",
       "      <td>0.341610</td>\n",
       "      <td>0.062252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478913</td>\n",
       "      <td>0.081449</td>\n",
       "      <td>0.241575</td>\n",
       "      <td>0.052796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.478913</td>\n",
       "      <td>0.081449</td>\n",
       "      <td>0.241575</td>\n",
       "      <td>0.052796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.479962</td>\n",
       "      <td>0.078233</td>\n",
       "      <td>0.361738</td>\n",
       "      <td>0.041086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480110</td>\n",
       "      <td>0.069608</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.050324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480298</td>\n",
       "      <td>0.075436</td>\n",
       "      <td>0.357047</td>\n",
       "      <td>0.044473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.482077</td>\n",
       "      <td>0.081705</td>\n",
       "      <td>0.370065</td>\n",
       "      <td>0.041756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.482504</td>\n",
       "      <td>0.077390</td>\n",
       "      <td>0.368863</td>\n",
       "      <td>0.039760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.482933</td>\n",
       "      <td>0.058507</td>\n",
       "      <td>0.326248</td>\n",
       "      <td>0.058033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488159</td>\n",
       "      <td>0.050604</td>\n",
       "      <td>0.279601</td>\n",
       "      <td>0.082573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488202</td>\n",
       "      <td>0.051675</td>\n",
       "      <td>0.278146</td>\n",
       "      <td>0.084074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488470</td>\n",
       "      <td>0.052307</td>\n",
       "      <td>0.277354</td>\n",
       "      <td>0.084912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488767</td>\n",
       "      <td>0.049806</td>\n",
       "      <td>0.280904</td>\n",
       "      <td>0.081262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489101</td>\n",
       "      <td>0.052880</td>\n",
       "      <td>0.276471</td>\n",
       "      <td>0.085698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489257</td>\n",
       "      <td>0.046363</td>\n",
       "      <td>0.282109</td>\n",
       "      <td>0.075518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489372</td>\n",
       "      <td>0.080539</td>\n",
       "      <td>0.369487</td>\n",
       "      <td>0.040892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489885</td>\n",
       "      <td>0.053378</td>\n",
       "      <td>0.275573</td>\n",
       "      <td>0.086440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490617</td>\n",
       "      <td>0.077328</td>\n",
       "      <td>0.368706</td>\n",
       "      <td>0.038603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491336</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.368853</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.501816</td>\n",
       "      <td>0.107404</td>\n",
       "      <td>0.383708</td>\n",
       "      <td>0.048247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.501816</td>\n",
       "      <td>0.107404</td>\n",
       "      <td>0.383708</td>\n",
       "      <td>0.048247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.501816</td>\n",
       "      <td>0.107404</td>\n",
       "      <td>0.383708</td>\n",
       "      <td>0.048247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.501816</td>\n",
       "      <td>0.107404</td>\n",
       "      <td>0.383708</td>\n",
       "      <td>0.048247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.503426</td>\n",
       "      <td>0.090842</td>\n",
       "      <td>0.321662</td>\n",
       "      <td>0.075819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.507495</td>\n",
       "      <td>0.111667</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.065443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510443</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.343271</td>\n",
       "      <td>0.176210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.510443</td>\n",
       "      <td>0.118388</td>\n",
       "      <td>0.343271</td>\n",
       "      <td>0.176210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.510606</td>\n",
       "      <td>0.127677</td>\n",
       "      <td>0.358811</td>\n",
       "      <td>0.087244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.510606</td>\n",
       "      <td>0.127677</td>\n",
       "      <td>0.358811</td>\n",
       "      <td>0.087244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.510606</td>\n",
       "      <td>0.127677</td>\n",
       "      <td>0.358811</td>\n",
       "      <td>0.087244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.510606</td>\n",
       "      <td>0.127677</td>\n",
       "      <td>0.358811</td>\n",
       "      <td>0.087244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.512838</td>\n",
       "      <td>0.121863</td>\n",
       "      <td>0.377351</td>\n",
       "      <td>0.122567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.521453</td>\n",
       "      <td>0.095789</td>\n",
       "      <td>0.360165</td>\n",
       "      <td>0.168045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521453</td>\n",
       "      <td>0.095789</td>\n",
       "      <td>0.360165</td>\n",
       "      <td>0.168045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.522564</td>\n",
       "      <td>0.110277</td>\n",
       "      <td>0.381273</td>\n",
       "      <td>0.070098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.522564</td>\n",
       "      <td>0.110277</td>\n",
       "      <td>0.381273</td>\n",
       "      <td>0.070098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.522564</td>\n",
       "      <td>0.110277</td>\n",
       "      <td>0.381273</td>\n",
       "      <td>0.070098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.522564</td>\n",
       "      <td>0.110277</td>\n",
       "      <td>0.381273</td>\n",
       "      <td>0.070098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.523476</td>\n",
       "      <td>0.106964</td>\n",
       "      <td>0.385398</td>\n",
       "      <td>0.106540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.525427</td>\n",
       "      <td>0.130341</td>\n",
       "      <td>0.296701</td>\n",
       "      <td>0.107129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.542057</td>\n",
       "      <td>0.118093</td>\n",
       "      <td>0.300088</td>\n",
       "      <td>0.075229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.542672</td>\n",
       "      <td>0.107555</td>\n",
       "      <td>0.386958</td>\n",
       "      <td>0.081783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.542874</td>\n",
       "      <td>0.107577</td>\n",
       "      <td>0.387210</td>\n",
       "      <td>0.081898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.551861</td>\n",
       "      <td>0.100143</td>\n",
       "      <td>0.355709</td>\n",
       "      <td>0.106519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.557257</td>\n",
       "      <td>0.101899</td>\n",
       "      <td>0.353399</td>\n",
       "      <td>0.116768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.647353</td>\n",
       "      <td>2.375551</td>\n",
       "      <td>2.375551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.085276</td>\n",
       "      <td>1.798008</td>\n",
       "      <td>1.798008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.757856</td>\n",
       "      <td>1.515308</td>\n",
       "      <td>1.515308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.459315</td>\n",
       "      <td>0.678605</td>\n",
       "      <td>0.678605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.159988</td>\n",
       "      <td>0.541177</td>\n",
       "      <td>0.541177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.129124</td>\n",
       "      <td>0.520743</td>\n",
       "      <td>0.520743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.865242</td>\n",
       "      <td>0.383996</td>\n",
       "      <td>0.383996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.704666</td>\n",
       "      <td>0.306805</td>\n",
       "      <td>0.306805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-1.053132</td>\n",
       "      <td>0.115208</td>\n",
       "      <td>0.115208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.921492</td>\n",
       "      <td>0.100176</td>\n",
       "      <td>0.100176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.854633</td>\n",
       "      <td>0.092245</td>\n",
       "      <td>0.092245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>-0.853379</td>\n",
       "      <td>0.076963</td>\n",
       "      <td>0.076963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.689761</td>\n",
       "      <td>0.047585</td>\n",
       "      <td>0.047585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.480614</td>\n",
       "      <td>0.022190</td>\n",
       "      <td>0.022190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.415275</td>\n",
       "      <td>0.015542</td>\n",
       "      <td>0.015542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.430462</td>\n",
       "      <td>0.015509</td>\n",
       "      <td>0.015509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.307431</td>\n",
       "      <td>0.013157</td>\n",
       "      <td>0.013157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.387403</td>\n",
       "      <td>0.010568</td>\n",
       "      <td>0.010568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.220563</td>\n",
       "      <td>0.006838</td>\n",
       "      <td>0.006838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>0.179529</td>\n",
       "      <td>0.005994</td>\n",
       "      <td>0.005994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.647</td>\n",
       "      <td>0.221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.376</td>\n",
       "      <td>0.007</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>2.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>1.798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.758</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.679</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.160</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.855</td>\n",
       "      <td>-1.053</td>\n",
       "      <td>-0.415</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.921</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_conscientiousness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.481</td>\n",
       "      <td>-0.430</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.307</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.011</td>\n",
       "      <td>-0.037</td>\n",
       "      <td>-0.387</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.14\n",
      "1          EDM                0.14\n",
      "2       BIS_11               -0.14\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.14\n",
      "5                       TRSQ                0.14\n",
      "6  ACES_neglectful_parenting               -0.14\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.12475068446440762, 0.29341133364449246, 0.2381192241042619, -0.09933365979467168, -0.28470751836858454]\n",
      "overall_score:\n",
      "0.05444801280998115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.297242</td>\n",
       "      <td>0.113614</td>\n",
       "      <td>0.265083</td>\n",
       "      <td>0.100870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.302255</td>\n",
       "      <td>0.123156</td>\n",
       "      <td>0.264094</td>\n",
       "      <td>0.105871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.308595</td>\n",
       "      <td>0.126664</td>\n",
       "      <td>0.263906</td>\n",
       "      <td>0.106069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.317413</td>\n",
       "      <td>0.130538</td>\n",
       "      <td>0.264239</td>\n",
       "      <td>0.107501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324057</td>\n",
       "      <td>0.131626</td>\n",
       "      <td>0.264591</td>\n",
       "      <td>0.108446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.332499</td>\n",
       "      <td>0.132190</td>\n",
       "      <td>0.265640</td>\n",
       "      <td>0.109458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.338442</td>\n",
       "      <td>0.051539</td>\n",
       "      <td>0.308855</td>\n",
       "      <td>0.039318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.338442</td>\n",
       "      <td>0.051539</td>\n",
       "      <td>0.308855</td>\n",
       "      <td>0.039318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343705</td>\n",
       "      <td>0.133011</td>\n",
       "      <td>0.268242</td>\n",
       "      <td>0.111221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.370348</td>\n",
       "      <td>0.080335</td>\n",
       "      <td>0.231593</td>\n",
       "      <td>0.047919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.370348</td>\n",
       "      <td>0.080335</td>\n",
       "      <td>0.231593</td>\n",
       "      <td>0.047919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.379331</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.328711</td>\n",
       "      <td>0.114257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.382658</td>\n",
       "      <td>0.085462</td>\n",
       "      <td>0.230498</td>\n",
       "      <td>0.048360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.382658</td>\n",
       "      <td>0.085462</td>\n",
       "      <td>0.230498</td>\n",
       "      <td>0.048360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.398045</td>\n",
       "      <td>0.085407</td>\n",
       "      <td>0.230281</td>\n",
       "      <td>0.045094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.398045</td>\n",
       "      <td>0.085407</td>\n",
       "      <td>0.230281</td>\n",
       "      <td>0.045094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415467</td>\n",
       "      <td>0.052452</td>\n",
       "      <td>0.303278</td>\n",
       "      <td>0.067288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.416859</td>\n",
       "      <td>0.055115</td>\n",
       "      <td>0.303222</td>\n",
       "      <td>0.073636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.419255</td>\n",
       "      <td>0.054205</td>\n",
       "      <td>0.302626</td>\n",
       "      <td>0.077505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.420054</td>\n",
       "      <td>0.085407</td>\n",
       "      <td>0.231980</td>\n",
       "      <td>0.042826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.420054</td>\n",
       "      <td>0.085407</td>\n",
       "      <td>0.231980</td>\n",
       "      <td>0.042826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.423115</td>\n",
       "      <td>0.053823</td>\n",
       "      <td>0.301845</td>\n",
       "      <td>0.082985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.426267</td>\n",
       "      <td>0.054279</td>\n",
       "      <td>0.300702</td>\n",
       "      <td>0.086095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.430558</td>\n",
       "      <td>0.055132</td>\n",
       "      <td>0.300216</td>\n",
       "      <td>0.090152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.434036</td>\n",
       "      <td>0.084883</td>\n",
       "      <td>0.233601</td>\n",
       "      <td>0.043567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.434036</td>\n",
       "      <td>0.084883</td>\n",
       "      <td>0.233601</td>\n",
       "      <td>0.043567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436921</td>\n",
       "      <td>0.056877</td>\n",
       "      <td>0.299707</td>\n",
       "      <td>0.095797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.438341</td>\n",
       "      <td>0.049677</td>\n",
       "      <td>0.343960</td>\n",
       "      <td>0.063794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.451276</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>0.365916</td>\n",
       "      <td>0.061669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.451276</td>\n",
       "      <td>0.042208</td>\n",
       "      <td>0.365916</td>\n",
       "      <td>0.061669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452108</td>\n",
       "      <td>0.063016</td>\n",
       "      <td>0.342383</td>\n",
       "      <td>0.096097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452201</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>0.236561</td>\n",
       "      <td>0.047091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452201</td>\n",
       "      <td>0.083216</td>\n",
       "      <td>0.236561</td>\n",
       "      <td>0.047091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452476</td>\n",
       "      <td>0.062706</td>\n",
       "      <td>0.340563</td>\n",
       "      <td>0.096335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452707</td>\n",
       "      <td>0.063753</td>\n",
       "      <td>0.343303</td>\n",
       "      <td>0.096321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.453692</td>\n",
       "      <td>0.061988</td>\n",
       "      <td>0.338073</td>\n",
       "      <td>0.096969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455926</td>\n",
       "      <td>0.065562</td>\n",
       "      <td>0.343578</td>\n",
       "      <td>0.095337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459512</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.343846</td>\n",
       "      <td>0.094167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.463229</td>\n",
       "      <td>0.063631</td>\n",
       "      <td>0.344422</td>\n",
       "      <td>0.087439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.467185</td>\n",
       "      <td>0.072671</td>\n",
       "      <td>0.357334</td>\n",
       "      <td>0.083739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478538</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.242560</td>\n",
       "      <td>0.052399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.478538</td>\n",
       "      <td>0.081094</td>\n",
       "      <td>0.242560</td>\n",
       "      <td>0.052399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.495428</td>\n",
       "      <td>0.075682</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.049888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.495428</td>\n",
       "      <td>0.075682</td>\n",
       "      <td>0.373252</td>\n",
       "      <td>0.049888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.519723</td>\n",
       "      <td>0.075571</td>\n",
       "      <td>0.359369</td>\n",
       "      <td>0.062229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.520554</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.364951</td>\n",
       "      <td>0.064104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.524796</td>\n",
       "      <td>0.086362</td>\n",
       "      <td>0.381456</td>\n",
       "      <td>0.180834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.524796</td>\n",
       "      <td>0.086362</td>\n",
       "      <td>0.381456</td>\n",
       "      <td>0.180834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.529624</td>\n",
       "      <td>0.083069</td>\n",
       "      <td>0.373101</td>\n",
       "      <td>0.047629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.533859</td>\n",
       "      <td>0.086474</td>\n",
       "      <td>0.385505</td>\n",
       "      <td>0.049532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.533859</td>\n",
       "      <td>0.086474</td>\n",
       "      <td>0.385505</td>\n",
       "      <td>0.049532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.537952</td>\n",
       "      <td>0.099954</td>\n",
       "      <td>0.386886</td>\n",
       "      <td>0.176697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.537952</td>\n",
       "      <td>0.099954</td>\n",
       "      <td>0.386886</td>\n",
       "      <td>0.176697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541318</td>\n",
       "      <td>0.085479</td>\n",
       "      <td>0.383720</td>\n",
       "      <td>0.052523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.543604</td>\n",
       "      <td>0.086768</td>\n",
       "      <td>0.375524</td>\n",
       "      <td>0.069193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.543848</td>\n",
       "      <td>0.084169</td>\n",
       "      <td>0.383731</td>\n",
       "      <td>0.056733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.545161</td>\n",
       "      <td>0.083603</td>\n",
       "      <td>0.385169</td>\n",
       "      <td>0.051523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.545299</td>\n",
       "      <td>0.085787</td>\n",
       "      <td>0.381634</td>\n",
       "      <td>0.062408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552215</td>\n",
       "      <td>0.165963</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.122079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.553312</td>\n",
       "      <td>0.092125</td>\n",
       "      <td>0.368289</td>\n",
       "      <td>0.051197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555458</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>0.385422</td>\n",
       "      <td>0.052820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555458</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>0.385422</td>\n",
       "      <td>0.052820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555458</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>0.385422</td>\n",
       "      <td>0.052820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555458</td>\n",
       "      <td>0.162755</td>\n",
       "      <td>0.385422</td>\n",
       "      <td>0.052820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.556383</td>\n",
       "      <td>0.168663</td>\n",
       "      <td>0.381433</td>\n",
       "      <td>0.102800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.558094</td>\n",
       "      <td>0.085904</td>\n",
       "      <td>0.387393</td>\n",
       "      <td>0.042964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.559591</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.386742</td>\n",
       "      <td>0.042759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.559591</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.386742</td>\n",
       "      <td>0.042759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.559591</td>\n",
       "      <td>0.086656</td>\n",
       "      <td>0.386742</td>\n",
       "      <td>0.042759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.562502</td>\n",
       "      <td>0.089551</td>\n",
       "      <td>0.338594</td>\n",
       "      <td>0.220984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.562502</td>\n",
       "      <td>0.089551</td>\n",
       "      <td>0.338594</td>\n",
       "      <td>0.220984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576355</td>\n",
       "      <td>0.087399</td>\n",
       "      <td>0.379138</td>\n",
       "      <td>0.046209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.576485</td>\n",
       "      <td>0.107278</td>\n",
       "      <td>0.324646</td>\n",
       "      <td>0.220895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.576485</td>\n",
       "      <td>0.107278</td>\n",
       "      <td>0.324646</td>\n",
       "      <td>0.220895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.577496</td>\n",
       "      <td>0.078634</td>\n",
       "      <td>0.359434</td>\n",
       "      <td>0.054981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.577526</td>\n",
       "      <td>0.080076</td>\n",
       "      <td>0.366979</td>\n",
       "      <td>0.052516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.579455</td>\n",
       "      <td>0.050331</td>\n",
       "      <td>0.373438</td>\n",
       "      <td>0.163966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.580884</td>\n",
       "      <td>0.082469</td>\n",
       "      <td>0.371221</td>\n",
       "      <td>0.046634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.581482</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.042303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.581482</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.042303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.581482</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.042303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.581482</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.383519</td>\n",
       "      <td>0.042303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.587971</td>\n",
       "      <td>0.081891</td>\n",
       "      <td>0.381060</td>\n",
       "      <td>0.041920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.588095</td>\n",
       "      <td>0.076962</td>\n",
       "      <td>0.335917</td>\n",
       "      <td>0.050031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589714</td>\n",
       "      <td>0.101343</td>\n",
       "      <td>0.408932</td>\n",
       "      <td>0.058251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589714</td>\n",
       "      <td>0.101343</td>\n",
       "      <td>0.408932</td>\n",
       "      <td>0.058251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589714</td>\n",
       "      <td>0.101343</td>\n",
       "      <td>0.408932</td>\n",
       "      <td>0.058251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589714</td>\n",
       "      <td>0.101343</td>\n",
       "      <td>0.408932</td>\n",
       "      <td>0.058251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.590838</td>\n",
       "      <td>0.105426</td>\n",
       "      <td>0.410442</td>\n",
       "      <td>0.132304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.591678</td>\n",
       "      <td>0.101830</td>\n",
       "      <td>0.418865</td>\n",
       "      <td>0.123855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.592611</td>\n",
       "      <td>0.069935</td>\n",
       "      <td>0.374182</td>\n",
       "      <td>0.152385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.592682</td>\n",
       "      <td>0.087744</td>\n",
       "      <td>0.380420</td>\n",
       "      <td>0.043823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598077</td>\n",
       "      <td>0.085509</td>\n",
       "      <td>0.381050</td>\n",
       "      <td>0.043420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.599950</td>\n",
       "      <td>0.082014</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>0.043045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.599950</td>\n",
       "      <td>0.082014</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>0.043045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.599950</td>\n",
       "      <td>0.082014</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>0.043045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.599950</td>\n",
       "      <td>0.082014</td>\n",
       "      <td>0.380743</td>\n",
       "      <td>0.043045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.603897</td>\n",
       "      <td>0.082913</td>\n",
       "      <td>0.379690</td>\n",
       "      <td>0.042239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604636</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>0.379878</td>\n",
       "      <td>0.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611334</td>\n",
       "      <td>0.075183</td>\n",
       "      <td>0.318503</td>\n",
       "      <td>0.043127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.611591</td>\n",
       "      <td>0.122069</td>\n",
       "      <td>0.388424</td>\n",
       "      <td>0.053059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611697</td>\n",
       "      <td>0.079445</td>\n",
       "      <td>0.318475</td>\n",
       "      <td>0.046232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.612092</td>\n",
       "      <td>0.079178</td>\n",
       "      <td>0.318424</td>\n",
       "      <td>0.046667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.612823</td>\n",
       "      <td>0.078882</td>\n",
       "      <td>0.318128</td>\n",
       "      <td>0.047169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613318</td>\n",
       "      <td>0.078652</td>\n",
       "      <td>0.317878</td>\n",
       "      <td>0.047521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613897</td>\n",
       "      <td>0.078272</td>\n",
       "      <td>0.317532</td>\n",
       "      <td>0.048023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.614535</td>\n",
       "      <td>0.077766</td>\n",
       "      <td>0.317230</td>\n",
       "      <td>0.048545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615428</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.080505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615428</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.080505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615428</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.080505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615428</td>\n",
       "      <td>0.134389</td>\n",
       "      <td>0.381410</td>\n",
       "      <td>0.080505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.624477</td>\n",
       "      <td>0.108780</td>\n",
       "      <td>0.384444</td>\n",
       "      <td>0.062649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.624477</td>\n",
       "      <td>0.108780</td>\n",
       "      <td>0.384444</td>\n",
       "      <td>0.062649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.624477</td>\n",
       "      <td>0.108780</td>\n",
       "      <td>0.384444</td>\n",
       "      <td>0.062649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.624477</td>\n",
       "      <td>0.108780</td>\n",
       "      <td>0.384444</td>\n",
       "      <td>0.062649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.635679</td>\n",
       "      <td>0.132385</td>\n",
       "      <td>0.358499</td>\n",
       "      <td>0.072556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.635679</td>\n",
       "      <td>0.132385</td>\n",
       "      <td>0.358499</td>\n",
       "      <td>0.072556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.636774</td>\n",
       "      <td>0.188931</td>\n",
       "      <td>0.316924</td>\n",
       "      <td>0.098301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.640575</td>\n",
       "      <td>0.195052</td>\n",
       "      <td>0.318764</td>\n",
       "      <td>0.074915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.641998</td>\n",
       "      <td>0.081892</td>\n",
       "      <td>0.365639</td>\n",
       "      <td>0.152704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648011</td>\n",
       "      <td>0.104821</td>\n",
       "      <td>0.365231</td>\n",
       "      <td>0.143871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.652969</td>\n",
       "      <td>0.108963</td>\n",
       "      <td>0.380274</td>\n",
       "      <td>0.100370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.654573</td>\n",
       "      <td>0.110896</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.091627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.675625</td>\n",
       "      <td>0.128624</td>\n",
       "      <td>0.361752</td>\n",
       "      <td>0.097155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.676937</td>\n",
       "      <td>0.133473</td>\n",
       "      <td>0.368131</td>\n",
       "      <td>0.085728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.240274</td>\n",
       "      <td>2.784220</td>\n",
       "      <td>2.784220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.662620</td>\n",
       "      <td>2.220577</td>\n",
       "      <td>2.220577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.284614</td>\n",
       "      <td>1.834663</td>\n",
       "      <td>1.834663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.894945</td>\n",
       "      <td>0.857064</td>\n",
       "      <td>0.857064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.483538</td>\n",
       "      <td>0.628980</td>\n",
       "      <td>0.628980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.119595</td>\n",
       "      <td>0.459059</td>\n",
       "      <td>0.459059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.805867</td>\n",
       "      <td>0.338728</td>\n",
       "      <td>0.338728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.765087</td>\n",
       "      <td>0.310993</td>\n",
       "      <td>0.310993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-1.073831</td>\n",
       "      <td>0.111741</td>\n",
       "      <td>0.111741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.948030</td>\n",
       "      <td>0.094241</td>\n",
       "      <td>0.094241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.857788</td>\n",
       "      <td>0.076420</td>\n",
       "      <td>0.076420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>-0.834194</td>\n",
       "      <td>0.069049</td>\n",
       "      <td>0.069049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.689677</td>\n",
       "      <td>0.051030</td>\n",
       "      <td>0.051030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.483827</td>\n",
       "      <td>0.022437</td>\n",
       "      <td>0.022437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.454011</td>\n",
       "      <td>0.021566</td>\n",
       "      <td>0.021566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.410765</td>\n",
       "      <td>0.017244</td>\n",
       "      <td>0.017244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.390931</td>\n",
       "      <td>0.016029</td>\n",
       "      <td>0.016029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.347547</td>\n",
       "      <td>0.011672</td>\n",
       "      <td>0.011672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.311056</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.006743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.220180</td>\n",
       "      <td>0.005361</td>\n",
       "      <td>0.005361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.240</td>\n",
       "      <td>0.148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.784</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>2.787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.221</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>2.221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.857</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.629</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.858</td>\n",
       "      <td>-1.074</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.948</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.012</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_conscientiousness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.16\n",
      "1          EDM                0.16\n",
      "2       BIS_11               -0.16\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.16\n",
      "5                       TRSQ                0.16\n",
      "6  ACES_neglectful_parenting               -0.16\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.17420313378439523, 0.3401113598789357, 0.28665746947232607, -0.03320082362174781, -0.26050509126009547]\n",
      "overall_score:\n",
      "0.10145320965076274\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.320681</td>\n",
       "      <td>0.120835</td>\n",
       "      <td>0.271586</td>\n",
       "      <td>0.110299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324916</td>\n",
       "      <td>0.132795</td>\n",
       "      <td>0.270193</td>\n",
       "      <td>0.117291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330933</td>\n",
       "      <td>0.137671</td>\n",
       "      <td>0.270299</td>\n",
       "      <td>0.119577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.339597</td>\n",
       "      <td>0.141897</td>\n",
       "      <td>0.271209</td>\n",
       "      <td>0.124281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345851</td>\n",
       "      <td>0.143454</td>\n",
       "      <td>0.272546</td>\n",
       "      <td>0.127838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354518</td>\n",
       "      <td>0.143893</td>\n",
       "      <td>0.274842</td>\n",
       "      <td>0.132536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.357496</td>\n",
       "      <td>0.056374</td>\n",
       "      <td>0.312419</td>\n",
       "      <td>0.039459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.357496</td>\n",
       "      <td>0.056374</td>\n",
       "      <td>0.312419</td>\n",
       "      <td>0.039459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366299</td>\n",
       "      <td>0.143883</td>\n",
       "      <td>0.279977</td>\n",
       "      <td>0.138598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.373992</td>\n",
       "      <td>0.081563</td>\n",
       "      <td>0.236647</td>\n",
       "      <td>0.047876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.373992</td>\n",
       "      <td>0.081563</td>\n",
       "      <td>0.236647</td>\n",
       "      <td>0.047876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.385422</td>\n",
       "      <td>0.086362</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>0.048606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.385422</td>\n",
       "      <td>0.086362</td>\n",
       "      <td>0.235181</td>\n",
       "      <td>0.048606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.399754</td>\n",
       "      <td>0.085852</td>\n",
       "      <td>0.234327</td>\n",
       "      <td>0.045470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.399754</td>\n",
       "      <td>0.085852</td>\n",
       "      <td>0.234327</td>\n",
       "      <td>0.045470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417536</td>\n",
       "      <td>0.078320</td>\n",
       "      <td>0.334268</td>\n",
       "      <td>0.127045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.420915</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.235093</td>\n",
       "      <td>0.042584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.420915</td>\n",
       "      <td>0.085271</td>\n",
       "      <td>0.235093</td>\n",
       "      <td>0.042584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.434677</td>\n",
       "      <td>0.084689</td>\n",
       "      <td>0.236158</td>\n",
       "      <td>0.043068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.434677</td>\n",
       "      <td>0.084689</td>\n",
       "      <td>0.236158</td>\n",
       "      <td>0.043068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083149</td>\n",
       "      <td>0.238539</td>\n",
       "      <td>0.046356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083149</td>\n",
       "      <td>0.238539</td>\n",
       "      <td>0.046356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.474312</td>\n",
       "      <td>0.035691</td>\n",
       "      <td>0.314687</td>\n",
       "      <td>0.056539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.475941</td>\n",
       "      <td>0.039195</td>\n",
       "      <td>0.311201</td>\n",
       "      <td>0.062555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.478231</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.243502</td>\n",
       "      <td>0.052095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478231</td>\n",
       "      <td>0.080844</td>\n",
       "      <td>0.243502</td>\n",
       "      <td>0.052095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478549</td>\n",
       "      <td>0.040084</td>\n",
       "      <td>0.308076</td>\n",
       "      <td>0.065954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.482001</td>\n",
       "      <td>0.041168</td>\n",
       "      <td>0.304374</td>\n",
       "      <td>0.071923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.484670</td>\n",
       "      <td>0.042937</td>\n",
       "      <td>0.301533</td>\n",
       "      <td>0.075140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.488334</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>0.299141</td>\n",
       "      <td>0.079017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.494160</td>\n",
       "      <td>0.047737</td>\n",
       "      <td>0.296991</td>\n",
       "      <td>0.083250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.494625</td>\n",
       "      <td>0.036456</td>\n",
       "      <td>0.359093</td>\n",
       "      <td>0.036900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.501854</td>\n",
       "      <td>0.066437</td>\n",
       "      <td>0.322992</td>\n",
       "      <td>0.095703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.502328</td>\n",
       "      <td>0.066888</td>\n",
       "      <td>0.325120</td>\n",
       "      <td>0.092927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.504904</td>\n",
       "      <td>0.066818</td>\n",
       "      <td>0.325978</td>\n",
       "      <td>0.090812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.506743</td>\n",
       "      <td>0.037273</td>\n",
       "      <td>0.376941</td>\n",
       "      <td>0.065121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.506743</td>\n",
       "      <td>0.037273</td>\n",
       "      <td>0.376941</td>\n",
       "      <td>0.065121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.508539</td>\n",
       "      <td>0.067341</td>\n",
       "      <td>0.326408</td>\n",
       "      <td>0.088602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.516101</td>\n",
       "      <td>0.068671</td>\n",
       "      <td>0.327515</td>\n",
       "      <td>0.084629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.522656</td>\n",
       "      <td>0.075787</td>\n",
       "      <td>0.364522</td>\n",
       "      <td>0.110877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.523355</td>\n",
       "      <td>0.068866</td>\n",
       "      <td>0.328157</td>\n",
       "      <td>0.081672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.529812</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.329110</td>\n",
       "      <td>0.074670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.573416</td>\n",
       "      <td>0.080055</td>\n",
       "      <td>0.380718</td>\n",
       "      <td>0.053123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.573416</td>\n",
       "      <td>0.080055</td>\n",
       "      <td>0.380718</td>\n",
       "      <td>0.053123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.601356</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.363890</td>\n",
       "      <td>0.042025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.602407</td>\n",
       "      <td>0.089428</td>\n",
       "      <td>0.371986</td>\n",
       "      <td>0.081771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.619479</td>\n",
       "      <td>0.090485</td>\n",
       "      <td>0.391633</td>\n",
       "      <td>0.054783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.619479</td>\n",
       "      <td>0.090485</td>\n",
       "      <td>0.391633</td>\n",
       "      <td>0.054783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.625759</td>\n",
       "      <td>0.095942</td>\n",
       "      <td>0.373682</td>\n",
       "      <td>0.045116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.637838</td>\n",
       "      <td>0.090850</td>\n",
       "      <td>0.387167</td>\n",
       "      <td>0.059196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639530</td>\n",
       "      <td>0.070889</td>\n",
       "      <td>0.375876</td>\n",
       "      <td>0.069482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.647255</td>\n",
       "      <td>0.080060</td>\n",
       "      <td>0.389430</td>\n",
       "      <td>0.066528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649714</td>\n",
       "      <td>0.082883</td>\n",
       "      <td>0.393522</td>\n",
       "      <td>0.063464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650016</td>\n",
       "      <td>0.100922</td>\n",
       "      <td>0.372930</td>\n",
       "      <td>0.062644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.650553</td>\n",
       "      <td>0.077912</td>\n",
       "      <td>0.384593</td>\n",
       "      <td>0.069357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.650555</td>\n",
       "      <td>0.094538</td>\n",
       "      <td>0.394901</td>\n",
       "      <td>0.172755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.650555</td>\n",
       "      <td>0.094538</td>\n",
       "      <td>0.394901</td>\n",
       "      <td>0.172755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.652009</td>\n",
       "      <td>0.146112</td>\n",
       "      <td>0.362857</td>\n",
       "      <td>0.112396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655584</td>\n",
       "      <td>0.148826</td>\n",
       "      <td>0.365653</td>\n",
       "      <td>0.082178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655584</td>\n",
       "      <td>0.148826</td>\n",
       "      <td>0.365653</td>\n",
       "      <td>0.082178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655584</td>\n",
       "      <td>0.148826</td>\n",
       "      <td>0.365653</td>\n",
       "      <td>0.082178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655584</td>\n",
       "      <td>0.148826</td>\n",
       "      <td>0.365653</td>\n",
       "      <td>0.082178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.663135</td>\n",
       "      <td>0.160753</td>\n",
       "      <td>0.363978</td>\n",
       "      <td>0.125311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.666696</td>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.343855</td>\n",
       "      <td>0.098851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.667228</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.396745</td>\n",
       "      <td>0.051748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.667228</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.396745</td>\n",
       "      <td>0.051748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.667228</td>\n",
       "      <td>0.087361</td>\n",
       "      <td>0.396745</td>\n",
       "      <td>0.051748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.667395</td>\n",
       "      <td>0.087094</td>\n",
       "      <td>0.396499</td>\n",
       "      <td>0.051270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668747</td>\n",
       "      <td>0.050130</td>\n",
       "      <td>0.299211</td>\n",
       "      <td>0.125869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668802</td>\n",
       "      <td>0.054726</td>\n",
       "      <td>0.295949</td>\n",
       "      <td>0.133567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.669077</td>\n",
       "      <td>0.116740</td>\n",
       "      <td>0.394603</td>\n",
       "      <td>0.173553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.669077</td>\n",
       "      <td>0.116740</td>\n",
       "      <td>0.394603</td>\n",
       "      <td>0.173553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.669096</td>\n",
       "      <td>0.056864</td>\n",
       "      <td>0.292380</td>\n",
       "      <td>0.133268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.670444</td>\n",
       "      <td>0.060009</td>\n",
       "      <td>0.287196</td>\n",
       "      <td>0.132159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.672466</td>\n",
       "      <td>0.062260</td>\n",
       "      <td>0.283075</td>\n",
       "      <td>0.131429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.675037</td>\n",
       "      <td>0.064969</td>\n",
       "      <td>0.278391</td>\n",
       "      <td>0.130453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.676013</td>\n",
       "      <td>0.080971</td>\n",
       "      <td>0.371469</td>\n",
       "      <td>0.081462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.677877</td>\n",
       "      <td>0.073243</td>\n",
       "      <td>0.351365</td>\n",
       "      <td>0.215589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.677877</td>\n",
       "      <td>0.073243</td>\n",
       "      <td>0.351365</td>\n",
       "      <td>0.215589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.678321</td>\n",
       "      <td>0.068307</td>\n",
       "      <td>0.273067</td>\n",
       "      <td>0.129025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.687238</td>\n",
       "      <td>0.087081</td>\n",
       "      <td>0.377948</td>\n",
       "      <td>0.062469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.687818</td>\n",
       "      <td>0.096238</td>\n",
       "      <td>0.385311</td>\n",
       "      <td>0.054171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.692004</td>\n",
       "      <td>0.088140</td>\n",
       "      <td>0.382372</td>\n",
       "      <td>0.056747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.692700</td>\n",
       "      <td>0.086951</td>\n",
       "      <td>0.394212</td>\n",
       "      <td>0.045215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.692700</td>\n",
       "      <td>0.086951</td>\n",
       "      <td>0.394212</td>\n",
       "      <td>0.045215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.692700</td>\n",
       "      <td>0.086951</td>\n",
       "      <td>0.394212</td>\n",
       "      <td>0.045215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.692722</td>\n",
       "      <td>0.086987</td>\n",
       "      <td>0.394229</td>\n",
       "      <td>0.045227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.697940</td>\n",
       "      <td>0.139536</td>\n",
       "      <td>0.336934</td>\n",
       "      <td>0.217628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.697940</td>\n",
       "      <td>0.139536</td>\n",
       "      <td>0.336934</td>\n",
       "      <td>0.217628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.702716</td>\n",
       "      <td>0.087323</td>\n",
       "      <td>0.391454</td>\n",
       "      <td>0.051141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.708339</td>\n",
       "      <td>0.093710</td>\n",
       "      <td>0.390392</td>\n",
       "      <td>0.049759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.711658</td>\n",
       "      <td>0.079862</td>\n",
       "      <td>0.338369</td>\n",
       "      <td>0.184247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.714425</td>\n",
       "      <td>0.088544</td>\n",
       "      <td>0.391680</td>\n",
       "      <td>0.050245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717383</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>0.415337</td>\n",
       "      <td>0.057744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717383</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>0.415337</td>\n",
       "      <td>0.057744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717383</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>0.415337</td>\n",
       "      <td>0.057744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717383</td>\n",
       "      <td>0.120351</td>\n",
       "      <td>0.415337</td>\n",
       "      <td>0.057744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.718524</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.388504</td>\n",
       "      <td>0.045273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718524</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.388504</td>\n",
       "      <td>0.045273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718524</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.388504</td>\n",
       "      <td>0.045273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718524</td>\n",
       "      <td>0.085084</td>\n",
       "      <td>0.388504</td>\n",
       "      <td>0.045273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.719217</td>\n",
       "      <td>0.060430</td>\n",
       "      <td>0.367546</td>\n",
       "      <td>0.182447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.723049</td>\n",
       "      <td>0.113001</td>\n",
       "      <td>0.427388</td>\n",
       "      <td>0.146591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.725762</td>\n",
       "      <td>0.086762</td>\n",
       "      <td>0.386912</td>\n",
       "      <td>0.046051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.726947</td>\n",
       "      <td>0.086531</td>\n",
       "      <td>0.387322</td>\n",
       "      <td>0.046353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.730837</td>\n",
       "      <td>0.120455</td>\n",
       "      <td>0.417977</td>\n",
       "      <td>0.154392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.733788</td>\n",
       "      <td>0.124974</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.735983</td>\n",
       "      <td>0.186119</td>\n",
       "      <td>0.330973</td>\n",
       "      <td>0.067580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.737739</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>0.365864</td>\n",
       "      <td>0.180535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.742595</td>\n",
       "      <td>0.122768</td>\n",
       "      <td>0.331485</td>\n",
       "      <td>0.201811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.743130</td>\n",
       "      <td>0.141134</td>\n",
       "      <td>0.371639</td>\n",
       "      <td>0.084028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.743130</td>\n",
       "      <td>0.141134</td>\n",
       "      <td>0.371639</td>\n",
       "      <td>0.084028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.746903</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.383205</td>\n",
       "      <td>0.050956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.746903</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.383205</td>\n",
       "      <td>0.050956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.746903</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.383205</td>\n",
       "      <td>0.050956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.746903</td>\n",
       "      <td>0.109119</td>\n",
       "      <td>0.383205</td>\n",
       "      <td>0.050956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.751083</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.389119</td>\n",
       "      <td>0.082054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.751083</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.389119</td>\n",
       "      <td>0.082054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.751083</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.389119</td>\n",
       "      <td>0.082054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.751083</td>\n",
       "      <td>0.161396</td>\n",
       "      <td>0.389119</td>\n",
       "      <td>0.082054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.752076</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>0.342370</td>\n",
       "      <td>0.105681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.753617</td>\n",
       "      <td>0.205644</td>\n",
       "      <td>0.326532</td>\n",
       "      <td>0.083477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.763267</td>\n",
       "      <td>0.100462</td>\n",
       "      <td>0.340238</td>\n",
       "      <td>0.124054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.777946</td>\n",
       "      <td>0.126189</td>\n",
       "      <td>0.401972</td>\n",
       "      <td>0.158359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.779453</td>\n",
       "      <td>0.126648</td>\n",
       "      <td>0.391675</td>\n",
       "      <td>0.169179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.994835</td>\n",
       "      <td>2.377183</td>\n",
       "      <td>2.377183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.811965</td>\n",
       "      <td>2.158199</td>\n",
       "      <td>2.158199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.166750</td>\n",
       "      <td>1.642677</td>\n",
       "      <td>1.642677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>3.338437</td>\n",
       "      <td>1.060573</td>\n",
       "      <td>1.060573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.812751</td>\n",
       "      <td>0.751929</td>\n",
       "      <td>0.751929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>2.371279</td>\n",
       "      <td>0.523716</td>\n",
       "      <td>0.523716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.110092</td>\n",
       "      <td>0.425058</td>\n",
       "      <td>0.425058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.825398</td>\n",
       "      <td>0.309397</td>\n",
       "      <td>0.309397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.971782</td>\n",
       "      <td>0.084796</td>\n",
       "      <td>0.084796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.853285</td>\n",
       "      <td>0.070007</td>\n",
       "      <td>0.070007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.783317</td>\n",
       "      <td>0.060480</td>\n",
       "      <td>0.060480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.699221</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.049080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.481084</td>\n",
       "      <td>0.022817</td>\n",
       "      <td>0.022817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.478275</td>\n",
       "      <td>0.021241</td>\n",
       "      <td>0.021241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.485086</td>\n",
       "      <td>0.020933</td>\n",
       "      <td>0.020933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.411460</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>0.016448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.397281</td>\n",
       "      <td>0.015146</td>\n",
       "      <td>0.015146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.312877</td>\n",
       "      <td>0.009908</td>\n",
       "      <td>0.009908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.250665</td>\n",
       "      <td>0.006618</td>\n",
       "      <td>0.006618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.304894</td>\n",
       "      <td>0.005766</td>\n",
       "      <td>0.005766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.377</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>2.377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.167</td>\n",
       "      <td>0.074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.643</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>1.643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.061</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.524</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.853</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.085</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.699</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.060</td>\n",
       "      <td>0.021</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "         feature_name  interaction_effect\n",
      "0                BSCS                0.08\n",
      "2              BIS_11               -0.08\n",
      "1                 EDM                0.08\n",
      "11  BFI_agreeableness                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.019391378692160455, 0.05103383687350138, -0.12333443118999532, -0.04514095692852438, -0.3178977602412687]\n",
      "overall_score:\n",
      "-0.09094613803568949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.268368</td>\n",
       "      <td>0.047258</td>\n",
       "      <td>0.309200</td>\n",
       "      <td>0.096481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.269053</td>\n",
       "      <td>0.072854</td>\n",
       "      <td>0.333186</td>\n",
       "      <td>0.078243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.280129</td>\n",
       "      <td>0.053543</td>\n",
       "      <td>0.334510</td>\n",
       "      <td>0.041095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282265</td>\n",
       "      <td>0.075672</td>\n",
       "      <td>0.338148</td>\n",
       "      <td>0.053572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285580</td>\n",
       "      <td>0.077469</td>\n",
       "      <td>0.341224</td>\n",
       "      <td>0.051844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.285924</td>\n",
       "      <td>0.054509</td>\n",
       "      <td>0.336622</td>\n",
       "      <td>0.034360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.290811</td>\n",
       "      <td>0.068708</td>\n",
       "      <td>0.346953</td>\n",
       "      <td>0.023353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.290827</td>\n",
       "      <td>0.068625</td>\n",
       "      <td>0.347245</td>\n",
       "      <td>0.023550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292086</td>\n",
       "      <td>0.054613</td>\n",
       "      <td>0.331360</td>\n",
       "      <td>0.084547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292451</td>\n",
       "      <td>0.077121</td>\n",
       "      <td>0.352444</td>\n",
       "      <td>0.044752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.292899</td>\n",
       "      <td>0.049516</td>\n",
       "      <td>0.288927</td>\n",
       "      <td>0.042831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292916</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.060843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292916</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.060843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292916</td>\n",
       "      <td>0.114204</td>\n",
       "      <td>0.334386</td>\n",
       "      <td>0.060843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.294279</td>\n",
       "      <td>0.075839</td>\n",
       "      <td>0.356341</td>\n",
       "      <td>0.034380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294496</td>\n",
       "      <td>0.114013</td>\n",
       "      <td>0.334393</td>\n",
       "      <td>0.060838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294701</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.316998</td>\n",
       "      <td>0.098707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.294853</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.034146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.295682</td>\n",
       "      <td>0.080454</td>\n",
       "      <td>0.350707</td>\n",
       "      <td>0.023482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.295964</td>\n",
       "      <td>0.075335</td>\n",
       "      <td>0.352844</td>\n",
       "      <td>0.023958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.296574</td>\n",
       "      <td>0.080699</td>\n",
       "      <td>0.350441</td>\n",
       "      <td>0.023730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.296873</td>\n",
       "      <td>0.040249</td>\n",
       "      <td>0.300339</td>\n",
       "      <td>0.052913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.298140</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.350294</td>\n",
       "      <td>0.034471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299520</td>\n",
       "      <td>0.070640</td>\n",
       "      <td>0.352882</td>\n",
       "      <td>0.037559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300707</td>\n",
       "      <td>0.066976</td>\n",
       "      <td>0.346114</td>\n",
       "      <td>0.031821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301337</td>\n",
       "      <td>0.071829</td>\n",
       "      <td>0.349508</td>\n",
       "      <td>0.038938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302009</td>\n",
       "      <td>0.072234</td>\n",
       "      <td>0.351014</td>\n",
       "      <td>0.036699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302018</td>\n",
       "      <td>0.072245</td>\n",
       "      <td>0.351010</td>\n",
       "      <td>0.036695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302078</td>\n",
       "      <td>0.071951</td>\n",
       "      <td>0.350718</td>\n",
       "      <td>0.023899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302154</td>\n",
       "      <td>0.074961</td>\n",
       "      <td>0.352191</td>\n",
       "      <td>0.022403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303547</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.037851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304050</td>\n",
       "      <td>0.058909</td>\n",
       "      <td>0.335633</td>\n",
       "      <td>0.031791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.307707</td>\n",
       "      <td>0.068662</td>\n",
       "      <td>0.328011</td>\n",
       "      <td>0.049524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.308096</td>\n",
       "      <td>0.070203</td>\n",
       "      <td>0.325649</td>\n",
       "      <td>0.049821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.308384</td>\n",
       "      <td>0.067817</td>\n",
       "      <td>0.330048</td>\n",
       "      <td>0.049990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.309249</td>\n",
       "      <td>0.063423</td>\n",
       "      <td>0.332250</td>\n",
       "      <td>0.048020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.309529</td>\n",
       "      <td>0.071308</td>\n",
       "      <td>0.324244</td>\n",
       "      <td>0.050389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.310327</td>\n",
       "      <td>0.073479</td>\n",
       "      <td>0.352731</td>\n",
       "      <td>0.027027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.311369</td>\n",
       "      <td>0.072851</td>\n",
       "      <td>0.322900</td>\n",
       "      <td>0.051122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313860</td>\n",
       "      <td>0.043981</td>\n",
       "      <td>0.317631</td>\n",
       "      <td>0.038524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.314910</td>\n",
       "      <td>0.074754</td>\n",
       "      <td>0.321150</td>\n",
       "      <td>0.052331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.319600</td>\n",
       "      <td>0.059432</td>\n",
       "      <td>0.352822</td>\n",
       "      <td>0.027599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.319892</td>\n",
       "      <td>0.072664</td>\n",
       "      <td>0.352702</td>\n",
       "      <td>0.035436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.320004</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>0.339455</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.320004</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>0.339455</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.320004</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>0.339455</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.320004</td>\n",
       "      <td>0.095418</td>\n",
       "      <td>0.339455</td>\n",
       "      <td>0.042300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321829</td>\n",
       "      <td>0.087993</td>\n",
       "      <td>0.346819</td>\n",
       "      <td>0.066756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.334056</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.334056</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.334056</td>\n",
       "      <td>0.092583</td>\n",
       "      <td>0.364504</td>\n",
       "      <td>0.076253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.334700</td>\n",
       "      <td>0.101003</td>\n",
       "      <td>0.366703</td>\n",
       "      <td>0.083421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.335636</td>\n",
       "      <td>0.093336</td>\n",
       "      <td>0.364110</td>\n",
       "      <td>0.076368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.337450</td>\n",
       "      <td>0.095239</td>\n",
       "      <td>0.363220</td>\n",
       "      <td>0.077932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.339250</td>\n",
       "      <td>0.047156</td>\n",
       "      <td>0.350539</td>\n",
       "      <td>0.026966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343701</td>\n",
       "      <td>0.027755</td>\n",
       "      <td>0.296362</td>\n",
       "      <td>0.049559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345577</td>\n",
       "      <td>0.029533</td>\n",
       "      <td>0.294201</td>\n",
       "      <td>0.050156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.347661</td>\n",
       "      <td>0.029882</td>\n",
       "      <td>0.291765</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350004</td>\n",
       "      <td>0.030581</td>\n",
       "      <td>0.288993</td>\n",
       "      <td>0.044666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351407</td>\n",
       "      <td>0.031103</td>\n",
       "      <td>0.287610</td>\n",
       "      <td>0.042888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352859</td>\n",
       "      <td>0.113390</td>\n",
       "      <td>0.262172</td>\n",
       "      <td>0.080464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353069</td>\n",
       "      <td>0.031679</td>\n",
       "      <td>0.286207</td>\n",
       "      <td>0.040813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354948</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.284664</td>\n",
       "      <td>0.038697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356086</td>\n",
       "      <td>0.118038</td>\n",
       "      <td>0.378191</td>\n",
       "      <td>0.069583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.356361</td>\n",
       "      <td>0.066592</td>\n",
       "      <td>0.352897</td>\n",
       "      <td>0.063130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.356361</td>\n",
       "      <td>0.066592</td>\n",
       "      <td>0.352897</td>\n",
       "      <td>0.063130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.356361</td>\n",
       "      <td>0.066592</td>\n",
       "      <td>0.352897</td>\n",
       "      <td>0.063130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.356361</td>\n",
       "      <td>0.066592</td>\n",
       "      <td>0.352897</td>\n",
       "      <td>0.063130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358045</td>\n",
       "      <td>0.119059</td>\n",
       "      <td>0.380679</td>\n",
       "      <td>0.072911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363721</td>\n",
       "      <td>0.121539</td>\n",
       "      <td>0.261627</td>\n",
       "      <td>0.083742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.364132</td>\n",
       "      <td>0.070708</td>\n",
       "      <td>0.353734</td>\n",
       "      <td>0.107223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365609</td>\n",
       "      <td>0.081429</td>\n",
       "      <td>0.351509</td>\n",
       "      <td>0.111833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.372864</td>\n",
       "      <td>0.109280</td>\n",
       "      <td>0.370472</td>\n",
       "      <td>0.087845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.374137</td>\n",
       "      <td>0.105025</td>\n",
       "      <td>0.368993</td>\n",
       "      <td>0.086651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377219</td>\n",
       "      <td>0.122091</td>\n",
       "      <td>0.261163</td>\n",
       "      <td>0.082600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.380604</td>\n",
       "      <td>0.119455</td>\n",
       "      <td>0.364520</td>\n",
       "      <td>0.079503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382975</td>\n",
       "      <td>0.105867</td>\n",
       "      <td>0.364802</td>\n",
       "      <td>0.059270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.385270</td>\n",
       "      <td>0.108775</td>\n",
       "      <td>0.355905</td>\n",
       "      <td>0.078085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385794</td>\n",
       "      <td>0.096559</td>\n",
       "      <td>0.279813</td>\n",
       "      <td>0.096009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393042</td>\n",
       "      <td>0.101054</td>\n",
       "      <td>0.362567</td>\n",
       "      <td>0.065183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394098</td>\n",
       "      <td>0.122395</td>\n",
       "      <td>0.260901</td>\n",
       "      <td>0.082618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.395871</td>\n",
       "      <td>0.114128</td>\n",
       "      <td>0.264513</td>\n",
       "      <td>0.109018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.404932</td>\n",
       "      <td>0.122168</td>\n",
       "      <td>0.260922</td>\n",
       "      <td>0.082758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.409157</td>\n",
       "      <td>0.098174</td>\n",
       "      <td>0.320131</td>\n",
       "      <td>0.067353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.409228</td>\n",
       "      <td>0.103345</td>\n",
       "      <td>0.331622</td>\n",
       "      <td>0.118639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.411823</td>\n",
       "      <td>0.105960</td>\n",
       "      <td>0.332611</td>\n",
       "      <td>0.106614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.417350</td>\n",
       "      <td>0.107680</td>\n",
       "      <td>0.319255</td>\n",
       "      <td>0.074146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418324</td>\n",
       "      <td>0.122146</td>\n",
       "      <td>0.260571</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.427368</td>\n",
       "      <td>0.111300</td>\n",
       "      <td>0.317514</td>\n",
       "      <td>0.077001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.432108</td>\n",
       "      <td>0.136691</td>\n",
       "      <td>0.370768</td>\n",
       "      <td>0.077508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.434039</td>\n",
       "      <td>0.122014</td>\n",
       "      <td>0.260568</td>\n",
       "      <td>0.081751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.439039</td>\n",
       "      <td>0.115469</td>\n",
       "      <td>0.315091</td>\n",
       "      <td>0.080376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.442287</td>\n",
       "      <td>0.132472</td>\n",
       "      <td>0.365296</td>\n",
       "      <td>0.075788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.446401</td>\n",
       "      <td>0.117580</td>\n",
       "      <td>0.313392</td>\n",
       "      <td>0.082480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455166</td>\n",
       "      <td>0.119801</td>\n",
       "      <td>0.310917</td>\n",
       "      <td>0.084878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468329</td>\n",
       "      <td>0.118830</td>\n",
       "      <td>0.307857</td>\n",
       "      <td>0.088190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.477451</td>\n",
       "      <td>0.106064</td>\n",
       "      <td>0.334278</td>\n",
       "      <td>0.102502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.500804</td>\n",
       "      <td>0.105517</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.071442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.505197</td>\n",
       "      <td>0.114893</td>\n",
       "      <td>0.313745</td>\n",
       "      <td>0.095465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.519583</td>\n",
       "      <td>0.078406</td>\n",
       "      <td>0.228225</td>\n",
       "      <td>0.064166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.538924</td>\n",
       "      <td>0.085158</td>\n",
       "      <td>0.227874</td>\n",
       "      <td>0.068670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.542032</td>\n",
       "      <td>0.120523</td>\n",
       "      <td>0.283429</td>\n",
       "      <td>0.055724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.563269</td>\n",
       "      <td>0.087077</td>\n",
       "      <td>0.226925</td>\n",
       "      <td>0.069061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.594981</td>\n",
       "      <td>0.089814</td>\n",
       "      <td>0.226129</td>\n",
       "      <td>0.069227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.598507</td>\n",
       "      <td>0.140060</td>\n",
       "      <td>0.243969</td>\n",
       "      <td>0.048030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.614856</td>\n",
       "      <td>0.091604</td>\n",
       "      <td>0.226629</td>\n",
       "      <td>0.068564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.624750</td>\n",
       "      <td>0.152260</td>\n",
       "      <td>0.245901</td>\n",
       "      <td>0.049912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639746</td>\n",
       "      <td>0.092471</td>\n",
       "      <td>0.228980</td>\n",
       "      <td>0.067778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657535</td>\n",
       "      <td>0.155708</td>\n",
       "      <td>0.248054</td>\n",
       "      <td>0.050784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.670994</td>\n",
       "      <td>0.093873</td>\n",
       "      <td>0.232621</td>\n",
       "      <td>0.068573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.699242</td>\n",
       "      <td>0.159485</td>\n",
       "      <td>0.251567</td>\n",
       "      <td>0.055429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.726014</td>\n",
       "      <td>0.162185</td>\n",
       "      <td>0.254714</td>\n",
       "      <td>0.061355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757841</td>\n",
       "      <td>0.166070</td>\n",
       "      <td>0.259378</td>\n",
       "      <td>0.070958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801947</td>\n",
       "      <td>0.175596</td>\n",
       "      <td>0.267642</td>\n",
       "      <td>0.086866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.385828</td>\n",
       "      <td>0.385828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.092698</td>\n",
       "      <td>0.092698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.056835</td>\n",
       "      <td>0.056835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>0.019450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.010201</td>\n",
       "      <td>0.010201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.006173</td>\n",
       "      <td>0.006173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.001180</td>\n",
       "      <td>0.001180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "         feature_name  interaction_effect\n",
      "0                BSCS                 0.1\n",
      "2              BIS_11                -0.1\n",
      "1                 EDM                 0.1\n",
      "11  BFI_agreeableness                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.036906016757977333, 0.025163581636640342, 0.04604500169276293, -0.03671511219721468, -0.2969751146633599]\n",
      "overall_score:\n",
      "-0.045115125354638796\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304918</td>\n",
       "      <td>0.063440</td>\n",
       "      <td>0.327492</td>\n",
       "      <td>0.108845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.327857</td>\n",
       "      <td>0.051110</td>\n",
       "      <td>0.296022</td>\n",
       "      <td>0.041828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334020</td>\n",
       "      <td>0.065040</td>\n",
       "      <td>0.340143</td>\n",
       "      <td>0.075081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.337082</td>\n",
       "      <td>0.041067</td>\n",
       "      <td>0.301169</td>\n",
       "      <td>0.054855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.337902</td>\n",
       "      <td>0.055844</td>\n",
       "      <td>0.341664</td>\n",
       "      <td>0.040095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.347777</td>\n",
       "      <td>0.059058</td>\n",
       "      <td>0.344863</td>\n",
       "      <td>0.033602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348666</td>\n",
       "      <td>0.117381</td>\n",
       "      <td>0.353344</td>\n",
       "      <td>0.102345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.351489</td>\n",
       "      <td>0.111644</td>\n",
       "      <td>0.349906</td>\n",
       "      <td>0.099458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355073</td>\n",
       "      <td>0.072706</td>\n",
       "      <td>0.347908</td>\n",
       "      <td>0.051814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.357613</td>\n",
       "      <td>0.079645</td>\n",
       "      <td>0.338289</td>\n",
       "      <td>0.065695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.357793</td>\n",
       "      <td>0.081047</td>\n",
       "      <td>0.336922</td>\n",
       "      <td>0.065777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.358450</td>\n",
       "      <td>0.054632</td>\n",
       "      <td>0.372343</td>\n",
       "      <td>0.100305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358653</td>\n",
       "      <td>0.106210</td>\n",
       "      <td>0.355172</td>\n",
       "      <td>0.088062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.358676</td>\n",
       "      <td>0.078411</td>\n",
       "      <td>0.340845</td>\n",
       "      <td>0.065665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.358823</td>\n",
       "      <td>0.083112</td>\n",
       "      <td>0.335134</td>\n",
       "      <td>0.065850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.360835</td>\n",
       "      <td>0.076710</td>\n",
       "      <td>0.343136</td>\n",
       "      <td>0.065846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.361528</td>\n",
       "      <td>0.075968</td>\n",
       "      <td>0.357235</td>\n",
       "      <td>0.019830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.361660</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.333184</td>\n",
       "      <td>0.066530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.362235</td>\n",
       "      <td>0.076449</td>\n",
       "      <td>0.357813</td>\n",
       "      <td>0.017876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.362895</td>\n",
       "      <td>0.070990</td>\n",
       "      <td>0.344898</td>\n",
       "      <td>0.061746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366980</td>\n",
       "      <td>0.122583</td>\n",
       "      <td>0.270095</td>\n",
       "      <td>0.111870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367200</td>\n",
       "      <td>0.114957</td>\n",
       "      <td>0.348451</td>\n",
       "      <td>0.071526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367622</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.353349</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.369659</td>\n",
       "      <td>0.116962</td>\n",
       "      <td>0.397206</td>\n",
       "      <td>0.148957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371729</td>\n",
       "      <td>0.077081</td>\n",
       "      <td>0.360293</td>\n",
       "      <td>0.045193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.371813</td>\n",
       "      <td>0.080107</td>\n",
       "      <td>0.369663</td>\n",
       "      <td>0.027847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.373296</td>\n",
       "      <td>0.062369</td>\n",
       "      <td>0.377023</td>\n",
       "      <td>0.102244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.373497</td>\n",
       "      <td>0.077653</td>\n",
       "      <td>0.368593</td>\n",
       "      <td>0.034168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.374215</td>\n",
       "      <td>0.081028</td>\n",
       "      <td>0.367685</td>\n",
       "      <td>0.034048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.375254</td>\n",
       "      <td>0.070965</td>\n",
       "      <td>0.340179</td>\n",
       "      <td>0.111060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.375380</td>\n",
       "      <td>0.080538</td>\n",
       "      <td>0.370196</td>\n",
       "      <td>0.026890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.375474</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.375474</td>\n",
       "      <td>0.085618</td>\n",
       "      <td>0.362608</td>\n",
       "      <td>0.014830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.377225</td>\n",
       "      <td>0.117343</td>\n",
       "      <td>0.389722</td>\n",
       "      <td>0.154579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377600</td>\n",
       "      <td>0.131883</td>\n",
       "      <td>0.270700</td>\n",
       "      <td>0.116884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.379202</td>\n",
       "      <td>0.088975</td>\n",
       "      <td>0.360521</td>\n",
       "      <td>0.014575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380388</td>\n",
       "      <td>0.113346</td>\n",
       "      <td>0.399217</td>\n",
       "      <td>0.148274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.381142</td>\n",
       "      <td>0.070391</td>\n",
       "      <td>0.356833</td>\n",
       "      <td>0.035260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.381293</td>\n",
       "      <td>0.076347</td>\n",
       "      <td>0.362009</td>\n",
       "      <td>0.038772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.381402</td>\n",
       "      <td>0.089613</td>\n",
       "      <td>0.359920</td>\n",
       "      <td>0.016259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.381708</td>\n",
       "      <td>0.076361</td>\n",
       "      <td>0.361999</td>\n",
       "      <td>0.038764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.381808</td>\n",
       "      <td>0.080259</td>\n",
       "      <td>0.369795</td>\n",
       "      <td>0.031543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.382289</td>\n",
       "      <td>0.084384</td>\n",
       "      <td>0.355893</td>\n",
       "      <td>0.038570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.382589</td>\n",
       "      <td>0.072827</td>\n",
       "      <td>0.360971</td>\n",
       "      <td>0.037757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383239</td>\n",
       "      <td>0.075651</td>\n",
       "      <td>0.359666</td>\n",
       "      <td>0.041389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383664</td>\n",
       "      <td>0.068407</td>\n",
       "      <td>0.351041</td>\n",
       "      <td>0.035836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384915</td>\n",
       "      <td>0.049051</td>\n",
       "      <td>0.323918</td>\n",
       "      <td>0.060162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385893</td>\n",
       "      <td>0.063549</td>\n",
       "      <td>0.342065</td>\n",
       "      <td>0.039767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.387954</td>\n",
       "      <td>0.112751</td>\n",
       "      <td>0.393366</td>\n",
       "      <td>0.152782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388361</td>\n",
       "      <td>0.091879</td>\n",
       "      <td>0.362525</td>\n",
       "      <td>0.030872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389257</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>0.358666</td>\n",
       "      <td>0.038876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390156</td>\n",
       "      <td>0.073377</td>\n",
       "      <td>0.357355</td>\n",
       "      <td>0.035709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390666</td>\n",
       "      <td>0.132591</td>\n",
       "      <td>0.270984</td>\n",
       "      <td>0.116302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390806</td>\n",
       "      <td>0.080669</td>\n",
       "      <td>0.367952</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.391884</td>\n",
       "      <td>0.071081</td>\n",
       "      <td>0.415396</td>\n",
       "      <td>0.162854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.398208</td>\n",
       "      <td>0.088789</td>\n",
       "      <td>0.344320</td>\n",
       "      <td>0.101436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.402613</td>\n",
       "      <td>0.066353</td>\n",
       "      <td>0.419933</td>\n",
       "      <td>0.158498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406603</td>\n",
       "      <td>0.110454</td>\n",
       "      <td>0.351789</td>\n",
       "      <td>0.073079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406948</td>\n",
       "      <td>0.133007</td>\n",
       "      <td>0.272066</td>\n",
       "      <td>0.116533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407881</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.359480</td>\n",
       "      <td>0.052645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407881</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.359480</td>\n",
       "      <td>0.052645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407881</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.359480</td>\n",
       "      <td>0.052645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407881</td>\n",
       "      <td>0.086619</td>\n",
       "      <td>0.359480</td>\n",
       "      <td>0.052645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.409138</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.379227</td>\n",
       "      <td>0.084285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.411962</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.375773</td>\n",
       "      <td>0.078904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.411962</td>\n",
       "      <td>0.098977</td>\n",
       "      <td>0.375773</td>\n",
       "      <td>0.078904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413268</td>\n",
       "      <td>0.099600</td>\n",
       "      <td>0.375235</td>\n",
       "      <td>0.079319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.414383</td>\n",
       "      <td>0.040193</td>\n",
       "      <td>0.288433</td>\n",
       "      <td>0.074842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415649</td>\n",
       "      <td>0.043669</td>\n",
       "      <td>0.287326</td>\n",
       "      <td>0.079088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417024</td>\n",
       "      <td>0.133177</td>\n",
       "      <td>0.273103</td>\n",
       "      <td>0.116697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417229</td>\n",
       "      <td>0.045047</td>\n",
       "      <td>0.286014</td>\n",
       "      <td>0.078473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.419315</td>\n",
       "      <td>0.046742</td>\n",
       "      <td>0.284190</td>\n",
       "      <td>0.077652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.420588</td>\n",
       "      <td>0.047902</td>\n",
       "      <td>0.283080</td>\n",
       "      <td>0.077111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422146</td>\n",
       "      <td>0.049300</td>\n",
       "      <td>0.281690</td>\n",
       "      <td>0.076469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424069</td>\n",
       "      <td>0.051138</td>\n",
       "      <td>0.279994</td>\n",
       "      <td>0.075691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.425655</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.366689</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.425655</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.366689</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.425655</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.366689</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.425655</td>\n",
       "      <td>0.085484</td>\n",
       "      <td>0.366689</td>\n",
       "      <td>0.062905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429332</td>\n",
       "      <td>0.133071</td>\n",
       "      <td>0.274467</td>\n",
       "      <td>0.117681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.439828</td>\n",
       "      <td>0.120828</td>\n",
       "      <td>0.300332</td>\n",
       "      <td>0.085673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.440957</td>\n",
       "      <td>0.105746</td>\n",
       "      <td>0.375967</td>\n",
       "      <td>0.070364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.441718</td>\n",
       "      <td>0.118511</td>\n",
       "      <td>0.306071</td>\n",
       "      <td>0.045020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442223</td>\n",
       "      <td>0.106621</td>\n",
       "      <td>0.377347</td>\n",
       "      <td>0.071956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.445347</td>\n",
       "      <td>0.132983</td>\n",
       "      <td>0.275069</td>\n",
       "      <td>0.118392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.448836</td>\n",
       "      <td>0.127240</td>\n",
       "      <td>0.303305</td>\n",
       "      <td>0.049393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451289</td>\n",
       "      <td>0.121726</td>\n",
       "      <td>0.277875</td>\n",
       "      <td>0.104293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454277</td>\n",
       "      <td>0.106494</td>\n",
       "      <td>0.367305</td>\n",
       "      <td>0.082260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.457811</td>\n",
       "      <td>0.070999</td>\n",
       "      <td>0.366900</td>\n",
       "      <td>0.155592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.457911</td>\n",
       "      <td>0.128800</td>\n",
       "      <td>0.300500</td>\n",
       "      <td>0.051050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461667</td>\n",
       "      <td>0.095021</td>\n",
       "      <td>0.368599</td>\n",
       "      <td>0.082677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468595</td>\n",
       "      <td>0.130618</td>\n",
       "      <td>0.297123</td>\n",
       "      <td>0.053851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.475274</td>\n",
       "      <td>0.131459</td>\n",
       "      <td>0.295143</td>\n",
       "      <td>0.056192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478773</td>\n",
       "      <td>0.075058</td>\n",
       "      <td>0.369144</td>\n",
       "      <td>0.143805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.483586</td>\n",
       "      <td>0.131604</td>\n",
       "      <td>0.293158</td>\n",
       "      <td>0.059541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.493914</td>\n",
       "      <td>0.077976</td>\n",
       "      <td>0.343536</td>\n",
       "      <td>0.191704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.496221</td>\n",
       "      <td>0.129746</td>\n",
       "      <td>0.291052</td>\n",
       "      <td>0.064617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.509312</td>\n",
       "      <td>0.103322</td>\n",
       "      <td>0.235489</td>\n",
       "      <td>0.081299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.512424</td>\n",
       "      <td>0.118686</td>\n",
       "      <td>0.312746</td>\n",
       "      <td>0.121671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.521362</td>\n",
       "      <td>0.086192</td>\n",
       "      <td>0.354846</td>\n",
       "      <td>0.201077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.527624</td>\n",
       "      <td>0.111501</td>\n",
       "      <td>0.235861</td>\n",
       "      <td>0.087882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.542496</td>\n",
       "      <td>0.114955</td>\n",
       "      <td>0.322420</td>\n",
       "      <td>0.125426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.550410</td>\n",
       "      <td>0.114304</td>\n",
       "      <td>0.236346</td>\n",
       "      <td>0.090646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.579715</td>\n",
       "      <td>0.117324</td>\n",
       "      <td>0.236668</td>\n",
       "      <td>0.093520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.597637</td>\n",
       "      <td>0.118870</td>\n",
       "      <td>0.237410</td>\n",
       "      <td>0.095876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.599810</td>\n",
       "      <td>0.140503</td>\n",
       "      <td>0.244955</td>\n",
       "      <td>0.050022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.618827</td>\n",
       "      <td>0.120688</td>\n",
       "      <td>0.238091</td>\n",
       "      <td>0.099021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.625576</td>\n",
       "      <td>0.152676</td>\n",
       "      <td>0.247007</td>\n",
       "      <td>0.052265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.647562</td>\n",
       "      <td>0.122232</td>\n",
       "      <td>0.240094</td>\n",
       "      <td>0.105328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.657793</td>\n",
       "      <td>0.156621</td>\n",
       "      <td>0.248994</td>\n",
       "      <td>0.052303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698816</td>\n",
       "      <td>0.159754</td>\n",
       "      <td>0.251970</td>\n",
       "      <td>0.056410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.725516</td>\n",
       "      <td>0.162281</td>\n",
       "      <td>0.254967</td>\n",
       "      <td>0.061912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.757104</td>\n",
       "      <td>0.165911</td>\n",
       "      <td>0.259432</td>\n",
       "      <td>0.070998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.801342</td>\n",
       "      <td>0.175274</td>\n",
       "      <td>0.267585</td>\n",
       "      <td>0.086837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.341333</td>\n",
       "      <td>0.670922</td>\n",
       "      <td>0.670922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.260258</td>\n",
       "      <td>0.208286</td>\n",
       "      <td>0.208286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.861930</td>\n",
       "      <td>0.102452</td>\n",
       "      <td>0.102452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.544510</td>\n",
       "      <td>0.031210</td>\n",
       "      <td>0.031210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.232784</td>\n",
       "      <td>0.009447</td>\n",
       "      <td>0.009447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.005210</td>\n",
       "      <td>0.005210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.182961</td>\n",
       "      <td>0.002939</td>\n",
       "      <td>0.002939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.085507</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.009696</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.000223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.341</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.671</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.208</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "         feature_name  interaction_effect\n",
      "0                BSCS                0.12\n",
      "2              BIS_11               -0.12\n",
      "1                 EDM                0.12\n",
      "11  BFI_agreeableness                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.12\n",
      "5                       TRSQ                0.12\n",
      "6  ACES_neglectful_parenting               -0.12\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.08964936208154684, 0.025169343246913112, -0.03780927215571217, -0.030855280472291247, -0.21499511600057986]\n",
      "overall_score:\n",
      "-0.03376819266002466\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343991</td>\n",
       "      <td>0.067163</td>\n",
       "      <td>0.336979</td>\n",
       "      <td>0.107993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.358898</td>\n",
       "      <td>0.054693</td>\n",
       "      <td>0.302829</td>\n",
       "      <td>0.046525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.368629</td>\n",
       "      <td>0.040869</td>\n",
       "      <td>0.313858</td>\n",
       "      <td>0.062584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.379095</td>\n",
       "      <td>0.114465</td>\n",
       "      <td>0.266752</td>\n",
       "      <td>0.112837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389212</td>\n",
       "      <td>0.123884</td>\n",
       "      <td>0.266222</td>\n",
       "      <td>0.116949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.401335</td>\n",
       "      <td>0.126595</td>\n",
       "      <td>0.265415</td>\n",
       "      <td>0.114720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.402237</td>\n",
       "      <td>0.056786</td>\n",
       "      <td>0.350545</td>\n",
       "      <td>0.040683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.405025</td>\n",
       "      <td>0.068458</td>\n",
       "      <td>0.346732</td>\n",
       "      <td>0.073520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413015</td>\n",
       "      <td>0.064153</td>\n",
       "      <td>0.355426</td>\n",
       "      <td>0.034867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417969</td>\n",
       "      <td>0.129339</td>\n",
       "      <td>0.264802</td>\n",
       "      <td>0.113479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.425576</td>\n",
       "      <td>0.098111</td>\n",
       "      <td>0.380870</td>\n",
       "      <td>0.138883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.428285</td>\n",
       "      <td>0.130999</td>\n",
       "      <td>0.264418</td>\n",
       "      <td>0.112739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.431733</td>\n",
       "      <td>0.111360</td>\n",
       "      <td>0.376856</td>\n",
       "      <td>0.145402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.432543</td>\n",
       "      <td>0.076769</td>\n",
       "      <td>0.357897</td>\n",
       "      <td>0.058110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.435065</td>\n",
       "      <td>0.078648</td>\n",
       "      <td>0.364533</td>\n",
       "      <td>0.024231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.438093</td>\n",
       "      <td>0.097248</td>\n",
       "      <td>0.386673</td>\n",
       "      <td>0.127770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.439818</td>\n",
       "      <td>0.082514</td>\n",
       "      <td>0.366783</td>\n",
       "      <td>0.018852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.440628</td>\n",
       "      <td>0.133425</td>\n",
       "      <td>0.263922</td>\n",
       "      <td>0.112182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442372</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.382079</td>\n",
       "      <td>0.084257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442372</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.382079</td>\n",
       "      <td>0.084257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442372</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.382079</td>\n",
       "      <td>0.084257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.442372</td>\n",
       "      <td>0.134761</td>\n",
       "      <td>0.382079</td>\n",
       "      <td>0.084257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.444226</td>\n",
       "      <td>0.083719</td>\n",
       "      <td>0.383550</td>\n",
       "      <td>0.097175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.444251</td>\n",
       "      <td>0.108198</td>\n",
       "      <td>0.383982</td>\n",
       "      <td>0.133627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.444547</td>\n",
       "      <td>0.070968</td>\n",
       "      <td>0.325741</td>\n",
       "      <td>0.056475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.444815</td>\n",
       "      <td>0.071499</td>\n",
       "      <td>0.327652</td>\n",
       "      <td>0.057906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.445196</td>\n",
       "      <td>0.072004</td>\n",
       "      <td>0.329371</td>\n",
       "      <td>0.058892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.445197</td>\n",
       "      <td>0.127846</td>\n",
       "      <td>0.375883</td>\n",
       "      <td>0.111357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.445240</td>\n",
       "      <td>0.070012</td>\n",
       "      <td>0.323485</td>\n",
       "      <td>0.053693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.445876</td>\n",
       "      <td>0.044321</td>\n",
       "      <td>0.388741</td>\n",
       "      <td>0.125243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.446350</td>\n",
       "      <td>0.072573</td>\n",
       "      <td>0.332504</td>\n",
       "      <td>0.060119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.447615</td>\n",
       "      <td>0.125791</td>\n",
       "      <td>0.373792</td>\n",
       "      <td>0.096483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.448330</td>\n",
       "      <td>0.072226</td>\n",
       "      <td>0.335458</td>\n",
       "      <td>0.060739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450324</td>\n",
       "      <td>0.067941</td>\n",
       "      <td>0.337827</td>\n",
       "      <td>0.057599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.456384</td>\n",
       "      <td>0.135313</td>\n",
       "      <td>0.263332</td>\n",
       "      <td>0.112863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.456984</td>\n",
       "      <td>0.082493</td>\n",
       "      <td>0.363020</td>\n",
       "      <td>0.041153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.458394</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.396588</td>\n",
       "      <td>0.125583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.459327</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.373996</td>\n",
       "      <td>0.029611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459327</td>\n",
       "      <td>0.087930</td>\n",
       "      <td>0.373996</td>\n",
       "      <td>0.029611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459413</td>\n",
       "      <td>0.088837</td>\n",
       "      <td>0.389978</td>\n",
       "      <td>0.105387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459477</td>\n",
       "      <td>0.084390</td>\n",
       "      <td>0.382010</td>\n",
       "      <td>0.030727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.460993</td>\n",
       "      <td>0.077874</td>\n",
       "      <td>0.379374</td>\n",
       "      <td>0.044582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.462211</td>\n",
       "      <td>0.082398</td>\n",
       "      <td>0.379309</td>\n",
       "      <td>0.034748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.462530</td>\n",
       "      <td>0.084640</td>\n",
       "      <td>0.382796</td>\n",
       "      <td>0.034758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.463859</td>\n",
       "      <td>0.058086</td>\n",
       "      <td>0.334744</td>\n",
       "      <td>0.073084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.463952</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>0.377609</td>\n",
       "      <td>0.032867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.463952</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>0.377609</td>\n",
       "      <td>0.032867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.463952</td>\n",
       "      <td>0.083813</td>\n",
       "      <td>0.377609</td>\n",
       "      <td>0.032867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466768</td>\n",
       "      <td>0.081608</td>\n",
       "      <td>0.369770</td>\n",
       "      <td>0.043682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468538</td>\n",
       "      <td>0.087120</td>\n",
       "      <td>0.380609</td>\n",
       "      <td>0.042375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.468826</td>\n",
       "      <td>0.067596</td>\n",
       "      <td>0.351568</td>\n",
       "      <td>0.050054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.469823</td>\n",
       "      <td>0.089074</td>\n",
       "      <td>0.372562</td>\n",
       "      <td>0.025067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.473621</td>\n",
       "      <td>0.080502</td>\n",
       "      <td>0.362159</td>\n",
       "      <td>0.040785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.473636</td>\n",
       "      <td>0.077137</td>\n",
       "      <td>0.357963</td>\n",
       "      <td>0.041216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.476327</td>\n",
       "      <td>0.091518</td>\n",
       "      <td>0.375189</td>\n",
       "      <td>0.051034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.478078</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.373131</td>\n",
       "      <td>0.038680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478078</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.373131</td>\n",
       "      <td>0.038680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478078</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.373131</td>\n",
       "      <td>0.038680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478078</td>\n",
       "      <td>0.082732</td>\n",
       "      <td>0.373131</td>\n",
       "      <td>0.038680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478130</td>\n",
       "      <td>0.089451</td>\n",
       "      <td>0.376081</td>\n",
       "      <td>0.024921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.478651</td>\n",
       "      <td>0.078110</td>\n",
       "      <td>0.369171</td>\n",
       "      <td>0.042412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480523</td>\n",
       "      <td>0.059595</td>\n",
       "      <td>0.281998</td>\n",
       "      <td>0.114794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.481788</td>\n",
       "      <td>0.063476</td>\n",
       "      <td>0.279447</td>\n",
       "      <td>0.123537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.482335</td>\n",
       "      <td>0.081786</td>\n",
       "      <td>0.370081</td>\n",
       "      <td>0.041771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.483338</td>\n",
       "      <td>0.063891</td>\n",
       "      <td>0.276494</td>\n",
       "      <td>0.125314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.485296</td>\n",
       "      <td>0.064555</td>\n",
       "      <td>0.273049</td>\n",
       "      <td>0.126956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.486526</td>\n",
       "      <td>0.065060</td>\n",
       "      <td>0.271075</td>\n",
       "      <td>0.127578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488097</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>0.268767</td>\n",
       "      <td>0.127902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.488507</td>\n",
       "      <td>0.087874</td>\n",
       "      <td>0.379279</td>\n",
       "      <td>0.032922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488581</td>\n",
       "      <td>0.081270</td>\n",
       "      <td>0.369327</td>\n",
       "      <td>0.041609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.489421</td>\n",
       "      <td>0.076919</td>\n",
       "      <td>0.369528</td>\n",
       "      <td>0.039097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490114</td>\n",
       "      <td>0.066535</td>\n",
       "      <td>0.266124</td>\n",
       "      <td>0.127714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490587</td>\n",
       "      <td>0.077319</td>\n",
       "      <td>0.368704</td>\n",
       "      <td>0.038601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491336</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.368853</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.492515</td>\n",
       "      <td>0.083057</td>\n",
       "      <td>0.351462</td>\n",
       "      <td>0.108794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.499243</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.383106</td>\n",
       "      <td>0.046669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.499243</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.383106</td>\n",
       "      <td>0.046669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.499243</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.383106</td>\n",
       "      <td>0.046669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.499243</td>\n",
       "      <td>0.109512</td>\n",
       "      <td>0.383106</td>\n",
       "      <td>0.046669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.504462</td>\n",
       "      <td>0.110125</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.062505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.506189</td>\n",
       "      <td>0.110889</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.062560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.506189</td>\n",
       "      <td>0.110889</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.062560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.506189</td>\n",
       "      <td>0.110889</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.062560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.506189</td>\n",
       "      <td>0.110889</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.062560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.506189</td>\n",
       "      <td>0.110889</td>\n",
       "      <td>0.387535</td>\n",
       "      <td>0.062560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.507464</td>\n",
       "      <td>0.111536</td>\n",
       "      <td>0.387256</td>\n",
       "      <td>0.062651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.507464</td>\n",
       "      <td>0.111536</td>\n",
       "      <td>0.387256</td>\n",
       "      <td>0.062651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.509760</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>0.074335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.509760</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>0.074335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.509760</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>0.074335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.509760</td>\n",
       "      <td>0.111350</td>\n",
       "      <td>0.368219</td>\n",
       "      <td>0.074335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510997</td>\n",
       "      <td>0.100655</td>\n",
       "      <td>0.330288</td>\n",
       "      <td>0.069665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.513184</td>\n",
       "      <td>0.118939</td>\n",
       "      <td>0.254407</td>\n",
       "      <td>0.088617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.515485</td>\n",
       "      <td>0.149091</td>\n",
       "      <td>0.297119</td>\n",
       "      <td>0.093742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.516595</td>\n",
       "      <td>0.103380</td>\n",
       "      <td>0.344963</td>\n",
       "      <td>0.174418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.517007</td>\n",
       "      <td>0.108674</td>\n",
       "      <td>0.327279</td>\n",
       "      <td>0.075508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521723</td>\n",
       "      <td>0.087168</td>\n",
       "      <td>0.380886</td>\n",
       "      <td>0.054797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521723</td>\n",
       "      <td>0.087168</td>\n",
       "      <td>0.380886</td>\n",
       "      <td>0.054797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521723</td>\n",
       "      <td>0.087168</td>\n",
       "      <td>0.380886</td>\n",
       "      <td>0.054797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521723</td>\n",
       "      <td>0.087168</td>\n",
       "      <td>0.380886</td>\n",
       "      <td>0.054797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.525342</td>\n",
       "      <td>0.110024</td>\n",
       "      <td>0.324021</td>\n",
       "      <td>0.076185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.528196</td>\n",
       "      <td>0.147528</td>\n",
       "      <td>0.305515</td>\n",
       "      <td>0.065736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.528782</td>\n",
       "      <td>0.085483</td>\n",
       "      <td>0.365539</td>\n",
       "      <td>0.101279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.529218</td>\n",
       "      <td>0.124872</td>\n",
       "      <td>0.408581</td>\n",
       "      <td>0.060469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.530676</td>\n",
       "      <td>0.122423</td>\n",
       "      <td>0.410320</td>\n",
       "      <td>0.057947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.531953</td>\n",
       "      <td>0.129928</td>\n",
       "      <td>0.253805</td>\n",
       "      <td>0.094615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.532672</td>\n",
       "      <td>0.090939</td>\n",
       "      <td>0.357144</td>\n",
       "      <td>0.174198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.535224</td>\n",
       "      <td>0.111594</td>\n",
       "      <td>0.320774</td>\n",
       "      <td>0.077261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541358</td>\n",
       "      <td>0.112480</td>\n",
       "      <td>0.318954</td>\n",
       "      <td>0.078012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.549565</td>\n",
       "      <td>0.112610</td>\n",
       "      <td>0.317066</td>\n",
       "      <td>0.079451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.554424</td>\n",
       "      <td>0.121444</td>\n",
       "      <td>0.324294</td>\n",
       "      <td>0.096365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555218</td>\n",
       "      <td>0.142975</td>\n",
       "      <td>0.396086</td>\n",
       "      <td>0.082802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.555843</td>\n",
       "      <td>0.134345</td>\n",
       "      <td>0.252576</td>\n",
       "      <td>0.095607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.559601</td>\n",
       "      <td>0.132456</td>\n",
       "      <td>0.394787</td>\n",
       "      <td>0.082978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.561098</td>\n",
       "      <td>0.111495</td>\n",
       "      <td>0.314860</td>\n",
       "      <td>0.081614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.569292</td>\n",
       "      <td>0.071490</td>\n",
       "      <td>0.336546</td>\n",
       "      <td>0.116453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.585638</td>\n",
       "      <td>0.140551</td>\n",
       "      <td>0.252042</td>\n",
       "      <td>0.098342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.588924</td>\n",
       "      <td>0.089537</td>\n",
       "      <td>0.349876</td>\n",
       "      <td>0.085023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.593382</td>\n",
       "      <td>0.056245</td>\n",
       "      <td>0.365340</td>\n",
       "      <td>0.093496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.601984</td>\n",
       "      <td>0.141081</td>\n",
       "      <td>0.245469</td>\n",
       "      <td>0.051573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.604900</td>\n",
       "      <td>0.143850</td>\n",
       "      <td>0.252447</td>\n",
       "      <td>0.100427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.626948</td>\n",
       "      <td>0.153278</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>0.054232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.628747</td>\n",
       "      <td>0.147406</td>\n",
       "      <td>0.252819</td>\n",
       "      <td>0.102933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.658492</td>\n",
       "      <td>0.157342</td>\n",
       "      <td>0.249753</td>\n",
       "      <td>0.054382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.659939</td>\n",
       "      <td>0.152050</td>\n",
       "      <td>0.253708</td>\n",
       "      <td>0.108252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698650</td>\n",
       "      <td>0.160191</td>\n",
       "      <td>0.252470</td>\n",
       "      <td>0.057674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.725032</td>\n",
       "      <td>0.162409</td>\n",
       "      <td>0.255258</td>\n",
       "      <td>0.062561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.756386</td>\n",
       "      <td>0.165737</td>\n",
       "      <td>0.259499</td>\n",
       "      <td>0.071084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.800728</td>\n",
       "      <td>0.174951</td>\n",
       "      <td>0.267536</td>\n",
       "      <td>0.086825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.991018</td>\n",
       "      <td>1.026009</td>\n",
       "      <td>1.026009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.882349</td>\n",
       "      <td>0.425273</td>\n",
       "      <td>0.425273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.723140</td>\n",
       "      <td>0.053218</td>\n",
       "      <td>0.053218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.611810</td>\n",
       "      <td>0.049923</td>\n",
       "      <td>0.049923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.440505</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.028777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.236736</td>\n",
       "      <td>0.009196</td>\n",
       "      <td>0.009196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.167047</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.007538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.258057</td>\n",
       "      <td>0.006040</td>\n",
       "      <td>0.006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.082954</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.991</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.026</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.425</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.723</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>0.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.083</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.258</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "         feature_name  interaction_effect\n",
      "0                BSCS                0.14\n",
      "2              BIS_11               -0.14\n",
      "1                 EDM                0.14\n",
      "11  BFI_agreeableness                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.14\n",
      "5                       TRSQ                0.14\n",
      "6  ACES_neglectful_parenting               -0.14\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.12475068446440762, 0.19058616216384583, 0.015531357926032885, 0.02099645694863994, -0.1737934774856953]\n",
      "overall_score:\n",
      "0.0356142368034462\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.372330</td>\n",
       "      <td>0.132148</td>\n",
       "      <td>0.266057</td>\n",
       "      <td>0.104696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.380018</td>\n",
       "      <td>0.143044</td>\n",
       "      <td>0.266194</td>\n",
       "      <td>0.107959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.384399</td>\n",
       "      <td>0.059740</td>\n",
       "      <td>0.307596</td>\n",
       "      <td>0.049380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.388456</td>\n",
       "      <td>0.077113</td>\n",
       "      <td>0.342498</td>\n",
       "      <td>0.129107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389359</td>\n",
       "      <td>0.146334</td>\n",
       "      <td>0.266195</td>\n",
       "      <td>0.104915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.401305</td>\n",
       "      <td>0.045319</td>\n",
       "      <td>0.328042</td>\n",
       "      <td>0.060187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.402743</td>\n",
       "      <td>0.149005</td>\n",
       "      <td>0.266155</td>\n",
       "      <td>0.104132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.412038</td>\n",
       "      <td>0.150532</td>\n",
       "      <td>0.266693</td>\n",
       "      <td>0.104996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424007</td>\n",
       "      <td>0.152456</td>\n",
       "      <td>0.267165</td>\n",
       "      <td>0.106479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.439368</td>\n",
       "      <td>0.153732</td>\n",
       "      <td>0.266448</td>\n",
       "      <td>0.108386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.466951</td>\n",
       "      <td>0.054389</td>\n",
       "      <td>0.360924</td>\n",
       "      <td>0.040327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.468848</td>\n",
       "      <td>0.071634</td>\n",
       "      <td>0.357550</td>\n",
       "      <td>0.086999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.484429</td>\n",
       "      <td>0.066668</td>\n",
       "      <td>0.362641</td>\n",
       "      <td>0.036753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507404</td>\n",
       "      <td>0.066199</td>\n",
       "      <td>0.390606</td>\n",
       "      <td>0.055861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.512985</td>\n",
       "      <td>0.083670</td>\n",
       "      <td>0.371295</td>\n",
       "      <td>0.028436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.520745</td>\n",
       "      <td>0.063354</td>\n",
       "      <td>0.350166</td>\n",
       "      <td>0.086578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521085</td>\n",
       "      <td>0.062172</td>\n",
       "      <td>0.348429</td>\n",
       "      <td>0.086244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521195</td>\n",
       "      <td>0.064423</td>\n",
       "      <td>0.351612</td>\n",
       "      <td>0.086488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521865</td>\n",
       "      <td>0.065411</td>\n",
       "      <td>0.352851</td>\n",
       "      <td>0.086224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.521984</td>\n",
       "      <td>0.091450</td>\n",
       "      <td>0.373609</td>\n",
       "      <td>0.020297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.523292</td>\n",
       "      <td>0.079657</td>\n",
       "      <td>0.365290</td>\n",
       "      <td>0.063156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.524049</td>\n",
       "      <td>0.067287</td>\n",
       "      <td>0.354288</td>\n",
       "      <td>0.085069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.526888</td>\n",
       "      <td>0.068690</td>\n",
       "      <td>0.354905</td>\n",
       "      <td>0.083561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.529046</td>\n",
       "      <td>0.111950</td>\n",
       "      <td>0.391488</td>\n",
       "      <td>0.166298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.529765</td>\n",
       "      <td>0.066110</td>\n",
       "      <td>0.355044</td>\n",
       "      <td>0.077357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.531471</td>\n",
       "      <td>0.104387</td>\n",
       "      <td>0.390552</td>\n",
       "      <td>0.166574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.535985</td>\n",
       "      <td>0.144257</td>\n",
       "      <td>0.240995</td>\n",
       "      <td>0.058331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.539786</td>\n",
       "      <td>0.138267</td>\n",
       "      <td>0.396529</td>\n",
       "      <td>0.125241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.539992</td>\n",
       "      <td>0.112226</td>\n",
       "      <td>0.392849</td>\n",
       "      <td>0.171230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.542417</td>\n",
       "      <td>0.106941</td>\n",
       "      <td>0.390563</td>\n",
       "      <td>0.172430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.543603</td>\n",
       "      <td>0.144118</td>\n",
       "      <td>0.387760</td>\n",
       "      <td>0.111761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.545889</td>\n",
       "      <td>0.073242</td>\n",
       "      <td>0.340440</td>\n",
       "      <td>0.059630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.548039</td>\n",
       "      <td>0.091734</td>\n",
       "      <td>0.384366</td>\n",
       "      <td>0.043752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.548142</td>\n",
       "      <td>0.091804</td>\n",
       "      <td>0.384265</td>\n",
       "      <td>0.043863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.550333</td>\n",
       "      <td>0.079790</td>\n",
       "      <td>0.337042</td>\n",
       "      <td>0.065604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552158</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552158</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552158</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552158</td>\n",
       "      <td>0.144248</td>\n",
       "      <td>0.391210</td>\n",
       "      <td>0.085751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.553471</td>\n",
       "      <td>0.158592</td>\n",
       "      <td>0.240312</td>\n",
       "      <td>0.064613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.556222</td>\n",
       "      <td>0.081355</td>\n",
       "      <td>0.332923</td>\n",
       "      <td>0.068904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.556368</td>\n",
       "      <td>0.084768</td>\n",
       "      <td>0.391790</td>\n",
       "      <td>0.046115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.557984</td>\n",
       "      <td>0.094053</td>\n",
       "      <td>0.370674</td>\n",
       "      <td>0.047180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.558077</td>\n",
       "      <td>0.086298</td>\n",
       "      <td>0.387859</td>\n",
       "      <td>0.048748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.558453</td>\n",
       "      <td>0.077836</td>\n",
       "      <td>0.402455</td>\n",
       "      <td>0.171407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.560627</td>\n",
       "      <td>0.095256</td>\n",
       "      <td>0.384422</td>\n",
       "      <td>0.044887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.560878</td>\n",
       "      <td>0.078254</td>\n",
       "      <td>0.402264</td>\n",
       "      <td>0.152176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.561256</td>\n",
       "      <td>0.103025</td>\n",
       "      <td>0.385627</td>\n",
       "      <td>0.042816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.562457</td>\n",
       "      <td>0.084432</td>\n",
       "      <td>0.392727</td>\n",
       "      <td>0.040366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.562471</td>\n",
       "      <td>0.103952</td>\n",
       "      <td>0.385639</td>\n",
       "      <td>0.043635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.563500</td>\n",
       "      <td>0.090958</td>\n",
       "      <td>0.381919</td>\n",
       "      <td>0.052586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.565013</td>\n",
       "      <td>0.081818</td>\n",
       "      <td>0.327855</td>\n",
       "      <td>0.072969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.565033</td>\n",
       "      <td>0.086155</td>\n",
       "      <td>0.390215</td>\n",
       "      <td>0.039012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.565033</td>\n",
       "      <td>0.086155</td>\n",
       "      <td>0.390215</td>\n",
       "      <td>0.039012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.565033</td>\n",
       "      <td>0.086155</td>\n",
       "      <td>0.390215</td>\n",
       "      <td>0.039012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.566670</td>\n",
       "      <td>0.089643</td>\n",
       "      <td>0.373849</td>\n",
       "      <td>0.055053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.570781</td>\n",
       "      <td>0.082024</td>\n",
       "      <td>0.324930</td>\n",
       "      <td>0.075749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.570882</td>\n",
       "      <td>0.069045</td>\n",
       "      <td>0.275901</td>\n",
       "      <td>0.101228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.571155</td>\n",
       "      <td>0.069144</td>\n",
       "      <td>0.274815</td>\n",
       "      <td>0.102654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.571324</td>\n",
       "      <td>0.068908</td>\n",
       "      <td>0.277893</td>\n",
       "      <td>0.098464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.571666</td>\n",
       "      <td>0.069103</td>\n",
       "      <td>0.273599</td>\n",
       "      <td>0.104213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572010</td>\n",
       "      <td>0.068836</td>\n",
       "      <td>0.279711</td>\n",
       "      <td>0.095988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572059</td>\n",
       "      <td>0.069442</td>\n",
       "      <td>0.329115</td>\n",
       "      <td>0.064041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572543</td>\n",
       "      <td>0.069120</td>\n",
       "      <td>0.272328</td>\n",
       "      <td>0.105927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572652</td>\n",
       "      <td>0.064836</td>\n",
       "      <td>0.281271</td>\n",
       "      <td>0.088600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.573463</td>\n",
       "      <td>0.080859</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.058119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576756</td>\n",
       "      <td>0.086944</td>\n",
       "      <td>0.379809</td>\n",
       "      <td>0.045243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.577042</td>\n",
       "      <td>0.163858</td>\n",
       "      <td>0.238786</td>\n",
       "      <td>0.069158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.577184</td>\n",
       "      <td>0.084345</td>\n",
       "      <td>0.368624</td>\n",
       "      <td>0.052989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.578593</td>\n",
       "      <td>0.081963</td>\n",
       "      <td>0.321241</td>\n",
       "      <td>0.079220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.580774</td>\n",
       "      <td>0.087104</td>\n",
       "      <td>0.372101</td>\n",
       "      <td>0.048314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.582556</td>\n",
       "      <td>0.086536</td>\n",
       "      <td>0.385083</td>\n",
       "      <td>0.041003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.582629</td>\n",
       "      <td>0.086638</td>\n",
       "      <td>0.385133</td>\n",
       "      <td>0.041045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.582629</td>\n",
       "      <td>0.086638</td>\n",
       "      <td>0.385133</td>\n",
       "      <td>0.041045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.582629</td>\n",
       "      <td>0.086638</td>\n",
       "      <td>0.385133</td>\n",
       "      <td>0.041045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.588120</td>\n",
       "      <td>0.082991</td>\n",
       "      <td>0.380441</td>\n",
       "      <td>0.043340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589288</td>\n",
       "      <td>0.100990</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>0.058362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589288</td>\n",
       "      <td>0.100990</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>0.058362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589288</td>\n",
       "      <td>0.100990</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>0.058362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589288</td>\n",
       "      <td>0.100990</td>\n",
       "      <td>0.408941</td>\n",
       "      <td>0.058362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589972</td>\n",
       "      <td>0.080876</td>\n",
       "      <td>0.316290</td>\n",
       "      <td>0.084173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.592034</td>\n",
       "      <td>0.088231</td>\n",
       "      <td>0.380073</td>\n",
       "      <td>0.044275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598143</td>\n",
       "      <td>0.085598</td>\n",
       "      <td>0.381092</td>\n",
       "      <td>0.043453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.600012</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.380829</td>\n",
       "      <td>0.042966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.600012</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.380829</td>\n",
       "      <td>0.042966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.600012</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.380829</td>\n",
       "      <td>0.042966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.600012</td>\n",
       "      <td>0.081998</td>\n",
       "      <td>0.380829</td>\n",
       "      <td>0.042966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.601100</td>\n",
       "      <td>0.136019</td>\n",
       "      <td>0.381069</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.601100</td>\n",
       "      <td>0.136019</td>\n",
       "      <td>0.381069</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.601100</td>\n",
       "      <td>0.136019</td>\n",
       "      <td>0.381069</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.601100</td>\n",
       "      <td>0.136019</td>\n",
       "      <td>0.381069</td>\n",
       "      <td>0.085224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.603512</td>\n",
       "      <td>0.083041</td>\n",
       "      <td>0.379535</td>\n",
       "      <td>0.042385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604636</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>0.379878</td>\n",
       "      <td>0.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.604868</td>\n",
       "      <td>0.141458</td>\n",
       "      <td>0.245798</td>\n",
       "      <td>0.052984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.605503</td>\n",
       "      <td>0.111301</td>\n",
       "      <td>0.388817</td>\n",
       "      <td>0.243574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.606367</td>\n",
       "      <td>0.169857</td>\n",
       "      <td>0.236954</td>\n",
       "      <td>0.076466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.606384</td>\n",
       "      <td>0.115435</td>\n",
       "      <td>0.388144</td>\n",
       "      <td>0.052047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.608184</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.388044</td>\n",
       "      <td>0.052051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.608184</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.388044</td>\n",
       "      <td>0.052051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.608184</td>\n",
       "      <td>0.116464</td>\n",
       "      <td>0.388044</td>\n",
       "      <td>0.052051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.610179</td>\n",
       "      <td>0.117068</td>\n",
       "      <td>0.387455</td>\n",
       "      <td>0.053140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.611521</td>\n",
       "      <td>0.117758</td>\n",
       "      <td>0.387053</td>\n",
       "      <td>0.053154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.611979</td>\n",
       "      <td>0.118011</td>\n",
       "      <td>0.387354</td>\n",
       "      <td>0.053142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.611979</td>\n",
       "      <td>0.118011</td>\n",
       "      <td>0.387354</td>\n",
       "      <td>0.053142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613722</td>\n",
       "      <td>0.143994</td>\n",
       "      <td>0.363560</td>\n",
       "      <td>0.058237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613722</td>\n",
       "      <td>0.143994</td>\n",
       "      <td>0.363560</td>\n",
       "      <td>0.058237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.613811</td>\n",
       "      <td>0.099224</td>\n",
       "      <td>0.377309</td>\n",
       "      <td>0.243620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.619738</td>\n",
       "      <td>0.091778</td>\n",
       "      <td>0.429634</td>\n",
       "      <td>0.151775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.619830</td>\n",
       "      <td>0.164259</td>\n",
       "      <td>0.310043</td>\n",
       "      <td>0.111404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.625023</td>\n",
       "      <td>0.172706</td>\n",
       "      <td>0.236645</td>\n",
       "      <td>0.082052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.628966</td>\n",
       "      <td>0.165390</td>\n",
       "      <td>0.314116</td>\n",
       "      <td>0.086720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.629094</td>\n",
       "      <td>0.153885</td>\n",
       "      <td>0.248172</td>\n",
       "      <td>0.055994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.634128</td>\n",
       "      <td>0.099315</td>\n",
       "      <td>0.442733</td>\n",
       "      <td>0.138672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.634250</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>0.377296</td>\n",
       "      <td>0.054117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.634250</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>0.377296</td>\n",
       "      <td>0.054117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.634250</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>0.377296</td>\n",
       "      <td>0.054117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.634250</td>\n",
       "      <td>0.088479</td>\n",
       "      <td>0.377296</td>\n",
       "      <td>0.054117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.643758</td>\n",
       "      <td>0.139574</td>\n",
       "      <td>0.340100</td>\n",
       "      <td>0.074497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.646724</td>\n",
       "      <td>0.140817</td>\n",
       "      <td>0.340173</td>\n",
       "      <td>0.080160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648078</td>\n",
       "      <td>0.174942</td>\n",
       "      <td>0.236980</td>\n",
       "      <td>0.090172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648187</td>\n",
       "      <td>0.086008</td>\n",
       "      <td>0.372981</td>\n",
       "      <td>0.150414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.650323</td>\n",
       "      <td>0.095504</td>\n",
       "      <td>0.391895</td>\n",
       "      <td>0.110063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.653658</td>\n",
       "      <td>0.065830</td>\n",
       "      <td>0.391344</td>\n",
       "      <td>0.136363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.659646</td>\n",
       "      <td>0.157893</td>\n",
       "      <td>0.250431</td>\n",
       "      <td>0.056698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.665982</td>\n",
       "      <td>0.103022</td>\n",
       "      <td>0.420433</td>\n",
       "      <td>0.073073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.679513</td>\n",
       "      <td>0.177428</td>\n",
       "      <td>0.238676</td>\n",
       "      <td>0.102207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.695395</td>\n",
       "      <td>0.095693</td>\n",
       "      <td>0.359239</td>\n",
       "      <td>0.131213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.698742</td>\n",
       "      <td>0.160671</td>\n",
       "      <td>0.253194</td>\n",
       "      <td>0.059228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.720576</td>\n",
       "      <td>0.098109</td>\n",
       "      <td>0.361959</td>\n",
       "      <td>0.120060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.724566</td>\n",
       "      <td>0.162608</td>\n",
       "      <td>0.255562</td>\n",
       "      <td>0.063322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.755935</td>\n",
       "      <td>0.165799</td>\n",
       "      <td>0.259467</td>\n",
       "      <td>0.071386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.800131</td>\n",
       "      <td>0.174670</td>\n",
       "      <td>0.267474</td>\n",
       "      <td>0.086838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.240274</td>\n",
       "      <td>2.788697</td>\n",
       "      <td>2.788697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.662620</td>\n",
       "      <td>2.184839</td>\n",
       "      <td>2.184839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.284614</td>\n",
       "      <td>1.849343</td>\n",
       "      <td>1.849343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.894945</td>\n",
       "      <td>0.863660</td>\n",
       "      <td>0.863660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.483538</td>\n",
       "      <td>0.645281</td>\n",
       "      <td>0.645281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.119595</td>\n",
       "      <td>0.476628</td>\n",
       "      <td>0.476628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.805867</td>\n",
       "      <td>0.331842</td>\n",
       "      <td>0.331842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.765087</td>\n",
       "      <td>0.309773</td>\n",
       "      <td>0.309773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-1.073831</td>\n",
       "      <td>0.111653</td>\n",
       "      <td>0.111653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.948030</td>\n",
       "      <td>0.094194</td>\n",
       "      <td>0.094194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>-0.834194</td>\n",
       "      <td>0.068529</td>\n",
       "      <td>0.068529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.857788</td>\n",
       "      <td>0.065170</td>\n",
       "      <td>0.065170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.689677</td>\n",
       "      <td>0.052674</td>\n",
       "      <td>0.052674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.454011</td>\n",
       "      <td>0.023894</td>\n",
       "      <td>0.023894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.410765</td>\n",
       "      <td>0.022130</td>\n",
       "      <td>0.022130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.483827</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>0.020971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.390931</td>\n",
       "      <td>0.014610</td>\n",
       "      <td>0.014610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.347547</td>\n",
       "      <td>0.014258</td>\n",
       "      <td>0.014258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.311056</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.220180</td>\n",
       "      <td>0.003684</td>\n",
       "      <td>0.003684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.240</td>\n",
       "      <td>0.148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.789</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>2.792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.663</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.185</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>2.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.849</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.895</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.283</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.484</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.858</td>\n",
       "      <td>-1.074</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.690</td>\n",
       "      <td>0.948</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_conscientiousness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.176</td>\n",
       "      <td>-0.484</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.024</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.391</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.311</td>\n",
       "      <td>-0.220</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "         feature_name  interaction_effect\n",
      "0                BSCS                0.16\n",
      "2              BIS_11               -0.16\n",
      "1                 EDM                0.16\n",
      "11  BFI_agreeableness                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.16\n",
      "5                       TRSQ                0.16\n",
      "6  ACES_neglectful_parenting               -0.16\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 20)\n",
      "(275, 20)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.15987907570804627, 0.31273035049300235, 0.1687555755829232, 0.07428941587101134, -0.12047102750349947]\n",
      "overall_score:\n",
      "0.11903667803029674\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.356747</td>\n",
       "      <td>0.128225</td>\n",
       "      <td>0.291423</td>\n",
       "      <td>0.075531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362828</td>\n",
       "      <td>0.135299</td>\n",
       "      <td>0.291287</td>\n",
       "      <td>0.076494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371313</td>\n",
       "      <td>0.134219</td>\n",
       "      <td>0.291837</td>\n",
       "      <td>0.073208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384897</td>\n",
       "      <td>0.132370</td>\n",
       "      <td>0.292289</td>\n",
       "      <td>0.074006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.394117</td>\n",
       "      <td>0.131840</td>\n",
       "      <td>0.293012</td>\n",
       "      <td>0.076542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.405611</td>\n",
       "      <td>0.064766</td>\n",
       "      <td>0.309535</td>\n",
       "      <td>0.048344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406003</td>\n",
       "      <td>0.131648</td>\n",
       "      <td>0.294088</td>\n",
       "      <td>0.081165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.421842</td>\n",
       "      <td>0.066927</td>\n",
       "      <td>0.327621</td>\n",
       "      <td>0.124104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.422014</td>\n",
       "      <td>0.131296</td>\n",
       "      <td>0.294047</td>\n",
       "      <td>0.085608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.428075</td>\n",
       "      <td>0.047556</td>\n",
       "      <td>0.332779</td>\n",
       "      <td>0.073471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.523320</td>\n",
       "      <td>0.051708</td>\n",
       "      <td>0.370084</td>\n",
       "      <td>0.042881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.527539</td>\n",
       "      <td>0.060681</td>\n",
       "      <td>0.354265</td>\n",
       "      <td>0.103152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.547285</td>\n",
       "      <td>0.069388</td>\n",
       "      <td>0.373953</td>\n",
       "      <td>0.042976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.552285</td>\n",
       "      <td>0.158660</td>\n",
       "      <td>0.243989</td>\n",
       "      <td>0.093487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.568635</td>\n",
       "      <td>0.173705</td>\n",
       "      <td>0.241704</td>\n",
       "      <td>0.102952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.580302</td>\n",
       "      <td>0.072257</td>\n",
       "      <td>0.403958</td>\n",
       "      <td>0.067247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.586959</td>\n",
       "      <td>0.087028</td>\n",
       "      <td>0.339581</td>\n",
       "      <td>0.087500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.587255</td>\n",
       "      <td>0.086312</td>\n",
       "      <td>0.337173</td>\n",
       "      <td>0.086925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.587258</td>\n",
       "      <td>0.087455</td>\n",
       "      <td>0.341722</td>\n",
       "      <td>0.087579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.588445</td>\n",
       "      <td>0.085186</td>\n",
       "      <td>0.334356</td>\n",
       "      <td>0.086075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589327</td>\n",
       "      <td>0.088014</td>\n",
       "      <td>0.344413</td>\n",
       "      <td>0.086511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.590061</td>\n",
       "      <td>0.178955</td>\n",
       "      <td>0.238908</td>\n",
       "      <td>0.108452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.591802</td>\n",
       "      <td>0.088154</td>\n",
       "      <td>0.346183</td>\n",
       "      <td>0.085261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.593633</td>\n",
       "      <td>0.088635</td>\n",
       "      <td>0.376214</td>\n",
       "      <td>0.030860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.593952</td>\n",
       "      <td>0.083463</td>\n",
       "      <td>0.347827</td>\n",
       "      <td>0.079351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.595731</td>\n",
       "      <td>0.080054</td>\n",
       "      <td>0.356603</td>\n",
       "      <td>0.071335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.598109</td>\n",
       "      <td>0.086703</td>\n",
       "      <td>0.352627</td>\n",
       "      <td>0.078569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.600514</td>\n",
       "      <td>0.089298</td>\n",
       "      <td>0.347828</td>\n",
       "      <td>0.082899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.605698</td>\n",
       "      <td>0.091149</td>\n",
       "      <td>0.341620</td>\n",
       "      <td>0.089278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.606877</td>\n",
       "      <td>0.071078</td>\n",
       "      <td>0.369206</td>\n",
       "      <td>0.076316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.608759</td>\n",
       "      <td>0.104541</td>\n",
       "      <td>0.378860</td>\n",
       "      <td>0.020254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.608865</td>\n",
       "      <td>0.141582</td>\n",
       "      <td>0.247086</td>\n",
       "      <td>0.054041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.610417</td>\n",
       "      <td>0.091043</td>\n",
       "      <td>0.338577</td>\n",
       "      <td>0.091840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.617220</td>\n",
       "      <td>0.090785</td>\n",
       "      <td>0.334799</td>\n",
       "      <td>0.093820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.617942</td>\n",
       "      <td>0.183997</td>\n",
       "      <td>0.235130</td>\n",
       "      <td>0.115139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.625459</td>\n",
       "      <td>0.091099</td>\n",
       "      <td>0.331069</td>\n",
       "      <td>0.096770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.631842</td>\n",
       "      <td>0.154064</td>\n",
       "      <td>0.248166</td>\n",
       "      <td>0.058065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.634663</td>\n",
       "      <td>0.095409</td>\n",
       "      <td>0.387916</td>\n",
       "      <td>0.048882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.635921</td>\n",
       "      <td>0.185788</td>\n",
       "      <td>0.233365</td>\n",
       "      <td>0.120328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.638886</td>\n",
       "      <td>0.099394</td>\n",
       "      <td>0.387813</td>\n",
       "      <td>0.048781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.643517</td>\n",
       "      <td>0.086182</td>\n",
       "      <td>0.379391</td>\n",
       "      <td>0.063718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.651305</td>\n",
       "      <td>0.084545</td>\n",
       "      <td>0.394969</td>\n",
       "      <td>0.065054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.651578</td>\n",
       "      <td>0.125357</td>\n",
       "      <td>0.352650</td>\n",
       "      <td>0.127605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.652119</td>\n",
       "      <td>0.112032</td>\n",
       "      <td>0.391149</td>\n",
       "      <td>0.059651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.652152</td>\n",
       "      <td>0.088034</td>\n",
       "      <td>0.388010</td>\n",
       "      <td>0.067030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.653073</td>\n",
       "      <td>0.098479</td>\n",
       "      <td>0.393402</td>\n",
       "      <td>0.174465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.654656</td>\n",
       "      <td>0.081794</td>\n",
       "      <td>0.400193</td>\n",
       "      <td>0.062494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.654876</td>\n",
       "      <td>0.107642</td>\n",
       "      <td>0.392059</td>\n",
       "      <td>0.058485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.656921</td>\n",
       "      <td>0.091754</td>\n",
       "      <td>0.377520</td>\n",
       "      <td>0.057312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.657378</td>\n",
       "      <td>0.098816</td>\n",
       "      <td>0.392880</td>\n",
       "      <td>0.060684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.658569</td>\n",
       "      <td>0.187388</td>\n",
       "      <td>0.233185</td>\n",
       "      <td>0.128107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.661294</td>\n",
       "      <td>0.158245</td>\n",
       "      <td>0.250817</td>\n",
       "      <td>0.058879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.662679</td>\n",
       "      <td>0.141145</td>\n",
       "      <td>0.354196</td>\n",
       "      <td>0.139015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.667601</td>\n",
       "      <td>0.110385</td>\n",
       "      <td>0.398615</td>\n",
       "      <td>0.190905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.669077</td>\n",
       "      <td>0.116740</td>\n",
       "      <td>0.394603</td>\n",
       "      <td>0.173553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.671137</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.369060</td>\n",
       "      <td>0.091577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.671137</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.369060</td>\n",
       "      <td>0.091577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.671137</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.369060</td>\n",
       "      <td>0.091577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.671137</td>\n",
       "      <td>0.132010</td>\n",
       "      <td>0.369060</td>\n",
       "      <td>0.091577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.672134</td>\n",
       "      <td>0.085569</td>\n",
       "      <td>0.402578</td>\n",
       "      <td>0.051694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.673506</td>\n",
       "      <td>0.086949</td>\n",
       "      <td>0.400598</td>\n",
       "      <td>0.051807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673506</td>\n",
       "      <td>0.086949</td>\n",
       "      <td>0.400598</td>\n",
       "      <td>0.051807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673602</td>\n",
       "      <td>0.086989</td>\n",
       "      <td>0.400521</td>\n",
       "      <td>0.051740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.681603</td>\n",
       "      <td>0.089456</td>\n",
       "      <td>0.363814</td>\n",
       "      <td>0.074120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.683606</td>\n",
       "      <td>0.123525</td>\n",
       "      <td>0.399188</td>\n",
       "      <td>0.190409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.685670</td>\n",
       "      <td>0.092328</td>\n",
       "      <td>0.334834</td>\n",
       "      <td>0.092339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.685966</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.377128</td>\n",
       "      <td>0.064930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.688006</td>\n",
       "      <td>0.190057</td>\n",
       "      <td>0.234205</td>\n",
       "      <td>0.137890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.690007</td>\n",
       "      <td>0.088457</td>\n",
       "      <td>0.383613</td>\n",
       "      <td>0.056834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.693857</td>\n",
       "      <td>0.087664</td>\n",
       "      <td>0.388498</td>\n",
       "      <td>0.049472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.694252</td>\n",
       "      <td>0.086828</td>\n",
       "      <td>0.396470</td>\n",
       "      <td>0.044831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.694252</td>\n",
       "      <td>0.086828</td>\n",
       "      <td>0.396470</td>\n",
       "      <td>0.044831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.694252</td>\n",
       "      <td>0.086828</td>\n",
       "      <td>0.396470</td>\n",
       "      <td>0.044831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.694274</td>\n",
       "      <td>0.086863</td>\n",
       "      <td>0.396487</td>\n",
       "      <td>0.044841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.699258</td>\n",
       "      <td>0.161403</td>\n",
       "      <td>0.253798</td>\n",
       "      <td>0.060901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701250</td>\n",
       "      <td>0.110508</td>\n",
       "      <td>0.282417</td>\n",
       "      <td>0.139868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701372</td>\n",
       "      <td>0.110083</td>\n",
       "      <td>0.282119</td>\n",
       "      <td>0.140924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701401</td>\n",
       "      <td>0.084682</td>\n",
       "      <td>0.389958</td>\n",
       "      <td>0.048429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701449</td>\n",
       "      <td>0.109613</td>\n",
       "      <td>0.282021</td>\n",
       "      <td>0.141703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701541</td>\n",
       "      <td>0.109121</td>\n",
       "      <td>0.282014</td>\n",
       "      <td>0.142206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701742</td>\n",
       "      <td>0.108144</td>\n",
       "      <td>0.282257</td>\n",
       "      <td>0.142460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701865</td>\n",
       "      <td>0.107287</td>\n",
       "      <td>0.282887</td>\n",
       "      <td>0.141904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.701948</td>\n",
       "      <td>0.100471</td>\n",
       "      <td>0.283758</td>\n",
       "      <td>0.132744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.703439</td>\n",
       "      <td>0.088443</td>\n",
       "      <td>0.403603</td>\n",
       "      <td>0.181537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.710825</td>\n",
       "      <td>0.089229</td>\n",
       "      <td>0.391229</td>\n",
       "      <td>0.048467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.714986</td>\n",
       "      <td>0.088420</td>\n",
       "      <td>0.390939</td>\n",
       "      <td>0.049174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717937</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.415989</td>\n",
       "      <td>0.057875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717937</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.415989</td>\n",
       "      <td>0.057875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717937</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.415989</td>\n",
       "      <td>0.057875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717937</td>\n",
       "      <td>0.119525</td>\n",
       "      <td>0.415989</td>\n",
       "      <td>0.057875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.718649</td>\n",
       "      <td>0.085053</td>\n",
       "      <td>0.388684</td>\n",
       "      <td>0.045180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718649</td>\n",
       "      <td>0.085053</td>\n",
       "      <td>0.388684</td>\n",
       "      <td>0.045180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718649</td>\n",
       "      <td>0.085053</td>\n",
       "      <td>0.388684</td>\n",
       "      <td>0.045180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718649</td>\n",
       "      <td>0.085053</td>\n",
       "      <td>0.388684</td>\n",
       "      <td>0.045180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.719444</td>\n",
       "      <td>0.104960</td>\n",
       "      <td>0.405085</td>\n",
       "      <td>0.175845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.721648</td>\n",
       "      <td>0.051523</td>\n",
       "      <td>0.408681</td>\n",
       "      <td>0.208026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.724208</td>\n",
       "      <td>0.162773</td>\n",
       "      <td>0.255807</td>\n",
       "      <td>0.064344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.725883</td>\n",
       "      <td>0.086549</td>\n",
       "      <td>0.387012</td>\n",
       "      <td>0.045905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.726947</td>\n",
       "      <td>0.086531</td>\n",
       "      <td>0.387322</td>\n",
       "      <td>0.046353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.728402</td>\n",
       "      <td>0.117136</td>\n",
       "      <td>0.386209</td>\n",
       "      <td>0.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.728402</td>\n",
       "      <td>0.117136</td>\n",
       "      <td>0.386209</td>\n",
       "      <td>0.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.728402</td>\n",
       "      <td>0.117136</td>\n",
       "      <td>0.386209</td>\n",
       "      <td>0.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.730275</td>\n",
       "      <td>0.118100</td>\n",
       "      <td>0.386191</td>\n",
       "      <td>0.042169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.732859</td>\n",
       "      <td>0.118743</td>\n",
       "      <td>0.385575</td>\n",
       "      <td>0.043189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.732859</td>\n",
       "      <td>0.118743</td>\n",
       "      <td>0.385575</td>\n",
       "      <td>0.043189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.732859</td>\n",
       "      <td>0.118743</td>\n",
       "      <td>0.385575</td>\n",
       "      <td>0.043189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.734732</td>\n",
       "      <td>0.119607</td>\n",
       "      <td>0.385556</td>\n",
       "      <td>0.043189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.736036</td>\n",
       "      <td>0.153144</td>\n",
       "      <td>0.387023</td>\n",
       "      <td>0.093973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.736036</td>\n",
       "      <td>0.153144</td>\n",
       "      <td>0.387023</td>\n",
       "      <td>0.093973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.736036</td>\n",
       "      <td>0.153144</td>\n",
       "      <td>0.387023</td>\n",
       "      <td>0.093973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.736036</td>\n",
       "      <td>0.153144</td>\n",
       "      <td>0.387023</td>\n",
       "      <td>0.093973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.739488</td>\n",
       "      <td>0.107383</td>\n",
       "      <td>0.389635</td>\n",
       "      <td>0.214201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.742505</td>\n",
       "      <td>0.085944</td>\n",
       "      <td>0.425134</td>\n",
       "      <td>0.152191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.744669</td>\n",
       "      <td>0.093818</td>\n",
       "      <td>0.419597</td>\n",
       "      <td>0.158833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.744785</td>\n",
       "      <td>0.077352</td>\n",
       "      <td>0.382412</td>\n",
       "      <td>0.051150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.744785</td>\n",
       "      <td>0.077352</td>\n",
       "      <td>0.382412</td>\n",
       "      <td>0.051150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.744785</td>\n",
       "      <td>0.077352</td>\n",
       "      <td>0.382412</td>\n",
       "      <td>0.051150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.744785</td>\n",
       "      <td>0.077352</td>\n",
       "      <td>0.382412</td>\n",
       "      <td>0.051150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.755589</td>\n",
       "      <td>0.165753</td>\n",
       "      <td>0.259579</td>\n",
       "      <td>0.071944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.756187</td>\n",
       "      <td>0.174557</td>\n",
       "      <td>0.331457</td>\n",
       "      <td>0.091768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.759376</td>\n",
       "      <td>0.076342</td>\n",
       "      <td>0.393057</td>\n",
       "      <td>0.171783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.760834</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.405712</td>\n",
       "      <td>0.089288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.760834</td>\n",
       "      <td>0.175258</td>\n",
       "      <td>0.405712</td>\n",
       "      <td>0.089288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.771367</td>\n",
       "      <td>0.199691</td>\n",
       "      <td>0.325819</td>\n",
       "      <td>0.105465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.779669</td>\n",
       "      <td>0.164452</td>\n",
       "      <td>0.384107</td>\n",
       "      <td>0.109802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.783306</td>\n",
       "      <td>0.127885</td>\n",
       "      <td>0.377908</td>\n",
       "      <td>0.183695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.789085</td>\n",
       "      <td>0.130783</td>\n",
       "      <td>0.400444</td>\n",
       "      <td>0.142455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.789740</td>\n",
       "      <td>0.173595</td>\n",
       "      <td>0.381157</td>\n",
       "      <td>0.126275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.792479</td>\n",
       "      <td>0.125465</td>\n",
       "      <td>0.427193</td>\n",
       "      <td>0.134508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.799551</td>\n",
       "      <td>0.174408</td>\n",
       "      <td>0.267416</td>\n",
       "      <td>0.086885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.822746</td>\n",
       "      <td>0.123531</td>\n",
       "      <td>0.329575</td>\n",
       "      <td>0.125993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.823253</td>\n",
       "      <td>0.080339</td>\n",
       "      <td>0.336467</td>\n",
       "      <td>0.123637</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.994835</td>\n",
       "      <td>2.398333</td>\n",
       "      <td>2.398333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.811965</td>\n",
       "      <td>2.251003</td>\n",
       "      <td>2.251003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.166750</td>\n",
       "      <td>1.704088</td>\n",
       "      <td>1.704088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>3.338437</td>\n",
       "      <td>1.076983</td>\n",
       "      <td>1.076983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.812751</td>\n",
       "      <td>0.755284</td>\n",
       "      <td>0.755284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>2.371279</td>\n",
       "      <td>0.556376</td>\n",
       "      <td>0.556376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.110092</td>\n",
       "      <td>0.417158</td>\n",
       "      <td>0.417158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.825398</td>\n",
       "      <td>0.325650</td>\n",
       "      <td>0.325650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.971782</td>\n",
       "      <td>0.094565</td>\n",
       "      <td>0.094565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.853285</td>\n",
       "      <td>0.062435</td>\n",
       "      <td>0.062435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.783317</td>\n",
       "      <td>0.056975</td>\n",
       "      <td>0.056975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.699221</td>\n",
       "      <td>0.049692</td>\n",
       "      <td>0.049692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.481084</td>\n",
       "      <td>0.024765</td>\n",
       "      <td>0.024765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.485086</td>\n",
       "      <td>0.023556</td>\n",
       "      <td>0.023556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.478275</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.022171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.397281</td>\n",
       "      <td>0.019479</td>\n",
       "      <td>0.019479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.411460</td>\n",
       "      <td>0.017948</td>\n",
       "      <td>0.017948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.304894</td>\n",
       "      <td>0.011044</td>\n",
       "      <td>0.011044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.312877</td>\n",
       "      <td>0.007037</td>\n",
       "      <td>0.007037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.250665</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.006701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>2.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.812</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.251</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.167</td>\n",
       "      <td>0.074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.704</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>1.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.338</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.077</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.297</td>\n",
       "      <td>0.450</td>\n",
       "      <td>1.077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.556</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.853</td>\n",
       "      <td>-0.972</td>\n",
       "      <td>-0.411</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.699</td>\n",
       "      <td>0.783</td>\n",
       "      <td>-0.478</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "       feature_name  interaction_effect\n",
      "0              BSCS                0.08\n",
      "2            BIS_11               -0.08\n",
      "1               EDM                0.08\n",
      "14  BFI_neuroticism                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 25)\n",
      "(275, 25)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.006113324875223869, 0.015382233580734317, -0.11909727101985212, -0.14403570203041016, -0.03116074306651906]\n",
      "overall_score:\n",
      "-0.05455963153216463\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.274434</td>\n",
       "      <td>0.070966</td>\n",
       "      <td>0.332318</td>\n",
       "      <td>0.074649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.275745</td>\n",
       "      <td>0.060991</td>\n",
       "      <td>0.308210</td>\n",
       "      <td>0.076795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282612</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.338813</td>\n",
       "      <td>0.053075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285153</td>\n",
       "      <td>0.115366</td>\n",
       "      <td>0.335123</td>\n",
       "      <td>0.064818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285153</td>\n",
       "      <td>0.115366</td>\n",
       "      <td>0.335123</td>\n",
       "      <td>0.064818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285153</td>\n",
       "      <td>0.115366</td>\n",
       "      <td>0.335123</td>\n",
       "      <td>0.064818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285153</td>\n",
       "      <td>0.115366</td>\n",
       "      <td>0.335123</td>\n",
       "      <td>0.064818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.286944</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.364100</td>\n",
       "      <td>0.047237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287004</td>\n",
       "      <td>0.077225</td>\n",
       "      <td>0.340647</td>\n",
       "      <td>0.051352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.288484</td>\n",
       "      <td>0.070706</td>\n",
       "      <td>0.362991</td>\n",
       "      <td>0.039062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.289406</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>0.362534</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.289406</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>0.362534</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.289406</td>\n",
       "      <td>0.073030</td>\n",
       "      <td>0.362534</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.289945</td>\n",
       "      <td>0.075465</td>\n",
       "      <td>0.364445</td>\n",
       "      <td>0.039629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.289945</td>\n",
       "      <td>0.075465</td>\n",
       "      <td>0.364445</td>\n",
       "      <td>0.039629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.290823</td>\n",
       "      <td>0.062890</td>\n",
       "      <td>0.361911</td>\n",
       "      <td>0.049577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.291481</td>\n",
       "      <td>0.066745</td>\n",
       "      <td>0.363227</td>\n",
       "      <td>0.040403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.291657</td>\n",
       "      <td>0.077962</td>\n",
       "      <td>0.363018</td>\n",
       "      <td>0.040341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291659</td>\n",
       "      <td>0.088036</td>\n",
       "      <td>0.326508</td>\n",
       "      <td>0.062405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291756</td>\n",
       "      <td>0.083951</td>\n",
       "      <td>0.340775</td>\n",
       "      <td>0.035591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.292100</td>\n",
       "      <td>0.067037</td>\n",
       "      <td>0.362999</td>\n",
       "      <td>0.039347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293306</td>\n",
       "      <td>0.078424</td>\n",
       "      <td>0.351426</td>\n",
       "      <td>0.043590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294174</td>\n",
       "      <td>0.078204</td>\n",
       "      <td>0.346772</td>\n",
       "      <td>0.032013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.295151</td>\n",
       "      <td>0.077804</td>\n",
       "      <td>0.349980</td>\n",
       "      <td>0.032317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.297725</td>\n",
       "      <td>0.062476</td>\n",
       "      <td>0.359730</td>\n",
       "      <td>0.052825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.298334</td>\n",
       "      <td>0.082971</td>\n",
       "      <td>0.362676</td>\n",
       "      <td>0.032942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299147</td>\n",
       "      <td>0.077443</td>\n",
       "      <td>0.351740</td>\n",
       "      <td>0.035098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.299257</td>\n",
       "      <td>0.071494</td>\n",
       "      <td>0.352559</td>\n",
       "      <td>0.037083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.299257</td>\n",
       "      <td>0.071494</td>\n",
       "      <td>0.352559</td>\n",
       "      <td>0.037083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.299257</td>\n",
       "      <td>0.071494</td>\n",
       "      <td>0.352559</td>\n",
       "      <td>0.037083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.299301</td>\n",
       "      <td>0.071517</td>\n",
       "      <td>0.352588</td>\n",
       "      <td>0.037123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301705</td>\n",
       "      <td>0.072615</td>\n",
       "      <td>0.348942</td>\n",
       "      <td>0.038369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.303913</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.349703</td>\n",
       "      <td>0.035025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.303913</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.349703</td>\n",
       "      <td>0.035025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.303913</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.349703</td>\n",
       "      <td>0.035025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.303913</td>\n",
       "      <td>0.068443</td>\n",
       "      <td>0.349703</td>\n",
       "      <td>0.035025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304175</td>\n",
       "      <td>0.072530</td>\n",
       "      <td>0.349412</td>\n",
       "      <td>0.037226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.305992</td>\n",
       "      <td>0.062526</td>\n",
       "      <td>0.357020</td>\n",
       "      <td>0.057114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.306642</td>\n",
       "      <td>0.116496</td>\n",
       "      <td>0.310633</td>\n",
       "      <td>0.093024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.307209</td>\n",
       "      <td>0.052451</td>\n",
       "      <td>0.347993</td>\n",
       "      <td>0.053737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307936</td>\n",
       "      <td>0.117078</td>\n",
       "      <td>0.304107</td>\n",
       "      <td>0.101132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.310070</td>\n",
       "      <td>0.052936</td>\n",
       "      <td>0.352555</td>\n",
       "      <td>0.045320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310163</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310163</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310163</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310163</td>\n",
       "      <td>0.123529</td>\n",
       "      <td>0.350306</td>\n",
       "      <td>0.069170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.312665</td>\n",
       "      <td>0.089796</td>\n",
       "      <td>0.361554</td>\n",
       "      <td>0.028740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.322022</td>\n",
       "      <td>0.089301</td>\n",
       "      <td>0.297819</td>\n",
       "      <td>0.087772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325508</td>\n",
       "      <td>0.094377</td>\n",
       "      <td>0.295174</td>\n",
       "      <td>0.090918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326799</td>\n",
       "      <td>0.145022</td>\n",
       "      <td>0.361072</td>\n",
       "      <td>0.057780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.329507</td>\n",
       "      <td>0.062117</td>\n",
       "      <td>0.360147</td>\n",
       "      <td>0.059667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.329824</td>\n",
       "      <td>0.094564</td>\n",
       "      <td>0.292229</td>\n",
       "      <td>0.088353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.331171</td>\n",
       "      <td>0.067432</td>\n",
       "      <td>0.359783</td>\n",
       "      <td>0.063269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.332092</td>\n",
       "      <td>0.101342</td>\n",
       "      <td>0.342321</td>\n",
       "      <td>0.037836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.332092</td>\n",
       "      <td>0.101342</td>\n",
       "      <td>0.342321</td>\n",
       "      <td>0.037836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.332092</td>\n",
       "      <td>0.101342</td>\n",
       "      <td>0.342321</td>\n",
       "      <td>0.037836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.332092</td>\n",
       "      <td>0.101342</td>\n",
       "      <td>0.342321</td>\n",
       "      <td>0.037836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.332527</td>\n",
       "      <td>0.140467</td>\n",
       "      <td>0.362500</td>\n",
       "      <td>0.063059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.333466</td>\n",
       "      <td>0.069452</td>\n",
       "      <td>0.359261</td>\n",
       "      <td>0.063255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335154</td>\n",
       "      <td>0.095399</td>\n",
       "      <td>0.288820</td>\n",
       "      <td>0.085318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.336644</td>\n",
       "      <td>0.072738</td>\n",
       "      <td>0.358630</td>\n",
       "      <td>0.063614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.337350</td>\n",
       "      <td>0.095191</td>\n",
       "      <td>0.363383</td>\n",
       "      <td>0.032792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.338430</td>\n",
       "      <td>0.096340</td>\n",
       "      <td>0.286822</td>\n",
       "      <td>0.083721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.338722</td>\n",
       "      <td>0.074879</td>\n",
       "      <td>0.358262</td>\n",
       "      <td>0.063750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.341728</td>\n",
       "      <td>0.076726</td>\n",
       "      <td>0.358219</td>\n",
       "      <td>0.063793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342233</td>\n",
       "      <td>0.097714</td>\n",
       "      <td>0.284634</td>\n",
       "      <td>0.082029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.344612</td>\n",
       "      <td>0.153253</td>\n",
       "      <td>0.343053</td>\n",
       "      <td>0.055813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.345356</td>\n",
       "      <td>0.078802</td>\n",
       "      <td>0.358469</td>\n",
       "      <td>0.063780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346106</td>\n",
       "      <td>0.143366</td>\n",
       "      <td>0.343092</td>\n",
       "      <td>0.057939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346576</td>\n",
       "      <td>0.099188</td>\n",
       "      <td>0.282289</td>\n",
       "      <td>0.079978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.351207</td>\n",
       "      <td>0.046596</td>\n",
       "      <td>0.314882</td>\n",
       "      <td>0.056011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.352277</td>\n",
       "      <td>0.077707</td>\n",
       "      <td>0.361454</td>\n",
       "      <td>0.049841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.352277</td>\n",
       "      <td>0.077707</td>\n",
       "      <td>0.361454</td>\n",
       "      <td>0.049841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.352277</td>\n",
       "      <td>0.077707</td>\n",
       "      <td>0.361454</td>\n",
       "      <td>0.049841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.352277</td>\n",
       "      <td>0.077707</td>\n",
       "      <td>0.361454</td>\n",
       "      <td>0.049841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.356398</td>\n",
       "      <td>0.109771</td>\n",
       "      <td>0.374469</td>\n",
       "      <td>0.078080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.356398</td>\n",
       "      <td>0.109771</td>\n",
       "      <td>0.374469</td>\n",
       "      <td>0.078080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.356398</td>\n",
       "      <td>0.109771</td>\n",
       "      <td>0.374469</td>\n",
       "      <td>0.078080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.359148</td>\n",
       "      <td>0.103775</td>\n",
       "      <td>0.370987</td>\n",
       "      <td>0.072652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362994</td>\n",
       "      <td>0.112660</td>\n",
       "      <td>0.265653</td>\n",
       "      <td>0.097754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365274</td>\n",
       "      <td>0.113312</td>\n",
       "      <td>0.367161</td>\n",
       "      <td>0.073966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365274</td>\n",
       "      <td>0.113312</td>\n",
       "      <td>0.367161</td>\n",
       "      <td>0.073966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365274</td>\n",
       "      <td>0.113312</td>\n",
       "      <td>0.367161</td>\n",
       "      <td>0.073966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365274</td>\n",
       "      <td>0.113312</td>\n",
       "      <td>0.367161</td>\n",
       "      <td>0.073966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.374655</td>\n",
       "      <td>0.046128</td>\n",
       "      <td>0.322608</td>\n",
       "      <td>0.059221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.379288</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>0.248115</td>\n",
       "      <td>0.119720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.384916</td>\n",
       "      <td>0.082946</td>\n",
       "      <td>0.406611</td>\n",
       "      <td>0.080846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.387222</td>\n",
       "      <td>0.074896</td>\n",
       "      <td>0.406980</td>\n",
       "      <td>0.079253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.396115</td>\n",
       "      <td>0.103818</td>\n",
       "      <td>0.330225</td>\n",
       "      <td>0.019558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.397572</td>\n",
       "      <td>0.102493</td>\n",
       "      <td>0.377850</td>\n",
       "      <td>0.048059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.397590</td>\n",
       "      <td>0.096159</td>\n",
       "      <td>0.329180</td>\n",
       "      <td>0.024540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.400163</td>\n",
       "      <td>0.126315</td>\n",
       "      <td>0.375446</td>\n",
       "      <td>0.053115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.405649</td>\n",
       "      <td>0.085734</td>\n",
       "      <td>0.375026</td>\n",
       "      <td>0.048759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.405748</td>\n",
       "      <td>0.106404</td>\n",
       "      <td>0.399422</td>\n",
       "      <td>0.064178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.408240</td>\n",
       "      <td>0.113541</td>\n",
       "      <td>0.374377</td>\n",
       "      <td>0.045673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.412281</td>\n",
       "      <td>0.106585</td>\n",
       "      <td>0.396518</td>\n",
       "      <td>0.057806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.429611</td>\n",
       "      <td>0.127487</td>\n",
       "      <td>0.317633</td>\n",
       "      <td>0.043201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.432714</td>\n",
       "      <td>0.122241</td>\n",
       "      <td>0.317913</td>\n",
       "      <td>0.044303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.436890</td>\n",
       "      <td>0.137561</td>\n",
       "      <td>0.252856</td>\n",
       "      <td>0.070552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.437255</td>\n",
       "      <td>0.064742</td>\n",
       "      <td>0.335321</td>\n",
       "      <td>0.078589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.446790</td>\n",
       "      <td>0.070678</td>\n",
       "      <td>0.333526</td>\n",
       "      <td>0.086705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454952</td>\n",
       "      <td>0.151193</td>\n",
       "      <td>0.252291</td>\n",
       "      <td>0.079259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.460309</td>\n",
       "      <td>0.075769</td>\n",
       "      <td>0.330682</td>\n",
       "      <td>0.089582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.477232</td>\n",
       "      <td>0.157364</td>\n",
       "      <td>0.252260</td>\n",
       "      <td>0.085054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478743</td>\n",
       "      <td>0.083064</td>\n",
       "      <td>0.327534</td>\n",
       "      <td>0.091533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.490741</td>\n",
       "      <td>0.088186</td>\n",
       "      <td>0.325827</td>\n",
       "      <td>0.091930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.497043</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.393034</td>\n",
       "      <td>0.080197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.505872</td>\n",
       "      <td>0.095920</td>\n",
       "      <td>0.324316</td>\n",
       "      <td>0.091635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505952</td>\n",
       "      <td>0.165251</td>\n",
       "      <td>0.252900</td>\n",
       "      <td>0.092305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.517181</td>\n",
       "      <td>0.095852</td>\n",
       "      <td>0.324079</td>\n",
       "      <td>0.087510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.519127</td>\n",
       "      <td>0.108410</td>\n",
       "      <td>0.376225</td>\n",
       "      <td>0.075790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.523930</td>\n",
       "      <td>0.169988</td>\n",
       "      <td>0.253702</td>\n",
       "      <td>0.097857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.525954</td>\n",
       "      <td>0.106833</td>\n",
       "      <td>0.323019</td>\n",
       "      <td>0.090913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.545992</td>\n",
       "      <td>0.175041</td>\n",
       "      <td>0.254886</td>\n",
       "      <td>0.104486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.558261</td>\n",
       "      <td>0.113419</td>\n",
       "      <td>0.308006</td>\n",
       "      <td>0.076171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.573635</td>\n",
       "      <td>0.181053</td>\n",
       "      <td>0.256598</td>\n",
       "      <td>0.112756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.637061</td>\n",
       "      <td>0.066126</td>\n",
       "      <td>0.294157</td>\n",
       "      <td>0.079570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.656316</td>\n",
       "      <td>0.069020</td>\n",
       "      <td>0.295670</td>\n",
       "      <td>0.087621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.679079</td>\n",
       "      <td>0.068917</td>\n",
       "      <td>0.297497</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.707856</td>\n",
       "      <td>0.072311</td>\n",
       "      <td>0.300960</td>\n",
       "      <td>0.098178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.725385</td>\n",
       "      <td>0.075886</td>\n",
       "      <td>0.303705</td>\n",
       "      <td>0.102232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.746930</td>\n",
       "      <td>0.079889</td>\n",
       "      <td>0.307618</td>\n",
       "      <td>0.106599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.774650</td>\n",
       "      <td>0.086241</td>\n",
       "      <td>0.313646</td>\n",
       "      <td>0.112875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.874988</td>\n",
       "      <td>0.122598</td>\n",
       "      <td>0.292612</td>\n",
       "      <td>0.112111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.912931</td>\n",
       "      <td>0.130042</td>\n",
       "      <td>0.291378</td>\n",
       "      <td>0.122776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.961986</td>\n",
       "      <td>0.129638</td>\n",
       "      <td>0.291446</td>\n",
       "      <td>0.125593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.029201</td>\n",
       "      <td>0.128007</td>\n",
       "      <td>0.293791</td>\n",
       "      <td>0.126931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.073016</td>\n",
       "      <td>0.125578</td>\n",
       "      <td>0.295068</td>\n",
       "      <td>0.127923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.128585</td>\n",
       "      <td>0.122757</td>\n",
       "      <td>0.296467</td>\n",
       "      <td>0.130172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.206407</td>\n",
       "      <td>0.117799</td>\n",
       "      <td>0.296141</td>\n",
       "      <td>0.135361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.745645</td>\n",
       "      <td>0.086381</td>\n",
       "      <td>0.086381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.403295</td>\n",
       "      <td>0.031686</td>\n",
       "      <td>0.031686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.194827</td>\n",
       "      <td>0.010759</td>\n",
       "      <td>0.010759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.059078</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.002682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.403</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.059</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.195</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "       feature_name  interaction_effect\n",
      "0              BSCS                 0.1\n",
      "2            BIS_11                -0.1\n",
      "1               EDM                 0.1\n",
      "14  BFI_neuroticism                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 25)\n",
      "(275, 25)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[-0.11145074619294992, -0.047957789945971996, -0.0917207614914386, -0.12353020740028908, -0.20630398035165598]\n",
      "overall_score:\n",
      "-0.11619269707646111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.340116</td>\n",
       "      <td>0.063683</td>\n",
       "      <td>0.326978</td>\n",
       "      <td>0.062987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348463</td>\n",
       "      <td>0.077774</td>\n",
       "      <td>0.347851</td>\n",
       "      <td>0.068625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358002</td>\n",
       "      <td>0.078881</td>\n",
       "      <td>0.353763</td>\n",
       "      <td>0.052688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.362821</td>\n",
       "      <td>0.080222</td>\n",
       "      <td>0.376775</td>\n",
       "      <td>0.040931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.364119</td>\n",
       "      <td>0.076080</td>\n",
       "      <td>0.377657</td>\n",
       "      <td>0.050867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365052</td>\n",
       "      <td>0.074682</td>\n",
       "      <td>0.373224</td>\n",
       "      <td>0.040124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365061</td>\n",
       "      <td>0.082236</td>\n",
       "      <td>0.354207</td>\n",
       "      <td>0.048839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365770</td>\n",
       "      <td>0.095508</td>\n",
       "      <td>0.374643</td>\n",
       "      <td>0.059375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365782</td>\n",
       "      <td>0.077736</td>\n",
       "      <td>0.373964</td>\n",
       "      <td>0.040642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365782</td>\n",
       "      <td>0.077736</td>\n",
       "      <td>0.373964</td>\n",
       "      <td>0.040642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.365782</td>\n",
       "      <td>0.077736</td>\n",
       "      <td>0.373964</td>\n",
       "      <td>0.040642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.366004</td>\n",
       "      <td>0.081734</td>\n",
       "      <td>0.377197</td>\n",
       "      <td>0.040989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.366005</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.379483</td>\n",
       "      <td>0.036272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.366005</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>0.379483</td>\n",
       "      <td>0.036272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.367711</td>\n",
       "      <td>0.076990</td>\n",
       "      <td>0.378114</td>\n",
       "      <td>0.054854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.369197</td>\n",
       "      <td>0.087194</td>\n",
       "      <td>0.376893</td>\n",
       "      <td>0.038027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.371172</td>\n",
       "      <td>0.067855</td>\n",
       "      <td>0.353123</td>\n",
       "      <td>0.054851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.371250</td>\n",
       "      <td>0.079092</td>\n",
       "      <td>0.360195</td>\n",
       "      <td>0.047140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.374373</td>\n",
       "      <td>0.096352</td>\n",
       "      <td>0.341569</td>\n",
       "      <td>0.051308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.375080</td>\n",
       "      <td>0.078259</td>\n",
       "      <td>0.377415</td>\n",
       "      <td>0.060370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.375255</td>\n",
       "      <td>0.093380</td>\n",
       "      <td>0.377170</td>\n",
       "      <td>0.034456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.375929</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>0.381728</td>\n",
       "      <td>0.055572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.375929</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>0.381728</td>\n",
       "      <td>0.055572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.375929</td>\n",
       "      <td>0.126584</td>\n",
       "      <td>0.381728</td>\n",
       "      <td>0.055572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376933</td>\n",
       "      <td>0.124726</td>\n",
       "      <td>0.380976</td>\n",
       "      <td>0.054987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.377308</td>\n",
       "      <td>0.075434</td>\n",
       "      <td>0.362530</td>\n",
       "      <td>0.039178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.377481</td>\n",
       "      <td>0.075621</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.039278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.377481</td>\n",
       "      <td>0.075621</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.039278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.377481</td>\n",
       "      <td>0.075621</td>\n",
       "      <td>0.362607</td>\n",
       "      <td>0.039278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.377567</td>\n",
       "      <td>0.083829</td>\n",
       "      <td>0.354471</td>\n",
       "      <td>0.034136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378716</td>\n",
       "      <td>0.087369</td>\n",
       "      <td>0.350486</td>\n",
       "      <td>0.035329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378862</td>\n",
       "      <td>0.094824</td>\n",
       "      <td>0.348955</td>\n",
       "      <td>0.038156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378870</td>\n",
       "      <td>0.079601</td>\n",
       "      <td>0.358852</td>\n",
       "      <td>0.038147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380048</td>\n",
       "      <td>0.099229</td>\n",
       "      <td>0.384477</td>\n",
       "      <td>0.051542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.382809</td>\n",
       "      <td>0.072231</td>\n",
       "      <td>0.357944</td>\n",
       "      <td>0.052533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383865</td>\n",
       "      <td>0.076682</td>\n",
       "      <td>0.358919</td>\n",
       "      <td>0.041889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.384935</td>\n",
       "      <td>0.079621</td>\n",
       "      <td>0.375447</td>\n",
       "      <td>0.064660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.387712</td>\n",
       "      <td>0.077054</td>\n",
       "      <td>0.357795</td>\n",
       "      <td>0.040101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388785</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.356855</td>\n",
       "      <td>0.035799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.388785</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.356855</td>\n",
       "      <td>0.035799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388785</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.356855</td>\n",
       "      <td>0.035799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388785</td>\n",
       "      <td>0.073269</td>\n",
       "      <td>0.356855</td>\n",
       "      <td>0.035799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.389899</td>\n",
       "      <td>0.101202</td>\n",
       "      <td>0.375918</td>\n",
       "      <td>0.036970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390303</td>\n",
       "      <td>0.073491</td>\n",
       "      <td>0.357318</td>\n",
       "      <td>0.035681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390374</td>\n",
       "      <td>0.073566</td>\n",
       "      <td>0.357245</td>\n",
       "      <td>0.035624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392780</td>\n",
       "      <td>0.123189</td>\n",
       "      <td>0.365385</td>\n",
       "      <td>0.100447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.393184</td>\n",
       "      <td>0.066198</td>\n",
       "      <td>0.324887</td>\n",
       "      <td>0.058390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.396905</td>\n",
       "      <td>0.062376</td>\n",
       "      <td>0.370289</td>\n",
       "      <td>0.082610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.398200</td>\n",
       "      <td>0.092963</td>\n",
       "      <td>0.380949</td>\n",
       "      <td>0.041221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.399011</td>\n",
       "      <td>0.066775</td>\n",
       "      <td>0.368807</td>\n",
       "      <td>0.088008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399030</td>\n",
       "      <td>0.114825</td>\n",
       "      <td>0.361767</td>\n",
       "      <td>0.088891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399441</td>\n",
       "      <td>0.151722</td>\n",
       "      <td>0.372754</td>\n",
       "      <td>0.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399441</td>\n",
       "      <td>0.151722</td>\n",
       "      <td>0.372754</td>\n",
       "      <td>0.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399441</td>\n",
       "      <td>0.151722</td>\n",
       "      <td>0.372754</td>\n",
       "      <td>0.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399441</td>\n",
       "      <td>0.151722</td>\n",
       "      <td>0.372754</td>\n",
       "      <td>0.062156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.401447</td>\n",
       "      <td>0.067573</td>\n",
       "      <td>0.367065</td>\n",
       "      <td>0.088320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.403073</td>\n",
       "      <td>0.074719</td>\n",
       "      <td>0.407298</td>\n",
       "      <td>0.101857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.403579</td>\n",
       "      <td>0.083165</td>\n",
       "      <td>0.309675</td>\n",
       "      <td>0.075284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.405043</td>\n",
       "      <td>0.068300</td>\n",
       "      <td>0.365331</td>\n",
       "      <td>0.088058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.405134</td>\n",
       "      <td>0.088760</td>\n",
       "      <td>0.307700</td>\n",
       "      <td>0.080212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.405903</td>\n",
       "      <td>0.120129</td>\n",
       "      <td>0.412225</td>\n",
       "      <td>0.141345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.406898</td>\n",
       "      <td>0.089450</td>\n",
       "      <td>0.305417</td>\n",
       "      <td>0.080465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.406995</td>\n",
       "      <td>0.045204</td>\n",
       "      <td>0.330258</td>\n",
       "      <td>0.057905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407356</td>\n",
       "      <td>0.068714</td>\n",
       "      <td>0.364291</td>\n",
       "      <td>0.087574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.408259</td>\n",
       "      <td>0.110965</td>\n",
       "      <td>0.419568</td>\n",
       "      <td>0.134796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.409123</td>\n",
       "      <td>0.090249</td>\n",
       "      <td>0.302517</td>\n",
       "      <td>0.080622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.410116</td>\n",
       "      <td>0.069431</td>\n",
       "      <td>0.363003</td>\n",
       "      <td>0.086751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.410450</td>\n",
       "      <td>0.090761</td>\n",
       "      <td>0.300810</td>\n",
       "      <td>0.080554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.412155</td>\n",
       "      <td>0.091141</td>\n",
       "      <td>0.298696</td>\n",
       "      <td>0.080256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.413619</td>\n",
       "      <td>0.070802</td>\n",
       "      <td>0.361521</td>\n",
       "      <td>0.085369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.414204</td>\n",
       "      <td>0.091646</td>\n",
       "      <td>0.296242</td>\n",
       "      <td>0.079755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.080822</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.044393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.417683</td>\n",
       "      <td>0.088881</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.050550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.417683</td>\n",
       "      <td>0.088881</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.050550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.417683</td>\n",
       "      <td>0.088881</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.050550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.417683</td>\n",
       "      <td>0.088881</td>\n",
       "      <td>0.362938</td>\n",
       "      <td>0.050550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.420181</td>\n",
       "      <td>0.113170</td>\n",
       "      <td>0.421881</td>\n",
       "      <td>0.135623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.422537</td>\n",
       "      <td>0.106319</td>\n",
       "      <td>0.426924</td>\n",
       "      <td>0.129934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423011</td>\n",
       "      <td>0.108046</td>\n",
       "      <td>0.381653</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.423011</td>\n",
       "      <td>0.108046</td>\n",
       "      <td>0.381653</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423011</td>\n",
       "      <td>0.108046</td>\n",
       "      <td>0.381653</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.423011</td>\n",
       "      <td>0.108046</td>\n",
       "      <td>0.381653</td>\n",
       "      <td>0.082269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.423664</td>\n",
       "      <td>0.083383</td>\n",
       "      <td>0.366157</td>\n",
       "      <td>0.053156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.423664</td>\n",
       "      <td>0.083383</td>\n",
       "      <td>0.366157</td>\n",
       "      <td>0.053156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.423664</td>\n",
       "      <td>0.083383</td>\n",
       "      <td>0.366157</td>\n",
       "      <td>0.053156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.423664</td>\n",
       "      <td>0.083383</td>\n",
       "      <td>0.366157</td>\n",
       "      <td>0.053156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.424037</td>\n",
       "      <td>0.076112</td>\n",
       "      <td>0.415465</td>\n",
       "      <td>0.099582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.424433</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.388560</td>\n",
       "      <td>0.121172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436656</td>\n",
       "      <td>0.109983</td>\n",
       "      <td>0.374229</td>\n",
       "      <td>0.080521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436656</td>\n",
       "      <td>0.109983</td>\n",
       "      <td>0.374229</td>\n",
       "      <td>0.080521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436656</td>\n",
       "      <td>0.109983</td>\n",
       "      <td>0.374229</td>\n",
       "      <td>0.080521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436656</td>\n",
       "      <td>0.109983</td>\n",
       "      <td>0.374229</td>\n",
       "      <td>0.080521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.437032</td>\n",
       "      <td>0.130851</td>\n",
       "      <td>0.384793</td>\n",
       "      <td>0.064798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.440803</td>\n",
       "      <td>0.124976</td>\n",
       "      <td>0.383945</td>\n",
       "      <td>0.070949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452534</td>\n",
       "      <td>0.080371</td>\n",
       "      <td>0.353063</td>\n",
       "      <td>0.027632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.454230</td>\n",
       "      <td>0.086800</td>\n",
       "      <td>0.395661</td>\n",
       "      <td>0.106150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459069</td>\n",
       "      <td>0.138489</td>\n",
       "      <td>0.387251</td>\n",
       "      <td>0.067031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459478</td>\n",
       "      <td>0.162347</td>\n",
       "      <td>0.279975</td>\n",
       "      <td>0.069279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.463810</td>\n",
       "      <td>0.129647</td>\n",
       "      <td>0.389482</td>\n",
       "      <td>0.070306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.465461</td>\n",
       "      <td>0.131592</td>\n",
       "      <td>0.339810</td>\n",
       "      <td>0.105151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.474705</td>\n",
       "      <td>0.179977</td>\n",
       "      <td>0.275955</td>\n",
       "      <td>0.075298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490218</td>\n",
       "      <td>0.143719</td>\n",
       "      <td>0.342936</td>\n",
       "      <td>0.066443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.494829</td>\n",
       "      <td>0.187616</td>\n",
       "      <td>0.271236</td>\n",
       "      <td>0.078311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.495473</td>\n",
       "      <td>0.038744</td>\n",
       "      <td>0.350186</td>\n",
       "      <td>0.093295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.503398</td>\n",
       "      <td>0.038669</td>\n",
       "      <td>0.347827</td>\n",
       "      <td>0.101868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.513502</td>\n",
       "      <td>0.039312</td>\n",
       "      <td>0.344567</td>\n",
       "      <td>0.104092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.520754</td>\n",
       "      <td>0.195995</td>\n",
       "      <td>0.266168</td>\n",
       "      <td>0.084991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.527611</td>\n",
       "      <td>0.044422</td>\n",
       "      <td>0.340407</td>\n",
       "      <td>0.104503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.534314</td>\n",
       "      <td>0.069006</td>\n",
       "      <td>0.380123</td>\n",
       "      <td>0.169663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.536561</td>\n",
       "      <td>0.049305</td>\n",
       "      <td>0.337905</td>\n",
       "      <td>0.104043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.537312</td>\n",
       "      <td>0.200176</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>0.090331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.539166</td>\n",
       "      <td>0.159579</td>\n",
       "      <td>0.367789</td>\n",
       "      <td>0.094816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.548316</td>\n",
       "      <td>0.055503</td>\n",
       "      <td>0.334939</td>\n",
       "      <td>0.102730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.557725</td>\n",
       "      <td>0.204836</td>\n",
       "      <td>0.259929</td>\n",
       "      <td>0.097145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.563887</td>\n",
       "      <td>0.064081</td>\n",
       "      <td>0.331406</td>\n",
       "      <td>0.100999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.568182</td>\n",
       "      <td>0.162143</td>\n",
       "      <td>0.373837</td>\n",
       "      <td>0.080495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.568996</td>\n",
       "      <td>0.072098</td>\n",
       "      <td>0.398178</td>\n",
       "      <td>0.164664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.582516</td>\n",
       "      <td>0.210730</td>\n",
       "      <td>0.256973</td>\n",
       "      <td>0.106039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.659683</td>\n",
       "      <td>0.089374</td>\n",
       "      <td>0.282764</td>\n",
       "      <td>0.069277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.677852</td>\n",
       "      <td>0.092057</td>\n",
       "      <td>0.281940</td>\n",
       "      <td>0.075535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.699354</td>\n",
       "      <td>0.088277</td>\n",
       "      <td>0.280628</td>\n",
       "      <td>0.078405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.727023</td>\n",
       "      <td>0.083266</td>\n",
       "      <td>0.280768</td>\n",
       "      <td>0.082217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.743894</td>\n",
       "      <td>0.081198</td>\n",
       "      <td>0.281032</td>\n",
       "      <td>0.085093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.764876</td>\n",
       "      <td>0.077861</td>\n",
       "      <td>0.281893</td>\n",
       "      <td>0.088179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.792114</td>\n",
       "      <td>0.073606</td>\n",
       "      <td>0.283660</td>\n",
       "      <td>0.093173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.876713</td>\n",
       "      <td>0.123535</td>\n",
       "      <td>0.295382</td>\n",
       "      <td>0.110884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.914244</td>\n",
       "      <td>0.131025</td>\n",
       "      <td>0.293607</td>\n",
       "      <td>0.121872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.962911</td>\n",
       "      <td>0.130767</td>\n",
       "      <td>0.293148</td>\n",
       "      <td>0.125456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.029448</td>\n",
       "      <td>0.128784</td>\n",
       "      <td>0.294990</td>\n",
       "      <td>0.126803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.072703</td>\n",
       "      <td>0.126511</td>\n",
       "      <td>0.296146</td>\n",
       "      <td>0.127821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.128262</td>\n",
       "      <td>0.123474</td>\n",
       "      <td>0.297094</td>\n",
       "      <td>0.130250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.205952</td>\n",
       "      <td>0.118057</td>\n",
       "      <td>0.296277</td>\n",
       "      <td>0.135697</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.341349</td>\n",
       "      <td>0.657891</td>\n",
       "      <td>0.657891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.260271</td>\n",
       "      <td>0.191827</td>\n",
       "      <td>0.191827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.861931</td>\n",
       "      <td>0.107155</td>\n",
       "      <td>0.107155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.544511</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.041783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.232786</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>0.008618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.182961</td>\n",
       "      <td>0.005119</td>\n",
       "      <td>0.005119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.122362</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.002992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.085508</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.001458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.009697</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.260</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.862</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.545</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.042</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.010</td>\n",
       "      <td>-0.233</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.183</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.122</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "       feature_name  interaction_effect\n",
      "0              BSCS                0.12\n",
      "2            BIS_11               -0.12\n",
      "1               EDM                0.12\n",
      "14  BFI_neuroticism                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.12\n",
      "5                       TRSQ                0.12\n",
      "6  ACES_neglectful_parenting               -0.12\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 25)\n",
      "(275, 25)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.07167807801960202, 0.025169343246913112, -0.04464029208682785, -0.17421781400872494, -0.3042187418693727]\n",
      "overall_score:\n",
      "-0.08524588533968207\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390133</td>\n",
       "      <td>0.094766</td>\n",
       "      <td>0.307740</td>\n",
       "      <td>0.097622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415409</td>\n",
       "      <td>0.083880</td>\n",
       "      <td>0.341580</td>\n",
       "      <td>0.082041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.436241</td>\n",
       "      <td>0.045530</td>\n",
       "      <td>0.337219</td>\n",
       "      <td>0.057969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.437159</td>\n",
       "      <td>0.084356</td>\n",
       "      <td>0.357706</td>\n",
       "      <td>0.060856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.437992</td>\n",
       "      <td>0.092472</td>\n",
       "      <td>0.384179</td>\n",
       "      <td>0.049647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.440444</td>\n",
       "      <td>0.080662</td>\n",
       "      <td>0.364640</td>\n",
       "      <td>0.058563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.445314</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.333376</td>\n",
       "      <td>0.052638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.448447</td>\n",
       "      <td>0.093727</td>\n",
       "      <td>0.392567</td>\n",
       "      <td>0.041973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.449391</td>\n",
       "      <td>0.093443</td>\n",
       "      <td>0.392633</td>\n",
       "      <td>0.041930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450340</td>\n",
       "      <td>0.084840</td>\n",
       "      <td>0.387925</td>\n",
       "      <td>0.055295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450674</td>\n",
       "      <td>0.095223</td>\n",
       "      <td>0.386328</td>\n",
       "      <td>0.046981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.450854</td>\n",
       "      <td>0.117474</td>\n",
       "      <td>0.347333</td>\n",
       "      <td>0.059248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.451861</td>\n",
       "      <td>0.081285</td>\n",
       "      <td>0.383684</td>\n",
       "      <td>0.042531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452308</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.385111</td>\n",
       "      <td>0.041861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.452353</td>\n",
       "      <td>0.083730</td>\n",
       "      <td>0.385104</td>\n",
       "      <td>0.041862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452353</td>\n",
       "      <td>0.083730</td>\n",
       "      <td>0.385104</td>\n",
       "      <td>0.041862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.453197</td>\n",
       "      <td>0.095652</td>\n",
       "      <td>0.391746</td>\n",
       "      <td>0.042135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.453901</td>\n",
       "      <td>0.091620</td>\n",
       "      <td>0.393149</td>\n",
       "      <td>0.040302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.453960</td>\n",
       "      <td>0.074259</td>\n",
       "      <td>0.392685</td>\n",
       "      <td>0.064659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455569</td>\n",
       "      <td>0.089037</td>\n",
       "      <td>0.384461</td>\n",
       "      <td>0.061838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.457312</td>\n",
       "      <td>0.086974</td>\n",
       "      <td>0.361803</td>\n",
       "      <td>0.043403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.459233</td>\n",
       "      <td>0.103109</td>\n",
       "      <td>0.393004</td>\n",
       "      <td>0.040045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459388</td>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>0.053586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459388</td>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>0.053586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459388</td>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>0.053586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459388</td>\n",
       "      <td>0.136091</td>\n",
       "      <td>0.384398</td>\n",
       "      <td>0.053586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.459587</td>\n",
       "      <td>0.122182</td>\n",
       "      <td>0.397435</td>\n",
       "      <td>0.137392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461256</td>\n",
       "      <td>0.099475</td>\n",
       "      <td>0.357573</td>\n",
       "      <td>0.047343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.463144</td>\n",
       "      <td>0.081854</td>\n",
       "      <td>0.368749</td>\n",
       "      <td>0.053630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.463475</td>\n",
       "      <td>0.094689</td>\n",
       "      <td>0.380044</td>\n",
       "      <td>0.070813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.467065</td>\n",
       "      <td>0.092240</td>\n",
       "      <td>0.360502</td>\n",
       "      <td>0.041608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.468175</td>\n",
       "      <td>0.083809</td>\n",
       "      <td>0.368770</td>\n",
       "      <td>0.044479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.470296</td>\n",
       "      <td>0.110157</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.041823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.470426</td>\n",
       "      <td>0.088914</td>\n",
       "      <td>0.362445</td>\n",
       "      <td>0.037682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.472493</td>\n",
       "      <td>0.082227</td>\n",
       "      <td>0.373486</td>\n",
       "      <td>0.038627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.472597</td>\n",
       "      <td>0.082367</td>\n",
       "      <td>0.373552</td>\n",
       "      <td>0.038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.472597</td>\n",
       "      <td>0.082367</td>\n",
       "      <td>0.373552</td>\n",
       "      <td>0.038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.472597</td>\n",
       "      <td>0.082367</td>\n",
       "      <td>0.373552</td>\n",
       "      <td>0.038707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.475395</td>\n",
       "      <td>0.099487</td>\n",
       "      <td>0.374228</td>\n",
       "      <td>0.079886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.477823</td>\n",
       "      <td>0.170623</td>\n",
       "      <td>0.361638</td>\n",
       "      <td>0.101292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.477874</td>\n",
       "      <td>0.082362</td>\n",
       "      <td>0.368365</td>\n",
       "      <td>0.039395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.477999</td>\n",
       "      <td>0.076363</td>\n",
       "      <td>0.400130</td>\n",
       "      <td>0.074660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.478126</td>\n",
       "      <td>0.108726</td>\n",
       "      <td>0.320151</td>\n",
       "      <td>0.068008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.478214</td>\n",
       "      <td>0.159296</td>\n",
       "      <td>0.275599</td>\n",
       "      <td>0.070584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.478526</td>\n",
       "      <td>0.112074</td>\n",
       "      <td>0.409330</td>\n",
       "      <td>0.121030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.479407</td>\n",
       "      <td>0.114899</td>\n",
       "      <td>0.319477</td>\n",
       "      <td>0.071605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480809</td>\n",
       "      <td>0.114405</td>\n",
       "      <td>0.318737</td>\n",
       "      <td>0.070966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.482370</td>\n",
       "      <td>0.113804</td>\n",
       "      <td>0.317907</td>\n",
       "      <td>0.070179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.483261</td>\n",
       "      <td>0.082814</td>\n",
       "      <td>0.368498</td>\n",
       "      <td>0.042802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.483363</td>\n",
       "      <td>0.113257</td>\n",
       "      <td>0.317331</td>\n",
       "      <td>0.069526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.484500</td>\n",
       "      <td>0.112548</td>\n",
       "      <td>0.316613</td>\n",
       "      <td>0.069041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.485777</td>\n",
       "      <td>0.111671</td>\n",
       "      <td>0.315813</td>\n",
       "      <td>0.068688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.487339</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.368364</td>\n",
       "      <td>0.038255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.487339</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.368364</td>\n",
       "      <td>0.038255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.487339</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.368364</td>\n",
       "      <td>0.038255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.487339</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.368364</td>\n",
       "      <td>0.038255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.487696</td>\n",
       "      <td>0.081518</td>\n",
       "      <td>0.368838</td>\n",
       "      <td>0.041701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489839</td>\n",
       "      <td>0.163208</td>\n",
       "      <td>0.359967</td>\n",
       "      <td>0.086909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490769</td>\n",
       "      <td>0.077493</td>\n",
       "      <td>0.368660</td>\n",
       "      <td>0.038571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490980</td>\n",
       "      <td>0.077555</td>\n",
       "      <td>0.368679</td>\n",
       "      <td>0.038587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.492471</td>\n",
       "      <td>0.066435</td>\n",
       "      <td>0.365207</td>\n",
       "      <td>0.092548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.493059</td>\n",
       "      <td>0.100976</td>\n",
       "      <td>0.387403</td>\n",
       "      <td>0.124836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.494031</td>\n",
       "      <td>0.174184</td>\n",
       "      <td>0.275141</td>\n",
       "      <td>0.072783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.495053</td>\n",
       "      <td>0.069853</td>\n",
       "      <td>0.363681</td>\n",
       "      <td>0.098384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.498280</td>\n",
       "      <td>0.069209</td>\n",
       "      <td>0.361955</td>\n",
       "      <td>0.098340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.500485</td>\n",
       "      <td>0.147780</td>\n",
       "      <td>0.367020</td>\n",
       "      <td>0.056203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.502189</td>\n",
       "      <td>0.068624</td>\n",
       "      <td>0.360041</td>\n",
       "      <td>0.097977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.502262</td>\n",
       "      <td>0.147944</td>\n",
       "      <td>0.379071</td>\n",
       "      <td>0.065644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.502262</td>\n",
       "      <td>0.147944</td>\n",
       "      <td>0.379071</td>\n",
       "      <td>0.065644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.502262</td>\n",
       "      <td>0.147944</td>\n",
       "      <td>0.379071</td>\n",
       "      <td>0.065644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.502262</td>\n",
       "      <td>0.147944</td>\n",
       "      <td>0.379071</td>\n",
       "      <td>0.065644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.504231</td>\n",
       "      <td>0.141833</td>\n",
       "      <td>0.365250</td>\n",
       "      <td>0.058089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.504465</td>\n",
       "      <td>0.068409</td>\n",
       "      <td>0.359006</td>\n",
       "      <td>0.097608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507132</td>\n",
       "      <td>0.068441</td>\n",
       "      <td>0.357899</td>\n",
       "      <td>0.097032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.509292</td>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.051597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.509292</td>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.051597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.509292</td>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.051597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.509292</td>\n",
       "      <td>0.116673</td>\n",
       "      <td>0.391800</td>\n",
       "      <td>0.051597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510267</td>\n",
       "      <td>0.101697</td>\n",
       "      <td>0.394374</td>\n",
       "      <td>0.045331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510267</td>\n",
       "      <td>0.101697</td>\n",
       "      <td>0.394374</td>\n",
       "      <td>0.045331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510267</td>\n",
       "      <td>0.101697</td>\n",
       "      <td>0.394374</td>\n",
       "      <td>0.045331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510267</td>\n",
       "      <td>0.101697</td>\n",
       "      <td>0.394374</td>\n",
       "      <td>0.045331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.510301</td>\n",
       "      <td>0.068569</td>\n",
       "      <td>0.357018</td>\n",
       "      <td>0.096229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.511998</td>\n",
       "      <td>0.097978</td>\n",
       "      <td>0.399968</td>\n",
       "      <td>0.113056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.514102</td>\n",
       "      <td>0.179020</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>0.070098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.516346</td>\n",
       "      <td>0.092530</td>\n",
       "      <td>0.382276</td>\n",
       "      <td>0.051963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.520060</td>\n",
       "      <td>0.105278</td>\n",
       "      <td>0.391760</td>\n",
       "      <td>0.059533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.520060</td>\n",
       "      <td>0.105278</td>\n",
       "      <td>0.391760</td>\n",
       "      <td>0.059533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.520330</td>\n",
       "      <td>0.053678</td>\n",
       "      <td>0.356913</td>\n",
       "      <td>0.105310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.520512</td>\n",
       "      <td>0.105425</td>\n",
       "      <td>0.391829</td>\n",
       "      <td>0.059504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.520512</td>\n",
       "      <td>0.105425</td>\n",
       "      <td>0.391829</td>\n",
       "      <td>0.059504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.528468</td>\n",
       "      <td>0.055788</td>\n",
       "      <td>0.352993</td>\n",
       "      <td>0.114923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.529815</td>\n",
       "      <td>0.128301</td>\n",
       "      <td>0.398416</td>\n",
       "      <td>0.149247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.530737</td>\n",
       "      <td>0.102001</td>\n",
       "      <td>0.403928</td>\n",
       "      <td>0.137832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.530868</td>\n",
       "      <td>0.178097</td>\n",
       "      <td>0.360553</td>\n",
       "      <td>0.059079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.532029</td>\n",
       "      <td>0.178934</td>\n",
       "      <td>0.368265</td>\n",
       "      <td>0.056970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.534408</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.379974</td>\n",
       "      <td>0.065147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.534408</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.379974</td>\n",
       "      <td>0.065147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.534408</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.379974</td>\n",
       "      <td>0.065147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.534408</td>\n",
       "      <td>0.115311</td>\n",
       "      <td>0.379974</td>\n",
       "      <td>0.065147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.534835</td>\n",
       "      <td>0.169449</td>\n",
       "      <td>0.271997</td>\n",
       "      <td>0.113039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.538552</td>\n",
       "      <td>0.055961</td>\n",
       "      <td>0.348909</td>\n",
       "      <td>0.117224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.539165</td>\n",
       "      <td>0.184063</td>\n",
       "      <td>0.272329</td>\n",
       "      <td>0.071691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.552819</td>\n",
       "      <td>0.057705</td>\n",
       "      <td>0.344761</td>\n",
       "      <td>0.116958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555280</td>\n",
       "      <td>0.186445</td>\n",
       "      <td>0.271933</td>\n",
       "      <td>0.075137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.555738</td>\n",
       "      <td>0.074058</td>\n",
       "      <td>0.383942</td>\n",
       "      <td>0.026265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.556154</td>\n",
       "      <td>0.097657</td>\n",
       "      <td>0.417642</td>\n",
       "      <td>0.123264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.558435</td>\n",
       "      <td>0.107135</td>\n",
       "      <td>0.410863</td>\n",
       "      <td>0.138318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.558496</td>\n",
       "      <td>0.177318</td>\n",
       "      <td>0.268248</td>\n",
       "      <td>0.103464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.562199</td>\n",
       "      <td>0.059475</td>\n",
       "      <td>0.342370</td>\n",
       "      <td>0.115413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.573649</td>\n",
       "      <td>0.062967</td>\n",
       "      <td>0.340462</td>\n",
       "      <td>0.113374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.575216</td>\n",
       "      <td>0.188784</td>\n",
       "      <td>0.270922</td>\n",
       "      <td>0.080025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.577158</td>\n",
       "      <td>0.108588</td>\n",
       "      <td>0.383892</td>\n",
       "      <td>0.151106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.589785</td>\n",
       "      <td>0.067714</td>\n",
       "      <td>0.339124</td>\n",
       "      <td>0.109224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.600185</td>\n",
       "      <td>0.191493</td>\n",
       "      <td>0.270401</td>\n",
       "      <td>0.088031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.600562</td>\n",
       "      <td>0.085919</td>\n",
       "      <td>0.401085</td>\n",
       "      <td>0.140401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.623524</td>\n",
       "      <td>0.092489</td>\n",
       "      <td>0.361263</td>\n",
       "      <td>0.083748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.651678</td>\n",
       "      <td>0.074706</td>\n",
       "      <td>0.375848</td>\n",
       "      <td>0.070755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.718752</td>\n",
       "      <td>0.078066</td>\n",
       "      <td>0.279563</td>\n",
       "      <td>0.049884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.737386</td>\n",
       "      <td>0.078205</td>\n",
       "      <td>0.280326</td>\n",
       "      <td>0.050865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.760372</td>\n",
       "      <td>0.071162</td>\n",
       "      <td>0.280373</td>\n",
       "      <td>0.050951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.788837</td>\n",
       "      <td>0.060727</td>\n",
       "      <td>0.282127</td>\n",
       "      <td>0.053584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.806453</td>\n",
       "      <td>0.054561</td>\n",
       "      <td>0.283360</td>\n",
       "      <td>0.056623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.828647</td>\n",
       "      <td>0.046407</td>\n",
       "      <td>0.285530</td>\n",
       "      <td>0.062428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.858449</td>\n",
       "      <td>0.035130</td>\n",
       "      <td>0.288808</td>\n",
       "      <td>0.073514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.878866</td>\n",
       "      <td>0.124556</td>\n",
       "      <td>0.298433</td>\n",
       "      <td>0.109575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.915979</td>\n",
       "      <td>0.132392</td>\n",
       "      <td>0.296382</td>\n",
       "      <td>0.120909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.964097</td>\n",
       "      <td>0.131927</td>\n",
       "      <td>0.295184</td>\n",
       "      <td>0.125128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.029842</td>\n",
       "      <td>0.129623</td>\n",
       "      <td>0.296446</td>\n",
       "      <td>0.126530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.072857</td>\n",
       "      <td>0.127096</td>\n",
       "      <td>0.297392</td>\n",
       "      <td>0.127641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.128197</td>\n",
       "      <td>0.124178</td>\n",
       "      <td>0.297875</td>\n",
       "      <td>0.130223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.205659</td>\n",
       "      <td>0.118410</td>\n",
       "      <td>0.296586</td>\n",
       "      <td>0.135885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.963519</td>\n",
       "      <td>1.009153</td>\n",
       "      <td>1.009153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.910246</td>\n",
       "      <td>0.436911</td>\n",
       "      <td>0.436911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.926245</td>\n",
       "      <td>0.109972</td>\n",
       "      <td>0.109972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.666139</td>\n",
       "      <td>0.044971</td>\n",
       "      <td>0.044971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.237334</td>\n",
       "      <td>0.009086</td>\n",
       "      <td>0.009086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.109589</td>\n",
       "      <td>0.004214</td>\n",
       "      <td>0.004214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.205338</td>\n",
       "      <td>0.003785</td>\n",
       "      <td>0.003785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.007753</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.042530</td>\n",
       "      <td>-0.000076</td>\n",
       "      <td>0.000076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>IMI_effort_importance*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.910</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.237</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.00</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.205</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "       feature_name  interaction_effect\n",
      "0              BSCS                0.14\n",
      "2            BIS_11               -0.14\n",
      "1               EDM                0.14\n",
      "14  BFI_neuroticism                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.14\n",
      "5                       TRSQ                0.14\n",
      "6  ACES_neglectful_parenting               -0.14\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 25)\n",
      "(275, 25)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.12475068446440762, 0.18478024365777235, 0.011680968891102705, -0.03853884701618626, -0.3559572458514768]\n",
      "overall_score:\n",
      "-0.014656839170876079\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.449656</td>\n",
       "      <td>0.101287</td>\n",
       "      <td>0.318538</td>\n",
       "      <td>0.090222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.457602</td>\n",
       "      <td>0.046165</td>\n",
       "      <td>0.340766</td>\n",
       "      <td>0.059430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.467001</td>\n",
       "      <td>0.057481</td>\n",
       "      <td>0.348051</td>\n",
       "      <td>0.048804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.486851</td>\n",
       "      <td>0.093757</td>\n",
       "      <td>0.350438</td>\n",
       "      <td>0.083999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.510742</td>\n",
       "      <td>0.089821</td>\n",
       "      <td>0.377779</td>\n",
       "      <td>0.066679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.516749</td>\n",
       "      <td>0.152337</td>\n",
       "      <td>0.278062</td>\n",
       "      <td>0.038589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.518775</td>\n",
       "      <td>0.107028</td>\n",
       "      <td>0.391315</td>\n",
       "      <td>0.056906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.526652</td>\n",
       "      <td>0.089158</td>\n",
       "      <td>0.417237</td>\n",
       "      <td>0.041488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.531238</td>\n",
       "      <td>0.166112</td>\n",
       "      <td>0.278001</td>\n",
       "      <td>0.036880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.531247</td>\n",
       "      <td>0.098566</td>\n",
       "      <td>0.364315</td>\n",
       "      <td>0.063708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.534031</td>\n",
       "      <td>0.106771</td>\n",
       "      <td>0.403125</td>\n",
       "      <td>0.051051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.537618</td>\n",
       "      <td>0.105118</td>\n",
       "      <td>0.402736</td>\n",
       "      <td>0.052934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.537827</td>\n",
       "      <td>0.110926</td>\n",
       "      <td>0.397130</td>\n",
       "      <td>0.049863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.537993</td>\n",
       "      <td>0.096165</td>\n",
       "      <td>0.385582</td>\n",
       "      <td>0.054603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541502</td>\n",
       "      <td>0.092444</td>\n",
       "      <td>0.399111</td>\n",
       "      <td>0.062935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.542782</td>\n",
       "      <td>0.104906</td>\n",
       "      <td>0.405221</td>\n",
       "      <td>0.051919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.543328</td>\n",
       "      <td>0.125983</td>\n",
       "      <td>0.360844</td>\n",
       "      <td>0.067204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.545465</td>\n",
       "      <td>0.097267</td>\n",
       "      <td>0.395837</td>\n",
       "      <td>0.070505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.546560</td>\n",
       "      <td>0.087354</td>\n",
       "      <td>0.397140</td>\n",
       "      <td>0.047977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.546839</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>0.398594</td>\n",
       "      <td>0.046482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.546839</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>0.398594</td>\n",
       "      <td>0.046482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.546839</td>\n",
       "      <td>0.091110</td>\n",
       "      <td>0.398594</td>\n",
       "      <td>0.046482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.547102</td>\n",
       "      <td>0.110838</td>\n",
       "      <td>0.406983</td>\n",
       "      <td>0.053210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.549827</td>\n",
       "      <td>0.085324</td>\n",
       "      <td>0.370977</td>\n",
       "      <td>0.111647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.549893</td>\n",
       "      <td>0.169823</td>\n",
       "      <td>0.279001</td>\n",
       "      <td>0.036503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.550412</td>\n",
       "      <td>0.088993</td>\n",
       "      <td>0.368751</td>\n",
       "      <td>0.119340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.551327</td>\n",
       "      <td>0.087503</td>\n",
       "      <td>0.365976</td>\n",
       "      <td>0.120232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.553586</td>\n",
       "      <td>0.085338</td>\n",
       "      <td>0.362302</td>\n",
       "      <td>0.120889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.553631</td>\n",
       "      <td>0.104009</td>\n",
       "      <td>0.391596</td>\n",
       "      <td>0.078006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.553782</td>\n",
       "      <td>0.105472</td>\n",
       "      <td>0.409538</td>\n",
       "      <td>0.167236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.553947</td>\n",
       "      <td>0.110320</td>\n",
       "      <td>0.368329</td>\n",
       "      <td>0.060760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.554691</td>\n",
       "      <td>0.110894</td>\n",
       "      <td>0.417293</td>\n",
       "      <td>0.167262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.555246</td>\n",
       "      <td>0.083997</td>\n",
       "      <td>0.360514</td>\n",
       "      <td>0.121165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.557489</td>\n",
       "      <td>0.082270</td>\n",
       "      <td>0.358705</td>\n",
       "      <td>0.121025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.557957</td>\n",
       "      <td>0.118306</td>\n",
       "      <td>0.406905</td>\n",
       "      <td>0.051586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.560484</td>\n",
       "      <td>0.106229</td>\n",
       "      <td>0.389624</td>\n",
       "      <td>0.085018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.560520</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.356628</td>\n",
       "      <td>0.120345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.561363</td>\n",
       "      <td>0.096563</td>\n",
       "      <td>0.372890</td>\n",
       "      <td>0.046261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.567680</td>\n",
       "      <td>0.099266</td>\n",
       "      <td>0.372938</td>\n",
       "      <td>0.051371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.569310</td>\n",
       "      <td>0.154802</td>\n",
       "      <td>0.378794</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.569310</td>\n",
       "      <td>0.154802</td>\n",
       "      <td>0.378794</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.569310</td>\n",
       "      <td>0.154802</td>\n",
       "      <td>0.378794</td>\n",
       "      <td>0.058700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.569456</td>\n",
       "      <td>0.119506</td>\n",
       "      <td>0.330564</td>\n",
       "      <td>0.063778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.570484</td>\n",
       "      <td>0.153072</td>\n",
       "      <td>0.377750</td>\n",
       "      <td>0.058993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.571018</td>\n",
       "      <td>0.126336</td>\n",
       "      <td>0.329330</td>\n",
       "      <td>0.067488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572782</td>\n",
       "      <td>0.125882</td>\n",
       "      <td>0.327934</td>\n",
       "      <td>0.067329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.573346</td>\n",
       "      <td>0.173608</td>\n",
       "      <td>0.280321</td>\n",
       "      <td>0.041576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.573600</td>\n",
       "      <td>0.095331</td>\n",
       "      <td>0.373869</td>\n",
       "      <td>0.043984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.574940</td>\n",
       "      <td>0.125494</td>\n",
       "      <td>0.326211</td>\n",
       "      <td>0.067090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.575781</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0.385565</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.575781</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0.385565</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.575781</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0.385565</td>\n",
       "      <td>0.039652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.575793</td>\n",
       "      <td>0.087403</td>\n",
       "      <td>0.385509</td>\n",
       "      <td>0.039598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576137</td>\n",
       "      <td>0.125242</td>\n",
       "      <td>0.325253</td>\n",
       "      <td>0.066992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576592</td>\n",
       "      <td>0.090847</td>\n",
       "      <td>0.379562</td>\n",
       "      <td>0.045428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.577603</td>\n",
       "      <td>0.124910</td>\n",
       "      <td>0.324044</td>\n",
       "      <td>0.067123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.578049</td>\n",
       "      <td>0.068099</td>\n",
       "      <td>0.365815</td>\n",
       "      <td>0.106271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.579151</td>\n",
       "      <td>0.124474</td>\n",
       "      <td>0.322782</td>\n",
       "      <td>0.067306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.583250</td>\n",
       "      <td>0.067942</td>\n",
       "      <td>0.359447</td>\n",
       "      <td>0.116359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.584276</td>\n",
       "      <td>0.088541</td>\n",
       "      <td>0.379526</td>\n",
       "      <td>0.041192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.585414</td>\n",
       "      <td>0.085584</td>\n",
       "      <td>0.389304</td>\n",
       "      <td>0.144930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.586553</td>\n",
       "      <td>0.185362</td>\n",
       "      <td>0.395456</td>\n",
       "      <td>0.135776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.586831</td>\n",
       "      <td>0.100474</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.154365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.588311</td>\n",
       "      <td>0.175790</td>\n",
       "      <td>0.281153</td>\n",
       "      <td>0.046960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.590332</td>\n",
       "      <td>0.062082</td>\n",
       "      <td>0.352013</td>\n",
       "      <td>0.119105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.591276</td>\n",
       "      <td>0.090162</td>\n",
       "      <td>0.380222</td>\n",
       "      <td>0.044256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.594188</td>\n",
       "      <td>0.177627</td>\n",
       "      <td>0.397451</td>\n",
       "      <td>0.121560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597529</td>\n",
       "      <td>0.090301</td>\n",
       "      <td>0.378309</td>\n",
       "      <td>0.043452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.597563</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.380147</td>\n",
       "      <td>0.041201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.597563</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.380147</td>\n",
       "      <td>0.041201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.597563</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.380147</td>\n",
       "      <td>0.041201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.597563</td>\n",
       "      <td>0.084153</td>\n",
       "      <td>0.380147</td>\n",
       "      <td>0.041201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.598893</td>\n",
       "      <td>0.065614</td>\n",
       "      <td>0.401655</td>\n",
       "      <td>0.115435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.598963</td>\n",
       "      <td>0.056386</td>\n",
       "      <td>0.343470</td>\n",
       "      <td>0.120375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.603186</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>0.405279</td>\n",
       "      <td>0.060839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.603186</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>0.405279</td>\n",
       "      <td>0.060839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.603186</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>0.405279</td>\n",
       "      <td>0.060839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.603186</td>\n",
       "      <td>0.109421</td>\n",
       "      <td>0.405279</td>\n",
       "      <td>0.060839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.603440</td>\n",
       "      <td>0.082985</td>\n",
       "      <td>0.379614</td>\n",
       "      <td>0.042411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.604694</td>\n",
       "      <td>0.053149</td>\n",
       "      <td>0.339203</td>\n",
       "      <td>0.119409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.605237</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.415171</td>\n",
       "      <td>0.058065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.605237</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.415171</td>\n",
       "      <td>0.058065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.605237</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.415171</td>\n",
       "      <td>0.058065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.605237</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.415171</td>\n",
       "      <td>0.058065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.606032</td>\n",
       "      <td>0.178018</td>\n",
       "      <td>0.282080</td>\n",
       "      <td>0.054089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.606441</td>\n",
       "      <td>0.085276</td>\n",
       "      <td>0.376993</td>\n",
       "      <td>0.041979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.607170</td>\n",
       "      <td>0.152750</td>\n",
       "      <td>0.383667</td>\n",
       "      <td>0.039833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.609372</td>\n",
       "      <td>0.149480</td>\n",
       "      <td>0.382342</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611026</td>\n",
       "      <td>0.171265</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.083171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611026</td>\n",
       "      <td>0.171265</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.083171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611026</td>\n",
       "      <td>0.171265</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.083171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611026</td>\n",
       "      <td>0.171265</td>\n",
       "      <td>0.386816</td>\n",
       "      <td>0.083171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.612041</td>\n",
       "      <td>0.051077</td>\n",
       "      <td>0.334644</td>\n",
       "      <td>0.116851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.619242</td>\n",
       "      <td>0.074011</td>\n",
       "      <td>0.419875</td>\n",
       "      <td>0.116917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.622445</td>\n",
       "      <td>0.050341</td>\n",
       "      <td>0.328783</td>\n",
       "      <td>0.112468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.626108</td>\n",
       "      <td>0.110961</td>\n",
       "      <td>0.390973</td>\n",
       "      <td>0.050769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.626108</td>\n",
       "      <td>0.110961</td>\n",
       "      <td>0.390973</td>\n",
       "      <td>0.050769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.626108</td>\n",
       "      <td>0.110961</td>\n",
       "      <td>0.390973</td>\n",
       "      <td>0.050769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.626108</td>\n",
       "      <td>0.110961</td>\n",
       "      <td>0.390973</td>\n",
       "      <td>0.050769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.628052</td>\n",
       "      <td>0.154943</td>\n",
       "      <td>0.344992</td>\n",
       "      <td>0.138286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.628834</td>\n",
       "      <td>0.180527</td>\n",
       "      <td>0.282927</td>\n",
       "      <td>0.063711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.630435</td>\n",
       "      <td>0.090538</td>\n",
       "      <td>0.426376</td>\n",
       "      <td>0.146613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.631447</td>\n",
       "      <td>0.123811</td>\n",
       "      <td>0.390971</td>\n",
       "      <td>0.132402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.632698</td>\n",
       "      <td>0.064829</td>\n",
       "      <td>0.349991</td>\n",
       "      <td>0.085356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639963</td>\n",
       "      <td>0.113848</td>\n",
       "      <td>0.381114</td>\n",
       "      <td>0.058662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639963</td>\n",
       "      <td>0.113848</td>\n",
       "      <td>0.381114</td>\n",
       "      <td>0.058662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639963</td>\n",
       "      <td>0.113848</td>\n",
       "      <td>0.381114</td>\n",
       "      <td>0.058662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639963</td>\n",
       "      <td>0.113848</td>\n",
       "      <td>0.381114</td>\n",
       "      <td>0.058662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.645963</td>\n",
       "      <td>0.155891</td>\n",
       "      <td>0.368174</td>\n",
       "      <td>0.099714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.647112</td>\n",
       "      <td>0.171866</td>\n",
       "      <td>0.401144</td>\n",
       "      <td>0.027116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.652663</td>\n",
       "      <td>0.092074</td>\n",
       "      <td>0.444781</td>\n",
       "      <td>0.134549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.656820</td>\n",
       "      <td>0.164741</td>\n",
       "      <td>0.397163</td>\n",
       "      <td>0.042887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.662308</td>\n",
       "      <td>0.118490</td>\n",
       "      <td>0.399084</td>\n",
       "      <td>0.116809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.666709</td>\n",
       "      <td>0.061587</td>\n",
       "      <td>0.368192</td>\n",
       "      <td>0.065900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.671650</td>\n",
       "      <td>0.082847</td>\n",
       "      <td>0.443816</td>\n",
       "      <td>0.193790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.676624</td>\n",
       "      <td>0.076590</td>\n",
       "      <td>0.421234</td>\n",
       "      <td>0.205469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.721255</td>\n",
       "      <td>0.046177</td>\n",
       "      <td>0.419979</td>\n",
       "      <td>0.097268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.721425</td>\n",
       "      <td>0.062131</td>\n",
       "      <td>0.405169</td>\n",
       "      <td>0.085655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.737764</td>\n",
       "      <td>0.053603</td>\n",
       "      <td>0.285576</td>\n",
       "      <td>0.053904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.755799</td>\n",
       "      <td>0.054646</td>\n",
       "      <td>0.284700</td>\n",
       "      <td>0.049660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.777252</td>\n",
       "      <td>0.053777</td>\n",
       "      <td>0.284542</td>\n",
       "      <td>0.040964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.804224</td>\n",
       "      <td>0.055185</td>\n",
       "      <td>0.285839</td>\n",
       "      <td>0.031770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.821170</td>\n",
       "      <td>0.057314</td>\n",
       "      <td>0.286760</td>\n",
       "      <td>0.028878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.842685</td>\n",
       "      <td>0.059629</td>\n",
       "      <td>0.288034</td>\n",
       "      <td>0.030401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.872071</td>\n",
       "      <td>0.062719</td>\n",
       "      <td>0.290255</td>\n",
       "      <td>0.040639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.881672</td>\n",
       "      <td>0.126057</td>\n",
       "      <td>0.301474</td>\n",
       "      <td>0.108309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.918201</td>\n",
       "      <td>0.133872</td>\n",
       "      <td>0.299367</td>\n",
       "      <td>0.119941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.965514</td>\n",
       "      <td>0.133062</td>\n",
       "      <td>0.297200</td>\n",
       "      <td>0.124509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.030499</td>\n",
       "      <td>0.130467</td>\n",
       "      <td>0.297880</td>\n",
       "      <td>0.126317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.073124</td>\n",
       "      <td>0.127645</td>\n",
       "      <td>0.298793</td>\n",
       "      <td>0.127411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.128202</td>\n",
       "      <td>0.124862</td>\n",
       "      <td>0.298716</td>\n",
       "      <td>0.130179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.205429</td>\n",
       "      <td>0.118798</td>\n",
       "      <td>0.296935</td>\n",
       "      <td>0.136060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>3.723237</td>\n",
       "      <td>1.483410</td>\n",
       "      <td>1.483410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-2.227152</td>\n",
       "      <td>0.552557</td>\n",
       "      <td>0.552557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.948716</td>\n",
       "      <td>0.105262</td>\n",
       "      <td>0.105262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.873699</td>\n",
       "      <td>0.073795</td>\n",
       "      <td>0.073795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.408866</td>\n",
       "      <td>0.022619</td>\n",
       "      <td>0.022619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.284311</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.012693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.261748</td>\n",
       "      <td>0.010188</td>\n",
       "      <td>0.010188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.309666</td>\n",
       "      <td>0.008593</td>\n",
       "      <td>0.008593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.177284</td>\n",
       "      <td>0.007712</td>\n",
       "      <td>0.007712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.050809</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>0.001234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.050413</td>\n",
       "      <td>0.000671</td>\n",
       "      <td>0.000671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.074099</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACES_divorced_separated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.483</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>1.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.227</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.949</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.105</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.874</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.074</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.177</td>\n",
       "      <td>-0.074</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "       feature_name  interaction_effect\n",
      "0              BSCS                0.16\n",
      "2            BIS_11               -0.16\n",
      "1               EDM                0.16\n",
      "14  BFI_neuroticism                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.16\n",
      "5                       TRSQ                0.16\n",
      "6  ACES_neglectful_parenting               -0.16\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 25)\n",
      "(275, 25)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14744987203984672, 0.2411193498982338, 0.06612692152628563, 0.018364244452595102, -0.2757750110672257]\n",
      "overall_score:\n",
      "0.039457075369947116\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.460240</td>\n",
       "      <td>0.129910</td>\n",
       "      <td>0.326718</td>\n",
       "      <td>0.110011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.475448</td>\n",
       "      <td>0.049498</td>\n",
       "      <td>0.343450</td>\n",
       "      <td>0.064093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.503705</td>\n",
       "      <td>0.061328</td>\n",
       "      <td>0.331569</td>\n",
       "      <td>0.041990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.526217</td>\n",
       "      <td>0.169460</td>\n",
       "      <td>0.308823</td>\n",
       "      <td>0.082503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.534894</td>\n",
       "      <td>0.110267</td>\n",
       "      <td>0.354301</td>\n",
       "      <td>0.099688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.541888</td>\n",
       "      <td>0.182716</td>\n",
       "      <td>0.310287</td>\n",
       "      <td>0.083807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.560504</td>\n",
       "      <td>0.185758</td>\n",
       "      <td>0.311680</td>\n",
       "      <td>0.080090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.571159</td>\n",
       "      <td>0.085722</td>\n",
       "      <td>0.391035</td>\n",
       "      <td>0.074366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.583642</td>\n",
       "      <td>0.188797</td>\n",
       "      <td>0.311830</td>\n",
       "      <td>0.075400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598497</td>\n",
       "      <td>0.190539</td>\n",
       "      <td>0.312207</td>\n",
       "      <td>0.073180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.602853</td>\n",
       "      <td>0.120500</td>\n",
       "      <td>0.399668</td>\n",
       "      <td>0.063315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613130</td>\n",
       "      <td>0.109416</td>\n",
       "      <td>0.368459</td>\n",
       "      <td>0.074981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.615504</td>\n",
       "      <td>0.099236</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>0.051655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616041</td>\n",
       "      <td>0.192447</td>\n",
       "      <td>0.312285</td>\n",
       "      <td>0.070972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.616465</td>\n",
       "      <td>0.099574</td>\n",
       "      <td>0.451560</td>\n",
       "      <td>0.033082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.621795</td>\n",
       "      <td>0.116836</td>\n",
       "      <td>0.409594</td>\n",
       "      <td>0.059624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.631990</td>\n",
       "      <td>0.115168</td>\n",
       "      <td>0.408721</td>\n",
       "      <td>0.063101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.632221</td>\n",
       "      <td>0.123780</td>\n",
       "      <td>0.402250</td>\n",
       "      <td>0.055264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637524</td>\n",
       "      <td>0.195393</td>\n",
       "      <td>0.312167</td>\n",
       "      <td>0.069764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639482</td>\n",
       "      <td>0.115480</td>\n",
       "      <td>0.415086</td>\n",
       "      <td>0.061495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.640891</td>\n",
       "      <td>0.078357</td>\n",
       "      <td>0.401275</td>\n",
       "      <td>0.096807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.641326</td>\n",
       "      <td>0.170004</td>\n",
       "      <td>0.363603</td>\n",
       "      <td>0.083339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.641367</td>\n",
       "      <td>0.078782</td>\n",
       "      <td>0.397431</td>\n",
       "      <td>0.109093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.641860</td>\n",
       "      <td>0.074353</td>\n",
       "      <td>0.392874</td>\n",
       "      <td>0.116018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.643009</td>\n",
       "      <td>0.069292</td>\n",
       "      <td>0.387679</td>\n",
       "      <td>0.121904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.644054</td>\n",
       "      <td>0.123319</td>\n",
       "      <td>0.419568</td>\n",
       "      <td>0.059610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.644780</td>\n",
       "      <td>0.093659</td>\n",
       "      <td>0.402720</td>\n",
       "      <td>0.073120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.645234</td>\n",
       "      <td>0.066124</td>\n",
       "      <td>0.384728</td>\n",
       "      <td>0.122771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.645439</td>\n",
       "      <td>0.093624</td>\n",
       "      <td>0.371542</td>\n",
       "      <td>0.098390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.645656</td>\n",
       "      <td>0.091266</td>\n",
       "      <td>0.370069</td>\n",
       "      <td>0.098878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.645737</td>\n",
       "      <td>0.096847</td>\n",
       "      <td>0.374140</td>\n",
       "      <td>0.097834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.646012</td>\n",
       "      <td>0.088614</td>\n",
       "      <td>0.368568</td>\n",
       "      <td>0.099377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.646527</td>\n",
       "      <td>0.098798</td>\n",
       "      <td>0.376690</td>\n",
       "      <td>0.097378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.646828</td>\n",
       "      <td>0.085328</td>\n",
       "      <td>0.367308</td>\n",
       "      <td>0.099653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.647186</td>\n",
       "      <td>0.094436</td>\n",
       "      <td>0.378816</td>\n",
       "      <td>0.091528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648480</td>\n",
       "      <td>0.062020</td>\n",
       "      <td>0.380524</td>\n",
       "      <td>0.122413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648546</td>\n",
       "      <td>0.096102</td>\n",
       "      <td>0.398343</td>\n",
       "      <td>0.079398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649989</td>\n",
       "      <td>0.097196</td>\n",
       "      <td>0.409420</td>\n",
       "      <td>0.052841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.649989</td>\n",
       "      <td>0.097196</td>\n",
       "      <td>0.409420</td>\n",
       "      <td>0.052841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.650002</td>\n",
       "      <td>0.097213</td>\n",
       "      <td>0.409421</td>\n",
       "      <td>0.052842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.652850</td>\n",
       "      <td>0.093063</td>\n",
       "      <td>0.406304</td>\n",
       "      <td>0.055525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.653364</td>\n",
       "      <td>0.179190</td>\n",
       "      <td>0.358019</td>\n",
       "      <td>0.128917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.653834</td>\n",
       "      <td>0.125582</td>\n",
       "      <td>0.425322</td>\n",
       "      <td>0.055646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.654267</td>\n",
       "      <td>0.057874</td>\n",
       "      <td>0.375832</td>\n",
       "      <td>0.119710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655188</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>0.380499</td>\n",
       "      <td>0.057979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.655251</td>\n",
       "      <td>0.187953</td>\n",
       "      <td>0.356555</td>\n",
       "      <td>0.136083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.656278</td>\n",
       "      <td>0.098578</td>\n",
       "      <td>0.393492</td>\n",
       "      <td>0.085339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.658330</td>\n",
       "      <td>0.183959</td>\n",
       "      <td>0.353809</td>\n",
       "      <td>0.133768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659057</td>\n",
       "      <td>0.119489</td>\n",
       "      <td>0.373773</td>\n",
       "      <td>0.063582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.662482</td>\n",
       "      <td>0.178230</td>\n",
       "      <td>0.349864</td>\n",
       "      <td>0.129959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.663768</td>\n",
       "      <td>0.102496</td>\n",
       "      <td>0.390110</td>\n",
       "      <td>0.090180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.664802</td>\n",
       "      <td>0.175035</td>\n",
       "      <td>0.347625</td>\n",
       "      <td>0.127931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.667531</td>\n",
       "      <td>0.171571</td>\n",
       "      <td>0.344985</td>\n",
       "      <td>0.126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.668879</td>\n",
       "      <td>0.097273</td>\n",
       "      <td>0.419680</td>\n",
       "      <td>0.171703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.670607</td>\n",
       "      <td>0.167693</td>\n",
       "      <td>0.342062</td>\n",
       "      <td>0.124176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.673371</td>\n",
       "      <td>0.108467</td>\n",
       "      <td>0.381131</td>\n",
       "      <td>0.058747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.680917</td>\n",
       "      <td>0.113797</td>\n",
       "      <td>0.414373</td>\n",
       "      <td>0.168315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682059</td>\n",
       "      <td>0.168789</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.070941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682059</td>\n",
       "      <td>0.168789</td>\n",
       "      <td>0.386134</td>\n",
       "      <td>0.070941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682435</td>\n",
       "      <td>0.168226</td>\n",
       "      <td>0.385850</td>\n",
       "      <td>0.071105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682435</td>\n",
       "      <td>0.168226</td>\n",
       "      <td>0.385850</td>\n",
       "      <td>0.071105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682812</td>\n",
       "      <td>0.100340</td>\n",
       "      <td>0.385754</td>\n",
       "      <td>0.051465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.684429</td>\n",
       "      <td>0.089667</td>\n",
       "      <td>0.397409</td>\n",
       "      <td>0.043115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.684429</td>\n",
       "      <td>0.089667</td>\n",
       "      <td>0.397409</td>\n",
       "      <td>0.043115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.684429</td>\n",
       "      <td>0.089667</td>\n",
       "      <td>0.397409</td>\n",
       "      <td>0.043115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.684957</td>\n",
       "      <td>0.089967</td>\n",
       "      <td>0.397377</td>\n",
       "      <td>0.043173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.690390</td>\n",
       "      <td>0.098987</td>\n",
       "      <td>0.387148</td>\n",
       "      <td>0.053444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.698851</td>\n",
       "      <td>0.091616</td>\n",
       "      <td>0.390155</td>\n",
       "      <td>0.045799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.708431</td>\n",
       "      <td>0.094004</td>\n",
       "      <td>0.390678</td>\n",
       "      <td>0.049819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.710784</td>\n",
       "      <td>0.199986</td>\n",
       "      <td>0.401441</td>\n",
       "      <td>0.147434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.711420</td>\n",
       "      <td>0.198846</td>\n",
       "      <td>0.399159</td>\n",
       "      <td>0.140481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.713515</td>\n",
       "      <td>0.070432</td>\n",
       "      <td>0.392692</td>\n",
       "      <td>0.191236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.715208</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.388524</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.715208</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.388524</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.715208</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.388524</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.715208</td>\n",
       "      <td>0.088994</td>\n",
       "      <td>0.388524</td>\n",
       "      <td>0.042540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.716320</td>\n",
       "      <td>0.090686</td>\n",
       "      <td>0.388969</td>\n",
       "      <td>0.049455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.725505</td>\n",
       "      <td>0.084906</td>\n",
       "      <td>0.388470</td>\n",
       "      <td>0.186177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.725537</td>\n",
       "      <td>0.086647</td>\n",
       "      <td>0.387156</td>\n",
       "      <td>0.046060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.729447</td>\n",
       "      <td>0.190650</td>\n",
       "      <td>0.389362</td>\n",
       "      <td>0.086701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.729447</td>\n",
       "      <td>0.190650</td>\n",
       "      <td>0.389362</td>\n",
       "      <td>0.086701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.729447</td>\n",
       "      <td>0.190650</td>\n",
       "      <td>0.389362</td>\n",
       "      <td>0.086701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.729447</td>\n",
       "      <td>0.190650</td>\n",
       "      <td>0.389362</td>\n",
       "      <td>0.086701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.730129</td>\n",
       "      <td>0.088410</td>\n",
       "      <td>0.384036</td>\n",
       "      <td>0.046771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.731991</td>\n",
       "      <td>0.124452</td>\n",
       "      <td>0.414133</td>\n",
       "      <td>0.070685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.731991</td>\n",
       "      <td>0.124452</td>\n",
       "      <td>0.414133</td>\n",
       "      <td>0.070685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.731991</td>\n",
       "      <td>0.124452</td>\n",
       "      <td>0.414133</td>\n",
       "      <td>0.070685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.731991</td>\n",
       "      <td>0.124452</td>\n",
       "      <td>0.414133</td>\n",
       "      <td>0.070685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.732284</td>\n",
       "      <td>0.210818</td>\n",
       "      <td>0.427176</td>\n",
       "      <td>0.067442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.733987</td>\n",
       "      <td>0.207614</td>\n",
       "      <td>0.425983</td>\n",
       "      <td>0.068578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.736477</td>\n",
       "      <td>0.115723</td>\n",
       "      <td>0.391834</td>\n",
       "      <td>0.040400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.738349</td>\n",
       "      <td>0.116537</td>\n",
       "      <td>0.391816</td>\n",
       "      <td>0.040403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.738349</td>\n",
       "      <td>0.116537</td>\n",
       "      <td>0.391816</td>\n",
       "      <td>0.040403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.738349</td>\n",
       "      <td>0.116537</td>\n",
       "      <td>0.391816</td>\n",
       "      <td>0.040403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.747031</td>\n",
       "      <td>0.062246</td>\n",
       "      <td>0.265079</td>\n",
       "      <td>0.081522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.749843</td>\n",
       "      <td>0.077560</td>\n",
       "      <td>0.433647</td>\n",
       "      <td>0.156331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.750145</td>\n",
       "      <td>0.214328</td>\n",
       "      <td>0.427363</td>\n",
       "      <td>0.054261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.750522</td>\n",
       "      <td>0.085308</td>\n",
       "      <td>0.419924</td>\n",
       "      <td>0.164197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752358</td>\n",
       "      <td>0.104204</td>\n",
       "      <td>0.385973</td>\n",
       "      <td>0.063735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752358</td>\n",
       "      <td>0.104204</td>\n",
       "      <td>0.385973</td>\n",
       "      <td>0.063735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752358</td>\n",
       "      <td>0.104204</td>\n",
       "      <td>0.385973</td>\n",
       "      <td>0.063735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752358</td>\n",
       "      <td>0.104204</td>\n",
       "      <td>0.385973</td>\n",
       "      <td>0.063735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752448</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.385277</td>\n",
       "      <td>0.041798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752448</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.385277</td>\n",
       "      <td>0.041798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752448</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.385277</td>\n",
       "      <td>0.041798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752448</td>\n",
       "      <td>0.109971</td>\n",
       "      <td>0.385277</td>\n",
       "      <td>0.041798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.752796</td>\n",
       "      <td>0.226116</td>\n",
       "      <td>0.424239</td>\n",
       "      <td>0.065323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752910</td>\n",
       "      <td>0.084197</td>\n",
       "      <td>0.410546</td>\n",
       "      <td>0.171335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.755524</td>\n",
       "      <td>0.068913</td>\n",
       "      <td>0.422731</td>\n",
       "      <td>0.163456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.763255</td>\n",
       "      <td>0.064796</td>\n",
       "      <td>0.264665</td>\n",
       "      <td>0.080410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.767353</td>\n",
       "      <td>0.195933</td>\n",
       "      <td>0.379373</td>\n",
       "      <td>0.091547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.768834</td>\n",
       "      <td>0.061575</td>\n",
       "      <td>0.442362</td>\n",
       "      <td>0.184102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.769939</td>\n",
       "      <td>0.119630</td>\n",
       "      <td>0.409879</td>\n",
       "      <td>0.183829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.773073</td>\n",
       "      <td>0.205630</td>\n",
       "      <td>0.376688</td>\n",
       "      <td>0.103563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.781166</td>\n",
       "      <td>0.113655</td>\n",
       "      <td>0.417982</td>\n",
       "      <td>0.173155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.783286</td>\n",
       "      <td>0.065289</td>\n",
       "      <td>0.264405</td>\n",
       "      <td>0.073709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.791028</td>\n",
       "      <td>0.106510</td>\n",
       "      <td>0.422585</td>\n",
       "      <td>0.185682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.807875</td>\n",
       "      <td>0.067890</td>\n",
       "      <td>0.265851</td>\n",
       "      <td>0.064667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.823175</td>\n",
       "      <td>0.070533</td>\n",
       "      <td>0.266505</td>\n",
       "      <td>0.059823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.834638</td>\n",
       "      <td>0.141766</td>\n",
       "      <td>0.367300</td>\n",
       "      <td>0.106813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.843533</td>\n",
       "      <td>0.071652</td>\n",
       "      <td>0.267863</td>\n",
       "      <td>0.056547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.851117</td>\n",
       "      <td>0.114292</td>\n",
       "      <td>0.373453</td>\n",
       "      <td>0.090941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.851906</td>\n",
       "      <td>0.037541</td>\n",
       "      <td>0.384814</td>\n",
       "      <td>0.120921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.870532</td>\n",
       "      <td>0.073484</td>\n",
       "      <td>0.270015</td>\n",
       "      <td>0.056484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.876727</td>\n",
       "      <td>0.065901</td>\n",
       "      <td>0.370822</td>\n",
       "      <td>0.118038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.885257</td>\n",
       "      <td>0.127872</td>\n",
       "      <td>0.304646</td>\n",
       "      <td>0.107316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.920689</td>\n",
       "      <td>0.135510</td>\n",
       "      <td>0.302157</td>\n",
       "      <td>0.119234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.967290</td>\n",
       "      <td>0.134353</td>\n",
       "      <td>0.299470</td>\n",
       "      <td>0.123758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.031343</td>\n",
       "      <td>0.131342</td>\n",
       "      <td>0.299367</td>\n",
       "      <td>0.126112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.073453</td>\n",
       "      <td>0.128243</td>\n",
       "      <td>0.300272</td>\n",
       "      <td>0.127163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.128232</td>\n",
       "      <td>0.125513</td>\n",
       "      <td>0.299604</td>\n",
       "      <td>0.130131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.205194</td>\n",
       "      <td>0.119201</td>\n",
       "      <td>0.297316</td>\n",
       "      <td>0.136236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.270023</td>\n",
       "      <td>1.816356</td>\n",
       "      <td>1.816356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.162491</td>\n",
       "      <td>1.021735</td>\n",
       "      <td>1.021735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.302038</td>\n",
       "      <td>0.178412</td>\n",
       "      <td>0.178412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-1.024869</td>\n",
       "      <td>0.095663</td>\n",
       "      <td>0.095663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.364256</td>\n",
       "      <td>0.011471</td>\n",
       "      <td>0.011471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.277059</td>\n",
       "      <td>0.010393</td>\n",
       "      <td>0.010393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.192148</td>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.124334</td>\n",
       "      <td>0.003205</td>\n",
       "      <td>0.003205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>IMI_perceived_competence*san</td>\n",
       "      <td>-0.100548</td>\n",
       "      <td>0.001728</td>\n",
       "      <td>0.001728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.048663</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.001109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.050800</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.000066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.008247</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ACES_divorced_separated</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>1.816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.162</td>\n",
       "      <td>-0.008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>1.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.049</td>\n",
       "      <td>-1.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.364</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.192</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IMI_perceived_competence</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.08\n",
      "2                          BIS_11               -0.08\n",
      "1                             EDM                0.08\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 30)\n",
      "(275, 30)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.006113324875223869, 0.05709921616504188, -0.06825537308380403, 0.06467622040865917, -0.0017303461596511749]\n",
      "overall_score:\n",
      "0.011580608441093942\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.278751</td>\n",
       "      <td>0.067542</td>\n",
       "      <td>0.321748</td>\n",
       "      <td>0.065640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281780</td>\n",
       "      <td>0.060949</td>\n",
       "      <td>0.281906</td>\n",
       "      <td>0.092456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285367</td>\n",
       "      <td>0.073604</td>\n",
       "      <td>0.333488</td>\n",
       "      <td>0.048831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288392</td>\n",
       "      <td>0.076775</td>\n",
       "      <td>0.338952</td>\n",
       "      <td>0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.288882</td>\n",
       "      <td>0.072497</td>\n",
       "      <td>0.353523</td>\n",
       "      <td>0.029416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.288882</td>\n",
       "      <td>0.072497</td>\n",
       "      <td>0.353523</td>\n",
       "      <td>0.029416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288882</td>\n",
       "      <td>0.072497</td>\n",
       "      <td>0.353523</td>\n",
       "      <td>0.029416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.288989</td>\n",
       "      <td>0.072798</td>\n",
       "      <td>0.352432</td>\n",
       "      <td>0.028336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.289093</td>\n",
       "      <td>0.075263</td>\n",
       "      <td>0.347401</td>\n",
       "      <td>0.030674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.290096</td>\n",
       "      <td>0.072905</td>\n",
       "      <td>0.351934</td>\n",
       "      <td>0.027489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.290175</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>0.351956</td>\n",
       "      <td>0.027383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.291776</td>\n",
       "      <td>0.076257</td>\n",
       "      <td>0.351394</td>\n",
       "      <td>0.031043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291868</td>\n",
       "      <td>0.125631</td>\n",
       "      <td>0.342504</td>\n",
       "      <td>0.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291868</td>\n",
       "      <td>0.125631</td>\n",
       "      <td>0.342504</td>\n",
       "      <td>0.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291868</td>\n",
       "      <td>0.125631</td>\n",
       "      <td>0.342504</td>\n",
       "      <td>0.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291868</td>\n",
       "      <td>0.125631</td>\n",
       "      <td>0.342504</td>\n",
       "      <td>0.058400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293876</td>\n",
       "      <td>0.077278</td>\n",
       "      <td>0.345421</td>\n",
       "      <td>0.031741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294099</td>\n",
       "      <td>0.074748</td>\n",
       "      <td>0.349926</td>\n",
       "      <td>0.034387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.294461</td>\n",
       "      <td>0.079459</td>\n",
       "      <td>0.343722</td>\n",
       "      <td>0.031665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294479</td>\n",
       "      <td>0.076109</td>\n",
       "      <td>0.322574</td>\n",
       "      <td>0.043328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294839</td>\n",
       "      <td>0.079637</td>\n",
       "      <td>0.350211</td>\n",
       "      <td>0.041223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294868</td>\n",
       "      <td>0.078510</td>\n",
       "      <td>0.337474</td>\n",
       "      <td>0.031175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.296602</td>\n",
       "      <td>0.071935</td>\n",
       "      <td>0.349050</td>\n",
       "      <td>0.023713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.297925</td>\n",
       "      <td>0.074028</td>\n",
       "      <td>0.352758</td>\n",
       "      <td>0.037675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.299641</td>\n",
       "      <td>0.070851</td>\n",
       "      <td>0.350414</td>\n",
       "      <td>0.023049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.300909</td>\n",
       "      <td>0.072483</td>\n",
       "      <td>0.347111</td>\n",
       "      <td>0.030502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.300911</td>\n",
       "      <td>0.072489</td>\n",
       "      <td>0.347104</td>\n",
       "      <td>0.030494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.300911</td>\n",
       "      <td>0.072489</td>\n",
       "      <td>0.347104</td>\n",
       "      <td>0.030494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.300911</td>\n",
       "      <td>0.072489</td>\n",
       "      <td>0.347104</td>\n",
       "      <td>0.030494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.302314</td>\n",
       "      <td>0.073137</td>\n",
       "      <td>0.348786</td>\n",
       "      <td>0.038493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302420</td>\n",
       "      <td>0.083028</td>\n",
       "      <td>0.349975</td>\n",
       "      <td>0.026600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.302432</td>\n",
       "      <td>0.083205</td>\n",
       "      <td>0.340714</td>\n",
       "      <td>0.037454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303547</td>\n",
       "      <td>0.071764</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.037851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.305679</td>\n",
       "      <td>0.069338</td>\n",
       "      <td>0.346344</td>\n",
       "      <td>0.030389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.305679</td>\n",
       "      <td>0.069338</td>\n",
       "      <td>0.346344</td>\n",
       "      <td>0.030389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.305679</td>\n",
       "      <td>0.069338</td>\n",
       "      <td>0.346344</td>\n",
       "      <td>0.030389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.305679</td>\n",
       "      <td>0.069338</td>\n",
       "      <td>0.346344</td>\n",
       "      <td>0.030389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.307152</td>\n",
       "      <td>0.101253</td>\n",
       "      <td>0.312688</td>\n",
       "      <td>0.081918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.311350</td>\n",
       "      <td>0.092424</td>\n",
       "      <td>0.299030</td>\n",
       "      <td>0.090047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.313110</td>\n",
       "      <td>0.086032</td>\n",
       "      <td>0.337969</td>\n",
       "      <td>0.045849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314471</td>\n",
       "      <td>0.117167</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>0.062559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314471</td>\n",
       "      <td>0.117167</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>0.062559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314471</td>\n",
       "      <td>0.117167</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>0.062559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.314471</td>\n",
       "      <td>0.117167</td>\n",
       "      <td>0.355530</td>\n",
       "      <td>0.062559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.318707</td>\n",
       "      <td>0.090694</td>\n",
       "      <td>0.350328</td>\n",
       "      <td>0.031504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.325265</td>\n",
       "      <td>0.065666</td>\n",
       "      <td>0.325162</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325643</td>\n",
       "      <td>0.067593</td>\n",
       "      <td>0.297791</td>\n",
       "      <td>0.079577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326976</td>\n",
       "      <td>0.072895</td>\n",
       "      <td>0.297360</td>\n",
       "      <td>0.085533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.328605</td>\n",
       "      <td>0.074620</td>\n",
       "      <td>0.296691</td>\n",
       "      <td>0.086901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.330538</td>\n",
       "      <td>0.076590</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>0.088815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.331613</td>\n",
       "      <td>0.077742</td>\n",
       "      <td>0.295695</td>\n",
       "      <td>0.089987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.332698</td>\n",
       "      <td>0.067016</td>\n",
       "      <td>0.336644</td>\n",
       "      <td>0.037953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.332957</td>\n",
       "      <td>0.078794</td>\n",
       "      <td>0.295072</td>\n",
       "      <td>0.090871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334571</td>\n",
       "      <td>0.079844</td>\n",
       "      <td>0.294247</td>\n",
       "      <td>0.091623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.338199</td>\n",
       "      <td>0.081659</td>\n",
       "      <td>0.345071</td>\n",
       "      <td>0.063298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.339623</td>\n",
       "      <td>0.087196</td>\n",
       "      <td>0.344898</td>\n",
       "      <td>0.067368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.341806</td>\n",
       "      <td>0.088188</td>\n",
       "      <td>0.344421</td>\n",
       "      <td>0.067063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.344777</td>\n",
       "      <td>0.089793</td>\n",
       "      <td>0.343666</td>\n",
       "      <td>0.066744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.346645</td>\n",
       "      <td>0.090967</td>\n",
       "      <td>0.343347</td>\n",
       "      <td>0.066373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.348904</td>\n",
       "      <td>0.092462</td>\n",
       "      <td>0.343111</td>\n",
       "      <td>0.065681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349156</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>0.295897</td>\n",
       "      <td>0.113360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.351428</td>\n",
       "      <td>0.094347</td>\n",
       "      <td>0.343019</td>\n",
       "      <td>0.064698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.351690</td>\n",
       "      <td>0.104464</td>\n",
       "      <td>0.355527</td>\n",
       "      <td>0.047134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352175</td>\n",
       "      <td>0.134842</td>\n",
       "      <td>0.396150</td>\n",
       "      <td>0.050958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.354295</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.332474</td>\n",
       "      <td>0.026735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.354295</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.332474</td>\n",
       "      <td>0.026735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.354295</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.332474</td>\n",
       "      <td>0.026735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.354295</td>\n",
       "      <td>0.111237</td>\n",
       "      <td>0.332474</td>\n",
       "      <td>0.026735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355963</td>\n",
       "      <td>0.134767</td>\n",
       "      <td>0.397907</td>\n",
       "      <td>0.054535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.359095</td>\n",
       "      <td>0.089706</td>\n",
       "      <td>0.359074</td>\n",
       "      <td>0.058608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.359945</td>\n",
       "      <td>0.112464</td>\n",
       "      <td>0.363644</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.359945</td>\n",
       "      <td>0.112464</td>\n",
       "      <td>0.363644</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.359945</td>\n",
       "      <td>0.112464</td>\n",
       "      <td>0.363644</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.359945</td>\n",
       "      <td>0.112464</td>\n",
       "      <td>0.363644</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.361404</td>\n",
       "      <td>0.142356</td>\n",
       "      <td>0.376754</td>\n",
       "      <td>0.056460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.361545</td>\n",
       "      <td>0.138492</td>\n",
       "      <td>0.376892</td>\n",
       "      <td>0.060253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.369890</td>\n",
       "      <td>0.075916</td>\n",
       "      <td>0.364204</td>\n",
       "      <td>0.054947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.370644</td>\n",
       "      <td>0.118288</td>\n",
       "      <td>0.400228</td>\n",
       "      <td>0.092269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.372469</td>\n",
       "      <td>0.128940</td>\n",
       "      <td>0.284652</td>\n",
       "      <td>0.120483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.373275</td>\n",
       "      <td>0.075662</td>\n",
       "      <td>0.333902</td>\n",
       "      <td>0.090494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376609</td>\n",
       "      <td>0.107254</td>\n",
       "      <td>0.350250</td>\n",
       "      <td>0.055648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376609</td>\n",
       "      <td>0.107254</td>\n",
       "      <td>0.350250</td>\n",
       "      <td>0.055648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376609</td>\n",
       "      <td>0.107254</td>\n",
       "      <td>0.350250</td>\n",
       "      <td>0.055648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376609</td>\n",
       "      <td>0.107254</td>\n",
       "      <td>0.350250</td>\n",
       "      <td>0.055648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.379732</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.336652</td>\n",
       "      <td>0.057175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.379732</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.336652</td>\n",
       "      <td>0.057175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.379732</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.336652</td>\n",
       "      <td>0.057175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.379732</td>\n",
       "      <td>0.109603</td>\n",
       "      <td>0.336652</td>\n",
       "      <td>0.057175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.379875</td>\n",
       "      <td>0.091482</td>\n",
       "      <td>0.394728</td>\n",
       "      <td>0.096443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380090</td>\n",
       "      <td>0.100902</td>\n",
       "      <td>0.406586</td>\n",
       "      <td>0.089280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.387245</td>\n",
       "      <td>0.075824</td>\n",
       "      <td>0.319943</td>\n",
       "      <td>0.063614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.390406</td>\n",
       "      <td>0.125826</td>\n",
       "      <td>0.407327</td>\n",
       "      <td>0.110695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.390706</td>\n",
       "      <td>0.081778</td>\n",
       "      <td>0.404647</td>\n",
       "      <td>0.094045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.396671</td>\n",
       "      <td>0.087856</td>\n",
       "      <td>0.387048</td>\n",
       "      <td>0.099204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.398911</td>\n",
       "      <td>0.066627</td>\n",
       "      <td>0.324597</td>\n",
       "      <td>0.073441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.400178</td>\n",
       "      <td>0.128322</td>\n",
       "      <td>0.414556</td>\n",
       "      <td>0.100935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407502</td>\n",
       "      <td>0.084398</td>\n",
       "      <td>0.397492</td>\n",
       "      <td>0.096538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.413978</td>\n",
       "      <td>0.070278</td>\n",
       "      <td>0.289411</td>\n",
       "      <td>0.064364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.435702</td>\n",
       "      <td>0.153134</td>\n",
       "      <td>0.244116</td>\n",
       "      <td>0.094948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451965</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>0.246609</td>\n",
       "      <td>0.103492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.457789</td>\n",
       "      <td>0.080814</td>\n",
       "      <td>0.360115</td>\n",
       "      <td>0.086093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.469185</td>\n",
       "      <td>0.083337</td>\n",
       "      <td>0.357942</td>\n",
       "      <td>0.090273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472147</td>\n",
       "      <td>0.169970</td>\n",
       "      <td>0.249670</td>\n",
       "      <td>0.107596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.478676</td>\n",
       "      <td>0.082072</td>\n",
       "      <td>0.345759</td>\n",
       "      <td>0.119070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.483043</td>\n",
       "      <td>0.081516</td>\n",
       "      <td>0.355874</td>\n",
       "      <td>0.088833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.498115</td>\n",
       "      <td>0.174945</td>\n",
       "      <td>0.253710</td>\n",
       "      <td>0.113742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.501294</td>\n",
       "      <td>0.078721</td>\n",
       "      <td>0.354874</td>\n",
       "      <td>0.086237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.511039</td>\n",
       "      <td>0.080105</td>\n",
       "      <td>0.367587</td>\n",
       "      <td>0.057370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.512613</td>\n",
       "      <td>0.077594</td>\n",
       "      <td>0.354652</td>\n",
       "      <td>0.084367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.514007</td>\n",
       "      <td>0.178010</td>\n",
       "      <td>0.256999</td>\n",
       "      <td>0.117507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.515778</td>\n",
       "      <td>0.094090</td>\n",
       "      <td>0.332180</td>\n",
       "      <td>0.097775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.525740</td>\n",
       "      <td>0.077433</td>\n",
       "      <td>0.354775</td>\n",
       "      <td>0.082376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.532568</td>\n",
       "      <td>0.181084</td>\n",
       "      <td>0.261624</td>\n",
       "      <td>0.122951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541659</td>\n",
       "      <td>0.078925</td>\n",
       "      <td>0.355772</td>\n",
       "      <td>0.080884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.555887</td>\n",
       "      <td>0.184195</td>\n",
       "      <td>0.268244</td>\n",
       "      <td>0.131770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.572159</td>\n",
       "      <td>0.103865</td>\n",
       "      <td>0.345724</td>\n",
       "      <td>0.032844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.670031</td>\n",
       "      <td>0.101912</td>\n",
       "      <td>0.278246</td>\n",
       "      <td>0.061987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.691182</td>\n",
       "      <td>0.103552</td>\n",
       "      <td>0.275736</td>\n",
       "      <td>0.069996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.717509</td>\n",
       "      <td>0.098601</td>\n",
       "      <td>0.272906</td>\n",
       "      <td>0.074769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.752095</td>\n",
       "      <td>0.093286</td>\n",
       "      <td>0.270095</td>\n",
       "      <td>0.080379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.773943</td>\n",
       "      <td>0.090706</td>\n",
       "      <td>0.269598</td>\n",
       "      <td>0.083007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.799328</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>0.270591</td>\n",
       "      <td>0.085210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.829765</td>\n",
       "      <td>0.090783</td>\n",
       "      <td>0.274993</td>\n",
       "      <td>0.086256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.977590</td>\n",
       "      <td>0.196564</td>\n",
       "      <td>0.283850</td>\n",
       "      <td>0.094513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.026672</td>\n",
       "      <td>0.209449</td>\n",
       "      <td>0.288139</td>\n",
       "      <td>0.108543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.089284</td>\n",
       "      <td>0.211457</td>\n",
       "      <td>0.293859</td>\n",
       "      <td>0.118120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.176520</td>\n",
       "      <td>0.214533</td>\n",
       "      <td>0.304129</td>\n",
       "      <td>0.124351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.234663</td>\n",
       "      <td>0.217474</td>\n",
       "      <td>0.311589</td>\n",
       "      <td>0.126718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.314089</td>\n",
       "      <td>0.222116</td>\n",
       "      <td>0.317770</td>\n",
       "      <td>0.135375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.427876</td>\n",
       "      <td>0.228688</td>\n",
       "      <td>0.318947</td>\n",
       "      <td>0.151438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.008567</td>\n",
       "      <td>0.149602</td>\n",
       "      <td>0.149602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.410348</td>\n",
       "      <td>0.032607</td>\n",
       "      <td>0.032607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NCS_thinking_not_exciting*ni</td>\n",
       "      <td>-0.311953</td>\n",
       "      <td>0.018373</td>\n",
       "      <td>0.018373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.237632</td>\n",
       "      <td>0.014364</td>\n",
       "      <td>0.014364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>IMI_perceived_choice*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_thinking_not_exciting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                 0.1\n",
      "2                          BIS_11                -0.1\n",
      "1                             EDM                 0.1\n",
      "16  DEMO_mcarthur_social_standing                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 30)\n",
      "(275, 30)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.039899262862452045, 0.025163581636640342, -0.07650996400976284, -0.08641345453255145, -0.424148173838232]\n",
      "overall_score:\n",
      "-0.10440174957629078\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345067</td>\n",
       "      <td>0.055138</td>\n",
       "      <td>0.267919</td>\n",
       "      <td>0.103437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357484</td>\n",
       "      <td>0.124513</td>\n",
       "      <td>0.338950</td>\n",
       "      <td>0.067131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357484</td>\n",
       "      <td>0.124513</td>\n",
       "      <td>0.338950</td>\n",
       "      <td>0.067131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357484</td>\n",
       "      <td>0.124513</td>\n",
       "      <td>0.338950</td>\n",
       "      <td>0.067131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357484</td>\n",
       "      <td>0.124513</td>\n",
       "      <td>0.338950</td>\n",
       "      <td>0.067131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359964</td>\n",
       "      <td>0.071889</td>\n",
       "      <td>0.321283</td>\n",
       "      <td>0.069907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.360088</td>\n",
       "      <td>0.079753</td>\n",
       "      <td>0.339160</td>\n",
       "      <td>0.042838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.363396</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.367191</td>\n",
       "      <td>0.030518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.363396</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>0.367191</td>\n",
       "      <td>0.030518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.363416</td>\n",
       "      <td>0.077165</td>\n",
       "      <td>0.367186</td>\n",
       "      <td>0.030515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.363945</td>\n",
       "      <td>0.085376</td>\n",
       "      <td>0.368820</td>\n",
       "      <td>0.026479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.364763</td>\n",
       "      <td>0.087537</td>\n",
       "      <td>0.363504</td>\n",
       "      <td>0.032338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.364927</td>\n",
       "      <td>0.086215</td>\n",
       "      <td>0.368323</td>\n",
       "      <td>0.026380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.365495</td>\n",
       "      <td>0.077510</td>\n",
       "      <td>0.364519</td>\n",
       "      <td>0.028284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.367973</td>\n",
       "      <td>0.087617</td>\n",
       "      <td>0.365266</td>\n",
       "      <td>0.031583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368127</td>\n",
       "      <td>0.081666</td>\n",
       "      <td>0.346670</td>\n",
       "      <td>0.039066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.371116</td>\n",
       "      <td>0.083205</td>\n",
       "      <td>0.361591</td>\n",
       "      <td>0.029485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373256</td>\n",
       "      <td>0.080181</td>\n",
       "      <td>0.357360</td>\n",
       "      <td>0.040950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.373846</td>\n",
       "      <td>0.089704</td>\n",
       "      <td>0.362624</td>\n",
       "      <td>0.030916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376227</td>\n",
       "      <td>0.096971</td>\n",
       "      <td>0.362775</td>\n",
       "      <td>0.033689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376741</td>\n",
       "      <td>0.074141</td>\n",
       "      <td>0.358677</td>\n",
       "      <td>0.035055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376741</td>\n",
       "      <td>0.074141</td>\n",
       "      <td>0.358677</td>\n",
       "      <td>0.035055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.376741</td>\n",
       "      <td>0.074141</td>\n",
       "      <td>0.358677</td>\n",
       "      <td>0.035055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.376858</td>\n",
       "      <td>0.074290</td>\n",
       "      <td>0.358552</td>\n",
       "      <td>0.034921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.380088</td>\n",
       "      <td>0.087462</td>\n",
       "      <td>0.357052</td>\n",
       "      <td>0.032900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.383093</td>\n",
       "      <td>0.072592</td>\n",
       "      <td>0.328311</td>\n",
       "      <td>0.045179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384042</td>\n",
       "      <td>0.077228</td>\n",
       "      <td>0.358853</td>\n",
       "      <td>0.039624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.384735</td>\n",
       "      <td>0.072295</td>\n",
       "      <td>0.360968</td>\n",
       "      <td>0.038646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.386843</td>\n",
       "      <td>0.071581</td>\n",
       "      <td>0.358614</td>\n",
       "      <td>0.033965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388404</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.353716</td>\n",
       "      <td>0.031708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388404</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.353716</td>\n",
       "      <td>0.031708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.388404</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.353716</td>\n",
       "      <td>0.031708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.388404</td>\n",
       "      <td>0.072630</td>\n",
       "      <td>0.353716</td>\n",
       "      <td>0.031708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389559</td>\n",
       "      <td>0.076658</td>\n",
       "      <td>0.358833</td>\n",
       "      <td>0.038811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.389593</td>\n",
       "      <td>0.104525</td>\n",
       "      <td>0.361088</td>\n",
       "      <td>0.042660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389890</td>\n",
       "      <td>0.070832</td>\n",
       "      <td>0.353965</td>\n",
       "      <td>0.033411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390320</td>\n",
       "      <td>0.073577</td>\n",
       "      <td>0.357217</td>\n",
       "      <td>0.035663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.391736</td>\n",
       "      <td>0.068124</td>\n",
       "      <td>0.345184</td>\n",
       "      <td>0.037759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.392268</td>\n",
       "      <td>0.089741</td>\n",
       "      <td>0.352571</td>\n",
       "      <td>0.041144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.392428</td>\n",
       "      <td>0.055675</td>\n",
       "      <td>0.330489</td>\n",
       "      <td>0.055183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399379</td>\n",
       "      <td>0.017582</td>\n",
       "      <td>0.305725</td>\n",
       "      <td>0.060691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399487</td>\n",
       "      <td>0.019463</td>\n",
       "      <td>0.305695</td>\n",
       "      <td>0.063411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399551</td>\n",
       "      <td>0.020611</td>\n",
       "      <td>0.305693</td>\n",
       "      <td>0.062322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399591</td>\n",
       "      <td>0.118358</td>\n",
       "      <td>0.263569</td>\n",
       "      <td>0.056163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399766</td>\n",
       "      <td>0.021930</td>\n",
       "      <td>0.305546</td>\n",
       "      <td>0.061155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.399926</td>\n",
       "      <td>0.022729</td>\n",
       "      <td>0.305475</td>\n",
       "      <td>0.060510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.400065</td>\n",
       "      <td>0.082905</td>\n",
       "      <td>0.343871</td>\n",
       "      <td>0.037650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.400274</td>\n",
       "      <td>0.023551</td>\n",
       "      <td>0.305396</td>\n",
       "      <td>0.059748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.400747</td>\n",
       "      <td>0.024363</td>\n",
       "      <td>0.305307</td>\n",
       "      <td>0.058955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.400878</td>\n",
       "      <td>0.078015</td>\n",
       "      <td>0.382724</td>\n",
       "      <td>0.057701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.406339</td>\n",
       "      <td>0.092379</td>\n",
       "      <td>0.346935</td>\n",
       "      <td>0.050443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.407218</td>\n",
       "      <td>0.106769</td>\n",
       "      <td>0.370087</td>\n",
       "      <td>0.058978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.410021</td>\n",
       "      <td>0.117062</td>\n",
       "      <td>0.350152</td>\n",
       "      <td>0.079762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.410021</td>\n",
       "      <td>0.117062</td>\n",
       "      <td>0.350152</td>\n",
       "      <td>0.079762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.410021</td>\n",
       "      <td>0.117062</td>\n",
       "      <td>0.350152</td>\n",
       "      <td>0.079762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.410021</td>\n",
       "      <td>0.117062</td>\n",
       "      <td>0.350152</td>\n",
       "      <td>0.079762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411739</td>\n",
       "      <td>0.128626</td>\n",
       "      <td>0.269295</td>\n",
       "      <td>0.067666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.412934</td>\n",
       "      <td>0.102428</td>\n",
       "      <td>0.325595</td>\n",
       "      <td>0.045332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.417779</td>\n",
       "      <td>0.123452</td>\n",
       "      <td>0.319435</td>\n",
       "      <td>0.053907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.419738</td>\n",
       "      <td>0.066091</td>\n",
       "      <td>0.397624</td>\n",
       "      <td>0.054544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423623</td>\n",
       "      <td>0.113177</td>\n",
       "      <td>0.389045</td>\n",
       "      <td>0.096143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.426769</td>\n",
       "      <td>0.084169</td>\n",
       "      <td>0.398801</td>\n",
       "      <td>0.109801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.427224</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>0.349743</td>\n",
       "      <td>0.067638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.428834</td>\n",
       "      <td>0.083183</td>\n",
       "      <td>0.348695</td>\n",
       "      <td>0.072161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.428864</td>\n",
       "      <td>0.129771</td>\n",
       "      <td>0.275880</td>\n",
       "      <td>0.081925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.430869</td>\n",
       "      <td>0.083359</td>\n",
       "      <td>0.347350</td>\n",
       "      <td>0.072339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.432472</td>\n",
       "      <td>0.117931</td>\n",
       "      <td>0.366963</td>\n",
       "      <td>0.074421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.432472</td>\n",
       "      <td>0.117931</td>\n",
       "      <td>0.366963</td>\n",
       "      <td>0.074421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.432472</td>\n",
       "      <td>0.117931</td>\n",
       "      <td>0.366963</td>\n",
       "      <td>0.074421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.433765</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>0.345769</td>\n",
       "      <td>0.071833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.435295</td>\n",
       "      <td>0.112064</td>\n",
       "      <td>0.363515</td>\n",
       "      <td>0.067278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.435465</td>\n",
       "      <td>0.084263</td>\n",
       "      <td>0.344903</td>\n",
       "      <td>0.071404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.436614</td>\n",
       "      <td>0.121717</td>\n",
       "      <td>0.395020</td>\n",
       "      <td>0.049706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436969</td>\n",
       "      <td>0.111229</td>\n",
       "      <td>0.341079</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436969</td>\n",
       "      <td>0.111229</td>\n",
       "      <td>0.341079</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436969</td>\n",
       "      <td>0.111229</td>\n",
       "      <td>0.341079</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.436969</td>\n",
       "      <td>0.111229</td>\n",
       "      <td>0.341079</td>\n",
       "      <td>0.045057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.437376</td>\n",
       "      <td>0.084785</td>\n",
       "      <td>0.343994</td>\n",
       "      <td>0.070797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.437881</td>\n",
       "      <td>0.121965</td>\n",
       "      <td>0.396619</td>\n",
       "      <td>0.050525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.438067</td>\n",
       "      <td>0.064705</td>\n",
       "      <td>0.330069</td>\n",
       "      <td>0.062662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.439200</td>\n",
       "      <td>0.061726</td>\n",
       "      <td>0.384618</td>\n",
       "      <td>0.087557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.439766</td>\n",
       "      <td>0.085620</td>\n",
       "      <td>0.343190</td>\n",
       "      <td>0.069695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.441226</td>\n",
       "      <td>0.105380</td>\n",
       "      <td>0.408236</td>\n",
       "      <td>0.087303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.444372</td>\n",
       "      <td>0.088551</td>\n",
       "      <td>0.417748</td>\n",
       "      <td>0.101074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.446787</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.365557</td>\n",
       "      <td>0.096922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.446947</td>\n",
       "      <td>0.072296</td>\n",
       "      <td>0.300023</td>\n",
       "      <td>0.070837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450080</td>\n",
       "      <td>0.108985</td>\n",
       "      <td>0.352661</td>\n",
       "      <td>0.055439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450080</td>\n",
       "      <td>0.108985</td>\n",
       "      <td>0.352661</td>\n",
       "      <td>0.055439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450080</td>\n",
       "      <td>0.108985</td>\n",
       "      <td>0.352661</td>\n",
       "      <td>0.055439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.450080</td>\n",
       "      <td>0.108985</td>\n",
       "      <td>0.352661</td>\n",
       "      <td>0.055439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451196</td>\n",
       "      <td>0.130503</td>\n",
       "      <td>0.285120</td>\n",
       "      <td>0.100005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.453010</td>\n",
       "      <td>0.103448</td>\n",
       "      <td>0.389972</td>\n",
       "      <td>0.045714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455639</td>\n",
       "      <td>0.136167</td>\n",
       "      <td>0.348543</td>\n",
       "      <td>0.070749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455639</td>\n",
       "      <td>0.136167</td>\n",
       "      <td>0.348543</td>\n",
       "      <td>0.070749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455639</td>\n",
       "      <td>0.136167</td>\n",
       "      <td>0.348543</td>\n",
       "      <td>0.070749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455639</td>\n",
       "      <td>0.136167</td>\n",
       "      <td>0.348543</td>\n",
       "      <td>0.070749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459021</td>\n",
       "      <td>0.098068</td>\n",
       "      <td>0.391948</td>\n",
       "      <td>0.048744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.462008</td>\n",
       "      <td>0.141664</td>\n",
       "      <td>0.297833</td>\n",
       "      <td>0.087721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.462465</td>\n",
       "      <td>0.055780</td>\n",
       "      <td>0.398874</td>\n",
       "      <td>0.079699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.464795</td>\n",
       "      <td>0.131410</td>\n",
       "      <td>0.290965</td>\n",
       "      <td>0.110429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472105</td>\n",
       "      <td>0.134844</td>\n",
       "      <td>0.281970</td>\n",
       "      <td>0.091758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.474058</td>\n",
       "      <td>0.043497</td>\n",
       "      <td>0.414172</td>\n",
       "      <td>0.099466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.480451</td>\n",
       "      <td>0.101308</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.087770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.481090</td>\n",
       "      <td>0.133253</td>\n",
       "      <td>0.298066</td>\n",
       "      <td>0.121999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.499460</td>\n",
       "      <td>0.052461</td>\n",
       "      <td>0.439107</td>\n",
       "      <td>0.106496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.501554</td>\n",
       "      <td>0.135581</td>\n",
       "      <td>0.306205</td>\n",
       "      <td>0.135372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.506790</td>\n",
       "      <td>0.072386</td>\n",
       "      <td>0.352912</td>\n",
       "      <td>0.121644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.507371</td>\n",
       "      <td>0.084633</td>\n",
       "      <td>0.349518</td>\n",
       "      <td>0.103125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.516309</td>\n",
       "      <td>0.073210</td>\n",
       "      <td>0.348539</td>\n",
       "      <td>0.130783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.528126</td>\n",
       "      <td>0.068233</td>\n",
       "      <td>0.344040</td>\n",
       "      <td>0.131693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.531008</td>\n",
       "      <td>0.072568</td>\n",
       "      <td>0.327974</td>\n",
       "      <td>0.106583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.543584</td>\n",
       "      <td>0.061492</td>\n",
       "      <td>0.339461</td>\n",
       "      <td>0.132395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.550478</td>\n",
       "      <td>0.110552</td>\n",
       "      <td>0.347916</td>\n",
       "      <td>0.069919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.554333</td>\n",
       "      <td>0.056244</td>\n",
       "      <td>0.335605</td>\n",
       "      <td>0.134124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.568250</td>\n",
       "      <td>0.049799</td>\n",
       "      <td>0.332175</td>\n",
       "      <td>0.134675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.586296</td>\n",
       "      <td>0.042572</td>\n",
       "      <td>0.329548</td>\n",
       "      <td>0.135024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.590746</td>\n",
       "      <td>0.098683</td>\n",
       "      <td>0.339986</td>\n",
       "      <td>0.081175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.690723</td>\n",
       "      <td>0.119268</td>\n",
       "      <td>0.294258</td>\n",
       "      <td>0.045990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.709810</td>\n",
       "      <td>0.124619</td>\n",
       "      <td>0.292199</td>\n",
       "      <td>0.050119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.733655</td>\n",
       "      <td>0.122100</td>\n",
       "      <td>0.288465</td>\n",
       "      <td>0.053139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.765325</td>\n",
       "      <td>0.118165</td>\n",
       "      <td>0.283860</td>\n",
       "      <td>0.058159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.785163</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.282232</td>\n",
       "      <td>0.063064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.809482</td>\n",
       "      <td>0.114941</td>\n",
       "      <td>0.281661</td>\n",
       "      <td>0.069947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.840321</td>\n",
       "      <td>0.114338</td>\n",
       "      <td>0.283539</td>\n",
       "      <td>0.079577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.984191</td>\n",
       "      <td>0.199185</td>\n",
       "      <td>0.285412</td>\n",
       "      <td>0.094840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.032596</td>\n",
       "      <td>0.212416</td>\n",
       "      <td>0.289518</td>\n",
       "      <td>0.108546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.093493</td>\n",
       "      <td>0.215200</td>\n",
       "      <td>0.295432</td>\n",
       "      <td>0.118061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.180155</td>\n",
       "      <td>0.217418</td>\n",
       "      <td>0.305306</td>\n",
       "      <td>0.124355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.237633</td>\n",
       "      <td>0.219513</td>\n",
       "      <td>0.312656</td>\n",
       "      <td>0.126651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.315715</td>\n",
       "      <td>0.223585</td>\n",
       "      <td>0.319149</td>\n",
       "      <td>0.134806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.428493</td>\n",
       "      <td>0.229745</td>\n",
       "      <td>0.320030</td>\n",
       "      <td>0.150651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.564326</td>\n",
       "      <td>0.799749</td>\n",
       "      <td>0.799749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NCS_thinking_not_exciting*ni</td>\n",
       "      <td>-1.044852</td>\n",
       "      <td>0.141007</td>\n",
       "      <td>0.141007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.645220</td>\n",
       "      <td>0.060394</td>\n",
       "      <td>0.060394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.599573</td>\n",
       "      <td>0.052256</td>\n",
       "      <td>0.052256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.519440</td>\n",
       "      <td>0.027989</td>\n",
       "      <td>0.027989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.222472</td>\n",
       "      <td>0.009338</td>\n",
       "      <td>0.009338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.158232</td>\n",
       "      <td>0.005242</td>\n",
       "      <td>0.005242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.193473</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>0.003157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.075831</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.000254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>IMI_perceived_choice*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.564</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_thinking_not_exciting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.600</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.519</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.158</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.193</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.12\n",
      "2                          BIS_11               -0.12\n",
      "1                             EDM                0.12\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.12\n",
      "5                       TRSQ                0.12\n",
      "6  ACES_neglectful_parenting               -0.12\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 30)\n",
      "(275, 30)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.07168248931675658, 0.0253779900950859, -0.09814567628438953, 0.12668826352515983, -0.3547493416952787]\n",
      "overall_score:\n",
      "-0.04582925500853319\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378012</td>\n",
       "      <td>0.043888</td>\n",
       "      <td>0.317027</td>\n",
       "      <td>0.116114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.416709</td>\n",
       "      <td>0.064195</td>\n",
       "      <td>0.351041</td>\n",
       "      <td>0.087232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.433182</td>\n",
       "      <td>0.073417</td>\n",
       "      <td>0.360779</td>\n",
       "      <td>0.063187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.440148</td>\n",
       "      <td>0.102306</td>\n",
       "      <td>0.368202</td>\n",
       "      <td>0.044371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.445901</td>\n",
       "      <td>0.100932</td>\n",
       "      <td>0.382500</td>\n",
       "      <td>0.038040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.448646</td>\n",
       "      <td>0.101041</td>\n",
       "      <td>0.380086</td>\n",
       "      <td>0.039904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.449344</td>\n",
       "      <td>0.090335</td>\n",
       "      <td>0.374547</td>\n",
       "      <td>0.044644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.449466</td>\n",
       "      <td>0.085184</td>\n",
       "      <td>0.375430</td>\n",
       "      <td>0.031712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.449639</td>\n",
       "      <td>0.085264</td>\n",
       "      <td>0.375395</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.449639</td>\n",
       "      <td>0.085264</td>\n",
       "      <td>0.375395</td>\n",
       "      <td>0.031700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.449658</td>\n",
       "      <td>0.084335</td>\n",
       "      <td>0.373047</td>\n",
       "      <td>0.031388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.450344</td>\n",
       "      <td>0.117086</td>\n",
       "      <td>0.289923</td>\n",
       "      <td>0.071412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.451122</td>\n",
       "      <td>0.085793</td>\n",
       "      <td>0.331757</td>\n",
       "      <td>0.050044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.452887</td>\n",
       "      <td>0.112127</td>\n",
       "      <td>0.375337</td>\n",
       "      <td>0.039216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.453806</td>\n",
       "      <td>0.102551</td>\n",
       "      <td>0.376088</td>\n",
       "      <td>0.040805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.454348</td>\n",
       "      <td>0.077506</td>\n",
       "      <td>0.369209</td>\n",
       "      <td>0.045585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.455678</td>\n",
       "      <td>0.095577</td>\n",
       "      <td>0.370717</td>\n",
       "      <td>0.052400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.461401</td>\n",
       "      <td>0.113290</td>\n",
       "      <td>0.372479</td>\n",
       "      <td>0.047288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.461456</td>\n",
       "      <td>0.132019</td>\n",
       "      <td>0.293954</td>\n",
       "      <td>0.077921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.466109</td>\n",
       "      <td>0.101429</td>\n",
       "      <td>0.365019</td>\n",
       "      <td>0.061902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466799</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>0.072162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466799</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>0.072162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466799</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>0.072162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466799</td>\n",
       "      <td>0.153205</td>\n",
       "      <td>0.383784</td>\n",
       "      <td>0.072162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.467567</td>\n",
       "      <td>0.071220</td>\n",
       "      <td>0.353174</td>\n",
       "      <td>0.062814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468028</td>\n",
       "      <td>0.112561</td>\n",
       "      <td>0.360084</td>\n",
       "      <td>0.038027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.468571</td>\n",
       "      <td>0.082387</td>\n",
       "      <td>0.372639</td>\n",
       "      <td>0.043054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468845</td>\n",
       "      <td>0.077802</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.033643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468845</td>\n",
       "      <td>0.077802</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.033643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.468845</td>\n",
       "      <td>0.077802</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.033643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.468941</td>\n",
       "      <td>0.078017</td>\n",
       "      <td>0.368597</td>\n",
       "      <td>0.033369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.469489</td>\n",
       "      <td>0.095964</td>\n",
       "      <td>0.353867</td>\n",
       "      <td>0.055600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.470618</td>\n",
       "      <td>0.075068</td>\n",
       "      <td>0.363191</td>\n",
       "      <td>0.051933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.473606</td>\n",
       "      <td>0.075070</td>\n",
       "      <td>0.366943</td>\n",
       "      <td>0.043045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.474077</td>\n",
       "      <td>0.066597</td>\n",
       "      <td>0.331066</td>\n",
       "      <td>0.073852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.475728</td>\n",
       "      <td>0.126084</td>\n",
       "      <td>0.366686</td>\n",
       "      <td>0.056847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.475729</td>\n",
       "      <td>0.123941</td>\n",
       "      <td>0.386564</td>\n",
       "      <td>0.113242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.476574</td>\n",
       "      <td>0.139900</td>\n",
       "      <td>0.299117</td>\n",
       "      <td>0.081778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.476651</td>\n",
       "      <td>0.067842</td>\n",
       "      <td>0.309787</td>\n",
       "      <td>0.075092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.479468</td>\n",
       "      <td>0.113840</td>\n",
       "      <td>0.374480</td>\n",
       "      <td>0.057080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.481067</td>\n",
       "      <td>0.123916</td>\n",
       "      <td>0.379393</td>\n",
       "      <td>0.100766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.481323</td>\n",
       "      <td>0.105879</td>\n",
       "      <td>0.358313</td>\n",
       "      <td>0.071414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.481428</td>\n",
       "      <td>0.076052</td>\n",
       "      <td>0.368461</td>\n",
       "      <td>0.039272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.482626</td>\n",
       "      <td>0.077000</td>\n",
       "      <td>0.414502</td>\n",
       "      <td>0.106343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.482667</td>\n",
       "      <td>0.083475</td>\n",
       "      <td>0.370826</td>\n",
       "      <td>0.041118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.484396</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.034960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.484396</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.034960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.484396</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.034960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.484396</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.364958</td>\n",
       "      <td>0.034960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.487296</td>\n",
       "      <td>0.110542</td>\n",
       "      <td>0.377374</td>\n",
       "      <td>0.101603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.489328</td>\n",
       "      <td>0.080491</td>\n",
       "      <td>0.369461</td>\n",
       "      <td>0.040863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.489720</td>\n",
       "      <td>0.141358</td>\n",
       "      <td>0.398659</td>\n",
       "      <td>0.104607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.490821</td>\n",
       "      <td>0.077251</td>\n",
       "      <td>0.368811</td>\n",
       "      <td>0.038479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.491336</td>\n",
       "      <td>0.077429</td>\n",
       "      <td>0.368853</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.492105</td>\n",
       "      <td>0.087234</td>\n",
       "      <td>0.352724</td>\n",
       "      <td>0.081702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.492708</td>\n",
       "      <td>0.091982</td>\n",
       "      <td>0.350910</td>\n",
       "      <td>0.086822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.493271</td>\n",
       "      <td>0.091295</td>\n",
       "      <td>0.348710</td>\n",
       "      <td>0.086931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.493842</td>\n",
       "      <td>0.090574</td>\n",
       "      <td>0.346070</td>\n",
       "      <td>0.086967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.494129</td>\n",
       "      <td>0.090205</td>\n",
       "      <td>0.344546</td>\n",
       "      <td>0.086957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.494374</td>\n",
       "      <td>0.089768</td>\n",
       "      <td>0.342822</td>\n",
       "      <td>0.086936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.494560</td>\n",
       "      <td>0.089243</td>\n",
       "      <td>0.340859</td>\n",
       "      <td>0.086913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.498440</td>\n",
       "      <td>0.147239</td>\n",
       "      <td>0.305733</td>\n",
       "      <td>0.090643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.499987</td>\n",
       "      <td>0.057991</td>\n",
       "      <td>0.308635</td>\n",
       "      <td>0.062353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.500979</td>\n",
       "      <td>0.061775</td>\n",
       "      <td>0.308608</td>\n",
       "      <td>0.065738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.502001</td>\n",
       "      <td>0.062094</td>\n",
       "      <td>0.308567</td>\n",
       "      <td>0.065342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.503059</td>\n",
       "      <td>0.062476</td>\n",
       "      <td>0.308518</td>\n",
       "      <td>0.064955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.503597</td>\n",
       "      <td>0.062683</td>\n",
       "      <td>0.308491</td>\n",
       "      <td>0.064766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.504134</td>\n",
       "      <td>0.066724</td>\n",
       "      <td>0.427367</td>\n",
       "      <td>0.104421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.504226</td>\n",
       "      <td>0.062728</td>\n",
       "      <td>0.308354</td>\n",
       "      <td>0.064697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.504981</td>\n",
       "      <td>0.062552</td>\n",
       "      <td>0.308282</td>\n",
       "      <td>0.064560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505312</td>\n",
       "      <td>0.129274</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.079377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505312</td>\n",
       "      <td>0.129274</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.079377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505312</td>\n",
       "      <td>0.129274</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.079377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.505312</td>\n",
       "      <td>0.129274</td>\n",
       "      <td>0.369289</td>\n",
       "      <td>0.079377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.509441</td>\n",
       "      <td>0.098519</td>\n",
       "      <td>0.415193</td>\n",
       "      <td>0.166481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.512234</td>\n",
       "      <td>0.152055</td>\n",
       "      <td>0.309807</td>\n",
       "      <td>0.096523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.515875</td>\n",
       "      <td>0.108525</td>\n",
       "      <td>0.386844</td>\n",
       "      <td>0.103448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.516915</td>\n",
       "      <td>0.136965</td>\n",
       "      <td>0.417574</td>\n",
       "      <td>0.119759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.517951</td>\n",
       "      <td>0.124765</td>\n",
       "      <td>0.383748</td>\n",
       "      <td>0.062851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.518153</td>\n",
       "      <td>0.124853</td>\n",
       "      <td>0.383966</td>\n",
       "      <td>0.063237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.526178</td>\n",
       "      <td>0.080710</td>\n",
       "      <td>0.413211</td>\n",
       "      <td>0.163827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.527518</td>\n",
       "      <td>0.160484</td>\n",
       "      <td>0.323060</td>\n",
       "      <td>0.116469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.528050</td>\n",
       "      <td>0.096200</td>\n",
       "      <td>0.434956</td>\n",
       "      <td>0.153814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.528887</td>\n",
       "      <td>0.156939</td>\n",
       "      <td>0.314221</td>\n",
       "      <td>0.102796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.533304</td>\n",
       "      <td>0.120284</td>\n",
       "      <td>0.377149</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.533304</td>\n",
       "      <td>0.120284</td>\n",
       "      <td>0.377149</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.533304</td>\n",
       "      <td>0.120284</td>\n",
       "      <td>0.377149</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.533304</td>\n",
       "      <td>0.120284</td>\n",
       "      <td>0.377149</td>\n",
       "      <td>0.045013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.539780</td>\n",
       "      <td>0.131485</td>\n",
       "      <td>0.367136</td>\n",
       "      <td>0.059983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.539780</td>\n",
       "      <td>0.131485</td>\n",
       "      <td>0.367136</td>\n",
       "      <td>0.059983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.539780</td>\n",
       "      <td>0.131485</td>\n",
       "      <td>0.367136</td>\n",
       "      <td>0.059983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.539780</td>\n",
       "      <td>0.131485</td>\n",
       "      <td>0.367136</td>\n",
       "      <td>0.059983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.540911</td>\n",
       "      <td>0.158835</td>\n",
       "      <td>0.328300</td>\n",
       "      <td>0.100457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541917</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.370856</td>\n",
       "      <td>0.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541917</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.370856</td>\n",
       "      <td>0.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541917</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.370856</td>\n",
       "      <td>0.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.541917</td>\n",
       "      <td>0.123511</td>\n",
       "      <td>0.370856</td>\n",
       "      <td>0.054604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.543050</td>\n",
       "      <td>0.125278</td>\n",
       "      <td>0.374040</td>\n",
       "      <td>0.063368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.543050</td>\n",
       "      <td>0.125278</td>\n",
       "      <td>0.374040</td>\n",
       "      <td>0.063368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.544215</td>\n",
       "      <td>0.126460</td>\n",
       "      <td>0.396346</td>\n",
       "      <td>0.124164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.544304</td>\n",
       "      <td>0.127497</td>\n",
       "      <td>0.392298</td>\n",
       "      <td>0.080305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.544324</td>\n",
       "      <td>0.125384</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.063383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.544324</td>\n",
       "      <td>0.125384</td>\n",
       "      <td>0.373761</td>\n",
       "      <td>0.063383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.544788</td>\n",
       "      <td>0.092294</td>\n",
       "      <td>0.432472</td>\n",
       "      <td>0.151873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.547306</td>\n",
       "      <td>0.126816</td>\n",
       "      <td>0.391529</td>\n",
       "      <td>0.088005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.549728</td>\n",
       "      <td>0.161941</td>\n",
       "      <td>0.318516</td>\n",
       "      <td>0.109955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.555216</td>\n",
       "      <td>0.093480</td>\n",
       "      <td>0.354249</td>\n",
       "      <td>0.136322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.563134</td>\n",
       "      <td>0.095431</td>\n",
       "      <td>0.349417</td>\n",
       "      <td>0.149094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.573270</td>\n",
       "      <td>0.091116</td>\n",
       "      <td>0.343534</td>\n",
       "      <td>0.152588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.577352</td>\n",
       "      <td>0.122316</td>\n",
       "      <td>0.426533</td>\n",
       "      <td>0.120859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.585602</td>\n",
       "      <td>0.102281</td>\n",
       "      <td>0.382461</td>\n",
       "      <td>0.193443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.585627</td>\n",
       "      <td>0.085877</td>\n",
       "      <td>0.337433</td>\n",
       "      <td>0.156072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.593402</td>\n",
       "      <td>0.082089</td>\n",
       "      <td>0.333861</td>\n",
       "      <td>0.157745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.600830</td>\n",
       "      <td>0.072080</td>\n",
       "      <td>0.400184</td>\n",
       "      <td>0.165232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.603070</td>\n",
       "      <td>0.077096</td>\n",
       "      <td>0.330473</td>\n",
       "      <td>0.158194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.611574</td>\n",
       "      <td>0.107792</td>\n",
       "      <td>0.405859</td>\n",
       "      <td>0.188138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.615799</td>\n",
       "      <td>0.069990</td>\n",
       "      <td>0.327407</td>\n",
       "      <td>0.157041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.621588</td>\n",
       "      <td>0.079061</td>\n",
       "      <td>0.428271</td>\n",
       "      <td>0.159299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.691299</td>\n",
       "      <td>0.110394</td>\n",
       "      <td>0.341877</td>\n",
       "      <td>0.062158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.707804</td>\n",
       "      <td>0.113327</td>\n",
       "      <td>0.342204</td>\n",
       "      <td>0.066049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.727937</td>\n",
       "      <td>0.109308</td>\n",
       "      <td>0.342249</td>\n",
       "      <td>0.068092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.755275</td>\n",
       "      <td>0.103923</td>\n",
       "      <td>0.340670</td>\n",
       "      <td>0.071869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.772611</td>\n",
       "      <td>0.101644</td>\n",
       "      <td>0.338931</td>\n",
       "      <td>0.076090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.794608</td>\n",
       "      <td>0.100109</td>\n",
       "      <td>0.336956</td>\n",
       "      <td>0.081084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.824660</td>\n",
       "      <td>0.098630</td>\n",
       "      <td>0.333375</td>\n",
       "      <td>0.086541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.991947</td>\n",
       "      <td>0.202358</td>\n",
       "      <td>0.287450</td>\n",
       "      <td>0.095291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.039087</td>\n",
       "      <td>0.215452</td>\n",
       "      <td>0.290979</td>\n",
       "      <td>0.109197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.098737</td>\n",
       "      <td>0.218466</td>\n",
       "      <td>0.296811</td>\n",
       "      <td>0.118946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.183954</td>\n",
       "      <td>0.220164</td>\n",
       "      <td>0.306713</td>\n",
       "      <td>0.124520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.240817</td>\n",
       "      <td>0.221780</td>\n",
       "      <td>0.313787</td>\n",
       "      <td>0.126671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.317533</td>\n",
       "      <td>0.224999</td>\n",
       "      <td>0.320535</td>\n",
       "      <td>0.134187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.429155</td>\n",
       "      <td>0.230737</td>\n",
       "      <td>0.321098</td>\n",
       "      <td>0.149827</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>3.206130</td>\n",
       "      <td>1.174457</td>\n",
       "      <td>1.174457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-1.217887</td>\n",
       "      <td>0.184635</td>\n",
       "      <td>0.184635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>NCS_thinking_not_exciting*ni</td>\n",
       "      <td>-1.075569</td>\n",
       "      <td>0.140549</td>\n",
       "      <td>0.140549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.665682</td>\n",
       "      <td>0.044539</td>\n",
       "      <td>0.044539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.522922</td>\n",
       "      <td>0.037803</td>\n",
       "      <td>0.037803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.472511</td>\n",
       "      <td>0.032509</td>\n",
       "      <td>0.032509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.168079</td>\n",
       "      <td>0.005409</td>\n",
       "      <td>0.005409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.242887</td>\n",
       "      <td>0.005161</td>\n",
       "      <td>0.005161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.044481</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.206</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.174</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.472</td>\n",
       "      <td>-0.028</td>\n",
       "      <td>1.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.218</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.489</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>0.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NCS_thinking_not_exciting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.045</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>0.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.523</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.473</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.168</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.14\n",
      "2                          BIS_11               -0.14\n",
      "1                             EDM                0.14\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.14\n",
      "5                       TRSQ                0.14\n",
      "6  ACES_neglectful_parenting               -0.14\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 30)\n",
      "(275, 30)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.10954543741474365, 0.03219224635140949, 0.026160309057938536, -0.03274630979647686, -0.17966571588879732]\n",
      "overall_score:\n",
      "-0.008902806572236499\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429569</td>\n",
       "      <td>0.055016</td>\n",
       "      <td>0.315018</td>\n",
       "      <td>0.096599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.469909</td>\n",
       "      <td>0.116103</td>\n",
       "      <td>0.274563</td>\n",
       "      <td>0.090642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.479009</td>\n",
       "      <td>0.077045</td>\n",
       "      <td>0.346521</td>\n",
       "      <td>0.092337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.480859</td>\n",
       "      <td>0.131133</td>\n",
       "      <td>0.280967</td>\n",
       "      <td>0.098037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.496868</td>\n",
       "      <td>0.138584</td>\n",
       "      <td>0.289778</td>\n",
       "      <td>0.103582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.502371</td>\n",
       "      <td>0.058750</td>\n",
       "      <td>0.317726</td>\n",
       "      <td>0.081735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.517531</td>\n",
       "      <td>0.092582</td>\n",
       "      <td>0.341329</td>\n",
       "      <td>0.058186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.518789</td>\n",
       "      <td>0.089888</td>\n",
       "      <td>0.359279</td>\n",
       "      <td>0.073587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.519029</td>\n",
       "      <td>0.146869</td>\n",
       "      <td>0.299731</td>\n",
       "      <td>0.112253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.519248</td>\n",
       "      <td>0.117119</td>\n",
       "      <td>0.368084</td>\n",
       "      <td>0.054499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.525796</td>\n",
       "      <td>0.102571</td>\n",
       "      <td>0.349463</td>\n",
       "      <td>0.038615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.532140</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>0.391973</td>\n",
       "      <td>0.053978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.533458</td>\n",
       "      <td>0.151421</td>\n",
       "      <td>0.306053</td>\n",
       "      <td>0.117942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.538925</td>\n",
       "      <td>0.113966</td>\n",
       "      <td>0.388967</td>\n",
       "      <td>0.058250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.540450</td>\n",
       "      <td>0.126304</td>\n",
       "      <td>0.382775</td>\n",
       "      <td>0.051613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.544891</td>\n",
       "      <td>0.096112</td>\n",
       "      <td>0.384421</td>\n",
       "      <td>0.040292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.544891</td>\n",
       "      <td>0.096112</td>\n",
       "      <td>0.384421</td>\n",
       "      <td>0.040292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.544901</td>\n",
       "      <td>0.096098</td>\n",
       "      <td>0.384554</td>\n",
       "      <td>0.040134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.547457</td>\n",
       "      <td>0.094582</td>\n",
       "      <td>0.380307</td>\n",
       "      <td>0.041520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.547685</td>\n",
       "      <td>0.112154</td>\n",
       "      <td>0.387046</td>\n",
       "      <td>0.057023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.547838</td>\n",
       "      <td>0.105612</td>\n",
       "      <td>0.379688</td>\n",
       "      <td>0.063121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.550430</td>\n",
       "      <td>0.157017</td>\n",
       "      <td>0.313829</td>\n",
       "      <td>0.124774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.551027</td>\n",
       "      <td>0.124555</td>\n",
       "      <td>0.362645</td>\n",
       "      <td>0.042102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552015</td>\n",
       "      <td>0.091728</td>\n",
       "      <td>0.372016</td>\n",
       "      <td>0.051075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552109</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.362665</td>\n",
       "      <td>0.076209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552109</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.362665</td>\n",
       "      <td>0.076209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552109</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.362665</td>\n",
       "      <td>0.076209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.552109</td>\n",
       "      <td>0.156400</td>\n",
       "      <td>0.362665</td>\n",
       "      <td>0.076209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.555741</td>\n",
       "      <td>0.121008</td>\n",
       "      <td>0.385423</td>\n",
       "      <td>0.063940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.556195</td>\n",
       "      <td>0.113379</td>\n",
       "      <td>0.375394</td>\n",
       "      <td>0.073744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.563545</td>\n",
       "      <td>0.157169</td>\n",
       "      <td>0.384151</td>\n",
       "      <td>0.104264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.567204</td>\n",
       "      <td>0.162809</td>\n",
       "      <td>0.384974</td>\n",
       "      <td>0.115845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.567482</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.381499</td>\n",
       "      <td>0.034035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.567482</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.381499</td>\n",
       "      <td>0.034035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.567482</td>\n",
       "      <td>0.081478</td>\n",
       "      <td>0.381499</td>\n",
       "      <td>0.034035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.568854</td>\n",
       "      <td>0.053688</td>\n",
       "      <td>0.341083</td>\n",
       "      <td>0.080646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.568917</td>\n",
       "      <td>0.082251</td>\n",
       "      <td>0.380226</td>\n",
       "      <td>0.033498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.568965</td>\n",
       "      <td>0.071276</td>\n",
       "      <td>0.367157</td>\n",
       "      <td>0.068825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.569696</td>\n",
       "      <td>0.132599</td>\n",
       "      <td>0.382475</td>\n",
       "      <td>0.070562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.569929</td>\n",
       "      <td>0.121948</td>\n",
       "      <td>0.370552</td>\n",
       "      <td>0.082609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.572868</td>\n",
       "      <td>0.075255</td>\n",
       "      <td>0.377286</td>\n",
       "      <td>0.060002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.573066</td>\n",
       "      <td>0.163980</td>\n",
       "      <td>0.322722</td>\n",
       "      <td>0.131482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.573311</td>\n",
       "      <td>0.135890</td>\n",
       "      <td>0.384959</td>\n",
       "      <td>0.066784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.575378</td>\n",
       "      <td>0.090894</td>\n",
       "      <td>0.381455</td>\n",
       "      <td>0.046097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.575995</td>\n",
       "      <td>0.051568</td>\n",
       "      <td>0.309433</td>\n",
       "      <td>0.069762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576153</td>\n",
       "      <td>0.055451</td>\n",
       "      <td>0.308966</td>\n",
       "      <td>0.073410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576249</td>\n",
       "      <td>0.056356</td>\n",
       "      <td>0.308484</td>\n",
       "      <td>0.072804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.576648</td>\n",
       "      <td>0.057437</td>\n",
       "      <td>0.307910</td>\n",
       "      <td>0.072033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.576651</td>\n",
       "      <td>0.136938</td>\n",
       "      <td>0.351860</td>\n",
       "      <td>0.096867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.577259</td>\n",
       "      <td>0.079749</td>\n",
       "      <td>0.379681</td>\n",
       "      <td>0.053770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.577317</td>\n",
       "      <td>0.057708</td>\n",
       "      <td>0.307578</td>\n",
       "      <td>0.071641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.577477</td>\n",
       "      <td>0.136869</td>\n",
       "      <td>0.353360</td>\n",
       "      <td>0.097574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.578202</td>\n",
       "      <td>0.057820</td>\n",
       "      <td>0.307151</td>\n",
       "      <td>0.071292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.578238</td>\n",
       "      <td>0.136803</td>\n",
       "      <td>0.354755</td>\n",
       "      <td>0.098288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.578894</td>\n",
       "      <td>0.136676</td>\n",
       "      <td>0.355952</td>\n",
       "      <td>0.098942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.579481</td>\n",
       "      <td>0.057683</td>\n",
       "      <td>0.306833</td>\n",
       "      <td>0.070869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.579923</td>\n",
       "      <td>0.136386</td>\n",
       "      <td>0.357939</td>\n",
       "      <td>0.100006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.580919</td>\n",
       "      <td>0.136387</td>\n",
       "      <td>0.359537</td>\n",
       "      <td>0.100568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.581906</td>\n",
       "      <td>0.128605</td>\n",
       "      <td>0.360714</td>\n",
       "      <td>0.095024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.584668</td>\n",
       "      <td>0.127107</td>\n",
       "      <td>0.436078</td>\n",
       "      <td>0.186821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.587884</td>\n",
       "      <td>0.125190</td>\n",
       "      <td>0.365922</td>\n",
       "      <td>0.091519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.588711</td>\n",
       "      <td>0.083901</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.042423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.591298</td>\n",
       "      <td>0.090841</td>\n",
       "      <td>0.380567</td>\n",
       "      <td>0.044198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.592351</td>\n",
       "      <td>0.078477</td>\n",
       "      <td>0.376588</td>\n",
       "      <td>0.038808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.592351</td>\n",
       "      <td>0.078477</td>\n",
       "      <td>0.376588</td>\n",
       "      <td>0.038808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.592351</td>\n",
       "      <td>0.078477</td>\n",
       "      <td>0.376588</td>\n",
       "      <td>0.038808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.592351</td>\n",
       "      <td>0.078477</td>\n",
       "      <td>0.376588</td>\n",
       "      <td>0.038808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.595539</td>\n",
       "      <td>0.141652</td>\n",
       "      <td>0.331052</td>\n",
       "      <td>0.098630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.598276</td>\n",
       "      <td>0.085781</td>\n",
       "      <td>0.380876</td>\n",
       "      <td>0.043288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.599282</td>\n",
       "      <td>0.153653</td>\n",
       "      <td>0.315059</td>\n",
       "      <td>0.127643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.601654</td>\n",
       "      <td>0.138313</td>\n",
       "      <td>0.454379</td>\n",
       "      <td>0.175186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.603523</td>\n",
       "      <td>0.083050</td>\n",
       "      <td>0.379522</td>\n",
       "      <td>0.042381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604636</td>\n",
       "      <td>0.083003</td>\n",
       "      <td>0.379878</td>\n",
       "      <td>0.042228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.605334</td>\n",
       "      <td>0.106930</td>\n",
       "      <td>0.364944</td>\n",
       "      <td>0.147502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.610034</td>\n",
       "      <td>0.109189</td>\n",
       "      <td>0.360229</td>\n",
       "      <td>0.160738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.615798</td>\n",
       "      <td>0.103546</td>\n",
       "      <td>0.354608</td>\n",
       "      <td>0.164288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616819</td>\n",
       "      <td>0.143891</td>\n",
       "      <td>0.374883</td>\n",
       "      <td>0.085688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616819</td>\n",
       "      <td>0.143891</td>\n",
       "      <td>0.374883</td>\n",
       "      <td>0.085688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616819</td>\n",
       "      <td>0.143891</td>\n",
       "      <td>0.374883</td>\n",
       "      <td>0.085688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616819</td>\n",
       "      <td>0.143891</td>\n",
       "      <td>0.374883</td>\n",
       "      <td>0.085688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.617183</td>\n",
       "      <td>0.026061</td>\n",
       "      <td>0.450144</td>\n",
       "      <td>0.126911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.622263</td>\n",
       "      <td>0.088782</td>\n",
       "      <td>0.418870</td>\n",
       "      <td>0.176888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.623332</td>\n",
       "      <td>0.095413</td>\n",
       "      <td>0.347450</td>\n",
       "      <td>0.166403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.628635</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.343450</td>\n",
       "      <td>0.164877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.632521</td>\n",
       "      <td>0.053052</td>\n",
       "      <td>0.448794</td>\n",
       "      <td>0.141096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.635585</td>\n",
       "      <td>0.084541</td>\n",
       "      <td>0.339011</td>\n",
       "      <td>0.160439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.638209</td>\n",
       "      <td>0.122517</td>\n",
       "      <td>0.418557</td>\n",
       "      <td>0.069406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.638209</td>\n",
       "      <td>0.122517</td>\n",
       "      <td>0.418557</td>\n",
       "      <td>0.069406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.639756</td>\n",
       "      <td>0.103981</td>\n",
       "      <td>0.442772</td>\n",
       "      <td>0.164733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.643877</td>\n",
       "      <td>0.036260</td>\n",
       "      <td>0.460614</td>\n",
       "      <td>0.125657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.644751</td>\n",
       "      <td>0.086894</td>\n",
       "      <td>0.440047</td>\n",
       "      <td>0.149394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.645633</td>\n",
       "      <td>0.126595</td>\n",
       "      <td>0.375219</td>\n",
       "      <td>0.059681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.646000</td>\n",
       "      <td>0.076557</td>\n",
       "      <td>0.333073</td>\n",
       "      <td>0.151964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.647433</td>\n",
       "      <td>0.126840</td>\n",
       "      <td>0.375118</td>\n",
       "      <td>0.059658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.647433</td>\n",
       "      <td>0.126840</td>\n",
       "      <td>0.375118</td>\n",
       "      <td>0.059658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.648775</td>\n",
       "      <td>0.127106</td>\n",
       "      <td>0.374684</td>\n",
       "      <td>0.059565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"13\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648802</td>\n",
       "      <td>0.120785</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.055246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648802</td>\n",
       "      <td>0.120785</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.055246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648802</td>\n",
       "      <td>0.120785</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.055246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648802</td>\n",
       "      <td>0.120785</td>\n",
       "      <td>0.380342</td>\n",
       "      <td>0.055246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648846</td>\n",
       "      <td>0.123759</td>\n",
       "      <td>0.375603</td>\n",
       "      <td>0.052536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648846</td>\n",
       "      <td>0.123759</td>\n",
       "      <td>0.375603</td>\n",
       "      <td>0.052536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648846</td>\n",
       "      <td>0.123759</td>\n",
       "      <td>0.375603</td>\n",
       "      <td>0.052536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.648846</td>\n",
       "      <td>0.123759</td>\n",
       "      <td>0.375603</td>\n",
       "      <td>0.052536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649816</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>0.371032</td>\n",
       "      <td>0.059416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649816</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>0.371032</td>\n",
       "      <td>0.059416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649816</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>0.371032</td>\n",
       "      <td>0.059416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649816</td>\n",
       "      <td>0.130558</td>\n",
       "      <td>0.371032</td>\n",
       "      <td>0.059416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.650281</td>\n",
       "      <td>0.082617</td>\n",
       "      <td>0.403127</td>\n",
       "      <td>0.166603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.652436</td>\n",
       "      <td>0.121755</td>\n",
       "      <td>0.406552</td>\n",
       "      <td>0.093072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659360</td>\n",
       "      <td>0.117214</td>\n",
       "      <td>0.409506</td>\n",
       "      <td>0.098917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.662175</td>\n",
       "      <td>0.051831</td>\n",
       "      <td>0.459580</td>\n",
       "      <td>0.141503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.684498</td>\n",
       "      <td>0.102999</td>\n",
       "      <td>0.427559</td>\n",
       "      <td>0.158149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.684827</td>\n",
       "      <td>0.075814</td>\n",
       "      <td>0.472390</td>\n",
       "      <td>0.155298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.695944</td>\n",
       "      <td>0.097418</td>\n",
       "      <td>0.434629</td>\n",
       "      <td>0.207948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.702086</td>\n",
       "      <td>0.041612</td>\n",
       "      <td>0.432943</td>\n",
       "      <td>0.180772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.708026</td>\n",
       "      <td>0.120461</td>\n",
       "      <td>0.453199</td>\n",
       "      <td>0.202684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.720391</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.460962</td>\n",
       "      <td>0.174548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.754379</td>\n",
       "      <td>0.091333</td>\n",
       "      <td>0.364743</td>\n",
       "      <td>0.076014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.770786</td>\n",
       "      <td>0.096034</td>\n",
       "      <td>0.367593</td>\n",
       "      <td>0.084272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.790954</td>\n",
       "      <td>0.097365</td>\n",
       "      <td>0.370868</td>\n",
       "      <td>0.089298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.817046</td>\n",
       "      <td>0.104198</td>\n",
       "      <td>0.373468</td>\n",
       "      <td>0.097918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.833222</td>\n",
       "      <td>0.111172</td>\n",
       "      <td>0.374961</td>\n",
       "      <td>0.103814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.853972</td>\n",
       "      <td>0.120453</td>\n",
       "      <td>0.376617</td>\n",
       "      <td>0.110140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.881985</td>\n",
       "      <td>0.133866</td>\n",
       "      <td>0.375937</td>\n",
       "      <td>0.115985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.000408</td>\n",
       "      <td>0.205411</td>\n",
       "      <td>0.289808</td>\n",
       "      <td>0.095459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.046079</td>\n",
       "      <td>0.218614</td>\n",
       "      <td>0.292737</td>\n",
       "      <td>0.109689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.104673</td>\n",
       "      <td>0.221009</td>\n",
       "      <td>0.298134</td>\n",
       "      <td>0.120029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.188009</td>\n",
       "      <td>0.222858</td>\n",
       "      <td>0.308047</td>\n",
       "      <td>0.125084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.244215</td>\n",
       "      <td>0.224035</td>\n",
       "      <td>0.315152</td>\n",
       "      <td>0.126766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.319618</td>\n",
       "      <td>0.226655</td>\n",
       "      <td>0.321784</td>\n",
       "      <td>0.133818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.429957</td>\n",
       "      <td>0.231650</td>\n",
       "      <td>0.322247</td>\n",
       "      <td>0.148928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.578960</td>\n",
       "      <td>0.700753</td>\n",
       "      <td>0.700753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-2.491251</td>\n",
       "      <td>0.645394</td>\n",
       "      <td>0.645394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.415214</td>\n",
       "      <td>0.220275</td>\n",
       "      <td>0.220275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.879578</td>\n",
       "      <td>0.096221</td>\n",
       "      <td>0.096221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.811326</td>\n",
       "      <td>0.076213</td>\n",
       "      <td>0.076213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.434982</td>\n",
       "      <td>0.023154</td>\n",
       "      <td>0.023154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.344945</td>\n",
       "      <td>0.019924</td>\n",
       "      <td>0.019924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.294496</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.010628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.215662</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.006699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.095991</td>\n",
       "      <td>0.001240</td>\n",
       "      <td>0.001240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.029357</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.579</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.044</td>\n",
       "      <td>0.701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-2.491</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.531</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>0.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.415</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.376</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.215</td>\n",
       "      <td>0.381</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.076</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.007</td>\n",
       "      <td>-0.338</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.345</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.216</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "                     feature_name  interaction_effect\n",
      "0                            BSCS                0.16\n",
      "2                          BIS_11               -0.16\n",
      "1                             EDM                0.16\n",
      "16  DEMO_mcarthur_social_standing                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.16\n",
      "5                       TRSQ                0.16\n",
      "6  ACES_neglectful_parenting               -0.16\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 30)\n",
      "(275, 30)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x17e5b7eb0>], 'feature_selection__k': [10, 25, 50], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14744987203984672, 0.25749139653960085, 0.044308187381510655, 0.14885280709085413, -0.13605301688594107]\n",
      "overall_score:\n",
      "0.09240984923317426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.459017</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.289509</td>\n",
       "      <td>0.103003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.476296</td>\n",
       "      <td>0.102076</td>\n",
       "      <td>0.282846</td>\n",
       "      <td>0.130985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.488054</td>\n",
       "      <td>0.111889</td>\n",
       "      <td>0.286784</td>\n",
       "      <td>0.144838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.503647</td>\n",
       "      <td>0.116068</td>\n",
       "      <td>0.293361</td>\n",
       "      <td>0.151260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.526594</td>\n",
       "      <td>0.121226</td>\n",
       "      <td>0.301758</td>\n",
       "      <td>0.159521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.526663</td>\n",
       "      <td>0.052526</td>\n",
       "      <td>0.321074</td>\n",
       "      <td>0.089009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.541873</td>\n",
       "      <td>0.086286</td>\n",
       "      <td>0.333931</td>\n",
       "      <td>0.103197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.542045</td>\n",
       "      <td>0.124070</td>\n",
       "      <td>0.307359</td>\n",
       "      <td>0.165589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.560783</td>\n",
       "      <td>0.127718</td>\n",
       "      <td>0.313939</td>\n",
       "      <td>0.172162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.582406</td>\n",
       "      <td>0.094581</td>\n",
       "      <td>0.349170</td>\n",
       "      <td>0.071168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.584100</td>\n",
       "      <td>0.133715</td>\n",
       "      <td>0.321624</td>\n",
       "      <td>0.179014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.595941</td>\n",
       "      <td>0.123059</td>\n",
       "      <td>0.364066</td>\n",
       "      <td>0.048404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.599148</td>\n",
       "      <td>0.127140</td>\n",
       "      <td>0.367252</td>\n",
       "      <td>0.062162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604031</td>\n",
       "      <td>0.093837</td>\n",
       "      <td>0.357634</td>\n",
       "      <td>0.084858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.618448</td>\n",
       "      <td>0.125596</td>\n",
       "      <td>0.394235</td>\n",
       "      <td>0.065597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.622238</td>\n",
       "      <td>0.094766</td>\n",
       "      <td>0.359076</td>\n",
       "      <td>0.104150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.629199</td>\n",
       "      <td>0.085628</td>\n",
       "      <td>0.342911</td>\n",
       "      <td>0.133065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.629255</td>\n",
       "      <td>0.085474</td>\n",
       "      <td>0.343419</td>\n",
       "      <td>0.133308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.629420</td>\n",
       "      <td>0.085450</td>\n",
       "      <td>0.343855</td>\n",
       "      <td>0.133288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.629596</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.344274</td>\n",
       "      <td>0.133301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.629941</td>\n",
       "      <td>0.085321</td>\n",
       "      <td>0.345054</td>\n",
       "      <td>0.133394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.630170</td>\n",
       "      <td>0.085351</td>\n",
       "      <td>0.345849</td>\n",
       "      <td>0.133480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.630325</td>\n",
       "      <td>0.080584</td>\n",
       "      <td>0.346638</td>\n",
       "      <td>0.125926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.634571</td>\n",
       "      <td>0.128376</td>\n",
       "      <td>0.392728</td>\n",
       "      <td>0.072331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.636151</td>\n",
       "      <td>0.138735</td>\n",
       "      <td>0.381289</td>\n",
       "      <td>0.057646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.640279</td>\n",
       "      <td>0.094620</td>\n",
       "      <td>0.385541</td>\n",
       "      <td>0.085969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.641571</td>\n",
       "      <td>0.137280</td>\n",
       "      <td>0.359472</td>\n",
       "      <td>0.048790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.645137</td>\n",
       "      <td>0.116834</td>\n",
       "      <td>0.388407</td>\n",
       "      <td>0.076361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.646907</td>\n",
       "      <td>0.106244</td>\n",
       "      <td>0.393931</td>\n",
       "      <td>0.054764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.646907</td>\n",
       "      <td>0.106244</td>\n",
       "      <td>0.393931</td>\n",
       "      <td>0.054764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.647626</td>\n",
       "      <td>0.104649</td>\n",
       "      <td>0.392216</td>\n",
       "      <td>0.055383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.647710</td>\n",
       "      <td>0.106098</td>\n",
       "      <td>0.394074</td>\n",
       "      <td>0.054032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.648863</td>\n",
       "      <td>0.103806</td>\n",
       "      <td>0.376231</td>\n",
       "      <td>0.061894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.649380</td>\n",
       "      <td>0.122809</td>\n",
       "      <td>0.397561</td>\n",
       "      <td>0.072136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.650939</td>\n",
       "      <td>0.125229</td>\n",
       "      <td>0.385199</td>\n",
       "      <td>0.086241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.657431</td>\n",
       "      <td>0.131304</td>\n",
       "      <td>0.398165</td>\n",
       "      <td>0.079304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.658932</td>\n",
       "      <td>0.163131</td>\n",
       "      <td>0.369156</td>\n",
       "      <td>0.102791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.658932</td>\n",
       "      <td>0.163131</td>\n",
       "      <td>0.369156</td>\n",
       "      <td>0.102791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.658932</td>\n",
       "      <td>0.163131</td>\n",
       "      <td>0.369156</td>\n",
       "      <td>0.102791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.658932</td>\n",
       "      <td>0.163131</td>\n",
       "      <td>0.369156</td>\n",
       "      <td>0.102791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.663640</td>\n",
       "      <td>0.132771</td>\n",
       "      <td>0.381001</td>\n",
       "      <td>0.094836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.664053</td>\n",
       "      <td>0.177427</td>\n",
       "      <td>0.374088</td>\n",
       "      <td>0.114709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.665308</td>\n",
       "      <td>0.176081</td>\n",
       "      <td>0.374411</td>\n",
       "      <td>0.115810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.666469</td>\n",
       "      <td>0.174816</td>\n",
       "      <td>0.374726</td>\n",
       "      <td>0.116836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.667589</td>\n",
       "      <td>0.173607</td>\n",
       "      <td>0.375086</td>\n",
       "      <td>0.117831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.668740</td>\n",
       "      <td>0.090039</td>\n",
       "      <td>0.389974</td>\n",
       "      <td>0.064268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.669872</td>\n",
       "      <td>0.171331</td>\n",
       "      <td>0.375365</td>\n",
       "      <td>0.119495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.670936</td>\n",
       "      <td>0.140137</td>\n",
       "      <td>0.397970</td>\n",
       "      <td>0.081955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.671901</td>\n",
       "      <td>0.169393</td>\n",
       "      <td>0.375521</td>\n",
       "      <td>0.120646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673342</td>\n",
       "      <td>0.144892</td>\n",
       "      <td>0.402698</td>\n",
       "      <td>0.083923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673414</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.392467</td>\n",
       "      <td>0.039538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.673414</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.392467</td>\n",
       "      <td>0.039538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673414</td>\n",
       "      <td>0.087830</td>\n",
       "      <td>0.392467</td>\n",
       "      <td>0.039538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673542</td>\n",
       "      <td>0.127249</td>\n",
       "      <td>0.367331</td>\n",
       "      <td>0.144354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673661</td>\n",
       "      <td>0.087802</td>\n",
       "      <td>0.392531</td>\n",
       "      <td>0.039579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.673673</td>\n",
       "      <td>0.158098</td>\n",
       "      <td>0.375576</td>\n",
       "      <td>0.114539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.674894</td>\n",
       "      <td>0.132260</td>\n",
       "      <td>0.362766</td>\n",
       "      <td>0.157663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.677915</td>\n",
       "      <td>0.126814</td>\n",
       "      <td>0.356424</td>\n",
       "      <td>0.160644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.682348</td>\n",
       "      <td>0.139457</td>\n",
       "      <td>0.378452</td>\n",
       "      <td>0.104697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.682391</td>\n",
       "      <td>0.118775</td>\n",
       "      <td>0.348086</td>\n",
       "      <td>0.161446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.683538</td>\n",
       "      <td>0.084035</td>\n",
       "      <td>0.391986</td>\n",
       "      <td>0.059001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.684584</td>\n",
       "      <td>0.113688</td>\n",
       "      <td>0.343547</td>\n",
       "      <td>0.161439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.686956</td>\n",
       "      <td>0.097393</td>\n",
       "      <td>0.386207</td>\n",
       "      <td>0.053113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.687017</td>\n",
       "      <td>0.107396</td>\n",
       "      <td>0.338906</td>\n",
       "      <td>0.160705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.688254</td>\n",
       "      <td>0.122867</td>\n",
       "      <td>0.336154</td>\n",
       "      <td>0.149811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.690453</td>\n",
       "      <td>0.142703</td>\n",
       "      <td>0.346134</td>\n",
       "      <td>0.153885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.691030</td>\n",
       "      <td>0.098274</td>\n",
       "      <td>0.334483</td>\n",
       "      <td>0.157595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.702348</td>\n",
       "      <td>0.092624</td>\n",
       "      <td>0.392023</td>\n",
       "      <td>0.045599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.706756</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.386044</td>\n",
       "      <td>0.041360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.706756</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.386044</td>\n",
       "      <td>0.041360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.706756</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.386044</td>\n",
       "      <td>0.041360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.706756</td>\n",
       "      <td>0.078704</td>\n",
       "      <td>0.386044</td>\n",
       "      <td>0.041360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.708992</td>\n",
       "      <td>0.096239</td>\n",
       "      <td>0.389374</td>\n",
       "      <td>0.048518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.713088</td>\n",
       "      <td>0.163570</td>\n",
       "      <td>0.417583</td>\n",
       "      <td>0.038649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.713088</td>\n",
       "      <td>0.163570</td>\n",
       "      <td>0.417583</td>\n",
       "      <td>0.038649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.716529</td>\n",
       "      <td>0.094009</td>\n",
       "      <td>0.387811</td>\n",
       "      <td>0.047759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.719339</td>\n",
       "      <td>0.137508</td>\n",
       "      <td>0.443555</td>\n",
       "      <td>0.197339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.722502</td>\n",
       "      <td>0.140952</td>\n",
       "      <td>0.456198</td>\n",
       "      <td>0.198353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.725503</td>\n",
       "      <td>0.086638</td>\n",
       "      <td>0.387147</td>\n",
       "      <td>0.046048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.728876</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.383749</td>\n",
       "      <td>0.046826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.732604</td>\n",
       "      <td>0.134776</td>\n",
       "      <td>0.416137</td>\n",
       "      <td>0.039384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.733739</td>\n",
       "      <td>0.134756</td>\n",
       "      <td>0.418727</td>\n",
       "      <td>0.045112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"9\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.740286</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.409194</td>\n",
       "      <td>0.063482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.740286</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.409194</td>\n",
       "      <td>0.063482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.740286</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.409194</td>\n",
       "      <td>0.063482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.740286</td>\n",
       "      <td>0.106783</td>\n",
       "      <td>0.409194</td>\n",
       "      <td>0.063482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.743541</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.061756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.743541</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.061756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.743541</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.061756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.743541</td>\n",
       "      <td>0.121919</td>\n",
       "      <td>0.399989</td>\n",
       "      <td>0.061756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.745691</td>\n",
       "      <td>0.066501</td>\n",
       "      <td>0.427256</td>\n",
       "      <td>0.165767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.746552</td>\n",
       "      <td>0.117131</td>\n",
       "      <td>0.389947</td>\n",
       "      <td>0.064214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.746552</td>\n",
       "      <td>0.117131</td>\n",
       "      <td>0.389947</td>\n",
       "      <td>0.064214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.746552</td>\n",
       "      <td>0.117131</td>\n",
       "      <td>0.389947</td>\n",
       "      <td>0.064214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.746621</td>\n",
       "      <td>0.162787</td>\n",
       "      <td>0.378028</td>\n",
       "      <td>0.096454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.746621</td>\n",
       "      <td>0.162787</td>\n",
       "      <td>0.378028</td>\n",
       "      <td>0.096454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.746621</td>\n",
       "      <td>0.162787</td>\n",
       "      <td>0.378028</td>\n",
       "      <td>0.096454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.746621</td>\n",
       "      <td>0.162787</td>\n",
       "      <td>0.378028</td>\n",
       "      <td>0.096454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.749834</td>\n",
       "      <td>0.118284</td>\n",
       "      <td>0.389325</td>\n",
       "      <td>0.064280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.753837</td>\n",
       "      <td>0.104768</td>\n",
       "      <td>0.391761</td>\n",
       "      <td>0.054915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.753837</td>\n",
       "      <td>0.104768</td>\n",
       "      <td>0.391761</td>\n",
       "      <td>0.054915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.753837</td>\n",
       "      <td>0.104768</td>\n",
       "      <td>0.391761</td>\n",
       "      <td>0.054915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.753837</td>\n",
       "      <td>0.104768</td>\n",
       "      <td>0.391761</td>\n",
       "      <td>0.054915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.755926</td>\n",
       "      <td>0.071435</td>\n",
       "      <td>0.436146</td>\n",
       "      <td>0.162463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.757388</td>\n",
       "      <td>0.053376</td>\n",
       "      <td>0.432933</td>\n",
       "      <td>0.162289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.764320</td>\n",
       "      <td>0.075311</td>\n",
       "      <td>0.447889</td>\n",
       "      <td>0.164742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.766246</td>\n",
       "      <td>0.171701</td>\n",
       "      <td>0.340267</td>\n",
       "      <td>0.096791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.770341</td>\n",
       "      <td>0.091279</td>\n",
       "      <td>0.402368</td>\n",
       "      <td>0.195081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.773472</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>0.339347</td>\n",
       "      <td>0.105238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.773552</td>\n",
       "      <td>0.097358</td>\n",
       "      <td>0.418364</td>\n",
       "      <td>0.193812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.778325</td>\n",
       "      <td>0.099841</td>\n",
       "      <td>0.421669</td>\n",
       "      <td>0.184872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.800234</td>\n",
       "      <td>0.056244</td>\n",
       "      <td>0.438876</td>\n",
       "      <td>0.202166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.803447</td>\n",
       "      <td>0.100558</td>\n",
       "      <td>0.467267</td>\n",
       "      <td>0.218476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.813690</td>\n",
       "      <td>0.108069</td>\n",
       "      <td>0.412209</td>\n",
       "      <td>0.175471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.816972</td>\n",
       "      <td>0.102832</td>\n",
       "      <td>0.447509</td>\n",
       "      <td>0.222086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.829979</td>\n",
       "      <td>0.058892</td>\n",
       "      <td>0.415941</td>\n",
       "      <td>0.214461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.833190</td>\n",
       "      <td>0.108360</td>\n",
       "      <td>0.365750</td>\n",
       "      <td>0.096685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.835602</td>\n",
       "      <td>0.116060</td>\n",
       "      <td>0.433849</td>\n",
       "      <td>0.172964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.836000</td>\n",
       "      <td>0.087029</td>\n",
       "      <td>0.389351</td>\n",
       "      <td>0.221055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.851305</td>\n",
       "      <td>0.109186</td>\n",
       "      <td>0.366243</td>\n",
       "      <td>0.101965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.873845</td>\n",
       "      <td>0.104402</td>\n",
       "      <td>0.367405</td>\n",
       "      <td>0.101806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.903585</td>\n",
       "      <td>0.103402</td>\n",
       "      <td>0.367031</td>\n",
       "      <td>0.101312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.921615</td>\n",
       "      <td>0.106521</td>\n",
       "      <td>0.366405</td>\n",
       "      <td>0.101117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.943653</td>\n",
       "      <td>0.112094</td>\n",
       "      <td>0.363521</td>\n",
       "      <td>0.101189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 50, 'feature_selection__score_func': &lt;function f_regression at 0x17e5b7eb0&gt;}</th>\n",
       "      <td>-3.971361</td>\n",
       "      <td>0.123518</td>\n",
       "      <td>0.358671</td>\n",
       "      <td>0.101545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-4.009167</td>\n",
       "      <td>0.208327</td>\n",
       "      <td>0.292303</td>\n",
       "      <td>0.095695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-4.053805</td>\n",
       "      <td>0.221433</td>\n",
       "      <td>0.294992</td>\n",
       "      <td>0.109773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-4.111066</td>\n",
       "      <td>0.223364</td>\n",
       "      <td>0.299552</td>\n",
       "      <td>0.120957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-4.192504</td>\n",
       "      <td>0.225610</td>\n",
       "      <td>0.309315</td>\n",
       "      <td>0.126184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-4.247780</td>\n",
       "      <td>0.226253</td>\n",
       "      <td>0.316501</td>\n",
       "      <td>0.127109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-4.321801</td>\n",
       "      <td>0.228360</td>\n",
       "      <td>0.323098</td>\n",
       "      <td>0.133472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-4.430940</td>\n",
       "      <td>0.232689</td>\n",
       "      <td>0.323356</td>\n",
       "      <td>0.147931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.184171</td>\n",
       "      <td>0.989051</td>\n",
       "      <td>0.989051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>2.963403</td>\n",
       "      <td>0.895696</td>\n",
       "      <td>0.895696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.739765</td>\n",
       "      <td>0.321790</td>\n",
       "      <td>0.321790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.311721</td>\n",
       "      <td>0.172764</td>\n",
       "      <td>0.172764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.957120</td>\n",
       "      <td>0.095619</td>\n",
       "      <td>0.095619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.446090</td>\n",
       "      <td>0.021620</td>\n",
       "      <td>0.021620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.340147</td>\n",
       "      <td>0.017789</td>\n",
       "      <td>0.017789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.265576</td>\n",
       "      <td>0.010182</td>\n",
       "      <td>0.010182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.298508</td>\n",
       "      <td>0.008965</td>\n",
       "      <td>0.008965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.220918</td>\n",
       "      <td>0.007568</td>\n",
       "      <td>0.007568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.098975</td>\n",
       "      <td>0.002332</td>\n",
       "      <td>0.002332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.017445</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.184</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.567</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>0.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.963</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.002</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.564</td>\n",
       "      <td>-0.058</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.740</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.412</td>\n",
       "      <td>-0.087</td>\n",
       "      <td>0.322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.230</td>\n",
       "      <td>0.412</td>\n",
       "      <td>0.173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.957</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.096</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.005</td>\n",
       "      <td>-0.370</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.221</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_54493/1551958940.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    }
   ],
   "source": [
    "overall_scores = pd.DataFrame(columns=['n_features','effect_size', 'overall_score'])\n",
    "        \n",
    "        \n",
    "# hypers = {\n",
    "#     'r2':do_hyperparameter_selection_loop_r2,\n",
    "#     'mae':do_hyperparameter_selection_loop\n",
    "# }\n",
    "\n",
    "\n",
    "for pcount in [15,20,25,30]:\n",
    "    for effect_size in [0.08,0.10,0.12,0.14, 0.16]:\n",
    "        custom_interaction_effects_g1    =  [0]*pcount\n",
    "        custom_interaction_effects_g1[0] =  effect_size\n",
    "        custom_interaction_effects_g1[1] =  effect_size\n",
    "        custom_interaction_effects_g1[2] = -effect_size\n",
    "\n",
    "        custom_interaction_effects_g2 = custom_interaction_effects_g1\n",
    "\n",
    "        custom_interaction_effects = {'nisan':custom_interaction_effects_g1}\n",
    "\n",
    "\n",
    "        overall_score = run_full_limited_predictor_analysis(\n",
    "            pcount,\n",
    "            outcome_measures,\n",
    "            analysis_data_imputed,\n",
    "            effect_size= effect_size,\n",
    "            hyperparameter_optimizer = do_hyperparameter_selection_loop\n",
    "            )\n",
    "\n",
    "        #run the analysis with a limited number of predictors\n",
    "        overall_scores = overall_scores.append(\n",
    "            {'n_features':pcount,\n",
    "            'effect_size':effect_size,\n",
    "            'overall_score':overall_score\n",
    "            #,'hyper_target':'mae'\n",
    "            },\n",
    "            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.078301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.121002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.004276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.054448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.101453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.090946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.045115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.033768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.035614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.119037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.054560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.116193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.085246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.014657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.039457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.011581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.104402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>-0.045829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>-0.008903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>30.0</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.092410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_features  effect_size  overall_score\n",
       "0         15.0         0.08      -0.078301\n",
       "1         15.0         0.10      -0.121002\n",
       "2         15.0         0.12       0.004276\n",
       "3         15.0         0.14       0.054448\n",
       "4         15.0         0.16       0.101453\n",
       "5         20.0         0.08      -0.090946\n",
       "6         20.0         0.10      -0.045115\n",
       "7         20.0         0.12      -0.033768\n",
       "8         20.0         0.14       0.035614\n",
       "9         20.0         0.16       0.119037\n",
       "10        25.0         0.08      -0.054560\n",
       "11        25.0         0.10      -0.116193\n",
       "12        25.0         0.12      -0.085246\n",
       "13        25.0         0.14      -0.014657\n",
       "14        25.0         0.16       0.039457\n",
       "15        30.0         0.08       0.011581\n",
       "16        30.0         0.10      -0.104402\n",
       "17        30.0         0.12      -0.045829\n",
       "18        30.0         0.14      -0.008903\n",
       "19        30.0         0.16       0.092410"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014247d405695287815678bf9349a8dffb2674e9fe9a5bd4bb9820af018d638d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
