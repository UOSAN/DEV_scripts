{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "from socket import gethostname\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from dev_interaction_util import generate_synthetic_dev_outcomes, generate_synthetic_dev_data, set_up_interactions\n",
    "from dev_interaction_util import do_scoring_loop, get_best_model, summarize_overall_df_results, do_final_fit, present_model_results, present_results_vs_ground_truth_cors\n",
    "from dev_interaction_util import load_and_preprocess_data, impute_data, run_full_limited_predictor_analysis\n",
    "from ml_util import *\n",
    "# Imputing with MICE\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, KNNImputer\n",
    "from sklearn import linear_model\n",
    "from ml_util import get_data_for_imputation\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "from sklearn.base import clone\n",
    "from sklearn.inspection import permutation_importance\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, RFE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benjamins-MacBook-Pro-2.local\n",
      "{'dropbox_data_dir': '/Users/benjaminsmith/Dropbox (University of Oregon)/UO-SAN Lab/Berkman Lab/Devaluation/analysis_files/data/'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(gethostname())\n",
    "# Open the file and load the file\n",
    "with open('config.yml') as f:\n",
    "    all_yaml = yaml.load(f, Loader=SafeLoader)\n",
    "    if gethostname() in all_yaml.keys():\n",
    "        config = all_yaml[gethostname()]\n",
    "    else:\n",
    "        config = all_yaml['default']\n",
    "        \n",
    "print(config)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is derived from `test_feature_selection.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropbox_data_dir = config['dropbox_data_dir']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_data, outcome_measures = load_and_preprocess_data(dropbox_data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/opt/anaconda3/envs/dataanalysis3_10/lib/python3.10/site-packages/sklearn/impute/_iterative.py:713: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "analysis_data_imputed = impute_data(analysis_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def do_hyperparameter_selection_loop_r2(X,y,cv):\n",
    "    return(do_hyperparameter_selection_loop_w_metric(X,y,cv,'r2'))\n",
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop(X, y,cv):\n",
    "    return(do_hyperparameter_selection_loop_w_metric(X,y,cv,'neg_mean_absolute_error'))\n",
    "\n",
    "#loops through the different estimators and feature selection methods and does a grid search over all to find the best hyperparameters\n",
    "def do_hyperparameter_selection_loop_w_metric(X, y,cv,metric):\n",
    "    #alpha parameters for Ridge and Lasso\n",
    "    alpha_10pow_lower = 1\n",
    "    alpha_10pow_upper = 0\n",
    "    alpha_increments=1\n",
    "    alpha_range = np.concatenate([np.power(10,np.linspace(-alpha_10pow_lower,alpha_10pow_upper,(alpha_10pow_lower+alpha_10pow_upper)*alpha_increments+1)),\n",
    "        [0.2,0.3,0.4,0.6,0.8,1.0]])\n",
    "    \n",
    "    all_cv_results = []\n",
    "\n",
    "    pipeline_estimator_name = 'estimator'\n",
    "    feature_selection_name = 'feature_selection'\n",
    "\n",
    "\n",
    "    #define the param_grid for the estimators\n",
    "    estimators_to_run = {\n",
    "        'Ridge':{\n",
    "            'estimator':linear_model.Ridge,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'Lasso':{\n",
    "            'estimator':linear_model.Lasso,\n",
    "            'parameters':{'alpha':alpha_range}\n",
    "        },\n",
    "        'DecisionTreeRegressor':{\n",
    "            'estimator':DecisionTreeRegressor,\n",
    "            'parameters':{\n",
    "                'max_depth':[2, 4],\n",
    "                'min_samples_split':[20,50],\n",
    "                'min_samples_leaf':[20,50]\n",
    "            }\n",
    "        }             \n",
    "    }\n",
    "\n",
    "    k_max_val = np.min([50,X.shape[1]])\n",
    "\n",
    "    for estimator_name,estimator_dict in estimators_to_run.items():\n",
    "        #param grid for the feature seelction\n",
    "        #this is here because we need to know the estimator to pass to the feature selector\n",
    "        feature_selectors_to_run = {\n",
    "            'None':None,\n",
    "            'KBest':{\n",
    "                'selector':SelectKBest(),\n",
    "                'parameters':{\n",
    "                    'score_func' : [f_regression], \n",
    "                    'k' : [10,25,k_max_val]\n",
    "                    }\n",
    "            },\n",
    "            'RFE':{\n",
    "                'selector':RFE(linear_model.LinearRegression()),\n",
    "                'parameters':{\n",
    "                    'n_features_to_select' : [10,25],\n",
    "                    #'verbose':[1],\n",
    "                    'step':[5]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        for selector_name, selector_dict in feature_selectors_to_run.items():\n",
    "        #create the estimator\n",
    "            if selector_name == 'None':\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                     (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = {}\n",
    "            else:\n",
    "                pipeline = Pipeline([('scaler',StandardScaler()),\n",
    "                                     (feature_selection_name,selector_dict['selector']), \n",
    "                                     (pipeline_estimator_name,estimator_dict['estimator']())])\n",
    "                selector_params = selector_dict['parameters']\n",
    "\n",
    "            estimator_param_grid = {(pipeline_estimator_name + '__'+k):v for k,v in estimator_dict['parameters'].items()}\n",
    "            selector_param_grid = {(feature_selection_name + '__'+k):v for k,v in selector_params.items()}\n",
    "            #combine the two param grid dictionaries\n",
    "            full_param_grid = {**selector_param_grid, **estimator_param_grid}\n",
    "            print(pipeline)\n",
    "            print(full_param_grid)\n",
    "\n",
    "            \n",
    "        \n",
    "            gs_1 = GridSearchCV(estimator=pipeline, \n",
    "                                param_grid = full_param_grid, \n",
    "                                cv=cv,scoring=metric,verbose=1)\n",
    "            gs_1.fit(X,y)\n",
    "            all_cv_results.append(gs_1)\n",
    "\n",
    "    #create a dataframe with the best parameters, best mean_test_score, and name of the model\n",
    "\n",
    "    best_params_df = pd.DataFrame({\n",
    "        'model': [cv_result.estimator for cv_result in all_cv_results],\n",
    "        'model_name': [cv_result.estimator.__class__.__name__ for cv_result in all_cv_results],\n",
    "        'best_params': [extract_estimator_params_from_gridsearch(cv_result.best_params_) for cv_result in all_cv_results],\n",
    "        'best_score': [cv_result.best_score_ for cv_result in all_cv_results],\n",
    "        'best_raw_params' : [cv_result.best_params_ for cv_result in all_cv_results]\n",
    "        })\n",
    "    \n",
    "    best_params_df = best_params_df.sort_values('best_score',ascending=False).reset_index(drop=True)\n",
    "\n",
    "    best_model = clone(best_params_df['model'][0])\n",
    "    best_model_params = best_params_df['best_raw_params'][0]\n",
    "    best_model.set_params(**best_model_params)\n",
    "\n",
    "    return {\n",
    "        'best_model': best_model,\n",
    "        'best_params_df':best_params_df,\n",
    "        'raw_cv_results':all_cv_results\n",
    "    }\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving fit with manual theory-driven feature\n",
    "\n",
    "My past analysis showed that by manually removing some features before the analysis starts, we can improve performance beyond the chance performance otherwise seen.\n",
    "\n",
    "So, it might be useful to understand how much we can improve our performance by manual feature selection before the automatic feature selection applies.\n",
    "\n",
    "This was previously done in `test_limited_predictors.ipynb`. We tested as few as 2 distractor features. In that test, predictor features generally had correlations in the range of |r|=0.06 to 0.53, with most around 0.4 (we should confirm that because it seems fishy that PCS was detegted as an effect, but didn't model as a large predictor). With most `|r|=0.4`, this seems unrealistically high to expect, and we should aim to build a pipeline capable of detecting more subtle effects than that. An approximate `|r|=0.3` can be achieved by mixing in a predictor scaled to 8% of normal scale.\n",
    "\n",
    "I can imagine it is plausible to cut down to as few as two self-report, one behavioral, and one neural measure per intervention, plus sex and age. That would yield 10 different variables. At the other end, we might want 10 self-report, two behavioral, and five neural measures per intervention tested, plus 6 different demographic variables--a total of 40 variables. Let's see how these would perform, as well as mid-range of 20 predictor variables. In each case we'll restrict to three valid predictors per intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_2_group_predictor_analysis(total_predictor_count, outcome_measures, analysis_data_imputed, effect_size, hyperparameter_optimizer,\n",
    "                                        custom_interaction_effects=None\n",
    "                                        ):\n",
    "\n",
    "    #set np random seed\n",
    "    np.random.seed(3161527)\n",
    "\n",
    "    group_names = ['ichi','ni','san']\n",
    "    #assign each row randomly to a group\n",
    "    group_assignments_3 = np.random.choice(group_names,analysis_data_imputed.shape[0])\n",
    "    \n",
    "    #two-group analysis, comparing ichi vs ni and san\n",
    "    group_assignments_2 = group_assignments_3.copy()\n",
    "    group_assignments_2[group_assignments_2=='ni'] = 'nisan'\n",
    "    group_assignments_2[group_assignments_2=='san'] = 'nisan'\n",
    "\n",
    "\n",
    "    #synthetic outcomes\n",
    "    outcome_measures = generate_synthetic_dev_outcomes(outcome_measures)\n",
    "\n",
    "    #create a limited set of predictors\n",
    "    analysis_data_smol = analysis_data_imputed.iloc[:,0:total_predictor_count]\n",
    "\n",
    "    # add synthetic primary and interaction effects\n",
    "\n",
    "    if custom_interaction_effects is None:\n",
    "        #set up the interaction effects\n",
    "        #0.08 will give us correlations around 0.3 between the interaction effects and the outcome\n",
    "        custom_interaction_effects_g1 = [0]*analysis_data_smol.shape[1]\n",
    "        custom_interaction_effects_g1[0] = effect_size\n",
    "        custom_interaction_effects_g1[1] = effect_size\n",
    "        custom_interaction_effects_g1[2] = -effect_size\n",
    "\n",
    "\n",
    "        custom_interaction_effects = {'nisan':custom_interaction_effects_g1}\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    synthetic_data = generate_synthetic_dev_data(analysis_data_smol, group_assignments_2,outcome_measures, group_interaction_effects = custom_interaction_effects)\n",
    "    interaction_effect_df = synthetic_data['X_weights']\n",
    "    outcome_measures = synthetic_data['y']\n",
    "\n",
    "    # Set up outcome measures and group assignment one-hot\n",
    "\n",
    "    outcome_measures = calculate_outcome_changes(outcome_measures)\n",
    "    \n",
    "\n",
    "    group_assignment_onehots = pd.get_dummies(group_assignments_2).loc[:,['nisan']]\n",
    "\n",
    "    predictor_data = set_up_interactions(analysis_data_smol, group_assignment_onehots)\n",
    "\n",
    "\n",
    "    #remove any NA values for this outcome measure in both the predictor data and the outcome data\n",
    "    outcome_nas = outcome_measures['d_bf'].isna()\n",
    "\n",
    "    outcome_measures_nona = outcome_measures.loc[~outcome_nas,:]\n",
    "    predictor_data_nona = predictor_data.loc[~outcome_nas,:]\n",
    "    group_assignment_onehots_nonan = group_assignment_onehots.loc[~outcome_nas,:]\n",
    "    group_assignments_nona = group_assignments_2[~outcome_nas]\n",
    "\n",
    "    ### Try out CV with simple gridsearch\n",
    "\n",
    "    scoring_data = do_scoring_loop(X=predictor_data_nona, y= outcome_measures_nona['d_bf'], \n",
    "                    groups = group_assignments_nona, \n",
    "                    hyperparameter_selection_on_fold=hyperparameter_optimizer,\n",
    "                    outer_folds=5)\n",
    "\n",
    "    scores = scoring_data['scores']\n",
    "    best_models = scoring_data['best_models']\n",
    "    best_params_df_list = scoring_data['best_params_df_list']\n",
    "    raw_cv_results_list = scoring_data['raw_cv_results_list']\n",
    "\n",
    "    print(\"scores:\")\n",
    "    print(scores)\n",
    "    overall_score = np.mean(scores)\n",
    "    print(\"overall_score:\")\n",
    "    print(overall_score)\n",
    "\n",
    "\n",
    "\n",
    "    best_model = get_best_model(summarize_overall_df_results(raw_cv_results_list))\n",
    "    final_fit = do_final_fit(X=predictor_data_nona, y= outcome_measures_nona['d_bf'], final_model=best_model)\n",
    "    final_results = present_model_results(X=predictor_data_nona, final_fit=final_fit, y=outcome_measures_nona['d_bf'])\n",
    "\n",
    "    #print rows of final_results where feature_name is the list of features to check\n",
    "    base_regressors = interaction_effect_df.predictor[interaction_effect_df.interaction_effect!=0]\n",
    "    regressors_to_check = [x+y for y in ['','*nisan'] for x in base_regressors]\n",
    "    final_results['planned_regression'] = final_results['predictor'].isin(regressors_to_check)\n",
    "\n",
    "    present_results_vs_ground_truth_cors(predictor_data_nona,outcome_measures_nona,group_assignments_nona,final_results,base_regressors)\n",
    "\n",
    "    return(overall_score)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.030469308321608213, 0.015382233580734317, -0.11997251572222778, -0.06003743599259326, -0.28573969016478284]\n",
      "overall_score:\n",
      "-0.08397961999545227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.255178</td>\n",
       "      <td>0.036963</td>\n",
       "      <td>0.298413</td>\n",
       "      <td>0.065261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.262595</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.325744</td>\n",
       "      <td>0.063801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.263923</td>\n",
       "      <td>0.036615</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.050600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267383</td>\n",
       "      <td>0.061964</td>\n",
       "      <td>0.316593</td>\n",
       "      <td>0.046503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.271499</td>\n",
       "      <td>0.080776</td>\n",
       "      <td>0.335304</td>\n",
       "      <td>0.084335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.275463</td>\n",
       "      <td>0.061394</td>\n",
       "      <td>0.319901</td>\n",
       "      <td>0.048468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.276075</td>\n",
       "      <td>0.030953</td>\n",
       "      <td>0.300211</td>\n",
       "      <td>0.069192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277201</td>\n",
       "      <td>0.077547</td>\n",
       "      <td>0.292307</td>\n",
       "      <td>0.081428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.277943</td>\n",
       "      <td>0.069256</td>\n",
       "      <td>0.338283</td>\n",
       "      <td>0.051149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.278310</td>\n",
       "      <td>0.069960</td>\n",
       "      <td>0.333670</td>\n",
       "      <td>0.043135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.278310</td>\n",
       "      <td>0.069960</td>\n",
       "      <td>0.333670</td>\n",
       "      <td>0.043135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.278690</td>\n",
       "      <td>0.070323</td>\n",
       "      <td>0.333673</td>\n",
       "      <td>0.043088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.280277</td>\n",
       "      <td>0.064663</td>\n",
       "      <td>0.298993</td>\n",
       "      <td>0.061998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280728</td>\n",
       "      <td>0.079895</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280805</td>\n",
       "      <td>0.075365</td>\n",
       "      <td>0.345834</td>\n",
       "      <td>0.047544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281511</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.290852</td>\n",
       "      <td>0.084321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.281667</td>\n",
       "      <td>0.075960</td>\n",
       "      <td>0.344140</td>\n",
       "      <td>0.044526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.282129</td>\n",
       "      <td>0.077194</td>\n",
       "      <td>0.344139</td>\n",
       "      <td>0.044455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.283292</td>\n",
       "      <td>0.069279</td>\n",
       "      <td>0.297914</td>\n",
       "      <td>0.067429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.285261</td>\n",
       "      <td>0.077336</td>\n",
       "      <td>0.338665</td>\n",
       "      <td>0.043153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286057</td>\n",
       "      <td>0.078208</td>\n",
       "      <td>0.335517</td>\n",
       "      <td>0.058365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.286894</td>\n",
       "      <td>0.081446</td>\n",
       "      <td>0.289049</td>\n",
       "      <td>0.081249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.287043</td>\n",
       "      <td>0.070180</td>\n",
       "      <td>0.296941</td>\n",
       "      <td>0.069449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.287454</td>\n",
       "      <td>0.078392</td>\n",
       "      <td>0.340642</td>\n",
       "      <td>0.052722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.288602</td>\n",
       "      <td>0.074829</td>\n",
       "      <td>0.353791</td>\n",
       "      <td>0.040935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.288746</td>\n",
       "      <td>0.074945</td>\n",
       "      <td>0.353825</td>\n",
       "      <td>0.040974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.289907</td>\n",
       "      <td>0.075062</td>\n",
       "      <td>0.333861</td>\n",
       "      <td>0.043680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290244</td>\n",
       "      <td>0.060751</td>\n",
       "      <td>0.254771</td>\n",
       "      <td>0.039511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290636</td>\n",
       "      <td>0.096552</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>0.077552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291442</td>\n",
       "      <td>0.080562</td>\n",
       "      <td>0.323388</td>\n",
       "      <td>0.078728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.291721</td>\n",
       "      <td>0.070757</td>\n",
       "      <td>0.295988</td>\n",
       "      <td>0.071932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.292894</td>\n",
       "      <td>0.076792</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>0.043927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293008</td>\n",
       "      <td>0.078943</td>\n",
       "      <td>0.322678</td>\n",
       "      <td>0.080799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294424</td>\n",
       "      <td>0.081105</td>\n",
       "      <td>0.286487</td>\n",
       "      <td>0.076811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.294663</td>\n",
       "      <td>0.070952</td>\n",
       "      <td>0.295443</td>\n",
       "      <td>0.073143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.295116</td>\n",
       "      <td>0.071345</td>\n",
       "      <td>0.329382</td>\n",
       "      <td>0.051954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.298068</td>\n",
       "      <td>0.071067</td>\n",
       "      <td>0.295009</td>\n",
       "      <td>0.074554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299060</td>\n",
       "      <td>0.065355</td>\n",
       "      <td>0.254976</td>\n",
       "      <td>0.041387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.299265</td>\n",
       "      <td>0.106431</td>\n",
       "      <td>0.369308</td>\n",
       "      <td>0.078984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299701</td>\n",
       "      <td>0.081017</td>\n",
       "      <td>0.284739</td>\n",
       "      <td>0.073831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.300960</td>\n",
       "      <td>0.064916</td>\n",
       "      <td>0.242873</td>\n",
       "      <td>0.037842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301215</td>\n",
       "      <td>0.072102</td>\n",
       "      <td>0.350608</td>\n",
       "      <td>0.038368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301298</td>\n",
       "      <td>0.072052</td>\n",
       "      <td>0.349327</td>\n",
       "      <td>0.038817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301333</td>\n",
       "      <td>0.072146</td>\n",
       "      <td>0.350600</td>\n",
       "      <td>0.038381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.302154</td>\n",
       "      <td>0.071008</td>\n",
       "      <td>0.294797</td>\n",
       "      <td>0.076432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305948</td>\n",
       "      <td>0.081232</td>\n",
       "      <td>0.282923</td>\n",
       "      <td>0.070529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.307457</td>\n",
       "      <td>0.069068</td>\n",
       "      <td>0.243628</td>\n",
       "      <td>0.039658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.307555</td>\n",
       "      <td>0.097735</td>\n",
       "      <td>0.359878</td>\n",
       "      <td>0.079943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.309391</td>\n",
       "      <td>0.100694</td>\n",
       "      <td>0.361802</td>\n",
       "      <td>0.079841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310575</td>\n",
       "      <td>0.082730</td>\n",
       "      <td>0.333777</td>\n",
       "      <td>0.058188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310993</td>\n",
       "      <td>0.066606</td>\n",
       "      <td>0.254811</td>\n",
       "      <td>0.040501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312164</td>\n",
       "      <td>0.094096</td>\n",
       "      <td>0.336469</td>\n",
       "      <td>0.057678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.312982</td>\n",
       "      <td>0.087085</td>\n",
       "      <td>0.358368</td>\n",
       "      <td>0.074732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313481</td>\n",
       "      <td>0.081784</td>\n",
       "      <td>0.280801</td>\n",
       "      <td>0.067084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.316247</td>\n",
       "      <td>0.069382</td>\n",
       "      <td>0.244720</td>\n",
       "      <td>0.038657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.320542</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.257971</td>\n",
       "      <td>0.062015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.322361</td>\n",
       "      <td>0.120326</td>\n",
       "      <td>0.358897</td>\n",
       "      <td>0.086919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.322545</td>\n",
       "      <td>0.103730</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.087422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327152</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.255202</td>\n",
       "      <td>0.038182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.327378</td>\n",
       "      <td>0.056499</td>\n",
       "      <td>0.259215</td>\n",
       "      <td>0.063780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.328056</td>\n",
       "      <td>0.126492</td>\n",
       "      <td>0.376758</td>\n",
       "      <td>0.078378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.328240</td>\n",
       "      <td>0.111983</td>\n",
       "      <td>0.369747</td>\n",
       "      <td>0.081434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.329564</td>\n",
       "      <td>0.069755</td>\n",
       "      <td>0.245397</td>\n",
       "      <td>0.036989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335929</td>\n",
       "      <td>0.057290</td>\n",
       "      <td>0.261040</td>\n",
       "      <td>0.061222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337594</td>\n",
       "      <td>0.068209</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.036713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.338616</td>\n",
       "      <td>0.069776</td>\n",
       "      <td>0.246064</td>\n",
       "      <td>0.035920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.338616</td>\n",
       "      <td>0.069776</td>\n",
       "      <td>0.246064</td>\n",
       "      <td>0.035920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343089</td>\n",
       "      <td>0.067954</td>\n",
       "      <td>0.302556</td>\n",
       "      <td>0.089983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.347177</td>\n",
       "      <td>0.057836</td>\n",
       "      <td>0.263728</td>\n",
       "      <td>0.058371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.347361</td>\n",
       "      <td>0.086042</td>\n",
       "      <td>0.355234</td>\n",
       "      <td>0.106691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350105</td>\n",
       "      <td>0.069737</td>\n",
       "      <td>0.247634</td>\n",
       "      <td>0.034918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350813</td>\n",
       "      <td>0.068399</td>\n",
       "      <td>0.257119</td>\n",
       "      <td>0.034419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.354360</td>\n",
       "      <td>0.091572</td>\n",
       "      <td>0.360383</td>\n",
       "      <td>0.102959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.354655</td>\n",
       "      <td>0.057611</td>\n",
       "      <td>0.265920</td>\n",
       "      <td>0.056895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355006</td>\n",
       "      <td>0.070376</td>\n",
       "      <td>0.311593</td>\n",
       "      <td>0.086577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.364376</td>\n",
       "      <td>0.056544</td>\n",
       "      <td>0.268553</td>\n",
       "      <td>0.054821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.365853</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.249857</td>\n",
       "      <td>0.034561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368240</td>\n",
       "      <td>0.068280</td>\n",
       "      <td>0.258145</td>\n",
       "      <td>0.031309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.377270</td>\n",
       "      <td>0.055268</td>\n",
       "      <td>0.271159</td>\n",
       "      <td>0.053036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.379639</td>\n",
       "      <td>0.142800</td>\n",
       "      <td>0.393186</td>\n",
       "      <td>0.109074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.383771</td>\n",
       "      <td>0.069268</td>\n",
       "      <td>0.359770</td>\n",
       "      <td>0.106847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389879</td>\n",
       "      <td>0.110180</td>\n",
       "      <td>0.321712</td>\n",
       "      <td>0.102402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.398388</td>\n",
       "      <td>0.126673</td>\n",
       "      <td>0.370259</td>\n",
       "      <td>0.136860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.403424</td>\n",
       "      <td>0.143640</td>\n",
       "      <td>0.330313</td>\n",
       "      <td>0.106799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.406994</td>\n",
       "      <td>0.069157</td>\n",
       "      <td>0.359774</td>\n",
       "      <td>0.105869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.411295</td>\n",
       "      <td>0.101653</td>\n",
       "      <td>0.310951</td>\n",
       "      <td>0.095744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.433075</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>0.340744</td>\n",
       "      <td>0.101008</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>0.972764</td>\n",
       "      <td>0.126574</td>\n",
       "      <td>0.126574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.581897</td>\n",
       "      <td>0.051583</td>\n",
       "      <td>0.051583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.392702</td>\n",
       "      <td>0.021206</td>\n",
       "      <td>0.021206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.008119</td>\n",
       "      <td>0.008119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.275182</td>\n",
       "      <td>0.007577</td>\n",
       "      <td>0.007577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.119865</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.107321</td>\n",
       "      <td>0.003098</td>\n",
       "      <td>0.003098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.156225</td>\n",
       "      <td>0.001753</td>\n",
       "      <td>0.001753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.109025</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>0.000542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.018454</td>\n",
       "      <td>0.000170</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ACES_divorced_separated*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.973</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.582</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.154</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.393</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.160</td>\n",
       "      <td>-0.109</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.275</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.107</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.222</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_88936/988887848.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.057500158838832416, 0.0652425453399087, -0.03244363267364525, -0.10007857858537106, -0.233033673622135]\n",
      "overall_score:\n",
      "-0.04856263614048204\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.280536</td>\n",
       "      <td>0.070711</td>\n",
       "      <td>0.303797</td>\n",
       "      <td>0.066271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.282740</td>\n",
       "      <td>0.075581</td>\n",
       "      <td>0.303263</td>\n",
       "      <td>0.068620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285976</td>\n",
       "      <td>0.075457</td>\n",
       "      <td>0.303230</td>\n",
       "      <td>0.066774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.291359</td>\n",
       "      <td>0.075054</td>\n",
       "      <td>0.302846</td>\n",
       "      <td>0.064125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293160</td>\n",
       "      <td>0.055817</td>\n",
       "      <td>0.257528</td>\n",
       "      <td>0.035962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.294270</td>\n",
       "      <td>0.042053</td>\n",
       "      <td>0.313554</td>\n",
       "      <td>0.063330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.295468</td>\n",
       "      <td>0.074691</td>\n",
       "      <td>0.302547</td>\n",
       "      <td>0.062963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.297475</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.284506</td>\n",
       "      <td>0.053181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300421</td>\n",
       "      <td>0.074639</td>\n",
       "      <td>0.302377</td>\n",
       "      <td>0.062179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300582</td>\n",
       "      <td>0.060656</td>\n",
       "      <td>0.258034</td>\n",
       "      <td>0.038725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304325</td>\n",
       "      <td>0.065285</td>\n",
       "      <td>0.246179</td>\n",
       "      <td>0.038906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.306252</td>\n",
       "      <td>0.075310</td>\n",
       "      <td>0.302226</td>\n",
       "      <td>0.062085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.309809</td>\n",
       "      <td>0.028059</td>\n",
       "      <td>0.308167</td>\n",
       "      <td>0.058285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.310005</td>\n",
       "      <td>0.069159</td>\n",
       "      <td>0.246610</td>\n",
       "      <td>0.040438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.310130</td>\n",
       "      <td>0.062629</td>\n",
       "      <td>0.258587</td>\n",
       "      <td>0.038809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.313456</td>\n",
       "      <td>0.063423</td>\n",
       "      <td>0.298658</td>\n",
       "      <td>0.061218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.315653</td>\n",
       "      <td>0.067707</td>\n",
       "      <td>0.296633</td>\n",
       "      <td>0.066865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.318025</td>\n",
       "      <td>0.069564</td>\n",
       "      <td>0.247294</td>\n",
       "      <td>0.039228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.318322</td>\n",
       "      <td>0.062978</td>\n",
       "      <td>0.265462</td>\n",
       "      <td>0.071001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.318920</td>\n",
       "      <td>0.068388</td>\n",
       "      <td>0.294937</td>\n",
       "      <td>0.069629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.319607</td>\n",
       "      <td>0.086710</td>\n",
       "      <td>0.340579</td>\n",
       "      <td>0.077290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.322337</td>\n",
       "      <td>0.067229</td>\n",
       "      <td>0.323274</td>\n",
       "      <td>0.046819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.323328</td>\n",
       "      <td>0.068874</td>\n",
       "      <td>0.293437</td>\n",
       "      <td>0.073048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324294</td>\n",
       "      <td>0.065022</td>\n",
       "      <td>0.258747</td>\n",
       "      <td>0.038023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.324805</td>\n",
       "      <td>0.068445</td>\n",
       "      <td>0.267112</td>\n",
       "      <td>0.073673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.326063</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.341145</td>\n",
       "      <td>0.069917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.326254</td>\n",
       "      <td>0.068934</td>\n",
       "      <td>0.292858</td>\n",
       "      <td>0.074990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.329746</td>\n",
       "      <td>0.068973</td>\n",
       "      <td>0.292444</td>\n",
       "      <td>0.077035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.330417</td>\n",
       "      <td>0.069657</td>\n",
       "      <td>0.247486</td>\n",
       "      <td>0.037227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.333064</td>\n",
       "      <td>0.070044</td>\n",
       "      <td>0.269195</td>\n",
       "      <td>0.071443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333661</td>\n",
       "      <td>0.066372</td>\n",
       "      <td>0.259026</td>\n",
       "      <td>0.036894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.334341</td>\n",
       "      <td>0.068766</td>\n",
       "      <td>0.292365</td>\n",
       "      <td>0.078994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.339150</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>0.035994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.339150</td>\n",
       "      <td>0.069524</td>\n",
       "      <td>0.247703</td>\n",
       "      <td>0.035994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.339692</td>\n",
       "      <td>0.066463</td>\n",
       "      <td>0.328883</td>\n",
       "      <td>0.039991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.344913</td>\n",
       "      <td>0.071129</td>\n",
       "      <td>0.272081</td>\n",
       "      <td>0.069695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.345042</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.344765</td>\n",
       "      <td>0.035074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.345042</td>\n",
       "      <td>0.078253</td>\n",
       "      <td>0.344765</td>\n",
       "      <td>0.035074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.345193</td>\n",
       "      <td>0.068044</td>\n",
       "      <td>0.259465</td>\n",
       "      <td>0.035140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.348200</td>\n",
       "      <td>0.078463</td>\n",
       "      <td>0.344799</td>\n",
       "      <td>0.033290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.349217</td>\n",
       "      <td>0.077211</td>\n",
       "      <td>0.354956</td>\n",
       "      <td>0.049818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.350495</td>\n",
       "      <td>0.069491</td>\n",
       "      <td>0.248627</td>\n",
       "      <td>0.034957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352848</td>\n",
       "      <td>0.084820</td>\n",
       "      <td>0.348796</td>\n",
       "      <td>0.071307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.352877</td>\n",
       "      <td>0.071304</td>\n",
       "      <td>0.273455</td>\n",
       "      <td>0.068449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.357259</td>\n",
       "      <td>0.075501</td>\n",
       "      <td>0.339890</td>\n",
       "      <td>0.045998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358048</td>\n",
       "      <td>0.078793</td>\n",
       "      <td>0.361033</td>\n",
       "      <td>0.046373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.359212</td>\n",
       "      <td>0.080082</td>\n",
       "      <td>0.354142</td>\n",
       "      <td>0.035558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.360595</td>\n",
       "      <td>0.070130</td>\n",
       "      <td>0.259809</td>\n",
       "      <td>0.033047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.361595</td>\n",
       "      <td>0.080374</td>\n",
       "      <td>0.354704</td>\n",
       "      <td>0.035836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.361774</td>\n",
       "      <td>0.081672</td>\n",
       "      <td>0.349012</td>\n",
       "      <td>0.034196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.363190</td>\n",
       "      <td>0.070539</td>\n",
       "      <td>0.274821</td>\n",
       "      <td>0.066681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.363338</td>\n",
       "      <td>0.080531</td>\n",
       "      <td>0.350533</td>\n",
       "      <td>0.056860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.365256</td>\n",
       "      <td>0.082006</td>\n",
       "      <td>0.342261</td>\n",
       "      <td>0.035913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365512</td>\n",
       "      <td>0.076325</td>\n",
       "      <td>0.364699</td>\n",
       "      <td>0.041511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.365943</td>\n",
       "      <td>0.076994</td>\n",
       "      <td>0.364206</td>\n",
       "      <td>0.041575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.366082</td>\n",
       "      <td>0.068914</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.034234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367144</td>\n",
       "      <td>0.134187</td>\n",
       "      <td>0.370470</td>\n",
       "      <td>0.090199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368648</td>\n",
       "      <td>0.098029</td>\n",
       "      <td>0.330297</td>\n",
       "      <td>0.075283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.368761</td>\n",
       "      <td>0.078618</td>\n",
       "      <td>0.352578</td>\n",
       "      <td>0.051769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370440</td>\n",
       "      <td>0.103911</td>\n",
       "      <td>0.378037</td>\n",
       "      <td>0.081086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.372953</td>\n",
       "      <td>0.078243</td>\n",
       "      <td>0.359609</td>\n",
       "      <td>0.043287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.373126</td>\n",
       "      <td>0.122264</td>\n",
       "      <td>0.378094</td>\n",
       "      <td>0.082357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.373937</td>\n",
       "      <td>0.113959</td>\n",
       "      <td>0.380317</td>\n",
       "      <td>0.078293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374455</td>\n",
       "      <td>0.138918</td>\n",
       "      <td>0.371488</td>\n",
       "      <td>0.092304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374972</td>\n",
       "      <td>0.113131</td>\n",
       "      <td>0.368918</td>\n",
       "      <td>0.083527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.376700</td>\n",
       "      <td>0.068904</td>\n",
       "      <td>0.276507</td>\n",
       "      <td>0.064899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.378800</td>\n",
       "      <td>0.130369</td>\n",
       "      <td>0.381389</td>\n",
       "      <td>0.084430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.379279</td>\n",
       "      <td>0.106779</td>\n",
       "      <td>0.362473</td>\n",
       "      <td>0.075130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.380331</td>\n",
       "      <td>0.075514</td>\n",
       "      <td>0.362062</td>\n",
       "      <td>0.040357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380490</td>\n",
       "      <td>0.076053</td>\n",
       "      <td>0.361746</td>\n",
       "      <td>0.040018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383812</td>\n",
       "      <td>0.077224</td>\n",
       "      <td>0.358956</td>\n",
       "      <td>0.039532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390169</td>\n",
       "      <td>0.073409</td>\n",
       "      <td>0.357324</td>\n",
       "      <td>0.035748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390392</td>\n",
       "      <td>0.073656</td>\n",
       "      <td>0.357084</td>\n",
       "      <td>0.035560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390402</td>\n",
       "      <td>0.083464</td>\n",
       "      <td>0.349142</td>\n",
       "      <td>0.105288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390518</td>\n",
       "      <td>0.080193</td>\n",
       "      <td>0.348067</td>\n",
       "      <td>0.107437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.401774</td>\n",
       "      <td>0.145669</td>\n",
       "      <td>0.387647</td>\n",
       "      <td>0.065251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.406119</td>\n",
       "      <td>0.138176</td>\n",
       "      <td>0.397882</td>\n",
       "      <td>0.059342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.418096</td>\n",
       "      <td>0.171865</td>\n",
       "      <td>0.338926</td>\n",
       "      <td>0.107341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.421770</td>\n",
       "      <td>0.097651</td>\n",
       "      <td>0.359664</td>\n",
       "      <td>0.109374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.423479</td>\n",
       "      <td>0.180416</td>\n",
       "      <td>0.336280</td>\n",
       "      <td>0.105096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.425092</td>\n",
       "      <td>0.085598</td>\n",
       "      <td>0.362408</td>\n",
       "      <td>0.099936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.451667</td>\n",
       "      <td>0.080558</td>\n",
       "      <td>0.313566</td>\n",
       "      <td>0.124625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.453425</td>\n",
       "      <td>0.093819</td>\n",
       "      <td>0.357815</td>\n",
       "      <td>0.126289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.456979</td>\n",
       "      <td>0.082932</td>\n",
       "      <td>0.314455</td>\n",
       "      <td>0.113557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.458174</td>\n",
       "      <td>0.165387</td>\n",
       "      <td>0.340652</td>\n",
       "      <td>0.117338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.463417</td>\n",
       "      <td>0.127703</td>\n",
       "      <td>0.335019</td>\n",
       "      <td>0.122756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.473608</td>\n",
       "      <td>0.158563</td>\n",
       "      <td>0.371658</td>\n",
       "      <td>0.082078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.474836</td>\n",
       "      <td>0.084723</td>\n",
       "      <td>0.364816</td>\n",
       "      <td>0.110905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.501541</td>\n",
       "      <td>0.139367</td>\n",
       "      <td>0.372800</td>\n",
       "      <td>0.106978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>san</td>\n",
       "      <td>-3.813027</td>\n",
       "      <td>1.657010</td>\n",
       "      <td>1.657010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>3.054898</td>\n",
       "      <td>1.097093</td>\n",
       "      <td>1.097093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.033321</td>\n",
       "      <td>1.044694</td>\n",
       "      <td>1.044694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>2.389706</td>\n",
       "      <td>0.678421</td>\n",
       "      <td>0.678421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>1.935767</td>\n",
       "      <td>0.461544</td>\n",
       "      <td>0.461544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.514676</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.256900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.425740</td>\n",
       "      <td>0.241843</td>\n",
       "      <td>0.241843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.158152</td>\n",
       "      <td>0.164594</td>\n",
       "      <td>0.164594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-1.102637</td>\n",
       "      <td>0.135514</td>\n",
       "      <td>0.135514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>0.773653</td>\n",
       "      <td>0.080227</td>\n",
       "      <td>0.080227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-3.813</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.055</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>1.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.033</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.045</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>1.045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.678</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.774</td>\n",
       "      <td>-1.515</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-1.103</td>\n",
       "      <td>1.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.136</td>\n",
       "      <td>0.165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.426</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.15\n",
      "1          EDM                0.15\n",
      "2       BIS_11               -0.15\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.15\n",
      "5                       TRSQ                0.15\n",
      "6  ACES_neglectful_parenting               -0.15\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 10)\n",
      "(275, 10)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_88936/988887848.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 32], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.23333482278298356, 0.22360590980202688, 0.10895360443227087, 0.03862980769093127, -0.20744706091260579]\n",
      "overall_score:\n",
      "0.07941541675912137\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.309146</td>\n",
       "      <td>0.076570</td>\n",
       "      <td>0.253920</td>\n",
       "      <td>0.072560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.313291</td>\n",
       "      <td>0.058710</td>\n",
       "      <td>0.271523</td>\n",
       "      <td>0.038085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.313851</td>\n",
       "      <td>0.082828</td>\n",
       "      <td>0.250985</td>\n",
       "      <td>0.078523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.314713</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.042587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.314713</td>\n",
       "      <td>0.065306</td>\n",
       "      <td>0.255188</td>\n",
       "      <td>0.042587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.318083</td>\n",
       "      <td>0.062447</td>\n",
       "      <td>0.270421</td>\n",
       "      <td>0.040601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.318897</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.318897</td>\n",
       "      <td>0.069451</td>\n",
       "      <td>0.254652</td>\n",
       "      <td>0.043786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.320567</td>\n",
       "      <td>0.084618</td>\n",
       "      <td>0.248095</td>\n",
       "      <td>0.081016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.324787</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.254367</td>\n",
       "      <td>0.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.324787</td>\n",
       "      <td>0.069078</td>\n",
       "      <td>0.254367</td>\n",
       "      <td>0.041618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325055</td>\n",
       "      <td>0.062563</td>\n",
       "      <td>0.269010</td>\n",
       "      <td>0.041189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.329543</td>\n",
       "      <td>0.085972</td>\n",
       "      <td>0.245707</td>\n",
       "      <td>0.084379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.334725</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.334725</td>\n",
       "      <td>0.069707</td>\n",
       "      <td>0.253148</td>\n",
       "      <td>0.038973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334893</td>\n",
       "      <td>0.112657</td>\n",
       "      <td>0.328888</td>\n",
       "      <td>0.081433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334973</td>\n",
       "      <td>0.105402</td>\n",
       "      <td>0.332893</td>\n",
       "      <td>0.078332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335059</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.244798</td>\n",
       "      <td>0.086373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335664</td>\n",
       "      <td>0.113665</td>\n",
       "      <td>0.324804</td>\n",
       "      <td>0.079446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.336151</td>\n",
       "      <td>0.063554</td>\n",
       "      <td>0.266503</td>\n",
       "      <td>0.040563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.338583</td>\n",
       "      <td>0.113678</td>\n",
       "      <td>0.320940</td>\n",
       "      <td>0.077627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.341848</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.252261</td>\n",
       "      <td>0.037150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.341848</td>\n",
       "      <td>0.069575</td>\n",
       "      <td>0.252261</td>\n",
       "      <td>0.037150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.341893</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.244056</td>\n",
       "      <td>0.088504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.342116</td>\n",
       "      <td>0.113313</td>\n",
       "      <td>0.318467</td>\n",
       "      <td>0.077372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.344320</td>\n",
       "      <td>0.064311</td>\n",
       "      <td>0.264863</td>\n",
       "      <td>0.039445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.346590</td>\n",
       "      <td>0.112708</td>\n",
       "      <td>0.315752</td>\n",
       "      <td>0.077662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.348176</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.348176</td>\n",
       "      <td>0.034231</td>\n",
       "      <td>0.299499</td>\n",
       "      <td>0.056649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.350462</td>\n",
       "      <td>0.044303</td>\n",
       "      <td>0.326058</td>\n",
       "      <td>0.079796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.351557</td>\n",
       "      <td>0.084894</td>\n",
       "      <td>0.243925</td>\n",
       "      <td>0.091496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.351797</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.251206</td>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.351797</td>\n",
       "      <td>0.068922</td>\n",
       "      <td>0.251206</td>\n",
       "      <td>0.035142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.352976</td>\n",
       "      <td>0.111500</td>\n",
       "      <td>0.313138</td>\n",
       "      <td>0.079296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.354759</td>\n",
       "      <td>0.045979</td>\n",
       "      <td>0.329881</td>\n",
       "      <td>0.051990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355639</td>\n",
       "      <td>0.064503</td>\n",
       "      <td>0.262926</td>\n",
       "      <td>0.038217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.366802</td>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.033704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.366802</td>\n",
       "      <td>0.068276</td>\n",
       "      <td>0.251446</td>\n",
       "      <td>0.033704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370572</td>\n",
       "      <td>0.065570</td>\n",
       "      <td>0.260941</td>\n",
       "      <td>0.036324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.433376</td>\n",
       "      <td>0.095087</td>\n",
       "      <td>0.382965</td>\n",
       "      <td>0.091533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.448676</td>\n",
       "      <td>0.044722</td>\n",
       "      <td>0.370129</td>\n",
       "      <td>0.078252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.450365</td>\n",
       "      <td>0.044436</td>\n",
       "      <td>0.370710</td>\n",
       "      <td>0.075137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.452345</td>\n",
       "      <td>0.043846</td>\n",
       "      <td>0.371526</td>\n",
       "      <td>0.072335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.454156</td>\n",
       "      <td>0.043320</td>\n",
       "      <td>0.372380</td>\n",
       "      <td>0.069835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.458034</td>\n",
       "      <td>0.042903</td>\n",
       "      <td>0.373112</td>\n",
       "      <td>0.065255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.461852</td>\n",
       "      <td>0.042888</td>\n",
       "      <td>0.373440</td>\n",
       "      <td>0.062299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.465624</td>\n",
       "      <td>0.040448</td>\n",
       "      <td>0.373534</td>\n",
       "      <td>0.057129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.471679</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.056303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.471679</td>\n",
       "      <td>0.061721</td>\n",
       "      <td>0.355682</td>\n",
       "      <td>0.056303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.472749</td>\n",
       "      <td>0.057145</td>\n",
       "      <td>0.371170</td>\n",
       "      <td>0.074490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.486390</td>\n",
       "      <td>0.081494</td>\n",
       "      <td>0.359163</td>\n",
       "      <td>0.063983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.518113</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.050414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.518113</td>\n",
       "      <td>0.091386</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.050414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.527282</td>\n",
       "      <td>0.084701</td>\n",
       "      <td>0.387274</td>\n",
       "      <td>0.102775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.533257</td>\n",
       "      <td>0.093512</td>\n",
       "      <td>0.388138</td>\n",
       "      <td>0.064855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.536542</td>\n",
       "      <td>0.099239</td>\n",
       "      <td>0.379243</td>\n",
       "      <td>0.050327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.550067</td>\n",
       "      <td>0.068961</td>\n",
       "      <td>0.383783</td>\n",
       "      <td>0.026969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.566573</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.388973</td>\n",
       "      <td>0.051971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.566573</td>\n",
       "      <td>0.090321</td>\n",
       "      <td>0.388973</td>\n",
       "      <td>0.051971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.569927</td>\n",
       "      <td>0.091163</td>\n",
       "      <td>0.388715</td>\n",
       "      <td>0.052460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.583859</td>\n",
       "      <td>0.099309</td>\n",
       "      <td>0.396817</td>\n",
       "      <td>0.053920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.586131</td>\n",
       "      <td>0.088744</td>\n",
       "      <td>0.382046</td>\n",
       "      <td>0.047159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.587624</td>\n",
       "      <td>0.087511</td>\n",
       "      <td>0.380344</td>\n",
       "      <td>0.043698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.588209</td>\n",
       "      <td>0.094508</td>\n",
       "      <td>0.379896</td>\n",
       "      <td>0.079718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.590283</td>\n",
       "      <td>0.089750</td>\n",
       "      <td>0.383605</td>\n",
       "      <td>0.048835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.597237</td>\n",
       "      <td>0.143846</td>\n",
       "      <td>0.362699</td>\n",
       "      <td>0.065589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.602994</td>\n",
       "      <td>0.143454</td>\n",
       "      <td>0.397971</td>\n",
       "      <td>0.125048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.603928</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.603928</td>\n",
       "      <td>0.142720</td>\n",
       "      <td>0.400452</td>\n",
       "      <td>0.122516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604194</td>\n",
       "      <td>0.142660</td>\n",
       "      <td>0.400596</td>\n",
       "      <td>0.123536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.608473</td>\n",
       "      <td>0.153630</td>\n",
       "      <td>0.394455</td>\n",
       "      <td>0.129145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.609766</td>\n",
       "      <td>0.154966</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.128182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.609766</td>\n",
       "      <td>0.154966</td>\n",
       "      <td>0.394880</td>\n",
       "      <td>0.128182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.610032</td>\n",
       "      <td>0.154868</td>\n",
       "      <td>0.395024</td>\n",
       "      <td>0.129202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.610506</td>\n",
       "      <td>0.085274</td>\n",
       "      <td>0.389897</td>\n",
       "      <td>0.043931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.610567</td>\n",
       "      <td>0.085346</td>\n",
       "      <td>0.390027</td>\n",
       "      <td>0.043958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.611638</td>\n",
       "      <td>0.203372</td>\n",
       "      <td>0.405227</td>\n",
       "      <td>0.131484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.613091</td>\n",
       "      <td>0.096461</td>\n",
       "      <td>0.379837</td>\n",
       "      <td>0.059097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.615905</td>\n",
       "      <td>0.129869</td>\n",
       "      <td>0.408493</td>\n",
       "      <td>0.078971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.616944</td>\n",
       "      <td>0.170896</td>\n",
       "      <td>0.363531</td>\n",
       "      <td>0.118143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.617476</td>\n",
       "      <td>0.216084</td>\n",
       "      <td>0.399037</td>\n",
       "      <td>0.136352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.617682</td>\n",
       "      <td>0.090644</td>\n",
       "      <td>0.394352</td>\n",
       "      <td>0.045920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.623825</td>\n",
       "      <td>0.182559</td>\n",
       "      <td>0.356952</td>\n",
       "      <td>0.129224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.627956</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.055653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.627956</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.055653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.627956</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.055653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.627956</td>\n",
       "      <td>0.125008</td>\n",
       "      <td>0.391275</td>\n",
       "      <td>0.055653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.632651</td>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.394602</td>\n",
       "      <td>0.063415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.634539</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.387715</td>\n",
       "      <td>0.042469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636144</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>0.380207</td>\n",
       "      <td>0.047227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636144</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>0.380207</td>\n",
       "      <td>0.047227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636144</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>0.380207</td>\n",
       "      <td>0.047227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636144</td>\n",
       "      <td>0.125068</td>\n",
       "      <td>0.380207</td>\n",
       "      <td>0.047227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637249</td>\n",
       "      <td>0.096373</td>\n",
       "      <td>0.379414</td>\n",
       "      <td>0.052483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.637975</td>\n",
       "      <td>0.089121</td>\n",
       "      <td>0.387756</td>\n",
       "      <td>0.042431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.645172</td>\n",
       "      <td>0.150724</td>\n",
       "      <td>0.386638</td>\n",
       "      <td>0.079965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.646218</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.361509</td>\n",
       "      <td>0.071593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.646218</td>\n",
       "      <td>0.139302</td>\n",
       "      <td>0.361509</td>\n",
       "      <td>0.071593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650424</td>\n",
       "      <td>0.167471</td>\n",
       "      <td>0.333073</td>\n",
       "      <td>0.124623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.651009</td>\n",
       "      <td>0.162725</td>\n",
       "      <td>0.378653</td>\n",
       "      <td>0.088932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.654022</td>\n",
       "      <td>0.094483</td>\n",
       "      <td>0.380363</td>\n",
       "      <td>0.047612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.658879</td>\n",
       "      <td>0.083865</td>\n",
       "      <td>0.384121</td>\n",
       "      <td>0.044558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659164</td>\n",
       "      <td>0.084247</td>\n",
       "      <td>0.383653</td>\n",
       "      <td>0.044340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.659214</td>\n",
       "      <td>0.189013</td>\n",
       "      <td>0.400215</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.659532</td>\n",
       "      <td>0.147259</td>\n",
       "      <td>0.334754</td>\n",
       "      <td>0.102269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.665857</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 32, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.665857</td>\n",
       "      <td>0.158603</td>\n",
       "      <td>0.355980</td>\n",
       "      <td>0.101659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.667015</td>\n",
       "      <td>0.086959</td>\n",
       "      <td>0.380291</td>\n",
       "      <td>0.043989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.670445</td>\n",
       "      <td>0.231664</td>\n",
       "      <td>0.392787</td>\n",
       "      <td>0.123503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.707471</td>\n",
       "      <td>0.156524</td>\n",
       "      <td>0.383586</td>\n",
       "      <td>0.117136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.711151</td>\n",
       "      <td>0.142886</td>\n",
       "      <td>0.397392</td>\n",
       "      <td>0.104466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>4.668619</td>\n",
       "      <td>2.178039</td>\n",
       "      <td>2.178039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-3.064834</td>\n",
       "      <td>0.892193</td>\n",
       "      <td>0.892193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>TRSQ*ni</td>\n",
       "      <td>-3.028787</td>\n",
       "      <td>0.874044</td>\n",
       "      <td>0.874044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.816278</td>\n",
       "      <td>0.765277</td>\n",
       "      <td>0.765277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-1.987660</td>\n",
       "      <td>0.376462</td>\n",
       "      <td>0.376462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.538929</td>\n",
       "      <td>0.241385</td>\n",
       "      <td>0.241385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>1.388399</td>\n",
       "      <td>0.199411</td>\n",
       "      <td>0.199411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>EDM*san</td>\n",
       "      <td>-1.295907</td>\n",
       "      <td>0.177492</td>\n",
       "      <td>0.177492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ACES_sum</td>\n",
       "      <td>1.279268</td>\n",
       "      <td>0.162508</td>\n",
       "      <td>0.162508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>1.044533</td>\n",
       "      <td>0.114822</td>\n",
       "      <td>0.114822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.997109</td>\n",
       "      <td>0.102791</td>\n",
       "      <td>0.102791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.896277</td>\n",
       "      <td>0.081404</td>\n",
       "      <td>0.081404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.701804</td>\n",
       "      <td>0.053139</td>\n",
       "      <td>0.053139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.558003</td>\n",
       "      <td>0.036097</td>\n",
       "      <td>0.036097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.504307</td>\n",
       "      <td>0.025437</td>\n",
       "      <td>0.025437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.405463</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>0.019457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PCS*ni</td>\n",
       "      <td>0.418446</td>\n",
       "      <td>0.019283</td>\n",
       "      <td>0.019283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.409288</td>\n",
       "      <td>0.016494</td>\n",
       "      <td>0.016494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSCS</td>\n",
       "      <td>-0.355257</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>0.013460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.389397</td>\n",
       "      <td>0.013444</td>\n",
       "      <td>0.013444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.355</td>\n",
       "      <td>4.669</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.013</td>\n",
       "      <td>2.178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>2.191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.702</td>\n",
       "      <td>-3.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.504</td>\n",
       "      <td>-3.065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.892</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>0.918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.122</td>\n",
       "      <td>2.816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>1.279</td>\n",
       "      <td>-1.988</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>0.163</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.409</td>\n",
       "      <td>1.388</td>\n",
       "      <td>-1.296</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.199</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.394</td>\n",
       "      <td>-0.084</td>\n",
       "      <td>0.393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.539</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.896</td>\n",
       "      <td>1.045</td>\n",
       "      <td>-0.558</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.115</td>\n",
       "      <td>0.036</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.08\n",
      "1          EDM                0.08\n",
      "2       BIS_11               -0.08\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.08\n",
      "5                       TRSQ                0.08\n",
      "6  ACES_neglectful_parenting               -0.08\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_88936/988887848.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.011029072644280769, 0.05103383687350138, -0.10485951827373197, 0.037046924382313384, -0.38575629856163185]\n",
      "overall_score:\n",
      "-0.07830119658705366\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.250385</td>\n",
       "      <td>0.053035</td>\n",
       "      <td>0.298879</td>\n",
       "      <td>0.081511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.253106</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.289953</td>\n",
       "      <td>0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.253106</td>\n",
       "      <td>0.047541</td>\n",
       "      <td>0.289953</td>\n",
       "      <td>0.035348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.264384</td>\n",
       "      <td>0.061781</td>\n",
       "      <td>0.327677</td>\n",
       "      <td>0.069726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.267684</td>\n",
       "      <td>0.049697</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.267684</td>\n",
       "      <td>0.049697</td>\n",
       "      <td>0.329519</td>\n",
       "      <td>0.044714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.279107</td>\n",
       "      <td>0.068210</td>\n",
       "      <td>0.339821</td>\n",
       "      <td>0.050708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.279376</td>\n",
       "      <td>0.066624</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.043856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.279376</td>\n",
       "      <td>0.066624</td>\n",
       "      <td>0.342303</td>\n",
       "      <td>0.043856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.281872</td>\n",
       "      <td>0.081962</td>\n",
       "      <td>0.257870</td>\n",
       "      <td>0.092071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.283315</td>\n",
       "      <td>0.056060</td>\n",
       "      <td>0.357960</td>\n",
       "      <td>0.043367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.284202</td>\n",
       "      <td>0.067280</td>\n",
       "      <td>0.341063</td>\n",
       "      <td>0.046535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.285404</td>\n",
       "      <td>0.072023</td>\n",
       "      <td>0.343528</td>\n",
       "      <td>0.049963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.286469</td>\n",
       "      <td>0.083171</td>\n",
       "      <td>0.350206</td>\n",
       "      <td>0.042443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.286801</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.348245</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.286801</td>\n",
       "      <td>0.078064</td>\n",
       "      <td>0.348245</td>\n",
       "      <td>0.043032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.287008</td>\n",
       "      <td>0.078122</td>\n",
       "      <td>0.348216</td>\n",
       "      <td>0.043031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.288373</td>\n",
       "      <td>0.086073</td>\n",
       "      <td>0.348183</td>\n",
       "      <td>0.041424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.289511</td>\n",
       "      <td>0.058278</td>\n",
       "      <td>0.322922</td>\n",
       "      <td>0.086736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290555</td>\n",
       "      <td>0.058118</td>\n",
       "      <td>0.341598</td>\n",
       "      <td>0.087181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.290663</td>\n",
       "      <td>0.090495</td>\n",
       "      <td>0.257907</td>\n",
       "      <td>0.095559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.291705</td>\n",
       "      <td>0.052861</td>\n",
       "      <td>0.326872</td>\n",
       "      <td>0.056337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.291741</td>\n",
       "      <td>0.057937</td>\n",
       "      <td>0.353814</td>\n",
       "      <td>0.046674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.292157</td>\n",
       "      <td>0.078377</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>0.039612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.292240</td>\n",
       "      <td>0.078375</td>\n",
       "      <td>0.352827</td>\n",
       "      <td>0.039541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.293070</td>\n",
       "      <td>0.088797</td>\n",
       "      <td>0.346690</td>\n",
       "      <td>0.040574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.293392</td>\n",
       "      <td>0.073605</td>\n",
       "      <td>0.352856</td>\n",
       "      <td>0.043913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.298844</td>\n",
       "      <td>0.090731</td>\n",
       "      <td>0.345626</td>\n",
       "      <td>0.039949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.299437</td>\n",
       "      <td>0.066993</td>\n",
       "      <td>0.353033</td>\n",
       "      <td>0.036018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300071</td>\n",
       "      <td>0.070655</td>\n",
       "      <td>0.353187</td>\n",
       "      <td>0.037746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301186</td>\n",
       "      <td>0.094844</td>\n",
       "      <td>0.258220</td>\n",
       "      <td>0.092990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301422</td>\n",
       "      <td>0.072278</td>\n",
       "      <td>0.350224</td>\n",
       "      <td>0.037816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301434</td>\n",
       "      <td>0.071783</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.038996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.301640</td>\n",
       "      <td>0.065566</td>\n",
       "      <td>0.350558</td>\n",
       "      <td>0.034295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.301688</td>\n",
       "      <td>0.034013</td>\n",
       "      <td>0.295086</td>\n",
       "      <td>0.058242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303563</td>\n",
       "      <td>0.071772</td>\n",
       "      <td>0.350074</td>\n",
       "      <td>0.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.303748</td>\n",
       "      <td>0.100220</td>\n",
       "      <td>0.332958</td>\n",
       "      <td>0.060939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.304313</td>\n",
       "      <td>0.068543</td>\n",
       "      <td>0.349269</td>\n",
       "      <td>0.034975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.305983</td>\n",
       "      <td>0.067095</td>\n",
       "      <td>0.349222</td>\n",
       "      <td>0.035289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.311036</td>\n",
       "      <td>0.070140</td>\n",
       "      <td>0.336489</td>\n",
       "      <td>0.038642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.312155</td>\n",
       "      <td>0.058151</td>\n",
       "      <td>0.342988</td>\n",
       "      <td>0.043755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.314560</td>\n",
       "      <td>0.073926</td>\n",
       "      <td>0.334561</td>\n",
       "      <td>0.044023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.315396</td>\n",
       "      <td>0.098410</td>\n",
       "      <td>0.258818</td>\n",
       "      <td>0.089979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.318666</td>\n",
       "      <td>0.073553</td>\n",
       "      <td>0.332368</td>\n",
       "      <td>0.047723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.324171</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.329467</td>\n",
       "      <td>0.052956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.324518</td>\n",
       "      <td>0.099955</td>\n",
       "      <td>0.259418</td>\n",
       "      <td>0.088546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.325360</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.325360</td>\n",
       "      <td>0.083517</td>\n",
       "      <td>0.385223</td>\n",
       "      <td>0.112299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325696</td>\n",
       "      <td>0.107610</td>\n",
       "      <td>0.366627</td>\n",
       "      <td>0.057871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.326397</td>\n",
       "      <td>0.081598</td>\n",
       "      <td>0.375988</td>\n",
       "      <td>0.113371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.327817</td>\n",
       "      <td>0.072968</td>\n",
       "      <td>0.327884</td>\n",
       "      <td>0.055946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.330718</td>\n",
       "      <td>0.069918</td>\n",
       "      <td>0.328412</td>\n",
       "      <td>0.056157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.332245</td>\n",
       "      <td>0.072276</td>\n",
       "      <td>0.326097</td>\n",
       "      <td>0.059363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.333225</td>\n",
       "      <td>0.074841</td>\n",
       "      <td>0.375473</td>\n",
       "      <td>0.112484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335057</td>\n",
       "      <td>0.086793</td>\n",
       "      <td>0.357100</td>\n",
       "      <td>0.061689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.335583</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>0.109870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.335583</td>\n",
       "      <td>0.071519</td>\n",
       "      <td>0.380639</td>\n",
       "      <td>0.109870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.335657</td>\n",
       "      <td>0.101631</td>\n",
       "      <td>0.260564</td>\n",
       "      <td>0.087354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.336483</td>\n",
       "      <td>0.092945</td>\n",
       "      <td>0.366369</td>\n",
       "      <td>0.078940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.337336</td>\n",
       "      <td>0.130104</td>\n",
       "      <td>0.390732</td>\n",
       "      <td>0.043883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.337488</td>\n",
       "      <td>0.071748</td>\n",
       "      <td>0.324063</td>\n",
       "      <td>0.063663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.339295</td>\n",
       "      <td>0.130873</td>\n",
       "      <td>0.393410</td>\n",
       "      <td>0.047624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.342433</td>\n",
       "      <td>0.030988</td>\n",
       "      <td>0.255656</td>\n",
       "      <td>0.073663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.344328</td>\n",
       "      <td>0.078530</td>\n",
       "      <td>0.316097</td>\n",
       "      <td>0.060761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.347025</td>\n",
       "      <td>0.033794</td>\n",
       "      <td>0.255396</td>\n",
       "      <td>0.079528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.348129</td>\n",
       "      <td>0.038453</td>\n",
       "      <td>0.305526</td>\n",
       "      <td>0.034893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350150</td>\n",
       "      <td>0.102973</td>\n",
       "      <td>0.261865</td>\n",
       "      <td>0.085574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350708</td>\n",
       "      <td>0.040140</td>\n",
       "      <td>0.302595</td>\n",
       "      <td>0.033151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.352324</td>\n",
       "      <td>0.035266</td>\n",
       "      <td>0.255594</td>\n",
       "      <td>0.081496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353707</td>\n",
       "      <td>0.039670</td>\n",
       "      <td>0.299160</td>\n",
       "      <td>0.028737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.357318</td>\n",
       "      <td>0.039553</td>\n",
       "      <td>0.295012</td>\n",
       "      <td>0.023589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.359366</td>\n",
       "      <td>0.038013</td>\n",
       "      <td>0.255811</td>\n",
       "      <td>0.083043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359466</td>\n",
       "      <td>0.039734</td>\n",
       "      <td>0.292563</td>\n",
       "      <td>0.020651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.361018</td>\n",
       "      <td>0.067091</td>\n",
       "      <td>0.343952</td>\n",
       "      <td>0.063342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.362008</td>\n",
       "      <td>0.040128</td>\n",
       "      <td>0.289711</td>\n",
       "      <td>0.017463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.363831</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.216066</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.363831</td>\n",
       "      <td>0.078141</td>\n",
       "      <td>0.216066</td>\n",
       "      <td>0.046816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.364414</td>\n",
       "      <td>0.040536</td>\n",
       "      <td>0.255698</td>\n",
       "      <td>0.082776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.365126</td>\n",
       "      <td>0.040856</td>\n",
       "      <td>0.286342</td>\n",
       "      <td>0.014032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.371146</td>\n",
       "      <td>0.044645</td>\n",
       "      <td>0.256015</td>\n",
       "      <td>0.082400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374608</td>\n",
       "      <td>0.067666</td>\n",
       "      <td>0.337801</td>\n",
       "      <td>0.125979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.375624</td>\n",
       "      <td>0.123566</td>\n",
       "      <td>0.371496</td>\n",
       "      <td>0.059611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.376963</td>\n",
       "      <td>0.109118</td>\n",
       "      <td>0.300138</td>\n",
       "      <td>0.125292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.377514</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.377514</td>\n",
       "      <td>0.083844</td>\n",
       "      <td>0.216792</td>\n",
       "      <td>0.047635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.378659</td>\n",
       "      <td>0.112119</td>\n",
       "      <td>0.373034</td>\n",
       "      <td>0.062625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380412</td>\n",
       "      <td>0.050949</td>\n",
       "      <td>0.256345</td>\n",
       "      <td>0.082113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390867</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.277128</td>\n",
       "      <td>0.148082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.394970</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.218784</td>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.394970</td>\n",
       "      <td>0.084876</td>\n",
       "      <td>0.218784</td>\n",
       "      <td>0.045326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.406245</td>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.328546</td>\n",
       "      <td>0.131979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.417910</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.417910</td>\n",
       "      <td>0.086034</td>\n",
       "      <td>0.223261</td>\n",
       "      <td>0.045017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433097</td>\n",
       "      <td>0.085431</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.046248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433097</td>\n",
       "      <td>0.085431</td>\n",
       "      <td>0.226360</td>\n",
       "      <td>0.046248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.443822</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.111131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.443822</td>\n",
       "      <td>0.082458</td>\n",
       "      <td>0.298981</td>\n",
       "      <td>0.111131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.452620</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452620</td>\n",
       "      <td>0.083971</td>\n",
       "      <td>0.231485</td>\n",
       "      <td>0.048975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.479704</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.053432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479704</td>\n",
       "      <td>0.082156</td>\n",
       "      <td>0.239575</td>\n",
       "      <td>0.053432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.490854</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.490854</td>\n",
       "      <td>0.075441</td>\n",
       "      <td>0.303802</td>\n",
       "      <td>0.089966</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.724228</td>\n",
       "      <td>0.382029</td>\n",
       "      <td>0.382029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.792246</td>\n",
       "      <td>0.096467</td>\n",
       "      <td>0.096467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.611822</td>\n",
       "      <td>0.050630</td>\n",
       "      <td>0.050630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.425717</td>\n",
       "      <td>0.028504</td>\n",
       "      <td>0.028504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.234528</td>\n",
       "      <td>0.009089</td>\n",
       "      <td>0.009089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.161720</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>0.004410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.133042</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>0.003520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.127256</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.027042</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.000049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ACES_abuse*san</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BFI_conscientiousness*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.724</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.051</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>-0.043</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.029</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.017</td>\n",
       "      <td>-0.218</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.027</td>\n",
       "      <td>-0.235</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.133</td>\n",
       "      <td>-0.127</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                 0.1\n",
      "1          EDM                 0.1\n",
      "2       BIS_11                -0.1\n",
      "3          PCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                 0.1\n",
      "5                       TRSQ                 0.1\n",
      "6  ACES_neglectful_parenting                -0.1\n",
      "0                       BSCS                 0.0\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_88936/988887848.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.02522862129908343, 0.025163581636640342, -0.07364967084625151, -0.21854703231558892, -0.36320442525420504]\n",
      "overall_score:\n",
      "-0.12100178509606434\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.285414</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.298713</td>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.285414</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.298713</td>\n",
       "      <td>0.035208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.300585</td>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.319323</td>\n",
       "      <td>0.067024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.304495</td>\n",
       "      <td>0.120749</td>\n",
       "      <td>0.276454</td>\n",
       "      <td>0.067585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.311944</td>\n",
       "      <td>0.131912</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.070760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.321352</td>\n",
       "      <td>0.136164</td>\n",
       "      <td>0.276253</td>\n",
       "      <td>0.070526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.324230</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.324230</td>\n",
       "      <td>0.046617</td>\n",
       "      <td>0.339216</td>\n",
       "      <td>0.047183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.327913</td>\n",
       "      <td>0.067239</td>\n",
       "      <td>0.341078</td>\n",
       "      <td>0.061043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.334452</td>\n",
       "      <td>0.140091</td>\n",
       "      <td>0.276935</td>\n",
       "      <td>0.070247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.337538</td>\n",
       "      <td>0.059220</td>\n",
       "      <td>0.368947</td>\n",
       "      <td>0.077641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.342223</td>\n",
       "      <td>0.057349</td>\n",
       "      <td>0.368398</td>\n",
       "      <td>0.076590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.343175</td>\n",
       "      <td>0.142158</td>\n",
       "      <td>0.278188</td>\n",
       "      <td>0.070289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.344851</td>\n",
       "      <td>0.061754</td>\n",
       "      <td>0.337880</td>\n",
       "      <td>0.033026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.345440</td>\n",
       "      <td>0.064166</td>\n",
       "      <td>0.334902</td>\n",
       "      <td>0.036291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.347131</td>\n",
       "      <td>0.062813</td>\n",
       "      <td>0.331073</td>\n",
       "      <td>0.037787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.348110</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.355173</td>\n",
       "      <td>0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.348110</td>\n",
       "      <td>0.070732</td>\n",
       "      <td>0.355173</td>\n",
       "      <td>0.038338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.349669</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.326368</td>\n",
       "      <td>0.040100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.350318</td>\n",
       "      <td>0.077237</td>\n",
       "      <td>0.349656</td>\n",
       "      <td>0.046702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.351702</td>\n",
       "      <td>0.059801</td>\n",
       "      <td>0.323294</td>\n",
       "      <td>0.041930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.353826</td>\n",
       "      <td>0.144244</td>\n",
       "      <td>0.280347</td>\n",
       "      <td>0.070758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.354124</td>\n",
       "      <td>0.031993</td>\n",
       "      <td>0.312422</td>\n",
       "      <td>0.057298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.354698</td>\n",
       "      <td>0.057848</td>\n",
       "      <td>0.319875</td>\n",
       "      <td>0.043896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.355962</td>\n",
       "      <td>0.119837</td>\n",
       "      <td>0.348240</td>\n",
       "      <td>0.090726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.358862</td>\n",
       "      <td>0.056026</td>\n",
       "      <td>0.315860</td>\n",
       "      <td>0.047020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.359631</td>\n",
       "      <td>0.113483</td>\n",
       "      <td>0.344839</td>\n",
       "      <td>0.073175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.359868</td>\n",
       "      <td>0.070397</td>\n",
       "      <td>0.354737</td>\n",
       "      <td>0.043573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.363585</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.363585</td>\n",
       "      <td>0.083403</td>\n",
       "      <td>0.361174</td>\n",
       "      <td>0.037115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.364220</td>\n",
       "      <td>0.080867</td>\n",
       "      <td>0.353181</td>\n",
       "      <td>0.043774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.364533</td>\n",
       "      <td>0.083818</td>\n",
       "      <td>0.361000</td>\n",
       "      <td>0.037108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.365554</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.365554</td>\n",
       "      <td>0.078798</td>\n",
       "      <td>0.221069</td>\n",
       "      <td>0.047144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.366133</td>\n",
       "      <td>0.089044</td>\n",
       "      <td>0.359814</td>\n",
       "      <td>0.038225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.366732</td>\n",
       "      <td>0.135969</td>\n",
       "      <td>0.344069</td>\n",
       "      <td>0.060607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.367200</td>\n",
       "      <td>0.146591</td>\n",
       "      <td>0.284069</td>\n",
       "      <td>0.071861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.368016</td>\n",
       "      <td>0.092195</td>\n",
       "      <td>0.359188</td>\n",
       "      <td>0.035592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.368472</td>\n",
       "      <td>0.053184</td>\n",
       "      <td>0.336913</td>\n",
       "      <td>0.056795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.370313</td>\n",
       "      <td>0.081699</td>\n",
       "      <td>0.363720</td>\n",
       "      <td>0.041459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.370383</td>\n",
       "      <td>0.078174</td>\n",
       "      <td>0.360104</td>\n",
       "      <td>0.045049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.370514</td>\n",
       "      <td>0.081751</td>\n",
       "      <td>0.363814</td>\n",
       "      <td>0.041289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.372614</td>\n",
       "      <td>0.092474</td>\n",
       "      <td>0.358390</td>\n",
       "      <td>0.036465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.372665</td>\n",
       "      <td>0.086650</td>\n",
       "      <td>0.358909</td>\n",
       "      <td>0.029829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374045</td>\n",
       "      <td>0.070226</td>\n",
       "      <td>0.333590</td>\n",
       "      <td>0.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.374292</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.388962</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.374292</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.388962</td>\n",
       "      <td>0.151163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.376441</td>\n",
       "      <td>0.043951</td>\n",
       "      <td>0.256594</td>\n",
       "      <td>0.071256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.378945</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>0.221267</td>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.378945</td>\n",
       "      <td>0.084380</td>\n",
       "      <td>0.221267</td>\n",
       "      <td>0.047618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.379681</td>\n",
       "      <td>0.097342</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.148586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.379681</td>\n",
       "      <td>0.097342</td>\n",
       "      <td>0.388899</td>\n",
       "      <td>0.148586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380595</td>\n",
       "      <td>0.047816</td>\n",
       "      <td>0.255355</td>\n",
       "      <td>0.079440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.380863</td>\n",
       "      <td>0.076409</td>\n",
       "      <td>0.361438</td>\n",
       "      <td>0.039636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.383012</td>\n",
       "      <td>0.075569</td>\n",
       "      <td>0.359680</td>\n",
       "      <td>0.041392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.385123</td>\n",
       "      <td>0.072903</td>\n",
       "      <td>0.359459</td>\n",
       "      <td>0.039081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.385716</td>\n",
       "      <td>0.049229</td>\n",
       "      <td>0.254623</td>\n",
       "      <td>0.083900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.386045</td>\n",
       "      <td>0.070844</td>\n",
       "      <td>0.354320</td>\n",
       "      <td>0.037626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.387811</td>\n",
       "      <td>0.068986</td>\n",
       "      <td>0.350749</td>\n",
       "      <td>0.038258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.388910</td>\n",
       "      <td>0.082919</td>\n",
       "      <td>0.318575</td>\n",
       "      <td>0.074520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.389411</td>\n",
       "      <td>0.076709</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.038957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.390216</td>\n",
       "      <td>0.073510</td>\n",
       "      <td>0.357285</td>\n",
       "      <td>0.035717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390217</td>\n",
       "      <td>0.073397</td>\n",
       "      <td>0.357353</td>\n",
       "      <td>0.035709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.390505</td>\n",
       "      <td>0.073536</td>\n",
       "      <td>0.357320</td>\n",
       "      <td>0.035521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.392408</td>\n",
       "      <td>0.051154</td>\n",
       "      <td>0.253489</td>\n",
       "      <td>0.088712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.393555</td>\n",
       "      <td>0.066924</td>\n",
       "      <td>0.346417</td>\n",
       "      <td>0.040194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.395240</td>\n",
       "      <td>0.083594</td>\n",
       "      <td>0.401948</td>\n",
       "      <td>0.154185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.395730</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>0.044928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.395730</td>\n",
       "      <td>0.084963</td>\n",
       "      <td>0.222547</td>\n",
       "      <td>0.044928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.397175</td>\n",
       "      <td>0.052829</td>\n",
       "      <td>0.251956</td>\n",
       "      <td>0.090524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.400629</td>\n",
       "      <td>0.076749</td>\n",
       "      <td>0.399760</td>\n",
       "      <td>0.154282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.403833</td>\n",
       "      <td>0.055744</td>\n",
       "      <td>0.250554</td>\n",
       "      <td>0.092793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.405266</td>\n",
       "      <td>0.060046</td>\n",
       "      <td>0.330600</td>\n",
       "      <td>0.037445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.413535</td>\n",
       "      <td>0.060837</td>\n",
       "      <td>0.249249</td>\n",
       "      <td>0.095563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.415488</td>\n",
       "      <td>0.116147</td>\n",
       "      <td>0.355522</td>\n",
       "      <td>0.074687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415582</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.377388</td>\n",
       "      <td>0.081381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.415625</td>\n",
       "      <td>0.096728</td>\n",
       "      <td>0.367648</td>\n",
       "      <td>0.061017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.418534</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.418534</td>\n",
       "      <td>0.085777</td>\n",
       "      <td>0.226070</td>\n",
       "      <td>0.044025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.424915</td>\n",
       "      <td>0.046703</td>\n",
       "      <td>0.300880</td>\n",
       "      <td>0.027111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.425065</td>\n",
       "      <td>0.050251</td>\n",
       "      <td>0.300696</td>\n",
       "      <td>0.028502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.425614</td>\n",
       "      <td>0.050878</td>\n",
       "      <td>0.300536</td>\n",
       "      <td>0.028191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.427059</td>\n",
       "      <td>0.051088</td>\n",
       "      <td>0.300229</td>\n",
       "      <td>0.028005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.428107</td>\n",
       "      <td>0.051122</td>\n",
       "      <td>0.300102</td>\n",
       "      <td>0.027869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.429290</td>\n",
       "      <td>0.051070</td>\n",
       "      <td>0.299920</td>\n",
       "      <td>0.027793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.430592</td>\n",
       "      <td>0.050967</td>\n",
       "      <td>0.299757</td>\n",
       "      <td>0.027724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.433229</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.228778</td>\n",
       "      <td>0.045213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433229</td>\n",
       "      <td>0.085296</td>\n",
       "      <td>0.228778</td>\n",
       "      <td>0.045213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.433994</td>\n",
       "      <td>0.087275</td>\n",
       "      <td>0.366298</td>\n",
       "      <td>0.074578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.435098</td>\n",
       "      <td>0.093692</td>\n",
       "      <td>0.363372</td>\n",
       "      <td>0.072388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.436364</td>\n",
       "      <td>0.094040</td>\n",
       "      <td>0.364972</td>\n",
       "      <td>0.073816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.450775</td>\n",
       "      <td>0.098792</td>\n",
       "      <td>0.375888</td>\n",
       "      <td>0.155372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.452382</td>\n",
       "      <td>0.083625</td>\n",
       "      <td>0.233106</td>\n",
       "      <td>0.048282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.462844</td>\n",
       "      <td>0.101645</td>\n",
       "      <td>0.368592</td>\n",
       "      <td>0.074591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.466339</td>\n",
       "      <td>0.122230</td>\n",
       "      <td>0.284734</td>\n",
       "      <td>0.118238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.469952</td>\n",
       "      <td>0.089226</td>\n",
       "      <td>0.372521</td>\n",
       "      <td>0.075975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.470453</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.470453</td>\n",
       "      <td>0.098165</td>\n",
       "      <td>0.345850</td>\n",
       "      <td>0.173641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.471184</td>\n",
       "      <td>0.110872</td>\n",
       "      <td>0.266708</td>\n",
       "      <td>0.127714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.479305</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.053128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.479305</td>\n",
       "      <td>0.081804</td>\n",
       "      <td>0.240573</td>\n",
       "      <td>0.053128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.484671</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>0.356781</td>\n",
       "      <td>0.151985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.493742</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.366265</td>\n",
       "      <td>0.163585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.493742</td>\n",
       "      <td>0.085640</td>\n",
       "      <td>0.366265</td>\n",
       "      <td>0.163585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 19\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>1.520835</td>\n",
       "      <td>0.280856</td>\n",
       "      <td>0.280856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>0.601340</td>\n",
       "      <td>0.053674</td>\n",
       "      <td>0.053674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>EDM*ni</td>\n",
       "      <td>0.521283</td>\n",
       "      <td>0.037669</td>\n",
       "      <td>0.037669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.454181</td>\n",
       "      <td>0.030541</td>\n",
       "      <td>0.030541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIS_11</td>\n",
       "      <td>-0.443326</td>\n",
       "      <td>0.030219</td>\n",
       "      <td>0.030219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-0.452073</td>\n",
       "      <td>0.028686</td>\n",
       "      <td>0.028686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>BFI_neuroticism*ni</td>\n",
       "      <td>-0.448212</td>\n",
       "      <td>0.028388</td>\n",
       "      <td>0.028388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BFI_extraversion</td>\n",
       "      <td>0.331615</td>\n",
       "      <td>0.022058</td>\n",
       "      <td>0.022058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>0.301765</td>\n",
       "      <td>0.017198</td>\n",
       "      <td>0.017198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BFI_agreeableness</td>\n",
       "      <td>-0.325563</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.014493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.262815</td>\n",
       "      <td>0.010228</td>\n",
       "      <td>0.010228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-0.190043</td>\n",
       "      <td>0.005946</td>\n",
       "      <td>0.005946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RS</td>\n",
       "      <td>0.107840</td>\n",
       "      <td>0.003983</td>\n",
       "      <td>0.003983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EDM</td>\n",
       "      <td>0.118715</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ACES_abuse*ni</td>\n",
       "      <td>-0.111035</td>\n",
       "      <td>0.002239</td>\n",
       "      <td>0.002239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TRSQ</td>\n",
       "      <td>0.138684</td>\n",
       "      <td>0.001944</td>\n",
       "      <td>0.001944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.092470</td>\n",
       "      <td>0.001942</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.072272</td>\n",
       "      <td>0.001739</td>\n",
       "      <td>0.001739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.036881</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>BIS_11*san</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>1.521</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.281</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.415</td>\n",
       "      <td>-0.011</td>\n",
       "      <td>0.281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>-0.443</td>\n",
       "      <td>-0.452</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.440</td>\n",
       "      <td>-0.033</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>0.108</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.177</td>\n",
       "      <td>0.304</td>\n",
       "      <td>0.058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EDM</th>\n",
       "      <td>0.119</td>\n",
       "      <td>0.521</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.287</td>\n",
       "      <td>-0.065</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>0.332</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.072</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.454</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.031</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>-0.262</td>\n",
       "      <td>0.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_neuroticism</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.448</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>-0.326</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-0.263</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.037</td>\n",
       "      <td>-0.190</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.092</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>0.139</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>0.319</td>\n",
       "      <td>0.002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ni' 'san']\n",
      "[1.28335298 0.42953651]\n",
      "['san' 'san' 'ni' 'ichi' 'san' 'san' 'ichi' 'san' 'san' 'san' 'ni' 'ichi'\n",
      " 'ichi' 'ichi' 'ichi' 'san' 'san' 'san' 'ichi' 'ichi' 'san' 'san' 'ni'\n",
      " 'ni' 'ni' 'ni' 'ni' 'ni' 'ni' 'san' 'ni' 'san' 'ni' 'ichi' 'ni' 'san'\n",
      " 'ni' 'ichi' 'san' 'ni' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni'\n",
      " 'san' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'san'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ichi' 'san' 'ni' 'ni' 'ni' 'san' 'ichi' 'ni' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'ichi' 'san' 'ichi' 'san' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ni' 'ichi' 'san' 'san' 'san' 'ichi'\n",
      " 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ichi' 'san' 'ni' 'ni' 'san' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ichi'\n",
      " 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ichi' 'san' 'san' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'ichi' 'san' 'ichi' 'ni' 'san' 'san' 'ni' 'ni' 'san' 'san' 'san'\n",
      " 'ichi' 'san' 'ni' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'san' 'ni' 'ni' 'ni'\n",
      " 'ichi' 'ni' 'ichi' 'san' 'ni' 'san' 'ichi' 'ni' 'ni' 'ni' 'ichi' 'ni'\n",
      " 'ichi' 'san' 'san' 'san' 'san' 'ichi' 'ni' 'san' 'san' 'san' 'ichi' 'san'\n",
      " 'ni' 'ni' 'san' 'ichi' 'ichi' 'san' 'ni' 'ni' 'san' 'ni' 'san' 'san' 'ni'\n",
      " 'san' 'ni' 'ni' 'san' 'ichi' 'san' 'ichi' 'san' 'ni' 'ni' 'ni' 'ichi'\n",
      " 'ni' 'ni' 'san' 'ni' 'ni' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'ni' 'san'\n",
      " 'ichi' 'ni' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'ichi' 'san'\n",
      " 'ichi' 'ni' 'san' 'san' 'ni' 'ichi' 'ni' 'ni' 'ichi' 'ni' 'san' 'san'\n",
      " 'ichi' 'ichi' 'ichi' 'ichi' 'san' 'san' 'ni' 'ni' 'ni' 'san' 'ichi'\n",
      " 'ichi' 'ichi' 'ni' 'ichi' 'ni' 'san' 'ichi' 'san' 'san' 'ni' 'san' 'san'\n",
      " 'san' 'san' 'ichi' 'ichi' 'ichi' 'ni' 'ni' 'ichi' 'san' 'san' 'san']\n",
      "['ichi' 'ni' 'san']\n",
      "ichi\n",
      "no interaction effects for group: ichi. No effects will be included for this group.\n",
      "ni\n",
      "  feature_name  interaction_effect\n",
      "0         BSCS                0.15\n",
      "1          EDM                0.15\n",
      "2       BIS_11               -0.15\n",
      "3          PCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "san\n",
      "                feature_name  interaction_effect\n",
      "4                         RS                0.15\n",
      "5                       TRSQ                0.15\n",
      "6  ACES_neglectful_parenting               -0.15\n",
      "0                       BSCS                0.00\n",
      "bf_2\n",
      "cancer_promoting_minus_preventing_FFQ_w2\n",
      "FFQ_v2_Mean_Energy_w2\n",
      "(275, 15)\n",
      "(275, 15)\n",
      "outer split0\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_88936/988887848.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split1\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split2\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split3\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "outer split4\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Ridge())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Ridge())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Ridge())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()), ('estimator', Lasso())])\n",
      "{'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()), ('estimator', Lasso())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', Lasso())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__alpha': array([0.1, 1. , 0.2, 0.3, 0.4, 0.6, 0.8, 1. ])}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 8 candidates, totalling 32 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', SelectKBest()),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__score_func': [<function f_regression at 0x180487eb0>], 'feature_selection__k': [10, 25, 47], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('feature_selection', RFE(estimator=LinearRegression())),\n",
      "                ('estimator', DecisionTreeRegressor())])\n",
      "{'feature_selection__n_features_to_select': [10, 25], 'feature_selection__step': [5], 'estimator__max_depth': [2, 4], 'estimator__min_samples_split': [20, 50], 'estimator__min_samples_leaf': [20, 50]}\n",
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n",
      "scores:\n",
      "[0.14598507818667295, 0.3170222601582635, 0.2626419743579804, -0.06654989340516115, -0.2857106496955475]\n",
      "overall_score:\n",
      "0.07467775392044165\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">mean_test_score</th>\n",
       "      <th colspan=\"2\" halign=\"left\">std_test_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_description</th>\n",
       "      <th>params_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.315547</td>\n",
       "      <td>0.117999</td>\n",
       "      <td>0.264293</td>\n",
       "      <td>0.103017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.319750</td>\n",
       "      <td>0.129352</td>\n",
       "      <td>0.262778</td>\n",
       "      <td>0.108908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.325414</td>\n",
       "      <td>0.133698</td>\n",
       "      <td>0.262301</td>\n",
       "      <td>0.110055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.333861</td>\n",
       "      <td>0.137856</td>\n",
       "      <td>0.262968</td>\n",
       "      <td>0.112172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.339882</td>\n",
       "      <td>0.139326</td>\n",
       "      <td>0.263513</td>\n",
       "      <td>0.113842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.347436</td>\n",
       "      <td>0.053581</td>\n",
       "      <td>0.310509</td>\n",
       "      <td>0.039265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.347436</td>\n",
       "      <td>0.053581</td>\n",
       "      <td>0.310509</td>\n",
       "      <td>0.039265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.347742</td>\n",
       "      <td>0.140151</td>\n",
       "      <td>0.264546</td>\n",
       "      <td>0.116099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.358515</td>\n",
       "      <td>0.140169</td>\n",
       "      <td>0.267755</td>\n",
       "      <td>0.118292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.372101</td>\n",
       "      <td>0.080915</td>\n",
       "      <td>0.234127</td>\n",
       "      <td>0.047910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.372101</td>\n",
       "      <td>0.080915</td>\n",
       "      <td>0.234127</td>\n",
       "      <td>0.047910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.384006</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.232816</td>\n",
       "      <td>0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.384006</td>\n",
       "      <td>0.085906</td>\n",
       "      <td>0.232816</td>\n",
       "      <td>0.048485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.398821</td>\n",
       "      <td>0.085554</td>\n",
       "      <td>0.232315</td>\n",
       "      <td>0.045287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.398821</td>\n",
       "      <td>0.085554</td>\n",
       "      <td>0.232315</td>\n",
       "      <td>0.045287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.405388</td>\n",
       "      <td>0.077106</td>\n",
       "      <td>0.338926</td>\n",
       "      <td>0.121565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.420469</td>\n",
       "      <td>0.085321</td>\n",
       "      <td>0.233540</td>\n",
       "      <td>0.042665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.420469</td>\n",
       "      <td>0.085321</td>\n",
       "      <td>0.233540</td>\n",
       "      <td>0.042665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.434329</td>\n",
       "      <td>0.084769</td>\n",
       "      <td>0.234846</td>\n",
       "      <td>0.043323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.434329</td>\n",
       "      <td>0.084769</td>\n",
       "      <td>0.234846</td>\n",
       "      <td>0.043323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.437919</td>\n",
       "      <td>0.061574</td>\n",
       "      <td>0.300812</td>\n",
       "      <td>0.063194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.439791</td>\n",
       "      <td>0.063252</td>\n",
       "      <td>0.300348</td>\n",
       "      <td>0.068965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.442519</td>\n",
       "      <td>0.060951</td>\n",
       "      <td>0.299537</td>\n",
       "      <td>0.072626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.446266</td>\n",
       "      <td>0.058509</td>\n",
       "      <td>0.298524</td>\n",
       "      <td>0.078227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.449702</td>\n",
       "      <td>0.058135</td>\n",
       "      <td>0.296833</td>\n",
       "      <td>0.081263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.452280</td>\n",
       "      <td>0.083181</td>\n",
       "      <td>0.237552</td>\n",
       "      <td>0.046729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.452280</td>\n",
       "      <td>0.083181</td>\n",
       "      <td>0.237552</td>\n",
       "      <td>0.046729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.454291</td>\n",
       "      <td>0.057799</td>\n",
       "      <td>0.296071</td>\n",
       "      <td>0.085291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.455025</td>\n",
       "      <td>0.061750</td>\n",
       "      <td>0.349501</td>\n",
       "      <td>0.057256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.461277</td>\n",
       "      <td>0.057819</td>\n",
       "      <td>0.294647</td>\n",
       "      <td>0.090642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.470086</td>\n",
       "      <td>0.060963</td>\n",
       "      <td>0.332608</td>\n",
       "      <td>0.103584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.470613</td>\n",
       "      <td>0.060326</td>\n",
       "      <td>0.329420</td>\n",
       "      <td>0.105297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.471147</td>\n",
       "      <td>0.061446</td>\n",
       "      <td>0.335001</td>\n",
       "      <td>0.102149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.473009</td>\n",
       "      <td>0.062376</td>\n",
       "      <td>0.336164</td>\n",
       "      <td>0.100976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1}</th>\n",
       "      <td>-3.478375</td>\n",
       "      <td>0.080959</td>\n",
       "      <td>0.243034</td>\n",
       "      <td>0.052245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.478375</td>\n",
       "      <td>0.080959</td>\n",
       "      <td>0.243034</td>\n",
       "      <td>0.052245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.478847</td>\n",
       "      <td>0.064363</td>\n",
       "      <td>0.337297</td>\n",
       "      <td>0.098069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.480264</td>\n",
       "      <td>0.039732</td>\n",
       "      <td>0.371074</td>\n",
       "      <td>0.062732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2}</th>\n",
       "      <td>-3.480264</td>\n",
       "      <td>0.039732</td>\n",
       "      <td>0.371074</td>\n",
       "      <td>0.062732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.484170</td>\n",
       "      <td>0.065982</td>\n",
       "      <td>0.338299</td>\n",
       "      <td>0.095709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.488905</td>\n",
       "      <td>0.063241</td>\n",
       "      <td>0.339398</td>\n",
       "      <td>0.088360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.500043</td>\n",
       "      <td>0.073513</td>\n",
       "      <td>0.365626</td>\n",
       "      <td>0.094888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.534819</td>\n",
       "      <td>0.077606</td>\n",
       "      <td>0.377583</td>\n",
       "      <td>0.051248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3}</th>\n",
       "      <td>-3.534819</td>\n",
       "      <td>0.077606</td>\n",
       "      <td>0.377583</td>\n",
       "      <td>0.051248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.553283</td>\n",
       "      <td>0.083054</td>\n",
       "      <td>0.368068</td>\n",
       "      <td>0.059897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.566149</td>\n",
       "      <td>0.085941</td>\n",
       "      <td>0.370576</td>\n",
       "      <td>0.070296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.573400</td>\n",
       "      <td>0.089009</td>\n",
       "      <td>0.377747</td>\n",
       "      <td>0.049016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4}</th>\n",
       "      <td>-3.577151</td>\n",
       "      <td>0.088005</td>\n",
       "      <td>0.389050</td>\n",
       "      <td>0.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.577151</td>\n",
       "      <td>0.088005</td>\n",
       "      <td>0.389050</td>\n",
       "      <td>0.051739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.584244</td>\n",
       "      <td>0.075309</td>\n",
       "      <td>0.379251</td>\n",
       "      <td>0.070947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.588208</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>0.386615</td>\n",
       "      <td>0.056013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.591561</td>\n",
       "      <td>0.079100</td>\n",
       "      <td>0.387932</td>\n",
       "      <td>0.062192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.592118</td>\n",
       "      <td>0.086688</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.181260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.592118</td>\n",
       "      <td>0.086688</td>\n",
       "      <td>0.386957</td>\n",
       "      <td>0.181260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.593267</td>\n",
       "      <td>0.078735</td>\n",
       "      <td>0.384871</td>\n",
       "      <td>0.067271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.595158</td>\n",
       "      <td>0.080908</td>\n",
       "      <td>0.389104</td>\n",
       "      <td>0.056520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.604628</td>\n",
       "      <td>0.094683</td>\n",
       "      <td>0.373360</td>\n",
       "      <td>0.056088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.609336</td>\n",
       "      <td>0.108535</td>\n",
       "      <td>0.388114</td>\n",
       "      <td>0.181784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.609336</td>\n",
       "      <td>0.108535</td>\n",
       "      <td>0.388114</td>\n",
       "      <td>0.181784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.610773</td>\n",
       "      <td>0.073752</td>\n",
       "      <td>0.348513</td>\n",
       "      <td>0.220902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.610773</td>\n",
       "      <td>0.073752</td>\n",
       "      <td>0.348513</td>\n",
       "      <td>0.220902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.611582</td>\n",
       "      <td>0.087208</td>\n",
       "      <td>0.392106</td>\n",
       "      <td>0.046392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611911</td>\n",
       "      <td>0.165320</td>\n",
       "      <td>0.386645</td>\n",
       "      <td>0.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611911</td>\n",
       "      <td>0.165320</td>\n",
       "      <td>0.386645</td>\n",
       "      <td>0.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611911</td>\n",
       "      <td>0.165320</td>\n",
       "      <td>0.386645</td>\n",
       "      <td>0.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.611911</td>\n",
       "      <td>0.165320</td>\n",
       "      <td>0.386645</td>\n",
       "      <td>0.052100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.612895</td>\n",
       "      <td>0.087723</td>\n",
       "      <td>0.391779</td>\n",
       "      <td>0.046377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.612895</td>\n",
       "      <td>0.087723</td>\n",
       "      <td>0.391779</td>\n",
       "      <td>0.046377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6}</th>\n",
       "      <td>-3.612895</td>\n",
       "      <td>0.087723</td>\n",
       "      <td>0.391779</td>\n",
       "      <td>0.046377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.622839</td>\n",
       "      <td>0.066196</td>\n",
       "      <td>0.353673</td>\n",
       "      <td>0.079756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.626520</td>\n",
       "      <td>0.080397</td>\n",
       "      <td>0.372364</td>\n",
       "      <td>0.072024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.627122</td>\n",
       "      <td>0.181217</td>\n",
       "      <td>0.403541</td>\n",
       "      <td>0.094799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.631036</td>\n",
       "      <td>0.044605</td>\n",
       "      <td>0.326828</td>\n",
       "      <td>0.087968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.631991</td>\n",
       "      <td>0.047512</td>\n",
       "      <td>0.324777</td>\n",
       "      <td>0.092073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.632429</td>\n",
       "      <td>0.107950</td>\n",
       "      <td>0.391835</td>\n",
       "      <td>0.096408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.633114</td>\n",
       "      <td>0.090178</td>\n",
       "      <td>0.383852</td>\n",
       "      <td>0.049655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.633177</td>\n",
       "      <td>0.048172</td>\n",
       "      <td>0.322331</td>\n",
       "      <td>0.090209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.633679</td>\n",
       "      <td>0.086204</td>\n",
       "      <td>0.373508</td>\n",
       "      <td>0.056681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.635297</td>\n",
       "      <td>0.087545</td>\n",
       "      <td>0.377171</td>\n",
       "      <td>0.052815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.4, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.635716</td>\n",
       "      <td>0.049718</td>\n",
       "      <td>0.318036</td>\n",
       "      <td>0.087865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.635944</td>\n",
       "      <td>0.192484</td>\n",
       "      <td>0.405201</td>\n",
       "      <td>0.105542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8}</th>\n",
       "      <td>-3.636258</td>\n",
       "      <td>0.087395</td>\n",
       "      <td>0.388966</td>\n",
       "      <td>0.043936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636258</td>\n",
       "      <td>0.087395</td>\n",
       "      <td>0.388966</td>\n",
       "      <td>0.043936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636258</td>\n",
       "      <td>0.087395</td>\n",
       "      <td>0.388966</td>\n",
       "      <td>0.043936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.636258</td>\n",
       "      <td>0.087395</td>\n",
       "      <td>0.388966</td>\n",
       "      <td>0.043936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.3, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.638294</td>\n",
       "      <td>0.050854</td>\n",
       "      <td>0.314822</td>\n",
       "      <td>0.086656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.639266</td>\n",
       "      <td>0.118940</td>\n",
       "      <td>0.382963</td>\n",
       "      <td>0.104673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.639329</td>\n",
       "      <td>0.116322</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.223094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.639329</td>\n",
       "      <td>0.116322</td>\n",
       "      <td>0.339697</td>\n",
       "      <td>0.223094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.2, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.641274</td>\n",
       "      <td>0.052251</td>\n",
       "      <td>0.311136</td>\n",
       "      <td>0.085233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.6, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.643433</td>\n",
       "      <td>0.085435</td>\n",
       "      <td>0.387600</td>\n",
       "      <td>0.047615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Ridge()])</th>\n",
       "      <th>{'estimator__alpha': 0.1, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.645144</td>\n",
       "      <td>0.053997</td>\n",
       "      <td>0.306905</td>\n",
       "      <td>0.083371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.648687</td>\n",
       "      <td>0.051830</td>\n",
       "      <td>0.355446</td>\n",
       "      <td>0.169473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.650167</td>\n",
       "      <td>0.089899</td>\n",
       "      <td>0.385264</td>\n",
       "      <td>0.046767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.652914</td>\n",
       "      <td>0.113160</td>\n",
       "      <td>0.410938</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.652914</td>\n",
       "      <td>0.113160</td>\n",
       "      <td>0.410938</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.652914</td>\n",
       "      <td>0.113160</td>\n",
       "      <td>0.410938</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.652914</td>\n",
       "      <td>0.113160</td>\n",
       "      <td>0.410938</td>\n",
       "      <td>0.055200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 0.8, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.654844</td>\n",
       "      <td>0.087369</td>\n",
       "      <td>0.386430</td>\n",
       "      <td>0.046774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0}</th>\n",
       "      <td>-3.659199</td>\n",
       "      <td>0.084294</td>\n",
       "      <td>0.384331</td>\n",
       "      <td>0.044663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.659199</td>\n",
       "      <td>0.084294</td>\n",
       "      <td>0.384331</td>\n",
       "      <td>0.044663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.659199</td>\n",
       "      <td>0.084294</td>\n",
       "      <td>0.384331</td>\n",
       "      <td>0.044663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.659199</td>\n",
       "      <td>0.084294</td>\n",
       "      <td>0.384331</td>\n",
       "      <td>0.044663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), Lasso()])</th>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.664482</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>0.382967</td>\n",
       "      <td>0.044177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__alpha': 1.0, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.665889</td>\n",
       "      <td>0.085404</td>\n",
       "      <td>0.383137</td>\n",
       "      <td>0.044123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.665904</td>\n",
       "      <td>0.080905</td>\n",
       "      <td>0.353183</td>\n",
       "      <td>0.168412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 47, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.670771</td>\n",
       "      <td>0.122660</td>\n",
       "      <td>0.385668</td>\n",
       "      <td>0.048206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.680859</td>\n",
       "      <td>0.130387</td>\n",
       "      <td>0.357077</td>\n",
       "      <td>0.070128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.680859</td>\n",
       "      <td>0.130387</td>\n",
       "      <td>0.357077</td>\n",
       "      <td>0.070128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682033</td>\n",
       "      <td>0.150761</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>0.079225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682033</td>\n",
       "      <td>0.150761</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>0.079225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682033</td>\n",
       "      <td>0.150761</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>0.079225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.682033</td>\n",
       "      <td>0.150761</td>\n",
       "      <td>0.390737</td>\n",
       "      <td>0.079225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.683564</td>\n",
       "      <td>0.108033</td>\n",
       "      <td>0.382221</td>\n",
       "      <td>0.057194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.683564</td>\n",
       "      <td>0.108033</td>\n",
       "      <td>0.382221</td>\n",
       "      <td>0.057194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.683564</td>\n",
       "      <td>0.108033</td>\n",
       "      <td>0.382221</td>\n",
       "      <td>0.057194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 2, 'estimator__min_samples_leaf': 50, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.683564</td>\n",
       "      <td>0.108033</td>\n",
       "      <td>0.382221</td>\n",
       "      <td>0.057194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.695460</td>\n",
       "      <td>0.084966</td>\n",
       "      <td>0.323938</td>\n",
       "      <td>0.187952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.695489</td>\n",
       "      <td>0.112806</td>\n",
       "      <td>0.358490</td>\n",
       "      <td>0.082836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.696314</td>\n",
       "      <td>0.194425</td>\n",
       "      <td>0.343858</td>\n",
       "      <td>0.038099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 10, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.701880</td>\n",
       "      <td>0.116360</td>\n",
       "      <td>0.359382</td>\n",
       "      <td>0.084292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 25, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.710095</td>\n",
       "      <td>0.210709</td>\n",
       "      <td>0.341426</td>\n",
       "      <td>0.058025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.712033</td>\n",
       "      <td>0.116375</td>\n",
       "      <td>0.362959</td>\n",
       "      <td>0.099543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), SelectKBest(), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 50, 'feature_selection__k': 25, 'feature_selection__score_func': &lt;function f_regression at 0x180487eb0&gt;}</th>\n",
       "      <td>-3.712743</td>\n",
       "      <td>0.130072</td>\n",
       "      <td>0.318218</td>\n",
       "      <td>0.183421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dict_values([StandardScaler(), RFE(estimator=LinearRegression()), DecisionTreeRegressor()])</th>\n",
       "      <th>{'estimator__max_depth': 4, 'estimator__min_samples_leaf': 20, 'estimator__min_samples_split': 20, 'feature_selection__n_features_to_select': 10, 'feature_selection__step': 5}</th>\n",
       "      <td>-3.722616</td>\n",
       "      <td>0.126043</td>\n",
       "      <td>0.359028</td>\n",
       "      <td>0.116282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing permutation test on importance; this may take time.\n",
      "Number of selected features: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictor</th>\n",
       "      <th>coef</th>\n",
       "      <th>feature_importance</th>\n",
       "      <th>fa_abs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BSCS*ni</td>\n",
       "      <td>5.096231</td>\n",
       "      <td>2.541397</td>\n",
       "      <td>2.541397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BIS_11*ni</td>\n",
       "      <td>-4.819430</td>\n",
       "      <td>2.295673</td>\n",
       "      <td>2.295673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>san</td>\n",
       "      <td>-4.441786</td>\n",
       "      <td>1.903963</td>\n",
       "      <td>1.903963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TRSQ*san</td>\n",
       "      <td>3.266038</td>\n",
       "      <td>1.053144</td>\n",
       "      <td>1.053144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>RS*san</td>\n",
       "      <td>2.745558</td>\n",
       "      <td>0.742469</td>\n",
       "      <td>0.742469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>BFI_extraversion*san</td>\n",
       "      <td>2.183413</td>\n",
       "      <td>0.471304</td>\n",
       "      <td>0.471304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>BFI_agreeableness*san</td>\n",
       "      <td>-1.864833</td>\n",
       "      <td>0.334916</td>\n",
       "      <td>0.334916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ni</td>\n",
       "      <td>1.278988</td>\n",
       "      <td>0.164381</td>\n",
       "      <td>0.164381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ACES_household_dysfunction*ni</td>\n",
       "      <td>-1.091946</td>\n",
       "      <td>0.112083</td>\n",
       "      <td>0.112083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ACES_neglectful_parenting*ni</td>\n",
       "      <td>0.964651</td>\n",
       "      <td>0.093608</td>\n",
       "      <td>0.093608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>BFI_conscientiousness*san</td>\n",
       "      <td>-0.894499</td>\n",
       "      <td>0.076067</td>\n",
       "      <td>0.076067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ACES_household_dysfunction</td>\n",
       "      <td>0.861960</td>\n",
       "      <td>0.074956</td>\n",
       "      <td>0.074956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACES_neglectful_parenting</td>\n",
       "      <td>-0.688557</td>\n",
       "      <td>0.049318</td>\n",
       "      <td>0.049318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>BSCS*san</td>\n",
       "      <td>0.662138</td>\n",
       "      <td>0.044036</td>\n",
       "      <td>0.044036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ACES_sum*ni</td>\n",
       "      <td>-0.493903</td>\n",
       "      <td>0.022878</td>\n",
       "      <td>0.022878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ACES_sum*san</td>\n",
       "      <td>-0.468009</td>\n",
       "      <td>0.022023</td>\n",
       "      <td>0.022023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ACES_neglectful_parenting*san</td>\n",
       "      <td>-0.426128</td>\n",
       "      <td>0.017131</td>\n",
       "      <td>0.017131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ACES_divorced_separated*san</td>\n",
       "      <td>-0.407406</td>\n",
       "      <td>0.016710</td>\n",
       "      <td>0.016710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ACES_household_dysfunction*san</td>\n",
       "      <td>-0.411618</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.016622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ACES_abuse</td>\n",
       "      <td>0.315816</td>\n",
       "      <td>0.006844</td>\n",
       "      <td>0.006844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/benjaminsmith/Google Drive/oregon/code/DEV_scripts/analyses/intervention_moderation/dev_interaction_util.py:358: FutureWarning: merging between different levels is deprecated and will be removed in a future version. (2 levels on the left, 1 on the right)\n",
      "  results_vs_cors = final_results_wide.merge(group_correlations, left_index=True, right_index=True, how='outer')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(coef, base)</th>\n",
       "      <th>(coef, ni)</th>\n",
       "      <th>(coef, san)</th>\n",
       "      <th>(feature_importance, base)</th>\n",
       "      <th>(feature_importance, ni)</th>\n",
       "      <th>(feature_importance, san)</th>\n",
       "      <th>ichi_cor</th>\n",
       "      <th>ni_cor</th>\n",
       "      <th>san_cor</th>\n",
       "      <th>abs_effect_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSCS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5.096</td>\n",
       "      <td>0.662</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.541</td>\n",
       "      <td>0.044</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>0.544</td>\n",
       "      <td>-0.051</td>\n",
       "      <td>2.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BIS_11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.296</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "      <td>-0.550</td>\n",
       "      <td>-0.009</td>\n",
       "      <td>2.296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>san</th>\n",
       "      <td>-4.442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRSQ</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.266</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.053</td>\n",
       "      <td>0.091</td>\n",
       "      <td>-0.291</td>\n",
       "      <td>0.432</td>\n",
       "      <td>1.053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.742</td>\n",
       "      <td>0.039</td>\n",
       "      <td>-0.223</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_extraversion</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.183</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_agreeableness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.865</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_household_dysfunction</th>\n",
       "      <td>0.862</td>\n",
       "      <td>-1.092</td>\n",
       "      <td>-0.412</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.112</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ni</th>\n",
       "      <td>1.279</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_neglectful_parenting</th>\n",
       "      <td>-0.689</td>\n",
       "      <td>0.965</td>\n",
       "      <td>-0.426</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.017</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>-0.355</td>\n",
       "      <td>0.160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BFI_conscientiousness</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_sum</th>\n",
       "      <td>0.172</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>-0.468</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_divorced_separated</th>\n",
       "      <td>-0.003</td>\n",
       "      <td>0.001</td>\n",
       "      <td>-0.407</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACES_abuse</th>\n",
       "      <td>0.316</td>\n",
       "      <td>-0.213</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cj/4mb6t1f906j397tj71pxfxz00000gn/T/ipykernel_88936/988887848.py:31: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  overall_scores = overall_scores.append(\n"
     ]
    }
   ],
   "source": [
    "overall_scores = pd.DataFrame(columns=['n_features','effect_size', 'overall_score'])\n",
    "        \n",
    "        \n",
    "# hypers = {\n",
    "#     'r2':do_hyperparameter_selection_loop_r2,\n",
    "#     'mae':do_hyperparameter_selection_loop\n",
    "# }\n",
    "\n",
    "\n",
    "for pcount in [10,15]:\n",
    "    for effect_size in [0.08,0.10,0.15]:\n",
    "        custom_interaction_effects_g1    =  [0]*pcount\n",
    "        custom_interaction_effects_g1[0] =  effect_size\n",
    "        custom_interaction_effects_g1[1] =  effect_size\n",
    "        custom_interaction_effects_g1[2] = -effect_size\n",
    "\n",
    "        custom_interaction_effects_g2 = custom_interaction_effects_g1\n",
    "\n",
    "        custom_interaction_effects = {'nisan':custom_interaction_effects_g1}\n",
    "\n",
    "\n",
    "        overall_score = run_full_limited_predictor_analysis(\n",
    "            pcount,\n",
    "            outcome_measures,\n",
    "            analysis_data_imputed,\n",
    "            effect_size= effect_size,\n",
    "            hyperparameter_optimizer = do_hyperparameter_selection_loop\n",
    "            )\n",
    "\n",
    "        #run the analysis with a limited number of predictors\n",
    "        overall_scores = overall_scores.append(\n",
    "            {'n_features':pcount,\n",
    "            'effect_size':effect_size,\n",
    "            'overall_score':overall_score\n",
    "            #,'hyper_target':'mae'\n",
    "            },\n",
    "            ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_features</th>\n",
       "      <th>effect_size</th>\n",
       "      <th>overall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.083980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.048563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.079415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.078301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>-0.121002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.074678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_features  effect_size  overall_score\n",
       "0        10.0         0.08      -0.083980\n",
       "1        10.0         0.10      -0.048563\n",
       "2        10.0         0.15       0.079415\n",
       "3        15.0         0.08      -0.078301\n",
       "4        15.0         0.10      -0.121002\n",
       "5        15.0         0.15       0.074678"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dataanalysis3_10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "014247d405695287815678bf9349a8dffb2674e9fe9a5bd4bb9820af018d638d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
